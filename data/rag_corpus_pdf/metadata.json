[
  {
    "id": "2506.06962v3",
    "title": "AR-RAG: Autoregressive Retrieval Augmentation for Image Generation",
    "authors": [
      "Jingyuan Qi",
      "Zhiyang Xu",
      "Qifan Wang",
      "Lifu Huang"
    ],
    "summary": "We introduce Autoregressive Retrieval Augmentation (AR-RAG), a novel paradigm that enhances image generation by autoregressively incorporating knearest neighbor retrievals at the patch level. Unlike prior methods that perform a single, static retrieval before generation and condition the entire generation on fixed reference images, AR-RAG performs context-aware retrievals at each generation step, using prior-generated patches as queries to retrieve and incorporate the most relevant patch-level visual references, enabling the model to respond to evolving generation needs while avoiding limitations (e.g., over-copying, stylistic bias, etc.) prevalent in existing methods. To realize AR-RAG, we propose two parallel frameworks: (1) Distribution-Augmentation in Decoding (DAiD), a training-free plug-and-use decoding strategy that directly merges the distribution of model-predicted patches with the distribution of retrieved patches, and (2) Feature-Augmentation in Decoding (FAiD), a parameter-efficient fine-tuning method that progressively smooths the features of retrieved patches via multi-scale convolution operations and leverages them to augment the image generation process. We validate the effectiveness of AR-RAG on widely adopted benchmarks, including Midjourney-30K, GenEval and DPG-Bench, demonstrating significant performance gains over state-of-the-art image generation models.",
    "published": "2025-06-08T01:33:05Z",
    "pdf_url": "https://arxiv.org/pdf/2506.06962v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.13684v1",
    "title": "Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation",
    "authors": [
      "Xiangrong",
      "Zhu",
      "Yuan Xu",
      "Tianjian Liu",
      "Jingwei Sun",
      "Yu Zhang",
      "Xin Tong"
    ],
    "summary": "Human cognition is constrained by processing limitations, leading to cognitive overload and inefficiencies in knowledge synthesis and decision-making. Large Language Models (LLMs) present an opportunity for cognitive augmentation, but their current reactive nature limits their real-world applicability. This position paper explores the potential of context-aware cognitive augmentation, where LLMs dynamically adapt to users' cognitive states and task environments to provide appropriate support. Through a think-aloud study in an exhibition setting, we examine how individuals interact with multi-modal information and identify key cognitive challenges in structuring, retrieving, and applying knowledge. Our findings highlight the need for AI-driven cognitive support systems that integrate real-time contextual awareness, personalized reasoning assistance, and socially adaptive interactions. We propose a framework for AI augmentation that seamlessly transitions between real-time cognitive support and post-experience knowledge organization, contributing to the design of more effective human-centered AI systems.",
    "published": "2025-04-18T13:35:21Z",
    "pdf_url": "https://arxiv.org/pdf/2504.13684v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.17204v1",
    "title": "Factually: Exploring Wearable Fact-Checking for Augmented Truth Discernment",
    "authors": [
      "Chitralekha Gupta",
      "Hanjun Wu",
      "Praveen Sasikumar",
      "Shreyas Sridhar",
      "Priambudi Bagaskara",
      "Suranga Nanayakkara"
    ],
    "summary": "Wearable devices are transforming human capabilities by seamlessly augmenting cognitive functions. In this position paper, we propose a voice-based, interactive learning companion designed to amplify and extend cognitive abilities through informal learning. Our vision is threefold: (1) to enable users to discover new knowledge on-the-go through contextual interactive quizzes, fostering critical thinking and mindfulness, (2) to proactively detect misinformation, empowering users to critically assess information in real time, and (3) to provide spoken language correction and prompting hints for second language learning and effective communication. As an initial step toward this vision, we present Factually - a proactive, wearable fact-checking system integrated into devices like smartwatches or rings. Factually discreetly alerts users to potential falsehoods via vibrotactile feedback, helping them assess information critically. We demonstrate its utility through three illustrative scenarios, highlighting its potential to extend cognitive abilities for real-time misinformation detection. Early qualitative feedback suggests that Factually can enhance users' fact-checking capabilities, offering both practical and experiential benefits.",
    "published": "2025-04-24T02:29:50Z",
    "pdf_url": "https://arxiv.org/pdf/2504.17204v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.14689v1",
    "title": "Designing AI Systems that Augment Human Performed vs. Demonstrated Critical Thinking",
    "authors": [
      "Katelyn Xiaoying Mei",
      "Nic Weber"
    ],
    "summary": "The recent rapid advancement of LLM-based AI systems has accelerated our search and production of information. While the advantages brought by these systems seemingly improve the performance or efficiency of human activities, they do not necessarily enhance human capabilities. Recent research has started to examine the impact of generative AI on individuals' cognitive abilities, especially critical thinking. Based on definitions of critical thinking across psychology and education, this position paper proposes the distinction between demonstrated and performed critical thinking in the era of generative AI and discusses the implication of this distinction in research and development of AI systems that aim to augment human critical thinking.",
    "published": "2025-04-20T17:40:28Z",
    "pdf_url": "https://arxiv.org/pdf/2504.14689v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2411.18583v1",
    "title": "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation",
    "authors": [
      "Nurshat Fateh Ali",
      "Md. Mahdi Mohtasim",
      "Shakil Mosharrof",
      "T. Gopi Krishna"
    ],
    "summary": "This research presents and compares multiple approaches to automate the generation of literature reviews using several Natural Language Processing (NLP) techniques and retrieval-augmented generation (RAG) with a Large Language Model (LLM). The ever-increasing number of research articles provides a huge challenge for manual literature review. It has resulted in an increased demand for automation. Developing a system capable of automatically generating the literature reviews from only the PDF files as input is the primary objective of this research work. The effectiveness of several Natural Language Processing (NLP) strategies, such as the frequency-based method (spaCy), the transformer model (Simple T5), and retrieval-augmented generation (RAG) with Large Language Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR dataset is chosen for this research experiment and three distinct techniques are utilized to implement three different systems for auto-generating the literature reviews. The ROUGE scores are used for the evaluation of all three systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo achieved the highest ROUGE-1 score, 0.364. The transformer model comes in second place and spaCy is at the last position. Finally, a graphical user interface is created for the best system based on the large language model.",
    "published": "2024-11-27T18:27:07Z",
    "pdf_url": "https://arxiv.org/pdf/2411.18583v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2402.12317v2",
    "title": "EVOR: Evolving Retrieval for Code Generation",
    "authors": [
      "Hongjin Su",
      "Shuyang Jiang",
      "Yuhang Lai",
      "Haoyuan Wu",
      "Boao Shi",
      "Che Liu",
      "Qian Liu",
      "Tao Yu"
    ],
    "summary": "Recently the retrieval-augmented generation (RAG) has been successfully applied in code generation. However, existing pipelines for retrieval-augmented code generation (RACG) employ static knowledge bases with a single source, limiting the adaptation capabilities of Large Language Models (LLMs) to domains they have insufficient knowledge of. In this work, we develop a novel pipeline, EVOR, that employs the synchronous evolution of both queries and diverse knowledge bases. On two realistic settings where the external knowledge is required to solve code generation tasks, we compile four new datasets associated with frequently updated libraries and long-tail programming languages, named EVOR-BENCH. Extensive experiments demonstrate that EVOR achieves two to four times of execution accuracy compared to other methods such as Reflexion (Shinn et al., 2024), DocPrompting (Zhou et al., 2023), etc. We demonstrate that EVOR is flexible and can be easily combined with them to achieve further improvement. Further analysis reveals that EVOR benefits from the synchronous evolution of queries and documents and the diverse information sources in the knowledge base. We hope that our studies will inspire more insights into the design of advanced RACG pipelines in future research. Our model, code, and data are available at https://arks-codegen.github.io.",
    "published": "2024-02-19T17:37:28Z",
    "pdf_url": "https://arxiv.org/pdf/2402.12317v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2502.00306v2",
    "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
    "authors": [
      "Ali Naseh",
      "Yuefeng Peng",
      "Anshuman Suri",
      "Harsh Chaudhari",
      "Alina Oprea",
      "Amir Houmansadr"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.",
    "published": "2025-02-01T04:01:18Z",
    "pdf_url": "https://arxiv.org/pdf/2502.00306v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2309.15217v2",
    "title": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
    "authors": [
      "Shahul Es",
      "Jithin James",
      "Luis Espinosa-Anke",
      "Steven Schockaert"
    ],
    "summary": "We introduce Ragas (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself. With Ragas, we put forward a suite of metrics which can be used to evaluate these different dimensions \\textit{without having to rely on ground truth human annotations}. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.",
    "published": "2023-09-26T19:23:54Z",
    "pdf_url": "https://arxiv.org/pdf/2309.15217v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.23334v2",
    "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation",
    "authors": [
      "Daeyong Kwon",
      "SeungHeon Doh",
      "Juhan Nam"
    ],
    "summary": "Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs' effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context information when generating answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency.",
    "published": "2025-07-31T08:31:05Z",
    "pdf_url": "https://arxiv.org/pdf/2507.23334v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.05264v1",
    "title": "Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems",
    "authors": [
      "Dean Wampler",
      "Dave Nielson",
      "Alireza Seddighi"
    ],
    "summary": "This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference.",
    "published": "2025-11-07T16:26:29Z",
    "pdf_url": "https://arxiv.org/pdf/2601.05264v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2510.22344v1",
    "title": "FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation",
    "authors": [
      "Mohammad Aghajani Asl",
      "Majid Asgari-Bidhendi",
      "Behrooz Minaei-Bidgoli"
    ],
    "summary": "While Retrieval-Augmented Generation (RAG) mitigates hallucination and knowledge staleness in Large Language Models (LLMs), existing frameworks often falter on complex, multi-hop queries that require synthesizing information from disparate sources. Current advanced RAG methods, employing iterative or adaptive strategies, lack a robust mechanism to systematically identify and fill evidence gaps, often propagating noise or failing to gather a comprehensive context. We introduce FAIR-RAG, a novel agentic framework that transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning process. At its core is an Iterative Refinement Cycle governed by a module we term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating mechanism: it deconstructs the initial query into a checklist of required findings and audits the aggregated evidence to identify confirmed facts and, critically, explicit informational gaps. These gaps provide a precise signal to an Adaptive Query Refinement agent, which generates new, targeted sub-queries to retrieve missing information. This cycle repeats until the evidence is verified as sufficient, ensuring a comprehensive context for a final, strictly faithful generation. We conducted experiments on challenging multi-hop QA benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified experimental setup, FAIR-RAG significantly outperforms strong baselines. On HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3 points over the strongest iterative baseline -- establishing a new state-of-the-art for this class of methods on these benchmarks. Our work demonstrates that a structured, evidence-driven refinement process with explicit gap analysis is crucial for unlocking reliable and accurate reasoning in advanced RAG systems for complex, knowledge-intensive tasks.",
    "published": "2025-10-25T15:59:33Z",
    "pdf_url": "https://arxiv.org/pdf/2510.22344v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.11863v1",
    "title": "Utilizing Metadata for Better Retrieval-Augmented Generation",
    "authors": [
      "Raquib Bin Yousuf",
      "Shengzhe Xu",
      "Mandar Sharma",
      "Andrew Neeser",
      "Chris Latimer",
      "Naren Ramakrishnan"
    ],
    "summary": "Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.",
    "published": "2026-01-17T01:11:03Z",
    "pdf_url": "https://arxiv.org/pdf/2601.11863v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2512.24268v1",
    "title": "RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation",
    "authors": [
      "Pankayaraj Pathmanathan",
      "Michael-Andrei Panaitescu-Liess",
      "Cho-Yu Jason Chiang",
      "Furong Huang"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.",
    "published": "2025-12-30T14:43:57Z",
    "pdf_url": "https://arxiv.org/pdf/2512.24268v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2602.07525v1",
    "title": "IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory",
    "authors": [
      "Xingliang Hou",
      "Yuyan Liu",
      "Qi Sun",
      "haoxiu wang",
      "Hao Hu",
      "Shaoyi Du",
      "Zhiqiang Tian"
    ],
    "summary": "Retrieval-augmented generation (RAG) equips large language models (LLMs) with reliable knowledge memory. To strengthen cross-text associations, recent research integrates graphs and hypergraphs into RAG to capture pairwise and multi-entity relations as structured links. However, their misaligned memory organization necessitates costly, disjointed retrieval. To address these limitations, we propose IGMiRAG, a framework inspired by human intuition-guided reasoning. It constructs a hierarchical heterogeneous hypergraph to align multi-granular knowledge, incorporating deductive pathways to simulate realistic memory structures. During querying, IGMiRAG distills intuitive strategies via a question parser to control mining depth and memory window, and activates instantaneous memories as anchors using dual-focus retrieval. Mirroring human intuition, the framework guides retrieval resource allocation dynamically. Furthermore, we design a bidirectional diffusion algorithm that navigates deductive paths to mine in-depth memories, emulating human reasoning processes. Extensive evaluations indicate IGMiRAG outperforms the state-of-the-art baseline by 4.8% EM and 5.0% F1 overall, with token costs adapting to task complexity (average 6.3k+, minimum 3.0k+). This work presents a cost-effective RAG paradigm that improves both efficiency and effectiveness.",
    "published": "2026-02-07T12:42:31Z",
    "pdf_url": "https://arxiv.org/pdf/2602.07525v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.19754v1",
    "title": "Reconstructing Context: Evaluating Advanced Chunking Strategies for Retrieval-Augmented Generation",
    "authors": [
      "Carlo Merola",
      "Jaspinder Singh"
    ],
    "summary": "Retrieval-augmented generation (RAG) has become a transformative approach for enhancing large language models (LLMs) by grounding their outputs in external knowledge sources. Yet, a critical question persists: how can vast volumes of external knowledge be managed effectively within the input constraints of LLMs? Traditional methods address this by chunking external documents into smaller, fixed-size segments. While this approach alleviates input limitations, it often fragments context, resulting in incomplete retrieval and diminished coherence in generation. To overcome these shortcomings, two advanced techniques, late chunking and contextual retrieval, have been introduced, both aiming to preserve global context. Despite their potential, their comparative strengths and limitations remain unclear. This study presents a rigorous analysis of late chunking and contextual retrieval, evaluating their effectiveness and efficiency in optimizing RAG systems. Our results indicate that contextual retrieval preserves semantic coherence more effectively but requires greater computational resources. In contrast, late chunking offers higher efficiency but tends to sacrifice relevance and completeness.",
    "published": "2025-04-28T12:52:05Z",
    "pdf_url": "https://arxiv.org/pdf/2504.19754v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2404.07220v2",
    "title": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
    "authors": [
      "Kunal Sawarkar",
      "Abhilasha Mangal",
      "Shivam Raj Solanki"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) is a prevalent approach to infuse a private knowledge base of documents with Large Language Models (LLM) to build Generative Q\\&A (Question-Answering) systems. However, RAG accuracy becomes increasingly challenging as the corpus of documents scales up, with Retrievers playing an outsized role in the overall RAG accuracy by extracting the most relevant document from the corpus to provide context to the LLM. In this paper, we propose the 'Blended RAG' method of leveraging semantic search techniques, such as Dense Vector indexes and Sparse Encoder indexes, blended with hybrid query strategies. Our study achieves better retrieval results and sets new benchmarks for IR (Information Retrieval) datasets like NQ and TREC-COVID datasets. We further extend such a 'Blended Retriever' to the RAG system to demonstrate far superior results on Generative Q\\&A datasets like SQUAD, even surpassing fine-tuning performance.",
    "published": "2024-03-22T17:13:46Z",
    "pdf_url": "https://arxiv.org/pdf/2404.07220v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2405.17706v1",
    "title": "Video Enriched Retrieval Augmented Generation Using Aligned Video Captions",
    "authors": [
      "Kevin Dela Rosa"
    ],
    "summary": "In this work, we propose the use of \"aligned visual captions\" as a mechanism for integrating information contained within videos into retrieval augmented generation (RAG) based chat assistant systems. These captions are able to describe the visual and audio content of videos in a large corpus while having the advantage of being in a textual format that is both easy to reason about & incorporate into large language model (LLM) prompts, but also typically require less multimedia content to be inserted into the multimodal LLM context window, where typical configurations can aggressively fill up the context window by sampling video frames from the source video. Furthermore, visual captions can be adapted to specific use cases by prompting the original foundational model / captioner for particular visual details or fine tuning. In hopes of helping advancing progress in this area, we curate a dataset and describe automatic evaluation procedures on common RAG tasks.",
    "published": "2024-05-27T23:39:17Z",
    "pdf_url": "https://arxiv.org/pdf/2405.17706v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2404.14464v1",
    "title": "Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering",
    "authors": [
      "Li Jiapeng",
      "Liu Runze",
      "Li Yabo",
      "Zhou Tong",
      "Li Mingling",
      "Chen Xiang"
    ],
    "summary": "Multi-hop question answering is a knowledge-intensive complex problem. Large Language Models (LLMs) use their Chain of Thoughts (CoT) capability to reason complex problems step by step, and retrieval-augmentation can effectively alleviate factual errors caused by outdated and unknown knowledge in LLMs. Recent works have introduced retrieval-augmentation in the CoT reasoning to solve multi-hop question answering. However, these chain methods have the following problems: 1) Retrieved irrelevant paragraphs may mislead the reasoning; 2) An error in the chain structure may lead to a cascade of errors.\n  In this paper, we propose a dynamic retrieval framework called Tree of Reviews (ToR), where the root node is the question, and the other nodes are paragraphs from retrieval, extending different reasoning paths from the root node to other nodes. Our framework dynamically decides to initiate a new search, reject, or accept based on the paragraphs on the reasoning paths. Compared to related work, we introduce a tree structure to handle each retrieved paragraph separately, alleviating the misleading effect of irrelevant paragraphs on the reasoning path; the diversity of reasoning path extension reduces the impact of a single reasoning error on the whole. We conducted experiments on three different multi-hop question answering datasets. The results show that compared to the baseline methods, ToR achieves state-of-the-art performance in both retrieval and response generation. In addition, we propose two tree-based search optimization strategies, pruning and effective expansion, to reduce time overhead and increase the diversity of path extension. We will release our code.",
    "published": "2024-04-22T09:25:05Z",
    "pdf_url": "https://arxiv.org/pdf/2404.14464v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2503.16581v1",
    "title": "Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models",
    "authors": [
      "Zahra Khalila",
      "Arbi Haza Nasution",
      "Winda Monika",
      "Aytug Onan",
      "Yohei Murakami",
      "Yasir Bin Ismail Radi",
      "Noor Mohammad Osmani"
    ],
    "summary": "Accurate and contextually faithful responses are critical when applying large language models (LLMs) to sensitive and domain-specific tasks, such as answering queries related to quranic studies. General-purpose LLMs often struggle with hallucinations, where generated responses deviate from authoritative sources, raising concerns about their reliability in religious contexts. This challenge highlights the need for systems that can integrate domain-specific knowledge while maintaining response accuracy, relevance, and faithfulness. In this study, we investigate 13 open-source LLMs categorized into large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b, Llama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented Generation (RAG) is used to make up for the problems that come with using separate models. This research utilizes a descriptive dataset of Quranic surahs including the meanings, historical context, and qualities of the 114 surahs, allowing the model to gather relevant knowledge before responding. The models are evaluated using three key metrics set by human evaluators: context relevance, answer faithfulness, and answer relevance. The findings reveal that large models consistently outperform smaller models in capturing query semantics and producing accurate, contextually grounded responses. The Llama3.2:3b model, even though it is considered small, does very well on faithfulness (4.619) and relevance (4.857), showing the promise of smaller architectures that have been well optimized. This article examines the trade-offs between model size, computational efficiency, and response quality while using LLMs in domain-specific applications.",
    "published": "2025-03-20T13:26:30Z",
    "pdf_url": "https://arxiv.org/pdf/2503.16581v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2207.03030v1",
    "title": "Multi-Task Retrieval-Augmented Text Generation with Relevance Sampling",
    "authors": [
      "Sebastian Hofst\u00e4tter",
      "Jiecao Chen",
      "Karthik Raman",
      "Hamed Zamani"
    ],
    "summary": "This paper studies multi-task training of retrieval-augmented generation models for knowledge-intensive tasks. We propose to clean the training set by utilizing a distinct property of knowledge-intensive generation: The connection of query-answer pairs to items in the knowledge base. We filter training examples via a threshold of confidence on the relevance labels, whether a pair is answerable by the knowledge base or not. We train a single Fusion-in-Decoder (FiD) generator on seven combined tasks of the KILT benchmark. The experimental results suggest that our simple yet effective approach substantially improves competitive baselines on two strongly imbalanced tasks; and shows either smaller improvements or no significant regression on the remaining tasks. Furthermore, we demonstrate our multi-task training with relevance label sampling scales well with increased model capacity and achieves state-of-the-art results in five out of seven KILT tasks.",
    "published": "2022-07-07T00:57:02Z",
    "pdf_url": "https://arxiv.org/pdf/2207.03030v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2509.25716v1",
    "title": "DeepCodeSeek: Real-Time API Retrieval for Context-Aware Code Generation",
    "authors": [
      "Esakkivel Esakkiraja",
      "Denis Akhiyarov",
      "Aditya Shanmugham",
      "Chitra Ganapathy"
    ],
    "summary": "Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models.",
    "published": "2025-09-30T03:23:27Z",
    "pdf_url": "https://arxiv.org/pdf/2509.25716v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2412.05838v1",
    "title": "A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data",
    "authors": [
      "Aniruddha Salve",
      "Saba Attar",
      "Mahesh Deshmukh",
      "Sayali Shivpuje",
      "Arnab Mitra Utsab"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by incorporating external, domain-specific data into the generative process. While LLMs are highly capable, they often rely on static, pre-trained datasets, limiting their ability to integrate dynamic or private data. Traditional RAG systems typically use a single-agent architecture to handle query generation, data retrieval, and response synthesis. However, this approach becomes inefficient when dealing with diverse data sources, such as relational databases, document stores, and graph databases, often leading to performance bottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system to address these limitations. Specialized agents, each optimized for a specific data source, handle query generation for relational, NoSQL, and document-based systems. These agents collaborate within a modular framework, with query execution delegated to an environment designed for compatibility across various database types. This distributed approach enhances query efficiency, reduces token overhead, and improves response accuracy by ensuring that each agent focuses on its specialized task. The proposed system is scalable and adaptable, making it ideal for generative AI workflows that require integration with diverse, dynamic, or private data sources. By leveraging specialized agents and a modular execution environment, the system provides an efficient and robust solution for handling complex, heterogeneous data environments in generative AI applications.",
    "published": "2024-12-08T07:18:19Z",
    "pdf_url": "https://arxiv.org/pdf/2412.05838v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2405.20245v1",
    "title": "Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use",
    "authors": [
      "Franz Louis Cesista",
      "Rui Aguiar",
      "Jason Kim",
      "Paolo Acilo"
    ],
    "summary": "Business Document Information Extraction (BDIE) is the problem of transforming a blob of unstructured information (raw text, scanned documents, etc.) into a structured format that downstream systems can parse and use. It has two main tasks: Key-Information Extraction (KIE) and Line Items Recognition (LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem, where the tools are these downstream systems. We then present Retrieval Augmented Structured Generation (RASG), a novel general framework for BDIE that achieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE benchmarks.\n  The contributions of this paper are threefold: (1) We show, with ablation benchmarks, that Large Language Models (LLMs) with RASG are already competitive with or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on BDIE benchmarks. (2) We propose a new metric class for Line Items Recognition, General Line Items Recognition Metric (GLIRM), that is more aligned with practical BDIE use cases compared to existing metrics, such as ANLS*, DocILE, and GriTS. (3) We provide a heuristic algorithm for backcalculating bounding boxes of predicted line items and tables without the need for vision encoders. Finally, we claim that, while LMMs might sometimes offer marginal performance benefits, LLMs + RASG is oftentimes superior given real-world applications and constraints of BDIE.",
    "published": "2024-05-30T16:54:42Z",
    "pdf_url": "https://arxiv.org/pdf/2405.20245v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2508.14066v1",
    "title": "Retrieval-Augmented Generation in Industry: An Interview Study on Use Cases, Requirements, Challenges, and Evaluation",
    "authors": [
      "Lorenz Brehme",
      "Benedikt Dornauer",
      "Thomas Str\u00f6hle",
      "Maximilian Ehrhart",
      "Ruth Breu"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) is a well-established and rapidly evolving field within AI that enhances the outputs of large language models by integrating relevant information retrieved from external knowledge sources. While industry adoption of RAG is now beginning, there is a significant lack of research on its practical application in industrial contexts. To address this gap, we conducted a semistructured interview study with 13 industry practitioners to explore the current state of RAG adoption in real-world settings. Our study investigates how companies apply RAG in practice, providing (1) an overview of industry use cases, (2) a consolidated list of system requirements, (3) key challenges and lessons learned from practical experiences, and (4) an analysis of current industry evaluation methods. Our main findings show that current RAG applications are mostly limited to domain-specific QA tasks, with systems still in prototype stages; industry requirements focus primarily on data protection, security, and quality, while issues such as ethics, bias, and scalability receive less attention; data preprocessing remains a key challenge, and system evaluation is predominantly conducted by humans rather than automated methods.",
    "published": "2025-08-11T09:40:54Z",
    "pdf_url": "https://arxiv.org/pdf/2508.14066v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.16021v1",
    "title": "Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support",
    "authors": [
      "Dinithi Dissanayake",
      "Suranga Nanayakkara"
    ],
    "summary": "Flow theory describes an optimal cognitive state where individuals experience deep focus and intrinsic motivation when a task's difficulty aligns with their skill level. In AI-augmented reasoning, interventions that disrupt the state of cognitive flow can hinder rather than enhance decision-making. This paper proposes a context-aware cognitive augmentation framework that adapts interventions based on three key contextual factors: type, timing, and scale. By leveraging multimodal behavioral cues (e.g., gaze behavior, typing hesitation, interaction speed), AI can dynamically adjust cognitive support to maintain or restore flow. We introduce the concept of cognitive flow, an extension of flow theory in AI-augmented reasoning, where interventions are personalized, adaptive, and minimally intrusive. By shifting from static interventions to context-aware augmentation, our approach ensures that AI systems support deep engagement in complex decision-making and reasoning without disrupting cognitive immersion.",
    "published": "2025-04-22T16:35:39Z",
    "pdf_url": "https://arxiv.org/pdf/2504.16021v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.16883v1",
    "title": "Enhancing Critical Thinking with AI: A Tailored Warning System for RAG Models",
    "authors": [
      "Xuyang Zhu",
      "Sejoon Chang",
      "Andrew Kuik"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) systems offer a powerful approach to enhancing large language model (LLM) outputs by incorporating fact-checked, contextually relevant information. However, fairness and reliability concerns persist, as hallucinations can emerge at both the retrieval and generation stages, affecting users' reasoning and decision-making. Our research explores how tailored warning messages -- whose content depends on the specific context of hallucination -- shape user reasoning and actions in an educational quiz setting. Preliminary findings suggest that while warnings improve accuracy and awareness of high-level hallucinations, they may also introduce cognitive friction, leading to confusion and diminished trust in the system. By examining these interactions, this work contributes to the broader goal of AI-augmented reasoning: developing systems that actively support human reflection, critical thinking, and informed decision-making rather than passive information consumption.",
    "published": "2025-04-23T17:00:25Z",
    "pdf_url": "https://arxiv.org/pdf/2504.16883v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2301.05508v1",
    "title": "Do the Findings of Document and Passage Retrieval Generalize to the Retrieval of Responses for Dialogues?",
    "authors": [
      "Gustavo Penha",
      "Claudia Hauff"
    ],
    "summary": "A number of learned sparse and dense retrieval approaches have recently been proposed and proven effective in tasks such as passage retrieval and document retrieval. In this paper we analyze with a replicability study if the lessons learned generalize to the retrieval of responses for dialogues, an important task for the increasingly popular field of conversational search. Unlike passage and document retrieval where documents are usually longer than queries, in response ranking for dialogues the queries (dialogue contexts) are often longer than the documents (responses). Additionally, dialogues have a particular structure, i.e. multiple utterances by different users. With these differences in mind, we here evaluate how generalizable the following major findings from previous works are: (F1) query expansion outperforms a no-expansion baseline; (F2) document expansion outperforms a no-expansion baseline; (F3) zero-shot dense retrieval underperforms sparse baselines; (F4) dense retrieval outperforms sparse baselines; (F5) hard negative sampling is better than random sampling for training dense models. Our experiments -- based on three different information-seeking dialogue datasets -- reveal that four out of five findings (F2-F5) generalize to our domain",
    "published": "2023-01-13T12:18:43Z",
    "pdf_url": "https://arxiv.org/pdf/2301.05508v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2406.13249v2",
    "title": "R^2AG: Incorporating Retrieval Information into Retrieval Augmented Generation",
    "authors": [
      "Fuda Ye",
      "Shuangyin Li",
      "Yongqi Zhang",
      "Lei Chen"
    ],
    "summary": "Retrieval augmented generation (RAG) has been applied in many scenarios to augment large language models (LLMs) with external documents provided by retrievers. However, a semantic gap exists between LLMs and retrievers due to differences in their training objectives and architectures. This misalignment forces LLMs to passively accept the documents provided by the retrievers, leading to incomprehension in the generation process, where the LLMs are burdened with the task of distinguishing these documents using their inherent knowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill this gap by incorporating Retrieval information into Retrieval Augmented Generation. Specifically, R$^2$AG utilizes the nuanced features from the retrievers and employs a R$^2$-Former to capture retrieval information. Then, a retrieval-aware prompting strategy is designed to integrate retrieval information into LLMs' generation. Notably, R$^2$AG suits low-source scenarios where LLMs and retrievers are frozen. Extensive experiments across five datasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our analysis reveals that retrieval information serves as an anchor to aid LLMs in the generation process, thereby filling the semantic gap.",
    "published": "2024-06-19T06:19:48Z",
    "pdf_url": "https://arxiv.org/pdf/2406.13249v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2505.21439v1",
    "title": "Towards Better Instruction Following Retrieval Models",
    "authors": [
      "Yuchen Zhuang",
      "Aaron Trinh",
      "Rushi Qiang",
      "Haotian Sun",
      "Chao Zhang",
      "Hanjun Dai",
      "Bo Dai"
    ],
    "summary": "Modern information retrieval (IR) models, trained exclusively on standard <query, passage> pairs, struggle to effectively interpret and follow explicit user instructions. We introduce InF-IR, a large-scale, high-quality training corpus tailored for enhancing retrieval models in Instruction-Following IR. InF-IR expands traditional training pairs into over 38,000 expressive <instruction, query, passage> triplets as positive samples. In particular, for each positive triplet, we generate two additional hard negative examples by poisoning both instructions and queries, then rigorously validated by an advanced reasoning model (o3-mini) to ensure semantic plausibility while maintaining instructional incorrectness. Unlike existing corpora that primarily support computationally intensive reranking tasks for decoder-only language models, the highly contrastive positive-negative triplets in InF-IR further enable efficient representation learning for smaller encoder-only models, facilitating direct embedding-based retrieval. Using this corpus, we train InF-Embed, an instruction-aware Embedding model optimized through contrastive learning and instruction-query attention mechanisms to align retrieval outcomes precisely with user intents. Extensive experiments across five instruction-based retrieval benchmarks demonstrate that InF-Embed significantly surpasses competitive baselines by 8.1% in p-MRR, measuring the instruction-following capabilities.",
    "published": "2025-05-27T17:14:37Z",
    "pdf_url": "https://arxiv.org/pdf/2505.21439v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.09935v1",
    "title": "Constrained Auto-Regressive Decoding Constrains Generative Retrieval",
    "authors": [
      "Shiguang Wu",
      "Zhaochun Ren",
      "Xin Xin",
      "Jiyuan Yang",
      "Mengqi Zhang",
      "Zhumin Chen",
      "Maarten de Rijke",
      "Pengjie Ren"
    ],
    "summary": "Generative retrieval seeks to replace traditional search index data structures with a single large-scale neural network, offering the potential for improved efficiency and seamless integration with generative large language models. As an end-to-end paradigm, generative retrieval adopts a learned differentiable search index to conduct retrieval by directly generating document identifiers through corpus-specific constrained decoding. The generalization capabilities of generative retrieval on out-of-distribution corpora have gathered significant attention.\n  In this paper, we examine the inherent limitations of constrained auto-regressive generation from two essential perspectives: constraints and beam search. We begin with the Bayes-optimal setting where the generative retrieval model exactly captures the underlying relevance distribution of all possible documents. Then we apply the model to specific corpora by simply adding corpus-specific constraints. Our main findings are two-fold: (i) For the effect of constraints, we derive a lower bound of the error, in terms of the KL divergence between the ground-truth and the model-predicted step-wise marginal distributions. (ii) For the beam search algorithm used during generation, we reveal that the usage of marginal distributions may not be an ideal approach. This paper aims to improve our theoretical understanding of the generalization capabilities of the auto-regressive decoding retrieval paradigm, laying a foundation for its limitations and inspiring future advancements toward more robust and generalizable generative retrieval.",
    "published": "2025-04-14T06:54:49Z",
    "pdf_url": "https://arxiv.org/pdf/2504.09935v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.11722v1",
    "title": "RAC: Retrieval-Augmented Clarification for Faithful Conversational Search",
    "authors": [
      "Ahmed Rayane Kebir",
      "Vincent Guigue",
      "Lynda Said Lhadj",
      "Laure Soulier"
    ],
    "summary": "Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.",
    "published": "2026-01-16T19:16:38Z",
    "pdf_url": "https://arxiv.org/pdf/2601.11722v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2510.23840v1",
    "title": "Reality Distortion Room: A Study of User Locomotion Responses to Spatial Augmented Reality Effects",
    "authors": [
      "You-Jin Kim",
      "Andrew D. Wilson",
      "Jennifer Jacobs",
      "Tobias H\u00f6llerer"
    ],
    "summary": "Reality Distortion Room (RDR) is a proof-of-concept augmented reality system using projection mapping and unencumbered interaction with the Microsoft RoomAlive system to study a user's locomotive response to visual effects that seemingly transform the physical room the user is in. This study presents five effects that augment the appearance of a physical room to subtly encourage user motion. Our experiment demonstrates users' reactions to the different distortion and augmentation effects in a standard living room, with the distortion effects projected as wall grids, furniture holograms, and small particles in the air. The augmented living room can give the impression of becoming elongated, wrapped, shifted, elevated, and enlarged. The study results support the implementation of AR experiences in limited physical spaces by providing an initial understanding of how users can be subtly encouraged to move throughout a room.",
    "published": "2025-10-27T20:25:26Z",
    "pdf_url": "https://arxiv.org/pdf/2510.23840v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2503.01763v2",
    "title": "Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models",
    "authors": [
      "Zhengliang Shi",
      "Yuhan Wang",
      "Lingyong Yan",
      "Pengjie Ren",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Zhaochun Ren"
    ],
    "summary": "Tool learning aims to augment large language models (LLMs) with diverse tools, enabling them to act as agents for solving practical tasks. Due to the limited context length of tool-using LLMs, adopting information retrieval (IR) models to select useful tools from large toolsets is a critical initial step. However, the performance of IR models in tool retrieval tasks remains underexplored and unclear. Most tool-use benchmarks simplify this step by manually pre-annotating a small set of relevant tools for each task, which is far from the real-world scenarios. In this paper, we propose ToolRet, a heterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks, and a corpus of 43k tools, collected from existing datasets. We benchmark six types of models on ToolRet. Surprisingly, even the models with strong performance in conventional IR benchmarks, exhibit poor performance on ToolRet. This low retrieval quality degrades the task pass rate of tool-use LLMs. As a further step, we contribute a large-scale training dataset with over 200k instances, which substantially optimizes the tool retrieval ability of IR models.",
    "published": "2025-03-03T17:37:16Z",
    "pdf_url": "https://arxiv.org/pdf/2503.01763v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2102.11903v2",
    "title": "Neural ranking models for document retrieval",
    "authors": [
      "Mohamed Trabelsi",
      "Zhiyu Chen",
      "Brian D. Davison",
      "Jeff Heflin"
    ],
    "summary": "Ranking models are the main components of information retrieval systems. Several approaches to ranking are based on traditional machine learning algorithms using a set of hand-crafted features. Recently, researchers have leveraged deep learning models in information retrieval. These models are trained end-to-end to extract features from the raw data for ranking tasks, so that they overcome the limitations of hand-crafted features. A variety of deep learning models have been proposed, and each model presents a set of neural network components to extract features that are used for ranking. In this paper, we compare the proposed models in the literature along different dimensions in order to understand the major contributions and limitations of each model. In our discussion of the literature, we analyze the promising neural components, and propose future research directions. We also show the analogy between document retrieval and other retrieval tasks where the items to be ranked are structured documents, answers, images and videos.",
    "published": "2021-02-23T19:30:37Z",
    "pdf_url": "https://arxiv.org/pdf/2102.11903v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.17397v1",
    "title": "Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains",
    "authors": [
      "Subhankar Maity",
      "Aniket Deroy",
      "Sudeshna Sarkar"
    ],
    "summary": "Question generation in education is a time-consuming and cognitively demanding task, as it requires creating questions that are both contextually relevant and pedagogically sound. Current automated question generation methods often generate questions that are out of context. In this work, we explore advanced techniques for automated question generation in educational contexts, focusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG), and a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL using few-shot examples and BART with a retrieval module for RAG. The Hybrid Model combines RAG and ICL to address these issues and improve question quality. Evaluation is conducted using automated metrics, followed by human evaluation metrics. Our results show that both the ICL approach and the Hybrid Model consistently outperform other methods, including baseline models, by generating more contextually accurate and relevant questions.",
    "published": "2025-01-29T03:25:19Z",
    "pdf_url": "https://arxiv.org/pdf/2501.17397v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "1907.06796v1",
    "title": "Instant Motion Tracking and Its Applications to Augmented Reality",
    "authors": [
      "Jianing Wei",
      "Genzhi Ye",
      "Tyler Mullen",
      "Matthias Grundmann",
      "Adel Ahmadyan",
      "Tingbo Hou"
    ],
    "summary": "Augmented Reality (AR) brings immersive experiences to users. With recent advances in computer vision and mobile computing, AR has scaled across platforms, and has increased adoption in major products. One of the key challenges in enabling AR features is proper anchoring of the virtual content to the real world, a process referred to as tracking. In this paper, we present a system for motion tracking, which is capable of robustly tracking planar targets and performing relative-scale 6DoF tracking without calibration. Our system runs in real-time on mobile phones and has been deployed in multiple major products on hundreds of millions of devices.",
    "published": "2019-07-16T00:13:09Z",
    "pdf_url": "https://arxiv.org/pdf/1907.06796v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2312.05708v1",
    "title": "Context Tuning for Retrieval Augmented Generation",
    "authors": [
      "Raviteja Anantha",
      "Tharun Bethi",
      "Danil Vodianik",
      "Srinivas Chappidi"
    ],
    "summary": "Large language models (LLMs) have the remarkable ability to solve new tasks with just a few examples, but they need access to the right tools. Retrieval Augmented Generation (RAG) addresses this problem by retrieving a list of relevant tools for a given task. However, RAG's tool retrieval step requires all the required information to be explicitly present in the query. This is a limitation, as semantic search, the widely adopted tool retrieval method, can fail when the query is incomplete or lacks context. To address this limitation, we propose Context Tuning for RAG, which employs a smart context retrieval system to fetch relevant information that improves both tool retrieval and plan generation. Our lightweight context retrieval model uses numerical, categorical, and habitual usage signals to retrieve and rank context items. Our empirical results demonstrate that context tuning significantly enhances semantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for context retrieval and tool retrieval tasks respectively, and resulting in an 11.6% increase in LLM-based planner accuracy. Additionally, we show that our proposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART outperforms GPT-4 based retrieval. Moreover, we observe context augmentation at plan generation, even after tool retrieval, reduces hallucination.",
    "published": "2023-12-09T23:33:16Z",
    "pdf_url": "https://arxiv.org/pdf/2312.05708v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2404.13892v2",
    "title": "Retrieval-Augmented Audio Deepfake Detection",
    "authors": [
      "Zuheng Kang",
      "Yayun He",
      "Botao Zhao",
      "Xiaoyang Qu",
      "Junqing Peng",
      "Jing Xiao",
      "Jianzong Wang"
    ],
    "summary": "With recent advances in speech synthesis including text-to-speech (TTS) and voice conversion (VC) systems enabling the generation of ultra-realistic audio deepfakes, there is growing concern about their potential misuse. However, most deepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a single model, resulting in performance bottlenecks and transparency issues. Inspired by retrieval-augmented generation (RAG), we propose a retrieval-augmented detection (RAD) framework that augments test samples with similar retrieved samples for enhanced detection. We also extend the multi-fusion attentive classifier to integrate it with our proposed RAD framework. Extensive experiments show the superior performance of the proposed RAD framework over baseline methods, achieving state-of-the-art results on the ASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets. Further sample analysis indicates that the retriever consistently retrieves samples mostly from the same speaker with acoustic characteristics highly consistent with the query audio, thereby improving detection performance.",
    "published": "2024-04-22T05:46:40Z",
    "pdf_url": "https://arxiv.org/pdf/2404.13892v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2408.02152v3",
    "title": "Generative Retrieval with Few-shot Indexing",
    "authors": [
      "Arian Askari",
      "Chuan Meng",
      "Mohammad Aliannejadi",
      "Zhaochun Ren",
      "Evangelos Kanoulas",
      "Suzan Verberne"
    ],
    "summary": "Existing generative retrieval (GR) methods rely on training-based indexing, which fine-tunes a model to memorise associations between queries and the document identifiers (docids) of relevant documents. Training-based indexing suffers from high training costs, under-utilisation of pre-trained knowledge in large language models (LLMs), and limited adaptability to dynamic document corpora. To address the issues, we propose a few-shot indexing-based GR framework (Few-Shot GR). It has a few-shot indexing process without any training, where we prompt an LLM to generate docids for all documents in a corpus, ultimately creating a docid bank for the entire corpus. During retrieval, we feed a query to the same LLM and constrain it to generate a docid within the docid bank created during indexing, and then map the generated docid back to its corresponding document. Moreover, we devise few-shot indexing with one-to-many mapping to further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves superior performance to state-of-the-art GR methods requiring heavy training.",
    "published": "2024-08-04T22:00:34Z",
    "pdf_url": "https://arxiv.org/pdf/2408.02152v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.08804v1",
    "title": "Cognitive Dissonance Artificial Intelligence (CD-AI): The Mind at War with Itself. Harnessing Discomfort to Sharpen Critical Thinking",
    "authors": [
      "Delia Deliu"
    ],
    "summary": "AI-augmented systems are traditionally designed to streamline human decision-making by minimizing cognitive load, clarifying arguments, and optimizing efficiency. However, in a world where algorithmic certainty risks becoming an Orwellian tool of epistemic control, true intellectual growth demands not passive acceptance but active struggle. Drawing on the dystopian visions of George Orwell and Philip K. Dick - where reality is unstable, perception malleable, and truth contested - this paper introduces Cognitive Dissonance AI (CD-AI): a novel framework that deliberately sustains uncertainty rather than resolving it. CD-AI does not offer closure, but compels users to navigate contradictions, challenge biases, and wrestle with competing truths. By delaying resolution and promoting dialectical engagement, CD-AI enhances reflective reasoning, epistemic humility, critical thinking, and adaptability in complex decision-making. This paper examines the theoretical foundations of the approach, presents an implementation model, explores its application in domains such as ethics, law, politics, and science, and addresses key ethical concerns - including decision paralysis, erosion of user autonomy, cognitive manipulation, and bias in AI reasoning. In reimagining AI as an engine of doubt rather than a deliverer of certainty, CD-AI challenges dominant paradigms of AI-augmented reasoning and offers a new vision - one in which AI sharpens the mind not by resolving conflict, but by sustaining it. Rather than reinforcing Huxleyan complacency or pacifying the user into intellectual conformity, CD-AI echoes Nietzsche's vision of the Uebermensch - urging users to transcend passive cognition through active epistemic struggle.",
    "published": "2025-04-23T03:18:05Z",
    "pdf_url": "https://arxiv.org/pdf/2507.08804v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2403.15450v1",
    "title": "Loops On Retrieval Augmented Generation (LoRAG)",
    "authors": [
      "Ayush Thakur",
      "Rashmi Vashisth"
    ],
    "summary": "This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new framework designed to enhance the quality of retrieval-augmented text generation through the incorporation of an iterative loop mechanism. The architecture integrates a generative model, a retrieval mechanism, and a dynamic loop module, allowing for iterative refinement of the generated text through interactions with relevant information retrieved from the input context. Experimental evaluations on benchmark datasets demonstrate that LoRAG surpasses existing state-of-the-art models in terms of BLEU score, ROUGE score, and perplexity, showcasing its effectiveness in achieving both coherence and relevance in generated text. The qualitative assessment further illustrates LoRAG's capability to produce contextually rich and coherent outputs. This research contributes valuable insights into the potential of iterative loops in mitigating challenges in text generation, positioning LoRAG as a promising advancement in the field.",
    "published": "2024-03-18T15:19:17Z",
    "pdf_url": "https://arxiv.org/pdf/2403.15450v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2406.15241v2",
    "title": "Retrieval Augmented Zero-Shot Text Classification",
    "authors": [
      "Tassallah Abdullahi",
      "Ritambhara Singh",
      "Carsten Eickhoff"
    ],
    "summary": "Zero-shot text learning enables text classifiers to handle unseen classes efficiently, alleviating the need for task-specific training data. A simple approach often relies on comparing embeddings of query (text) to those of potential classes. However, the embeddings of a simple query sometimes lack rich contextual information, which hinders the classification performance. Traditionally, this has been addressed by improving the embedding model with expensive training. We introduce QZero, a novel training-free knowledge augmentation approach that reformulates queries by retrieving supporting categories from Wikipedia to improve zero-shot text classification performance. Our experiments across six diverse datasets demonstrate that QZero enhances performance for state-of-the-art static and contextual embedding models without the need for retraining. Notably, in News and medical topic classification tasks, QZero improves the performance of even the largest OpenAI embedding model by at least 5% and 3%, respectively. Acting as a knowledge amplifier, QZero enables small word embedding models to achieve performance levels comparable to those of larger contextual models, offering the potential for significant computational savings. Additionally, QZero offers meaningful insights that illuminate query context and verify topic relevance, aiding in understanding model predictions. Overall, QZero improves embedding-based zero-shot classifiers while maintaining their simplicity. This makes it particularly valuable for resource-constrained environments and domains with constantly evolving information.",
    "published": "2024-06-21T15:28:50Z",
    "pdf_url": "https://arxiv.org/pdf/2406.15241v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.04925v1",
    "title": "RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations",
    "authors": [
      "Jiarui Rao",
      "Jionghao Lin"
    ],
    "summary": "Massive Open Online Courses (MOOCs) have significantly enhanced educational accessibility by offering a wide variety of courses and breaking down traditional barriers related to geography, finance, and time. However, students often face difficulties navigating the vast selection of courses, especially when exploring new fields of study. Driven by this challenge, researchers have been exploring course recommender systems to offer tailored guidance that aligns with individual learning preferences and career aspirations. These systems face particular challenges in effectively addressing the ``cold start'' problem for new users. Recent advancements in recommender systems suggest integrating large language models (LLMs) into the recommendation process to enhance personalized recommendations and address the ``cold start'' problem. Motivated by these advancements, our study introduces RAMO (Retrieval-Augmented Generation for MOOCs), a system specifically designed to overcome the ``cold start'' challenges of traditional course recommender systems. The RAMO system leverages the capabilities of LLMs, along with Retrieval-Augmented Generation (RAG)-facilitated contextual understanding, to provide course recommendations through a conversational interface, aiming to enhance the e-learning experience.",
    "published": "2024-07-06T02:22:25Z",
    "pdf_url": "https://arxiv.org/pdf/2407.04925v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.16770v1",
    "title": "DeBiasMe: De-biasing Human-AI Interactions with Metacognitive AIED (AI in Education) Interventions",
    "authors": [
      "Chaeyeon Lim"
    ],
    "summary": "While generative artificial intelligence (Gen AI) increasingly transforms academic environments, a critical gap exists in understanding and mitigating human biases in AI interactions, such as anchoring and confirmation bias. This position paper advocates for metacognitive AI literacy interventions to help university students critically engage with AI and address biases across the Human-AI interaction workflows. The paper presents the importance of considering (1) metacognitive support with deliberate friction focusing on human bias; (2) bi-directional Human-AI interaction intervention addressing both input formulation and output interpretation; and (3) adaptive scaffolding that responds to diverse user engagement patterns. These frameworks are illustrated through ongoing work on \"DeBiasMe,\" AIED (AI in Education) interventions designed to enhance awareness of cognitive biases while empowering user agency in AI interactions. The paper invites multiple stakeholders to engage in discussions on design and evaluation methods for scaffolding mechanisms, bias visualization, and analysis frameworks. This position contributes to the emerging field of AI-augmented learning by emphasizing the critical role of metacognition in helping students navigate the complex interaction between human, statistical, and systemic biases in AI use while highlighting how cognitive adaptation to AI systems must be explicitly integrated into comprehensive AI literacy frameworks.",
    "published": "2025-04-23T14:41:31Z",
    "pdf_url": "https://arxiv.org/pdf/2504.16770v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2111.13057v3",
    "title": "Evaluating the Robustness of Retrieval Pipelines with Query Variation Generators",
    "authors": [
      "Gustavo Penha",
      "Arthur C\u00e2mara",
      "Claudia Hauff"
    ],
    "summary": "Heavily pre-trained transformers for language modelling, such as BERT, have shown to be remarkably effective for Information Retrieval (IR) tasks, typically applied to re-rank the results of a first-stage retrieval model. IR benchmarks evaluate the effectiveness of retrieval pipelines based on the premise that a single query is used to instantiate the underlying information need. However, previous research has shown that (I) queries generated by users for a fixed information need are extremely variable and, in particular, (II) neural models are brittle and often make mistakes when tested with modified inputs. Motivated by those observations we aim to answer the following question: how robust are retrieval pipelines with respect to different variations in queries that do not change the queries' semantics? In order to obtain queries that are representative of users' querying variability, we first created a taxonomy based on the manual annotation of transformations occurring in a dataset (UQV100) of user-created query variations. For each syntax-changing category of our taxonomy, we employed different automatic methods that when applied to a query generate a query variation. Our experimental results across two datasets for two IR tasks reveal that retrieval pipelines are not robust to these query variations, with effectiveness drops of $\\approx20\\%$ on average. The code and datasets are available at https://github.com/Guzpenha/query_variation_generators.",
    "published": "2021-11-25T12:39:51Z",
    "pdf_url": "https://arxiv.org/pdf/2111.13057v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.14342v3",
    "title": "Chain-of-Retrieval Augmented Generation",
    "authors": [
      "Liang Wang",
      "Haonan Chen",
      "Nan Yang",
      "Xiaolong Huang",
      "Zhicheng Dou",
      "Furu Wei"
    ],
    "summary": "This paper introduces an approach for training o1-like RAG models that retrieve and reason over relevant information step by step before generating the final answer. Conventional RAG methods usually perform a single retrieval step before the generation process, which limits their effectiveness in addressing complex queries due to imperfect retrieval results. In contrast, our proposed method, CoRAG (Chain-of-Retrieval Augmented Generation), allows the model to dynamically reformulate the query based on the evolving state. To train CoRAG effectively, we utilize rejection sampling to automatically generate intermediate retrieval chains, thereby augmenting existing RAG datasets that only provide the correct final answer. At test time, we propose various decoding strategies to scale the model's test-time compute by controlling the length and number of sampled retrieval chains. Experimental results across multiple benchmarks validate the efficacy of CoRAG, particularly in multi-hop question answering tasks, where we observe more than 10 points improvement in EM score compared to strong baselines. On the KILT benchmark, CoRAG establishes a new state-of-the-art performance across a diverse range of knowledge-intensive tasks. Furthermore, we offer comprehensive analyses to understand the scaling behavior of CoRAG, laying the groundwork for future research aimed at developing factual and grounded foundation models.",
    "published": "2025-01-24T09:12:52Z",
    "pdf_url": "https://arxiv.org/pdf/2501.14342v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2411.16133v2",
    "title": "Context Awareness Gate For Retrieval Augmented Generation",
    "authors": [
      "Mohammad Hassan Heydari",
      "Arshia Hemmat",
      "Erfan Naman",
      "Afsaneh Fatemi"
    ],
    "summary": "Retrieval Augmented Generation (RAG) has emerged as a widely adopted approach to mitigate the limitations of large language models (LLMs) in answering domain-specific questions. Previous research has predominantly focused on improving the accuracy and quality of retrieved data chunks to enhance the overall performance of the generation pipeline. However, despite ongoing advancements, the critical issue of retrieving irrelevant information -- which can impair the ability of the model to utilize its internal knowledge effectively -- has received minimal attention. In this work, we investigate the impact of retrieving irrelevant information in open-domain question answering, highlighting its significant detrimental effect on the quality of LLM outputs. To address this challenge, we propose the Context Awareness Gate (CAG) architecture, a novel mechanism that dynamically adjusts the LLMs' input prompt based on whether the user query necessitates external context retrieval. Additionally, we introduce the Vector Candidates method, a core mathematical component of CAG that is statistical, LLM-independent, and highly scalable. We further examine the distributions of relationships between contexts and questions, presenting a statistical analysis of these distributions. This analysis can be leveraged to enhance the context retrieval process in Retrieval Augmented Generation (RAG) systems.",
    "published": "2024-11-25T06:48:38Z",
    "pdf_url": "https://arxiv.org/pdf/2411.16133v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2505.13129v1",
    "title": "Optimizing Retrieval Augmented Generation for Object Constraint Language",
    "authors": [
      "Kevin Chenhao Li",
      "Vahid Zolfaghari",
      "Nenad Petrovic",
      "Fengjunjie Pan",
      "Alois Knoll"
    ],
    "summary": "The Object Constraint Language (OCL) is essential for defining precise constraints within Model-Based Systems Engineering (MBSE). However, manually writing OCL rules is complex and time-consuming. This study explores the optimization of Retrieval-Augmented Generation (RAG) for automating OCL rule generation, focusing on the impact of different retrieval strategies. We evaluate three retrieval approaches $\\unicode{x2013}$ BM25 (lexical-based), BERT-based (semantic retrieval), and SPLADE (sparse-vector retrieval) $\\unicode{x2013}$ analyzing their effectiveness in providing relevant context for a large language model.\n  To further assess our approach, we compare and benchmark our retrieval-optimized generation results against PathOCL, a state-of-the-art graph-based method. We directly compare BM25, BERT, and SPLADE retrieval methods with PathOCL to understand how different retrieval methods perform for a unified evaluation framework. Our experimental results, focusing on retrieval-augmented generation, indicate that while retrieval can enhance generation accuracy, its effectiveness depends on the retrieval method and the number of retrieved chunks (k). BM25 underperforms the baseline, whereas semantic approaches (BERT and SPLADE) achieve better results, with SPLADE performing best at lower k values. However, excessive retrieval with high k parameter can lead to retrieving irrelevant chunks which degrades model performance. Our findings highlight the importance of optimizing retrieval configurations to balance context relevance and output consistency. This research provides insights into improving OCL rule generation using RAG and underscores the need for tailoring retrieval.",
    "published": "2025-05-19T14:00:10Z",
    "pdf_url": "https://arxiv.org/pdf/2505.13129v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.15518v1",
    "title": "DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking",
    "authors": [
      "Wenxin Zhou",
      "Ritesh Mehta",
      "Anthony Miyaguchi"
    ],
    "summary": "We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.",
    "published": "2026-01-21T23:09:17Z",
    "pdf_url": "https://arxiv.org/pdf/2601.15518v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2502.01113v3",
    "title": "GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation",
    "authors": [
      "Linhao Luo",
      "Zicheng Zhao",
      "Gholamreza Haffari",
      "Dinh Phung",
      "Chen Gong",
      "Shirui Pan"
    ],
    "summary": "Retrieval-augmented generation (RAG) has proven effective in integrating knowledge into large language models (LLMs). However, conventional RAGs struggle to capture complex relationships between pieces of knowledge, limiting their performance in intricate reasoning that requires integrating knowledge from multiple sources. Recently, graph-enhanced retrieval augmented generation (GraphRAG) builds graph structure to explicitly model these relationships, enabling more effective and efficient retrievers. Nevertheless, its performance is still hindered by the noise and incompleteness within the graph structure. To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for retrieval augmented generation. GFM-RAG is powered by an innovative graph neural network that reasons over graph structure to capture complex query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage training process on large-scale datasets, comprising 60 knowledge graphs with over 14M triples and 700k documents. This results in impressive performance and generalizability for GFM-RAG, making it the first graph foundation model applicable to unseen datasets for retrieval without any fine-tuning required. Extensive experiments on three multi-hop QA datasets and seven domain-specific RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance while maintaining efficiency and alignment with neural scaling laws, highlighting its potential for further improvement.",
    "published": "2025-02-03T07:04:29Z",
    "pdf_url": "https://arxiv.org/pdf/2502.01113v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.20114v3",
    "title": "FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis",
    "authors": [
      "Mikel Williams-Lekuona",
      "Georgina Cosma"
    ],
    "summary": "In the field of Image-Text Retrieval (ITR), recent advancements have leveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG) instance-level retrieval, achieving high accuracy at the cost of increased computational complexity. For Coarse-Grained (CG) category-level retrieval, prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency, albeit at the cost of retrieval performance. Due to differences in methodologies, FG and CG models are rarely compared directly within evaluations in the literature, resulting in a lack of empirical data quantifying the retrieval performance-efficiency tradeoffs between the two. This paper addresses this gap by introducing the FiCo-ITR library, which standardises evaluation methodologies for both FG and CG models, facilitating direct comparisons. We conduct empirical evaluations of representative models from both subfields, analysing precision, recall, and computational complexity across varying data scales. Our findings offer new insights into the performance-efficiency trade-offs between recent representative FG and CG models, highlighting their respective strengths and limitations. These findings provide the foundation necessary to make more informed decisions regarding model selection for specific retrieval tasks and highlight avenues for future research into hybrid systems that leverage the strengths of both FG and CG approaches.",
    "published": "2024-07-29T15:44:22Z",
    "pdf_url": "https://arxiv.org/pdf/2407.20114v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.08748v1",
    "title": "A Survey of Multimodal Retrieval-Augmented Generation",
    "authors": [
      "Lang Mei",
      "Siyu Mo",
      "Zhihan Yang",
      "Chong Chen"
    ],
    "summary": "Multimodal Retrieval-Augmented Generation (MRAG) enhances large language models (LLMs) by integrating multimodal data (text, images, videos) into retrieval and generation processes, overcoming the limitations of text-only Retrieval-Augmented Generation (RAG). While RAG improves response accuracy by incorporating external textual knowledge, MRAG extends this framework to include multimodal retrieval and generation, leveraging contextual information from diverse data types. This approach reduces hallucinations and enhances question-answering systems by grounding responses in factual, multimodal knowledge. Recent studies show MRAG outperforms traditional RAG, especially in scenarios requiring both visual and textual understanding. This survey reviews MRAG's essential components, datasets, evaluation methods, and limitations, providing insights into its construction and improvement. It also identifies challenges and future research directions, highlighting MRAG's potential to revolutionize multimodal information retrieval and generation. By offering a comprehensive perspective, this work encourages further exploration into this promising paradigm.",
    "published": "2025-03-26T02:43:09Z",
    "pdf_url": "https://arxiv.org/pdf/2504.08748v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.14996v1",
    "title": "Distributed Cognition for AI-supported Remote Operations: Challenges and Research Directions",
    "authors": [
      "Rune M\u00f8berg Jacobsen",
      "Joel Wester",
      "Helena B\u00f8jer Djern\u00e6s",
      "Niels van Berkel"
    ],
    "summary": "This paper investigates the impact of artificial intelligence integration on remote operations, emphasising its influence on both distributed and team cognition. As remote operations increasingly rely on digital interfaces, sensors, and networked communication, AI-driven systems transform decision-making processes across domains such as air traffic control, industrial automation, and intelligent ports. However, the integration of AI introduces significant challenges, including the reconfiguration of human-AI team cognition, the need for adaptive AI memory that aligns with human distributed cognition, and the design of AI fallback operators to maintain continuity during communication disruptions. Drawing on theories of distributed and team cognition, we analyse how cognitive overload, loss of situational awareness, and impaired team coordination may arise in AI-supported environments. Based on real-world intelligent port scenarios, we propose research directions that aim to safeguard human reasoning and enhance collaborative decision-making in AI-augmented remote operations.",
    "published": "2025-04-21T09:53:49Z",
    "pdf_url": "https://arxiv.org/pdf/2504.14996v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.04568v1",
    "title": "Neurosymbolic Retrievers for Retrieval-augmented Generation",
    "authors": [
      "Yash Saxena",
      "Manas Gaur"
    ],
    "summary": "Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance",
    "published": "2026-01-08T03:53:05Z",
    "pdf_url": "https://arxiv.org/pdf/2601.04568v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2505.04680v1",
    "title": "Retrieval Augmented Generation Evaluation for Health Documents",
    "authors": [
      "Mario Ceresa",
      "Lorenzo Bertolini",
      "Valentin Comte",
      "Nicholas Spadaro",
      "Barbara Raffael",
      "Brigitte Toussaint",
      "Sergio Consoli",
      "Amalia Mu\u00f1oz Pi\u00f1eiro",
      "Alex Patak",
      "Maddalena Querci",
      "Tobias Wiesenthal"
    ],
    "summary": "Safe and trustworthy use of Large Language Models (LLM) in the processing of healthcare documents and scientific papers could substantially help clinicians, scientists and policymakers in overcoming information overload and focusing on the most relevant information at a given moment. Retrieval Augmented Generation (RAG) is a promising method to leverage the potential of LLMs while enhancing the accuracy of their outcomes. This report assesses the potentials and shortcomings of such approaches in the automatic knowledge synthesis of different types of documents in the health domain. To this end, it describes: (1) an internally developed proof of concept pipeline that employs state-of-the-art practices to deliver safe and trustable analysis for healthcare documents and scientific papers called RAGEv (Retrieval Augmented Generation Evaluation); (2) a set of evaluation tools for LLM-based document retrieval and generation; (3) a benchmark dataset to verify the accuracy and veracity of the results called RAGEv-Bench. It concludes that careful implementations of RAG techniques could minimize most of the common problems in the use of LLMs for document processing in the health domain, obtaining very high scores both on short yes/no answers and long answers. There is a high potential for incorporating it into the day-to-day work of policy support tasks, but additional efforts are required to obtain a consistent and trustworthy tool.",
    "published": "2025-05-07T16:12:53Z",
    "pdf_url": "https://arxiv.org/pdf/2505.04680v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2412.14457v1",
    "title": "VISA: Retrieval Augmented Generation with Visual Source Attribution",
    "authors": [
      "Xueguang Ma",
      "Shengyao Zhuang",
      "Bevan Koopman",
      "Guido Zuccon",
      "Wenhu Chen",
      "Jimmy Lin"
    ],
    "summary": "Generation with source attribution is important for enhancing the verifiability of retrieval-augmented generation (RAG) systems. However, existing approaches in RAG primarily link generated content to document-level references, making it challenging for users to locate evidence among multiple content-rich retrieved documents. To address this challenge, we propose Retrieval-Augmented Generation with Visual Source Attribution (VISA), a novel approach that combines answer generation with visual source attribution. Leveraging large vision-language models (VLMs), VISA identifies the evidence and highlights the exact regions that support the generated answers with bounding boxes in the retrieved document screenshots. To evaluate its effectiveness, we curated two datasets: Wiki-VISA, based on crawled Wikipedia webpage screenshots, and Paper-VISA, derived from PubLayNet and tailored to the medical domain. Experimental results demonstrate the effectiveness of VISA for visual source attribution on documents' original look, as well as highlighting the challenges for improvement. Code, data, and model checkpoints will be released.",
    "published": "2024-12-19T02:17:35Z",
    "pdf_url": "https://arxiv.org/pdf/2412.14457v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2409.13707v1",
    "title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Support",
    "authors": [
      "Paulina Toro Isaza",
      "Michael Nidd",
      "Noah Zheutlin",
      "Jae-wook Ahn",
      "Chidansh Amitkumar Bhatt",
      "Yu Deng",
      "Ruchi Mahindru",
      "Martin Franz",
      "Hans Florian",
      "Salim Roukos"
    ],
    "summary": "Clients wishing to implement generative AI in the domain of IT Support and AIOps face two critical issues: domain coverage and model size constraints due to model choice limitations. Clients might choose to not use larger proprietary models such as GPT-4 due to cost and privacy concerns and so are limited to smaller models with potentially less domain coverage that do not generalize to the client's domain. Retrieval augmented generation is a common solution that addresses both of these issues: a retrieval system first retrieves the necessary domain knowledge which a smaller generative model leverages as context for generation. We present a system developed for a client in the IT Support domain for support case solution recommendation that combines retrieval augmented generation (RAG) for answer generation with an encoder-only model for classification and a generative large language model for query generation. We cover architecture details, data collection and annotation, development journey and preliminary validations, expected final deployment process and evaluation plans, and finally lessons learned.",
    "published": "2024-09-06T13:06:29Z",
    "pdf_url": "https://arxiv.org/pdf/2409.13707v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.05181v2",
    "title": "Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval",
    "authors": [
      "Kidist Amde Mekonnen",
      "Yubao Tang",
      "Maarten de Rijke"
    ],
    "summary": "Generative information retrieval (GenIR) is a promising neural retrieval paradigm that formulates document retrieval as a document identifier (docid) generation task, allowing for end-to-end optimization toward a unified global retrieval objective. However, existing GenIR models suffer from token-level misalignment, where models trained to predict the next token often fail to capture document-level relevance effectively. While reinforcement learning-based methods, such as reinforcement learning from relevance feedback (RLRF), aim to address this misalignment through reward modeling, they introduce significant complexity, requiring the optimization of an auxiliary reward function followed by reinforcement fine-tuning, which is computationally expensive and often unstable. To address these challenges, we propose direct document relevance optimization (DDRO), which aligns token-level docid generation with document-level relevance estimation through direct optimization via pairwise ranking, eliminating the need for explicit reward modeling and reinforcement learning. Experimental results on benchmark datasets, including MS MARCO document and Natural Questions, show that DDRO outperforms reinforcement learning-based methods, achieving a 7.4% improvement in MRR@10 for MS MARCO and a 19.9% improvement for Natural Questions. These findings highlight DDRO's potential to enhance retrieval effectiveness with a simplified optimization approach. By framing alignment as a direct optimization problem, DDRO simplifies the ranking optimization pipeline of GenIR models while offering a viable alternative to reinforcement learning-based methods.",
    "published": "2025-04-07T15:27:37Z",
    "pdf_url": "https://arxiv.org/pdf/2504.05181v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2205.02303v1",
    "title": "Analysing the Robustness of Dual Encoders for Dense Retrieval Against Misspellings",
    "authors": [
      "Georgios Sidiropoulos",
      "Evangelos Kanoulas"
    ],
    "summary": "Dense retrieval is becoming one of the standard approaches for document and passage ranking. The dual-encoder architecture is widely adopted for scoring question-passage pairs due to its efficiency and high performance. Typically, dense retrieval models are evaluated on clean and curated datasets. However, when deployed in real-life applications, these models encounter noisy user-generated text. That said, the performance of state-of-the-art dense retrievers can substantially deteriorate when exposed to noisy text. In this work, we study the robustness of dense retrievers against typos in the user question. We observe a significant drop in the performance of the dual-encoder model when encountering typos and explore ways to improve its robustness by combining data augmentation with contrastive learning. Our experiments on two large-scale passage ranking and open-domain question answering datasets show that our proposed approach outperforms competing approaches. Additionally, we perform a thorough analysis on robustness. Finally, we provide insights on how different typos affect the robustness of embeddings differently and how our method alleviates the effect of some typos but not of others.",
    "published": "2022-05-04T19:48:13Z",
    "pdf_url": "https://arxiv.org/pdf/2205.02303v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2008.05505v1",
    "title": "The Effects of Object Shape, Fidelity, Color, and Luminance on Depth Perception in Handheld Mobile Augmented Reality",
    "authors": [
      "Tiffany D. Do",
      "Joseph J. LaViola",
      "Ryan P. McMahan"
    ],
    "summary": "Depth perception of objects can greatly affect a user's experience of an augmented reality (AR) application. Many AR applications require depth matching of real and virtual objects and have the possibility to be influenced by depth cues. Color and luminance are depth cues that have been traditionally studied in two-dimensional (2D) objects. However, there is little research investigating how the properties of three-dimensional (3D) virtual objects interact with color and luminance to affect depth perception, despite the substantial use of 3D objects in visual applications. In this paper, we present the results of a paired comparison experiment that investigates the effects of object shape, fidelity, color, and luminance on depth perception of 3D objects in handheld mobile AR. The results of our study indicate that bright colors are perceived as nearer than dark colors for a high-fidelity, simple 3D object, regardless of hue. Additionally, bright red is perceived as nearer than any other color. These effects were not observed for a low-fidelity version of the simple object or for a more-complex 3D object. High-fidelity objects had more perceptual differences than low-fidelity objects, indicating that fidelity interacts with color and luminance to affect depth perception. These findings reveal how the properties of 3D models influence the effects of color and luminance on depth perception in handheld mobile AR and can help developers select colors for their applications.",
    "published": "2020-08-12T18:12:05Z",
    "pdf_url": "https://arxiv.org/pdf/2008.05505v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2202.00373v2",
    "title": "Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization",
    "authors": [
      "Amin Abolghasemi",
      "Suzan Verberne",
      "Leif Azzopardi"
    ],
    "summary": "Query-by-document (QBD) retrieval is an Information Retrieval task in which a seed document acts as the query and the goal is to retrieve related documents -- it is particular common in professional search tasks. In this work we improve the retrieval effectiveness of the BERT re-ranker, proposing an extension to its fine-tuning step to better exploit the context of queries. To this end, we use an additional document-level representation learning objective besides the ranking objective when fine-tuning the BERT re-ranker. Our experiments on two QBD retrieval benchmarks show that the proposed multi-task optimization significantly improves the ranking effectiveness without changing the BERT re-ranker or using additional training samples. In future work, the generalizability of our approach to other retrieval tasks should be further investigated.",
    "published": "2022-02-01T12:27:59Z",
    "pdf_url": "https://arxiv.org/pdf/2202.00373v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2305.06983v2",
    "title": "Active Retrieval Augmented Generation",
    "authors": [
      "Zhengbao Jiang",
      "Frank F. Xu",
      "Luyu Gao",
      "Zhiqing Sun",
      "Qian Liu",
      "Jane Dwivedi-Yu",
      "Yiming Yang",
      "Jamie Callan",
      "Graham Neubig"
    ],
    "summary": "Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",
    "published": "2023-05-11T17:13:40Z",
    "pdf_url": "https://arxiv.org/pdf/2305.06983v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2311.03374v1",
    "title": "Generative AI for Software Metadata: Overview of the Information Retrieval in Software Engineering Track at FIRE 2023",
    "authors": [
      "Srijoni Majumdar",
      "Soumen Paul",
      "Debjyoti Paul",
      "Ayan Bandyopadhyay",
      "Samiran Chattopadhyay",
      "Partha Pratim Das",
      "Paul D Clough",
      "Prasenjit Majumder"
    ],
    "summary": "The Information Retrieval in Software Engineering (IRSE) track aims to develop solutions for automated evaluation of code comments in a machine learning framework based on human and large language model generated labels. In this track, there is a binary classification task to classify comments as useful and not useful. The dataset consists of 9048 code comments and surrounding code snippet pairs extracted from open source github C based projects and an additional dataset generated individually by teams using large language models. Overall 56 experiments have been submitted by 17 teams from various universities and software companies. The submissions have been evaluated quantitatively using the F1-Score and qualitatively based on the type of features developed, the supervised learning model used and their corresponding hyper-parameters. The labels generated from large language models increase the bias in the prediction model but lead to less over-fitted results.",
    "published": "2023-10-27T14:13:23Z",
    "pdf_url": "https://arxiv.org/pdf/2311.03374v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.09292v3",
    "title": "To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation",
    "authors": [
      "Kaustubh D. Dhole"
    ],
    "summary": "Retrieval-Augmented Generation equips large language models with the capability to retrieve external knowledge, thereby mitigating hallucinations by incorporating information beyond the model's intrinsic abilities. However, most prior works have focused on invoking retrieval deterministically, which makes it unsuitable for tasks such as long-form question answering. Instead, dynamically performing retrieval by invoking it only when the underlying LLM lacks the required knowledge can be more efficient. In this context, we delve deeper into the question, \"To Retrieve or Not to Retrieve?\" by exploring multiple uncertainty detection methods. We evaluate these methods for the task of long-form question answering, employing dynamic retrieval, and present our comparisons. Our findings suggest that uncertainty detection metrics, such as Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval calls by almost half, with only a slight reduction in question-answering accuracy.",
    "published": "2025-01-16T04:56:33Z",
    "pdf_url": "https://arxiv.org/pdf/2501.09292v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.04006v1",
    "title": "Advancing Similarity Search with GenAI: A Retrieval Augmented Generation Approach",
    "authors": [
      "Jean Bertin"
    ],
    "summary": "This article introduces an innovative Retrieval Augmented Generation approach to similarity search. The proposed method uses a generative model to capture nuanced semantic information and retrieve similarity scores based on advanced context understanding. The study focuses on the BIOSSES dataset containing 100 pairs of sentences extracted from the biomedical domain, and introduces similarity search correlation results that outperform those previously attained on this dataset. Through an in-depth analysis of the model sensitivity, the research identifies optimal conditions leading to the highest similarity search accuracy: the results reveals high Pearson correlation scores, reaching specifically 0.905 at a temperature of 0.5 and a sample size of 20 examples provided in the prompt. The findings underscore the potential of generative models for semantic information retrieval and emphasize a promising research direction to similarity search.",
    "published": "2024-12-03T09:01:03Z",
    "pdf_url": "https://arxiv.org/pdf/2501.04006v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2510.11394v1",
    "title": "VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification",
    "authors": [
      "Haosheng Qian",
      "Yixing Fan",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Qi Chen",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for enhancing the responses of large language models (LLMs) with external knowledge sources. Despite the impressive performance in complex question-answering tasks, RAG still struggles with hallucinations. Attributing RAG-generated content through in-line citations has demonstrated potential in reducing hallucinations and facilitating human verification. Existing citation generation methods primarily rely on either fine-tuning the generator or employing post-processing approaches for citation matching. However, the former approach demands substantial annotated data and computational resources, while the latter often encounters difficulties in managing multiple citations and frequently produces suboptimal results. In this paper, we introduce a novel framework, called VeriCite, designed to rigorously validate supporting evidence and enhance answer attribution. Specifically, VeriCite breaks down into a three-stage generation: 1) The initial answer generation first generates a response based on all available contexts and has its claims verified through the NLI model; 2) the supporting evidence selection assesses the utility of each document and extracts useful supporting evidences; 3) the final answer refinement integrates the initial response and collected evidences to produce the final, refined answer.We conduct experiments across five open-source LLMs and four datasets, demonstrating that VeriCite can significantly improve citation quality while maintaining the correctness of the answers.",
    "published": "2025-10-13T13:38:54Z",
    "pdf_url": "https://arxiv.org/pdf/2510.11394v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2406.16383v2",
    "title": "Context-augmented Retrieval: A Novel Framework for Fast Information Retrieval based Response Generation using Large Language Model",
    "authors": [
      "Sai Ganesh",
      "Anupam Purwar",
      "Gautam B"
    ],
    "summary": "Generating high-quality answers consistently by providing contextual information embedded in the prompt passed to the Large Language Model (LLM) is dependent on the quality of information retrieval. As the corpus of contextual information grows, the answer/inference quality of Retrieval Augmented Generation (RAG) based Question Answering (QA) systems declines. This work solves this problem by combining classical text classification with the Large Language Model (LLM) to enable quick information retrieval from the vector store and ensure the relevancy of retrieved information. For the same, this work proposes a new approach Context Augmented retrieval (CAR), where partitioning of vector database by real-time classification of information flowing into the corpus is done. CAR demonstrates good quality answer generation along with significant reduction in information retrieval and answer generation time.",
    "published": "2024-06-24T07:52:05Z",
    "pdf_url": "https://arxiv.org/pdf/2406.16383v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2406.18960v1",
    "title": "A Surprisingly Simple yet Effective Multi-Query Rewriting Method for Conversational Passage Retrieval",
    "authors": [
      "Ivica Kostric",
      "Krisztian Balog"
    ],
    "summary": "Conversational passage retrieval is challenging as it often requires the resolution of references to previous utterances and needs to deal with the complexities of natural language, such as coreference and ellipsis. To address these challenges, pre-trained sequence-to-sequence neural query rewriters are commonly used to generate a single de-contextualized query based on conversation history. Previous research shows that combining multiple query rewrites for the same user utterance has a positive effect on retrieval performance. We propose the use of a neural query rewriter to generate multiple queries and show how to integrate those queries in the passage retrieval pipeline efficiently. The main strength of our approach lies in its simplicity: it leverages how the beam search algorithm works and can produce multiple query rewrites at no additional cost. Our contributions further include devising ways to utilize multi-query rewrites in both sparse and dense first-pass retrieval. We demonstrate that applying our approach on top of a standard passage retrieval pipeline delivers state-of-the-art performance without sacrificing efficiency.",
    "published": "2024-06-27T07:43:03Z",
    "pdf_url": "https://arxiv.org/pdf/2406.18960v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2403.13468v1",
    "title": "DESIRE-ME: Domain-Enhanced Supervised Information REtrieval using Mixture-of-Experts",
    "authors": [
      "Pranav Kasela",
      "Gabriella Pasi",
      "Raffaele Perego",
      "Nicola Tonellotto"
    ],
    "summary": "Open-domain question answering requires retrieval systems able to cope with the diverse and varied nature of questions, providing accurate answers across a broad spectrum of query types and topics. To deal with such topic heterogeneity through a unique model, we propose DESIRE-ME, a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models. We rely on Wikipedia data to train an effective neural gating mechanism that classifies the incoming query and that weighs the predictions of the different domain-specific experts correspondingly. This allows DESIRE-ME to specialize adaptively in multiple domains. Through extensive experiments on publicly available datasets, we show that our proposal can effectively generalize domain-enhanced neural models. DESIRE-ME excels in handling open-domain questions adaptively, boosting by up to 12% in NDCG@10 and 22% in P@1, the underlying state-of-the-art dense retrieval model.",
    "published": "2024-03-20T10:18:05Z",
    "pdf_url": "https://arxiv.org/pdf/2403.13468v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.11605v1",
    "title": "Interactions with Generative Information Retrieval Systems",
    "authors": [
      "Mohammad Aliannejadi",
      "Jacek Gwizdka",
      "Hamed Zamani"
    ],
    "summary": "At its core, information access and seeking is an interactive process. In existing search engines, interactions are limited to a few pre-defined actions, such as \"requery\", \"click on a document\", \"scrolling up/down\", \"going to the next result page\", \"leaving the search engine\", etc. A major benefit of moving towards generative IR systems is enabling users with a richer expression of information need and feedback and free-form interactions in natural language and beyond. In other words, the actions users take are no longer limited by the clickable links and buttons available on the search engine result page and users can express themselves freely through natural language. This can go even beyond natural language, through images, videos, gestures, and sensors using multi-modal generative IR systems. This chapter briefly discusses the role of interaction in generative IR systems. We will first discuss different ways users can express their information needs by interacting with generative IR systems. We then explain how users can provide explicit or implicit feedback to generative IR systems and how they can consume such feedback. Next, we will cover how users interactively can refine retrieval results. We will expand upon mixed-initiative interactions and discuss clarification and preference elicitation in more detail. We then discuss proactive generative IR systems, including context-aware recommendation, following up past conversations, contributing to multi-party conversations, and feedback requests. Providing explanation is another interaction type that we briefly discuss in this chapter. We will also briefly describe multi-modal interactions in generative information retrieval. Finally, we describe emerging frameworks and solutions for user interfaces with generative AI systems.",
    "published": "2024-07-16T11:12:22Z",
    "pdf_url": "https://arxiv.org/pdf/2407.11605v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.10529v1",
    "title": "HeteRAG: A Heterogeneous Retrieval-augmented Generation Framework with Decoupled Knowledge Representations",
    "authors": [
      "Peiru Yang",
      "Xintian Li",
      "Zhiyang Hu",
      "Jiapeng Wang",
      "Jinhua Yin",
      "Huili Wang",
      "Lizhi He",
      "Shuai Yang",
      "Shangguang Wang",
      "Yongfeng Huang",
      "Tao Qi"
    ],
    "summary": "Retrieval-augmented generation (RAG) methods can enhance the performance of LLMs by incorporating retrieved knowledge chunks into the generation process. In general, the retrieval and generation steps usually have different requirements for these knowledge chunks. The retrieval step benefits from comprehensive information to improve retrieval accuracy, whereas excessively long chunks may introduce redundant contextual information, thereby diminishing both the effectiveness and efficiency of the generation process. However, existing RAG methods typically employ identical representations of knowledge chunks for both retrieval and generation, resulting in suboptimal performance. In this paper, we propose a heterogeneous RAG framework (\\myname) that decouples the representations of knowledge chunks for retrieval and generation, thereby enhancing the LLMs in both effectiveness and efficiency. Specifically, we utilize short chunks to represent knowledge to adapt the generation step and utilize the corresponding chunk with its contextual information from multi-granular views to enhance retrieval accuracy. We further introduce an adaptive prompt tuning method for the retrieval model to adapt the heterogeneous retrieval augmented generation process. Extensive experiments demonstrate that \\myname achieves significant improvements compared to baselines.",
    "published": "2025-04-12T13:12:54Z",
    "pdf_url": "https://arxiv.org/pdf/2504.10529v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2509.01030v2",
    "title": "Identifying Origins of Place Names via Retrieval Augmented Generation",
    "authors": [
      "Alexis Horde-Vo",
      "Matt Duckham",
      "Estrid He",
      "Rafe Benli"
    ],
    "summary": "Who is the \"Batman\" behind \"Batman Street\" in Melbourne? Understanding the historical, cultural, and societal narratives behind place names can reveal the rich context that has shaped a community. Although place names serve as essential spatial references in gazetteers, they often lack information about place name origins. Enriching these place names in today's gazetteers is a time-consuming, manual process that requires extensive exploration of a vast archive of documents and text sources. Recent advances in natural language processing and language models (LMs) hold the promise of significant automation of identifying place name origins due to their powerful capability to exploit the semantics of the stored documents. This chapter presents a retrieval augmented generation pipeline designed to search for place name origins over a broad knowledge base, DBpedia. Given a spatial query, our approach first extracts sub-graphs that may contain knowledge relevant to the query; then ranks the extracted sub-graphs to generate the final answer to the query using fine-tuned LM-based models (i.e., ColBERTv2 and Llama2). Our results highlight the key challenges facing automated retrieval of place name origins, especially the tendency of language models to under-use the spatial information contained in texts as a discriminating factor. Our approach also frames the wider implications for geographic information retrieval using retrieval augmented generation.",
    "published": "2025-08-31T23:40:53Z",
    "pdf_url": "https://arxiv.org/pdf/2509.01030v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.06956v1",
    "title": "Investigating the Robustness of Retrieval-Augmented Generation at the Query Level",
    "authors": [
      "Sezen Per\u00e7in",
      "Xin Su",
      "Qutub Sha Syed",
      "Phillip Howard",
      "Aleksei Kuvshinov",
      "Leo Schwinn",
      "Kay-Ulrich Scholl"
    ],
    "summary": "Large language models (LLMs) are very costly and inefficient to update with new information. To address this limitation, retrieval-augmented generation (RAG) has been proposed as a solution that dynamically incorporates external knowledge during inference, improving factual consistency and reducing hallucinations. Despite its promise, RAG systems face practical challenges-most notably, a strong dependence on the quality of the input query for accurate retrieval. In this paper, we investigate the sensitivity of different components in the RAG pipeline to various types of query perturbations. Our analysis reveals that the performance of commonly used retrievers can degrade significantly even under minor query variations. We study each module in isolation as well as their combined effect in an end-to-end question answering setting, using both general-domain and domain-specific datasets. Additionally, we propose an evaluation framework to systematically assess the query-level robustness of RAG pipelines and offer actionable recommendations for practitioners based on the results of more than 1092 experiments we performed.",
    "published": "2025-07-09T15:39:17Z",
    "pdf_url": "https://arxiv.org/pdf/2507.06956v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.21712v1",
    "title": "Adaptive Retrieval-Augmented Generation for Conversational Systems",
    "authors": [
      "Xi Wang",
      "Procheta Sen",
      "Ruizhe Li",
      "Emine Yilmaz"
    ],
    "summary": "Despite the success of integrating large language models into the development of conversational systems, many studies have shown the effectiveness of retrieving and augmenting external knowledge for informative responses. Hence, many existing studies commonly assume the always need for Retrieval Augmented Generation (RAG) in a conversational system without explicit control. This raises a research question about such a necessity. In this study, we propose to investigate the need for each turn of system response to be augmented with external knowledge. In particular, by leveraging human judgements on the binary choice of adaptive augmentation, we develop RAGate, a gating model, which models conversation context and relevant inputs to predict if a conversational system requires RAG for improved responses. We conduct extensive experiments on devising and applying RAGate to conversational models and well-rounded analyses of different conversational scenarios. Our experimental results and analysis indicate the effective application of RAGate in RAG-based conversational systems in identifying system responses for appropriate RAG with high-quality responses and a high generation confidence. This study also identifies the correlation between the generation's confidence level and the relevance of the augmented knowledge.",
    "published": "2024-07-31T16:04:03Z",
    "pdf_url": "https://arxiv.org/pdf/2407.21712v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2412.15246v1",
    "title": "Accelerating Retrieval-Augmented Generation",
    "authors": [
      "Derrick Quinn",
      "Mohammad Nouri",
      "Neel Patel",
      "John Salihu",
      "Alireza Salemi",
      "Sukhan Lee",
      "Hamed Zamani",
      "Mohammad Alian"
    ],
    "summary": "An evolving solution to address hallucination and enhance accuracy in large language models (LLMs) is Retrieval-Augmented Generation (RAG), which involves augmenting LLMs with information retrieved from an external knowledge source, such as the web. This paper profiles several RAG execution pipelines and demystifies the complex interplay between their retrieval and generation phases. We demonstrate that while exact retrieval schemes are expensive, they can reduce inference time compared to approximate retrieval variants because an exact retrieval model can send a smaller but more accurate list of documents to the generative model while maintaining the same end-to-end accuracy. This observation motivates the acceleration of the exact nearest neighbor search for RAG.\n  In this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL device that implements a scale-out near-memory acceleration architecture with a novel cache-coherent interface between the host CPU and near-memory accelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a 512GB vector database compared with executing the search on Intel Sapphire Rapids CPUs. This higher search performance translates to 1.7-26.3x lower end-to-end inference time for representative RAG applications. IKS is inherently a memory expander; its internal DRAM can be disaggregated and used for other applications running on the server to prevent DRAM, which is the most expensive component in today's servers, from being stranded.",
    "published": "2024-12-14T06:47:56Z",
    "pdf_url": "https://arxiv.org/pdf/2412.15246v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.15470v2",
    "title": "CogPlanner: Unveiling the Potential of Agentic Multimodal Retrieval Augmented Generation with Planning",
    "authors": [
      "Xiaohan Yu",
      "Zhihan Yang",
      "Chong Chen"
    ],
    "summary": "Multimodal Retrieval Augmented Generation (MRAG) systems have shown promise in enhancing the generation capabilities of multimodal large language models (MLLMs). However, existing MRAG frameworks primarily adhere to rigid, single-step retrieval strategies that fail to address real-world challenges of information acquisition and query reformulation. In this work, we introduce the task of Multimodal Retrieval Augmented Generation Planning (MRAG Planning) that aims at effective information seeking and integration while minimizing computational overhead. Specifically, we propose CogPlanner, an agentic plug-and-play framework inspired by human cognitive processes, which iteratively determines query reformulation and retrieval strategies to generate accurate and contextually relevant responses. CogPlanner supports parallel and sequential modeling paradigms. Furthermore, we introduce CogBench, a new benchmark designed to rigorously evaluate the MRAG Planning task and facilitate lightweight CogPlanner integration with resource-efficient MLLMs, such as Qwen2-VL-7B-Cog. Experimental results demonstrate that CogPlanner significantly outperforms existing MRAG baselines, offering improvements in both accuracy and efficiency with minimal additional computational costs.",
    "published": "2025-01-26T10:16:42Z",
    "pdf_url": "https://arxiv.org/pdf/2501.15470v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2004.07716v1",
    "title": "Continuous Health Interface Event Retrieval",
    "authors": [
      "Vaibhav Pandey",
      "Nitish Nag",
      "Ramesh Jain"
    ],
    "summary": "Knowing the state of our health at every moment in time is critical for advances in health science. Using data obtained outside an episodic clinical setting is the first step towards building a continuous health estimation system. In this paper, we explore a system that allows users to combine events and data streams from different sources to retrieve complex biological events, such as cardiovascular volume overload. These complex events, which have been explored in biomedical literature and which we call interface events, have a direct causal impact on relevant biological systems. They are the interface through which the lifestyle events influence our health. We retrieve the interface events from existing events and data streams by encoding domain knowledge using an event operator language.",
    "published": "2020-04-16T15:49:13Z",
    "pdf_url": "https://arxiv.org/pdf/2004.07716v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2409.18575v1",
    "title": "Corpus-informed Retrieval Augmented Generation of Clarifying Questions",
    "authors": [
      "Antonios Minas Krasakis",
      "Andrew Yates",
      "Evangelos Kanoulas"
    ],
    "summary": "This study aims to develop models that generate corpus informed clarifying questions for web search, in a way that ensures the questions align with the available information in the retrieval corpus. We demonstrate the effectiveness of Retrieval Augmented Language Models (RAG) in this process, emphasising their ability to (i) jointly model the user query and retrieval corpus to pinpoint the uncertainty and ask for clarifications end-to-end and (ii) model more evidence documents, which can be used towards increasing the breadth of the questions asked. However, we observe that in current datasets search intents are largely unsupported by the corpus, which is problematic both for training and evaluation. This causes question generation models to ``hallucinate'', ie. suggest intents that are not in the corpus, which can have detrimental effects in performance. To address this, we propose dataset augmentation methods that align the ground truth clarifications with the retrieval corpus. Additionally, we explore techniques to enhance the relevance of the evidence pool during inference, but find that identifying ground truth intents within the corpus remains challenging. Our analysis suggests that this challenge is partly due to the bias of current datasets towards clarification taxonomies and calls for data that can support generating corpus-informed clarifications.",
    "published": "2024-09-27T09:20:42Z",
    "pdf_url": "https://arxiv.org/pdf/2409.18575v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2403.10939v1",
    "title": "Improving the Robustness of Dense Retrievers Against Typos via Multi-Positive Contrastive Learning",
    "authors": [
      "Georgios Sidiropoulos",
      "Evangelos Kanoulas"
    ],
    "summary": "Dense retrieval has become the new paradigm in passage retrieval. Despite its effectiveness on typo-free queries, it is not robust when dealing with queries that contain typos. Current works on improving the typo-robustness of dense retrievers combine (i) data augmentation to obtain the typoed queries during training time with (ii) additional robustifying subtasks that aim to align the original, typo-free queries with their typoed variants. Even though multiple typoed variants are available as positive samples per query, some methods assume a single positive sample and a set of negative ones per anchor and tackle the robustifying subtask with contrastive learning; therefore, making insufficient use of the multiple positives (typoed queries). In contrast, in this work, we argue that all available positives can be used at the same time and employ contrastive learning that supports multiple positives (multi-positive). Experimental results on two datasets show that our proposed approach of leveraging all positives simultaneously and employing multi-positive contrastive learning on the robustifying subtask yields improvements in robustness against using contrastive learning with a single positive.",
    "published": "2024-03-16T14:43:30Z",
    "pdf_url": "https://arxiv.org/pdf/2403.10939v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2108.06279v2",
    "title": "On Single and Multiple Representations in Dense Passage Retrieval",
    "authors": [
      "Craig Macdonald",
      "Nicola Tonellotto",
      "Iadh Ounis"
    ],
    "summary": "The advent of contextualised language models has brought gains in search effectiveness, not just when applied for re-ranking the output of classical weighting models such as BM25, but also when used directly for passage indexing and retrieval, a technique which is called dense retrieval. In the existing literature in neural ranking, two dense retrieval families have become apparent: single representation, where entire passages are represented by a single embedding (usually BERT's [CLS] token, as exemplified by the recent ANCE approach), or multiple representations, where each token in a passage is represented by its own embedding (as exemplified by the recent ColBERT approach). These two families have not been directly compared. However, because of the likely importance of dense retrieval moving forward, a clear understanding of their advantages and disadvantages is paramount. To this end, this paper contributes a direct study on their comparative effectiveness, noting situations where each method under/over performs w.r.t. each other, and w.r.t. a BM25 baseline. We observe that, while ANCE is more efficient than ColBERT in terms of response time and memory usage, multiple representations are statistically more effective than the single representations for MAP and MRR@10. We also show that multiple representations obtain better improvements than single representations for queries that are the hardest for BM25, as well as for definitional queries, and those with complex information needs.",
    "published": "2021-08-13T15:01:53Z",
    "pdf_url": "https://arxiv.org/pdf/2108.06279v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.05731v1",
    "title": "Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation",
    "authors": [
      "Teng Shi",
      "Jun Xu",
      "Xiao Zhang",
      "Xiaoxue Zang",
      "Kai Zheng",
      "Yang Song",
      "Han Li"
    ],
    "summary": "Recently, the personalization of Large Language Models (LLMs) to generate content that aligns with individual user preferences has garnered widespread attention. Personalized Retrieval-Augmented Generation (RAG), which retrieves relevant documents from the user's history to reflect their preferences and enhance LLM generation, is one commonly used approach for personalization. However, existing personalized RAG methods do not consider that the histories of similar users can also assist in personalized generation for the current user, meaning that collaborative information between users can also benefit personalized generation. Inspired by the application of collaborative filtering in recommender systems, we propose a method called CFRAG, which adapts Collaborative Filtering to RAG for personalized text generation. However, this presents two challenges: (1)~how to incorporate collaborative information without explicit user similarity labels? (2)~how to retrieve documents that support personalized LLM generation? For Challenge 1, we use contrastive learning to train user embeddings to retrieve similar users and introduce collaborative information. For Challenge 2, we design a personalized retriever and reranker to retrieve the top-$k$ documents from these users' histories. We take into account the user's preference during retrieval and reranking. Then we leverage feedback from the LLM to fine-tune the personalized retriever and reranker, enabling them to retrieve documents that meet the personalized generation needs of the LLM. Experimental results on the Language Model Personalization (LaMP) benchmark validate the effectiveness of CFRAG. Further analysis confirms the importance of incorporating collaborative information.",
    "published": "2025-04-08T07:03:36Z",
    "pdf_url": "https://arxiv.org/pdf/2504.05731v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2312.07796v1",
    "title": "Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge Gaps",
    "authors": [
      "Joan Figuerola Hurtado"
    ],
    "summary": "The paper presents a methodology for uncovering knowledge gaps on the internet using the Retrieval Augmented Generation (RAG) model. By simulating user search behaviour, the RAG system identifies and addresses gaps in information retrieval systems. The study demonstrates the effectiveness of the RAG system in generating relevant suggestions with a consistent accuracy of 93%. The methodology can be applied in various fields such as scientific discovery, educational enhancement, research development, market analysis, search engine optimisation, and content development. The results highlight the value of identifying and understanding knowledge gaps to guide future endeavours.",
    "published": "2023-12-12T23:22:57Z",
    "pdf_url": "https://arxiv.org/pdf/2312.07796v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.15915v1",
    "title": "Parametric Retrieval Augmented Generation",
    "authors": [
      "Weihang Su",
      "Yichen Tang",
      "Qingyao Ai",
      "Junxi Yan",
      "Changyue Wang",
      "Hongning Wang",
      "Ziyi Ye",
      "Yujia Zhou",
      "Yiqun Liu"
    ],
    "summary": "Retrieval-augmented generation (RAG) techniques have emerged as a promising solution to enhance the reliability of large language models (LLMs) by addressing issues like hallucinations, outdated knowledge, and domain adaptation. In particular, existing RAG methods append relevant documents retrieved from external corpus or databases to the input of LLMs to guide their generation process, which we refer to as the in-context knowledge injection method. While this approach is simple and often effective, it has inherent limitations. Firstly, increasing the context length and number of relevant documents can lead to higher computational overhead and degraded performance, especially in complex reasoning tasks. More importantly, in-context knowledge injection operates primarily at the input level, but LLMs store their internal knowledge in their parameters. This gap fundamentally limits the capacity of in-context methods. To this end, we introduce Parametric retrieval-augmented generation (Parametric RAG), a new RAG paradigm that integrates external knowledge directly into the parameters of feed-forward networks (FFN) of an LLM through document parameterization. This approach not only saves online computational costs by eliminating the need to inject multiple documents into the LLMs' input context, but also deepens the integration of external knowledge into the parametric knowledge space of the LLM. Experimental results demonstrate that Parametric RAG substantially enhances both the effectiveness and efficiency of knowledge augmentation in LLMs. Also, it can be combined with in-context RAG methods to achieve even better performance.\n  We have open-sourced all the code, data, and models in the following anonymized GitHub link: https://github.com/oneal2000/PRAG",
    "published": "2025-01-27T10:04:49Z",
    "pdf_url": "https://arxiv.org/pdf/2501.15915v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2310.13848v2",
    "title": "FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction",
    "authors": [
      "Priyanka Ranade",
      "Anupam Joshi"
    ],
    "summary": "Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construction techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps. This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports.\n  We introduce a Retrieval Augmented Generation (RAG) approach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to augment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy.",
    "published": "2023-10-20T22:47:18Z",
    "pdf_url": "https://arxiv.org/pdf/2310.13848v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2409.00851v1",
    "title": "Dissecting Temporal Understanding in Text-to-Audio Retrieval",
    "authors": [
      "Andreea-Maria Oncescu",
      "Jo\u00e3o F. Henriques",
      "A. Sophia Koepke"
    ],
    "summary": "Recent advancements in machine learning have fueled research on multimodal tasks, such as for instance text-to-video and text-to-audio retrieval. These tasks require models to understand the semantic content of video and audio data, including objects, and characters. The models also need to learn spatial arrangements and temporal relationships. In this work, we analyse the temporal ordering of sounds, which is an understudied problem in the context of text-to-audio retrieval. In particular, we dissect the temporal understanding capabilities of a state-of-the-art model for text-to-audio retrieval on the AudioCaps and Clotho datasets. Additionally, we introduce a synthetic text-audio dataset that provides a controlled setting for evaluating temporal capabilities of recent models. Lastly, we present a loss function that encourages text-audio models to focus on the temporal ordering of events. Code and data are available at https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/dtu/.",
    "published": "2024-09-01T22:01:21Z",
    "pdf_url": "https://arxiv.org/pdf/2409.00851v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2512.00367v1",
    "title": "Breaking It Down: Domain-Aware Semantic Segmentation for Retrieval Augmented Generation",
    "authors": [
      "Aparajitha Allamraju",
      "Maitreya Prafulla Chitale",
      "Hiranmai Sri Adibhatla",
      "Rahul Mishra",
      "Manish Shrivastava"
    ],
    "summary": "Document chunking is a crucial component of Retrieval-Augmented Generation (RAG), as it directly affects the retrieval of relevant and precise context. Conventional fixed-length and recursive splitters often produce arbitrary, incoherent segments that fail to preserve semantic structure. Although semantic chunking has gained traction, its influence on generation quality remains underexplored. This paper introduces two efficient semantic chunking methods, Projected Similarity Chunking (PSC) and Metric Fusion Chunking (MFC), trained on PubMed data using three different embedding models. We further present an evaluation framework that measures the effect of chunking on both retrieval and generation by augmenting PubMedQA with full-text PubMed Central articles. Our results show substantial retrieval improvements (24x with PSC) in MRR and higher Hits@k on PubMedQA. We provide a comprehensive analysis, including statistical significance and response-time comparisons with common chunking libraries. Despite being trained on a single domain, PSC and MFC also generalize well, achieving strong out-of-domain generation performance across multiple datasets. Overall, our findings confirm that our semantic chunkers, especially PSC, consistently deliver superior performance.",
    "published": "2025-11-29T07:30:37Z",
    "pdf_url": "https://arxiv.org/pdf/2512.00367v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2005.12739v1",
    "title": "An Effective Pipeline for a Real-world Clothes Retrieval System",
    "authors": [
      "Yang-Ho Ji",
      "HeeJae Jun",
      "Insik Kim",
      "Jongtack Kim",
      "Youngjoon Kim",
      "Byungsoo Ko",
      "Hyong-Keun Kook",
      "Jingeun Lee",
      "Sangwon Lee",
      "Sanghyuk Park"
    ],
    "summary": "In this paper, we propose an effective pipeline for clothes retrieval system which has sturdiness on large-scale real-world fashion data. Our proposed method consists of three components: detection, retrieval, and post-processing. We firstly conduct a detection task for precise retrieval on target clothes, then retrieve the corresponding items with the metric learning-based model. To improve the retrieval robustness against noise and misleading bounding boxes, we apply post-processing methods such as weighted boxes fusion and feature concatenation. With the proposed methodology, we achieved 2nd place in the DeepFashion2 Clothes Retrieval 2020 challenge.",
    "published": "2020-05-26T14:08:49Z",
    "pdf_url": "https://arxiv.org/pdf/2005.12739v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.07793v1",
    "title": "Unsupervised Query Routing for Retrieval Augmented Generation",
    "authors": [
      "Feiteng Mu",
      "Liwen Zhang",
      "Yong Jiang",
      "Wenjie Li",
      "Zhen Zhang",
      "Pengjun Xie",
      "Fei Huang"
    ],
    "summary": "Query routing for retrieval-augmented generation aims to assign an input query to the most suitable search engine. Existing works rely heavily on supervised datasets that require extensive manual annotation, resulting in high costs and limited scalability, as well as poor generalization to out-of-distribution scenarios. To address these challenges, we introduce a novel unsupervised method that constructs the \"upper-bound\" response to evaluate the quality of retrieval-augmented responses. This evaluation enables the decision of the most suitable search engine for a given query. By eliminating manual annotations, our approach can automatically process large-scale real user queries and create training data. We conduct extensive experiments across five datasets, demonstrating that our method significantly enhances scalability and generalization capabilities.",
    "published": "2025-01-14T02:27:06Z",
    "pdf_url": "https://arxiv.org/pdf/2501.07793v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.17519v1",
    "title": "Replication and Exploration of Generative Retrieval over Dynamic Corpora",
    "authors": [
      "Zhen Zhang",
      "Xinyu Ma",
      "Weiwei Sun",
      "Pengjie Ren",
      "Zhumin Chen",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Maarten de Rijke",
      "Zhaochun Ren"
    ],
    "summary": "Generative retrieval (GR) has emerged as a promising paradigm in information retrieval (IR). However, most existing GR models are developed and evaluated using a static document collection, and their performance in dynamic corpora where document collections evolve continuously is rarely studied. In this paper, we first reproduce and systematically evaluate various representative GR approaches over dynamic corpora. Through extensive experiments, we reveal that existing GR models with \\textit{text-based} docids show superior generalization to unseen documents. We observe that the more fine-grained the docid design in the GR model, the better its performance over dynamic corpora, surpassing BM25 and even being comparable to dense retrieval methods. While GR models with \\textit{numeric-based} docids show high efficiency, their performance drops significantly over dynamic corpora. Furthermore, our experiments find that the underperformance of numeric-based docids is partly due to their excessive tendency toward the initial document set, which likely results from overfitting on the training set. We then conduct an in-depth analysis of the best-performing GR methods. We identify three critical advantages of text-based docids in dynamic corpora: (i) Semantic alignment with language models' pretrained knowledge, (ii) Fine-grained docid design, and (iii) High lexical diversity. Building on these insights, we finally propose a novel multi-docid design that leverages both the efficiency of numeric-based docids and the effectiveness of text-based docids, achieving improved performance in dynamic corpus without requiring additional retraining. Our work offers empirical evidence for advancing GR methods over dynamic corpora and paves the way for developing more generalized yet efficient GR models in real-world search engines.",
    "published": "2025-04-24T13:01:23Z",
    "pdf_url": "https://arxiv.org/pdf/2504.17519v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2411.08891v4",
    "title": "Reliable Decision Making via Calibration Oriented Retrieval Augmented Generation",
    "authors": [
      "Chaeyun Jang",
      "Deukhwan Cho",
      "Seanie Lee",
      "Hyungi Lee",
      "Juho Lee"
    ],
    "summary": "Recently, Large Language Models (LLMs) have been increasingly used to support various decision-making tasks, assisting humans in making informed decisions. However, when LLMs confidently provide incorrect information, it can lead humans to make suboptimal decisions. To prevent LLMs from generating incorrect information on topics they are unsure of and to improve the accuracy of generated content, prior works have proposed Retrieval Augmented Generation (RAG), where external documents are referenced to generate responses. However, previous RAG methods focus only on retrieving documents most relevant to the input query, without specifically aiming to ensure that the human user's decisions are well-calibrated. To address this limitation, we propose a novel retrieval method called Calibrated Retrieval-Augmented Generation (CalibRAG), which ensures that decisions informed by RAG are well-calibrated. Then we empirically validate that CalibRAG improves calibration performance as well as accuracy, compared to other baselines across various datasets.",
    "published": "2024-10-28T06:41:05Z",
    "pdf_url": "https://arxiv.org/pdf/2411.08891v4.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2510.17354v1",
    "title": "Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation",
    "authors": [
      "Chenghao Zhang",
      "Guanting Dong",
      "Xinyu Yang",
      "Zhicheng Dou"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) by retrieving relevant documents from an external corpus. However, existing RAG systems primarily focus on unimodal text documents, and often fall short in real-world scenarios where both queries and documents may contain mixed modalities (such as text and images). In this paper, we address the challenge of Universal Retrieval-Augmented Generation (URAG), which involves retrieving and reasoning over mixed-modal information to improve vision-language generation. To this end, we propose Nyx, a unified mixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate the scarcity of realistic mixed-modal data, we introduce a four-stage automated pipeline for generation and filtering, leveraging web documents to construct NyxQA, a dataset comprising diverse mixed-modal question-answer pairs that better reflect real-world information needs. Building on this high-quality dataset, we adopt a two-stage training framework for Nyx: we first perform pre-training on NyxQA along with a variety of open-source retrieval datasets, followed by supervised fine-tuning using feedback from downstream vision-language models (VLMs) to align retrieval outputs with generative preferences. Experimental results demonstrate that Nyx not only performs competitively on standard text-only RAG benchmarks, but also excels in the more general and realistic URAG setting, significantly improving generation quality in vision-language tasks.",
    "published": "2025-10-20T09:56:43Z",
    "pdf_url": "https://arxiv.org/pdf/2510.17354v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "1904.05737v1",
    "title": "Investigating Retrieval Method Selection with Axiomatic Features",
    "authors": [
      "Siddhant Arora",
      "Andrew Yates"
    ],
    "summary": "We consider algorithm selection in the context of ad-hoc information retrieval. Given a query and a pair of retrieval methods, we propose a meta-learner that predicts how to combine the methods' relevance scores into an overall relevance score. Inspired by neural models' different properties with regard to IR axioms, these predictions are based on features that quantify axiom-related properties of the query and its top ranked documents. We conduct an evaluation on TREC Web Track data and find that the meta-learner often significantly improves over the individual methods. Finally, we conduct feature and query weight analyses to investigate the meta-learner's behavior.",
    "published": "2019-04-11T14:50:58Z",
    "pdf_url": "https://arxiv.org/pdf/1904.05737v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2210.09877v1",
    "title": "Towards Proactive Information Retrieval in Noisy Text with Wikipedia Concepts",
    "authors": [
      "Tabish Ahmed",
      "Sahan Bulathwela"
    ],
    "summary": "Extracting useful information from the user history to clearly understand informational needs is a crucial feature of a proactive information retrieval system. Regarding understanding information and relevance, Wikipedia can provide the background knowledge that an intelligent system needs. This work explores how exploiting the context of a query using Wikipedia concepts can improve proactive information retrieval on noisy text. We formulate two models that use entity linking to associate Wikipedia topics with the relevance model. Our experiments around a podcast segment retrieval task demonstrate that there is a clear signal of relevance in Wikipedia concepts while a ranking model can improve precision by incorporating them. We also find Wikifying the background context of a query can help disambiguate the meaning of the query, further helping proactive information retrieval.",
    "published": "2022-10-18T14:12:06Z",
    "pdf_url": "https://arxiv.org/pdf/2210.09877v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2201.04672v1",
    "title": "How Can Graph Neural Networks Help Document Retrieval: A Case Study on CORD19 with Concept Map Generation",
    "authors": [
      "Hejie Cui",
      "Jiaying Lu",
      "Yao Ge",
      "Carl Yang"
    ],
    "summary": "Graph neural networks (GNNs), as a group of powerful tools for representation learning on irregular data, have manifested superiority in various downstream tasks. With unstructured texts represented as concept maps, GNNs can be exploited for tasks like document retrieval. Intrigued by how can GNNs help document retrieval, we conduct an empirical study on a large-scale multi-discipline dataset CORD-19. Results show that instead of the complex structure-oriented GNNs such as GINs and GATs, our proposed semantics-oriented graph functions achieve better and more stable performance based on the BM25 retrieved candidates. Our insights in this case study can serve as a guideline for future work to develop effective GNNs with appropriate semantics-oriented inductive biases for textual reasoning tasks like document retrieval and classification. All code for this case study is available at https://github.com/HennyJie/GNN-DocRetrieval.",
    "published": "2022-01-12T19:52:29Z",
    "pdf_url": "https://arxiv.org/pdf/2201.04672v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2302.01690v2",
    "title": "See or Hear? Exploring the Effect of Visual and Audio Hints and Gaze-assisted Task Feedback for Visual Search Tasks in Augmented Reality",
    "authors": [
      "Yuchong Zhang",
      "Adam Nowak",
      "Yueming Xuan",
      "Andrzej Romanowski",
      "Morten Fjeld"
    ],
    "summary": "Augmented reality (AR) is emerging in visual search tasks for increasingly immersive interactions with virtual objects. We propose an AR approach providing visual and audio hints along with gaze-assisted instant post-task feedback for search tasks based on mobile head-mounted display (HMD). The target case was a book-searching task, in which we aimed to explore the effect of the hints together with the task feedback with two hypotheses. H1: Since visual and audio hints can positively affect AR search tasks, the combination outperforms the individuals. H2: The gaze-assisted instant post-task feedback can positively affect AR search tasks. The proof-of-concept was demonstrated by an AR app in HMD and a comprehensive user study (n=96) consisting of two sub-studies, Study I (n=48) without task feedback and Study II (n=48) with task feedback. Following quantitative and qualitative analysis, our results partially verified H1 and completely verified H2, enabling us to conclude that the synthesis of visual and audio hints conditionally improves the AR visual search task efficiency when coupled with task feedback.",
    "published": "2023-02-03T12:37:14Z",
    "pdf_url": "https://arxiv.org/pdf/2302.01690v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2210.05512v1",
    "title": "On the Interpolation of Contextualized Term-based Ranking with BM25 for Query-by-Example Retrieval",
    "authors": [
      "Amin Abolghasemi",
      "Arian Askari",
      "Suzan Verberne"
    ],
    "summary": "Term-based ranking with pre-trained transformer-based language models has recently gained attention as they bring the contextualization power of transformer models into the highly efficient term-based retrieval. In this work, we examine the generalizability of two of these deep contextualized term-based models in the context of query-by-example (QBE) retrieval in which a seed document acts as the query to find relevant documents. In this setting -- where queries are much longer than common keyword queries -- BERT inference at query time is problematic as it involves quadratic complexity. We investigate TILDE and TILDEv2, both of which leverage BERT tokenizer as their query encoder. With this approach, there is no need for BERT inference at query time, and also the query can be of any length. Our extensive evaluation on the four QBE tasks of SciDocs benchmark shows that in a query-by-example retrieval setting TILDE and TILDEv2 are still less effective than a cross-encoder BERT ranker. However, we observe that BM25 could show a competitive ranking quality compared to TILDE and TILDEv2 which is in contrast to the findings about the relative performance of these three models on retrieval for short queries reported in prior work. This result raises the question about the use of contextualized term-based ranking models being beneficial in QBE setting. We follow-up on our findings by studying the score interpolation between the relevance score from TILDE (TILDEv2) and BM25. We conclude that these two contextualized term-based ranking models capture different relevance signals than BM25 and combining the different term-based rankers results in statistically significant improvements in QBE retrieval. Our work sheds light on the challenges of retrieval settings different from the common evaluation benchmarks.",
    "published": "2022-10-11T15:03:39Z",
    "pdf_url": "https://arxiv.org/pdf/2210.05512v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2403.04256v1",
    "title": "Federated Recommendation via Hybrid Retrieval Augmented Generation",
    "authors": [
      "Huimin Zeng",
      "Zhenrui Yue",
      "Qian Jiang",
      "Dong Wang"
    ],
    "summary": "Federated Recommendation (FR) emerges as a novel paradigm that enables privacy-preserving recommendations. However, traditional FR systems usually represent users/items with discrete identities (IDs), suffering from performance degradation due to the data sparsity and heterogeneity in FR. On the other hand, Large Language Models (LLMs) as recommenders have proven effective across various recommendation scenarios. Yet, LLM-based recommenders encounter challenges such as low inference efficiency and potential hallucination, compromising their performance in real-world scenarios. To this end, we propose GPT-FedRec, a federated recommendation framework leveraging ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism. GPT-FedRec is a two-stage solution. The first stage is a hybrid retrieval process, mining ID-based user patterns and text-based item features. Next, the retrieved results are converted into text prompts and fed into GPT for re-ranking. Our proposed hybrid retrieval mechanism and LLM-based re-rank aims to extract generalized features from data and exploit pretrained knowledge within LLM, overcoming data sparsity and heterogeneity in FR. In addition, the RAG approach also prevents LLM hallucination, improving the recommendation performance for real-world users. Experimental results on diverse benchmark datasets demonstrate the superior performance of GPT-FedRec against state-of-the-art baseline methods.",
    "published": "2024-03-07T06:38:41Z",
    "pdf_url": "https://arxiv.org/pdf/2403.04256v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2506.21931v2",
    "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation",
    "authors": [
      "Reza Yousefi Maragheh",
      "Pratheek Vadla",
      "Priyank Gupta",
      "Kai Zhao",
      "Aysenur Inan",
      "Kehui Yao",
      "Jianpeng Xu",
      "Praveen Kanumala",
      "Jason Cho",
      "Sushant Kumar"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.",
    "published": "2025-06-27T05:45:59Z",
    "pdf_url": "https://arxiv.org/pdf/2506.21931v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2602.07739v1",
    "title": "HypRAG: Hyperbolic Dense Retrieval for Retrieval Augmented Generation",
    "authors": [
      "Hiren Madhu",
      "Ngoc Bui",
      "Ali Maatouk",
      "Leandros Tassiulas",
      "Smita Krishnaswamy",
      "Menglin Yang",
      "Sukanta Ganguly",
      "Kiran Srinivasan",
      "Rex Ying"
    ],
    "summary": "Embedding geometry plays a fundamental role in retrieval quality, yet dense retrievers for retrieval-augmented generation (RAG) remain largely confined to Euclidean space. However, natural language exhibits hierarchical structure from broad topics to specific entities that Euclidean embeddings fail to preserve, causing semantically distant documents to appear spuriously similar and increasing hallucination risk. To address these limitations, we introduce hyperbolic dense retrieval, developing two model variants in the Lorentz model of hyperbolic space: HyTE-FH, a fully hyperbolic transformer, and HyTE-H, a hybrid architecture projecting pre-trained Euclidean embeddings into hyperbolic space. To prevent representational collapse during sequence aggregation, we introduce the Outward Einstein Midpoint, a geometry-aware pooling operator that provably preserves hierarchical structure. On MTEB, HyTE-FH outperforms equivalent Euclidean baselines, while on RAGBench, HyTE-H achieves up to 29% gains over Euclidean baselines in context relevance and answer relevance using substantially smaller models than current state-of-the-art retrievers. Our analysis also reveals that hyperbolic representations encode document specificity through norm-based separation, with over 20% radial increase from general to specific concepts, a property absent in Euclidean embeddings, underscoring the critical role of geometric inductive bias in faithful RAG systems.",
    "published": "2026-02-08T00:18:05Z",
    "pdf_url": "https://arxiv.org/pdf/2602.07739v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2305.03950v1",
    "title": "Augmenting Passage Representations with Query Generation for Enhanced Cross-Lingual Dense Retrieval",
    "authors": [
      "Shengyao Zhuang",
      "Linjun Shou",
      "Guido Zuccon"
    ],
    "summary": "Effective cross-lingual dense retrieval methods that rely on multilingual pre-trained language models (PLMs) need to be trained to encompass both the relevance matching task and the cross-language alignment task. However, cross-lingual data for training is often scarcely available. In this paper, rather than using more cross-lingual data for training, we propose to use cross-lingual query generation to augment passage representations with queries in languages other than the original passage language. These augmented representations are used at inference time so that the representation can encode more information across the different target languages. Training of a cross-lingual query generator does not require additional training data to that used for the dense retriever. The query generator training is also effective because the pre-training task for the generator (T5 text-to-text training) is very similar to the fine-tuning task (generation of a query). The use of the generator does not increase query latency at inference and can be combined with any cross-lingual dense retrieval method. Results from experiments on a benchmark cross-lingual information retrieval dataset show that our approach can improve the effectiveness of existing cross-lingual dense retrieval methods. Implementation of our methods, along with all generated query files are made publicly available at https://github.com/ielab/xQG4xDR.",
    "published": "2023-05-06T06:34:21Z",
    "pdf_url": "https://arxiv.org/pdf/2305.03950v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.14546v1",
    "title": "Predicting Retrieval Utility and Answer Quality in Retrieval-Augmented Generation",
    "authors": [
      "Fangzheng Tian",
      "Debasis Ganguly",
      "Craig Macdonald"
    ],
    "summary": "The quality of answers generated by large language models (LLMs) in retrieval-augmented generation (RAG) is largely influenced by the contextual information contained in the retrieved documents. A key challenge for improving RAG is to predict both the utility of retrieved documents -- quantified as the performance gain from using context over generation without context -- and the quality of the final answers in terms of correctness and relevance. In this paper, we define two prediction tasks within RAG. The first is retrieval performance prediction (RPP), which estimates the utility of retrieved documents. The second is generation performance prediction (GPP), which estimates the final answer quality. We hypothesise that in RAG, the topical relevance of retrieved documents correlates with their utility, suggesting that query performance prediction (QPP) approaches can be adapted for RPP and GPP. Beyond these retriever-centric signals, we argue that reader-centric features, such as the LLM's perplexity of the retrieved context conditioned on the input query, can further enhance prediction accuracy for both RPP and GPP. Finally, we propose that features reflecting query-agnostic document quality and readability can also provide useful signals to the predictions. We train linear regression models with the above categories of predictors for both RPP and GPP. Experiments on the Natural Questions (NQ) dataset show that combining predictors from multiple feature categories yields the most accurate estimates of RAG performance.",
    "published": "2026-01-20T23:59:54Z",
    "pdf_url": "https://arxiv.org/pdf/2601.14546v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2007.02503v1",
    "title": "Tree-Augmented Cross-Modal Encoding for Complex-Query Video Retrieval",
    "authors": [
      "Xun Yang",
      "Jianfeng Dong",
      "Yixin Cao",
      "Xun Wang",
      "Meng Wang",
      "Tat-Seng Chua"
    ],
    "summary": "The rapid growth of user-generated videos on the Internet has intensified the need for text-based video retrieval systems. Traditional methods mainly favor the concept-based paradigm on retrieval with simple queries, which are usually ineffective for complex queries that carry far more complex semantics. Recently, embedding-based paradigm has emerged as a popular approach. It aims to map the queries and videos into a shared embedding space where semantically-similar texts and videos are much closer to each other. Despite its simplicity, it forgoes the exploitation of the syntactic structure of text queries, making it suboptimal to model the complex queries.\n  To facilitate video retrieval with complex queries, we propose a Tree-augmented Cross-modal Encoding method by jointly learning the linguistic structure of queries and the temporal representation of videos. Specifically, given a complex user query, we first recursively compose a latent semantic tree to structurally describe the text query. We then design a tree-augmented query encoder to derive structure-aware query representation and a temporal attentive video encoder to model the temporal characteristics of videos. Finally, both the query and videos are mapped into a joint embedding space for matching and ranking. In this approach, we have a better understanding and modeling of the complex queries, thereby achieving a better video retrieval performance. Extensive experiments on large scale video retrieval benchmark datasets demonstrate the effectiveness of our approach.",
    "published": "2020-07-06T02:50:27Z",
    "pdf_url": "https://arxiv.org/pdf/2007.02503v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2212.00999v1",
    "title": "Information Retrieval from the Digitized Books",
    "authors": [
      "Riya Gupta",
      "C. V. Jawahar"
    ],
    "summary": "Extracting the relevant information out of a large number of documents is a challenging and tedious task. The quality of results generated by the traditionally available full-text search engine and text-based image retrieval systems is not optimal. Information retrieval (IR) tasks become more challenging with the nontraditional language scripts, as in the case of Indic scripts. The authors have developed OCR (Optical Character Recognition) Search Engine to make an Information Retrieval & Extraction (IRE) system that replicates the current state-of-the-art methods using the IRE and Natural Language Processing (NLP) techniques. Here we have presented the study of the methods used for performing search and retrieval tasks. The details of this system, along with the statistics of the dataset (source: National Digital Library of India or NDLI), is also presented. Additionally, the ideas to further explore and add value to research in IRE are also discussed.",
    "published": "2022-12-02T06:36:57Z",
    "pdf_url": "https://arxiv.org/pdf/2212.00999v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2506.00054v1",
    "title": "Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers",
    "authors": [
      "Chaitanya Sharma"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to enhance large language models (LLMs) by conditioning generation on external evidence retrieved at inference time. While RAG addresses critical limitations of parametric knowledge storage-such as factual inconsistency and domain inflexibility-it introduces new challenges in retrieval quality, grounding fidelity, pipeline efficiency, and robustness against noisy or adversarial inputs. This survey provides a comprehensive synthesis of recent advances in RAG systems, offering a taxonomy that categorizes architectures into retriever-centric, generator-centric, hybrid, and robustness-oriented designs. We systematically analyze enhancements across retrieval optimization, context filtering, decoding control, and efficiency improvements, supported by comparative performance analyses on short-form and multi-hop question answering tasks. Furthermore, we review state-of-the-art evaluation frameworks and benchmarks, highlighting trends in retrieval-aware evaluation, robustness testing, and federated retrieval settings. Our analysis reveals recurring trade-offs between retrieval precision and generation flexibility, efficiency and faithfulness, and modularity and coordination. We conclude by identifying open challenges and future research directions, including adaptive retrieval architectures, real-time retrieval integration, structured reasoning over multi-hop evidence, and privacy-preserving retrieval mechanisms. This survey aims to consolidate current knowledge in RAG research and serve as a foundation for the next generation of retrieval-augmented language modeling systems.",
    "published": "2025-05-28T22:57:04Z",
    "pdf_url": "https://arxiv.org/pdf/2506.00054v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2408.02854v4",
    "title": "Creating a Taxonomy for Retrieval Augmented Generation Applications",
    "authors": [
      "Irina Nikishina",
      "\u00d6zge Sevgili",
      "Mahei Manhai Li",
      "Chris Biemann",
      "Martin Semmann"
    ],
    "summary": "In this research, we develop a taxonomy to conceptualize a comprehensive overview of the constituting characteristics that define retrieval augmented generation (RAG) applications, facilitating the adoption of this technology for different application domains. To the best of our knowledge, no holistic RAG application taxonomies have been developed so far. We employ the method foreign to ACL and thus contribute to the set of methods in the taxonomy creation. It comprises four iterative phases designed to refine and enhance our understanding and presentation of RAG's core dimensions. We have developed a total of five meta-dimensions and sixteen dimensions to comprehensively capture the concept of RAG applications. Thus, the taxonomy can be used to better understand RAG applications and to derive design knowledge for future solutions in specific application domains.",
    "published": "2024-08-05T22:34:28Z",
    "pdf_url": "https://arxiv.org/pdf/2408.02854v4.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2503.17876v1",
    "title": "Satisfactory Medical Consultation based on Terminology-Enhanced Information Retrieval and Emotional In-Context Learning",
    "authors": [
      "Kaiwen Zuo",
      "Jing Tang",
      "Hanbing Qin",
      "Binli Luo",
      "Ligang He",
      "Shiyan Tang"
    ],
    "summary": "Recent advancements in Large Language Models (LLMs) have marked significant progress in understanding and responding to medical inquiries. However, their performance still falls short of the standards set by professional consultations. This paper introduces a novel framework for medical consultation, comprising two main modules: Terminology-Enhanced Information Retrieval (TEIR) and Emotional In-Context Learning (EICL). TEIR ensures implicit reasoning through the utilization of inductive knowledge and key terminology retrieval, overcoming the limitations of restricted domain knowledge in public databases. Additionally, this module features capabilities for processing long context. The EICL module aids in generating sentences with high attribute relevance by memorizing semantic and attribute information from unlabelled corpora and applying controlled retrieval for the required information. Furthermore, a dataset comprising 803,564 consultation records was compiled in China, significantly enhancing the model's capability for complex dialogues and proactive inquiry initiation. Comprehensive experiments demonstrate the proposed method's effectiveness in extending the context window length of existing LLMs. The experimental outcomes and extensive data validate the framework's superiority over five baseline models in terms of BLEU and ROUGE performance metrics, with substantial leads in certain capabilities. Notably, ablation studies confirm the significance of the TEIR and EICL components. In addition, our new framework has the potential to significantly improve patient satisfaction in real clinical consulting situations.",
    "published": "2025-03-22T23:01:07Z",
    "pdf_url": "https://arxiv.org/pdf/2503.17876v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2411.02832v2",
    "title": "PersianRAG: A Retrieval-Augmented Generation System for Persian Language",
    "authors": [
      "Hossein Hosseini",
      "Mohammad Sobhan Zare",
      "Amir Hossein Mohammadi",
      "Arefeh Kazemi",
      "Zahra Zojaji",
      "Mohammad Ali Nematbakhsh"
    ],
    "summary": "Retrieval augmented generation (RAG) models, which integrate large-scale pre-trained generative models with external retrieval mechanisms, have shown significant success in various natural language processing (NLP) tasks. However, applying RAG models in Persian language as a low-resource language, poses distinct challenges. These challenges primarily involve the preprocessing, embedding, retrieval, prompt construction, language modeling, and response evaluation of the system. In this paper, we address the challenges towards implementing a real-world RAG system for Persian language called PersianRAG. We propose novel solutions to overcome these obstacles and evaluate our approach using several Persian benchmark datasets. Our experimental results demonstrate the capability of the PersianRAG framework to enhance question answering task in Persian.",
    "published": "2024-11-05T06:11:17Z",
    "pdf_url": "https://arxiv.org/pdf/2411.02832v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2511.15435v1",
    "title": "HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation",
    "authors": [
      "Linyin Luo",
      "Yujuan Ding",
      "Yunshan Ma",
      "Wenqi Fan",
      "Hanjiang Lai"
    ],
    "summary": "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.",
    "published": "2025-11-19T13:45:24Z",
    "pdf_url": "https://arxiv.org/pdf/2511.15435v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2504.05220v5",
    "title": "Utility-Focused LLM Annotation for Retrieval and Retrieval-Augmented Generation",
    "authors": [
      "Hengran Zhang",
      "Minghao Tang",
      "Keping Bi",
      "Jiafeng Guo",
      "Shihao Liu",
      "Daiting Shi",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "summary": "This paper explores the use of large language models (LLMs) for annotating document utility in training retrieval and retrieval-augmented generation (RAG) systems, aiming to reduce dependence on costly human annotations. We address the gap between retrieval relevance and generative utility by employing LLMs to annotate document utility. To effectively utilize multiple positive samples per query, we introduce a novel loss that maximizes their summed marginal likelihood. Using the Qwen-2.5-32B model, we annotate utility on the MS MARCO dataset and conduct retrieval experiments on MS MARCO and BEIR, as well as RAG experiments on MS MARCO QA, NQ, and HotpotQA. Our results show that LLM-generated annotations enhance out-of-domain retrieval performance and improve RAG outcomes compared to models trained solely on human annotations or downstream QA metrics. Furthermore, combining LLM annotations with just 20% of human labels achieves performance comparable to using full human annotations. Our study offers a comprehensive approach to utilizing LLM annotations for initializing QA systems on new corpora.",
    "published": "2025-04-07T16:05:52Z",
    "pdf_url": "https://arxiv.org/pdf/2504.05220v5.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2104.14994v2",
    "title": "GeoWINE: Geolocation based Wiki, Image,News and Event Retrieval",
    "authors": [
      "Golsa Tahmasebzadeh",
      "Endri Kacupaj",
      "Eric M\u00fcller-Budack",
      "Sherzod Hakimov",
      "Jens Lehmann",
      "Ralph Ewerth"
    ],
    "summary": "In the context of social media, geolocation inference on news or events has become a very important task. In this paper, we present the GeoWINE (Geolocation-based Wiki-Image-News-Event retrieval) demonstrator, an effective modular system for multimodal retrieval which expects only a single image as input. The GeoWINE system consists of five modules in order to retrieve related information from various sources. The first module is a state-of-the-art model for geolocation estimation of images. The second module performs a geospatial-based query for entity retrieval using the Wikidata knowledge graph. The third module exploits four different image embedding representations, which are used to retrieve most similar entities compared to the input image. The embeddings are derived from the tasks of geolocation estimation, place recognition, ImageNet-based image classification, and their combination. The last two modules perform news and event retrieval from EventRegistry and the Open Event Knowledge Graph (OEKG). GeoWINE provides an intuitive interface for end-users and is insightful for experts for reconfiguration to individual setups. The GeoWINE achieves promising results in entity label prediction for images on Google Landmarks dataset. The demonstrator is publicly available at http://cleopatra.ijs.si/geowine/.",
    "published": "2021-04-30T13:27:50Z",
    "pdf_url": "https://arxiv.org/pdf/2104.14994v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2403.10081v3",
    "title": "DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models",
    "authors": [
      "Weihang Su",
      "Yichen Tang",
      "Qingyao Ai",
      "Zhijing Wu",
      "Yiqun Liu"
    ],
    "summary": "Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs). There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to retrieve) and crafting the appropriate query once retrieval is triggered (determining what to retrieve). However, current dynamic RAG methods fall short in both aspects. Firstly, the strategies for deciding when to retrieve often rely on static rules. Moreover, the strategies for deciding what to retrieve typically limit themselves to the LLM's most recent sentence or the last few tokens, while the LLM's real-time information needs may span across the entire context. To overcome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic Retrieval Augmented Generation based on the real-time Information Needs of LLMs. Our framework is specifically designed to make decisions on when and what to retrieve based on the LLM's real-time information needs during the text generation process. We evaluate DRAGIN along with existing methods comprehensively over 4 knowledge-intensive generation datasets. Experimental results show that DRAGIN achieves superior performance on all tasks, demonstrating the effectiveness of our method. We have open-sourced all the code, data, and models in GitHub: https://github.com/oneal2000/DRAGIN/tree/main",
    "published": "2024-03-15T07:45:37Z",
    "pdf_url": "https://arxiv.org/pdf/2403.10081v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2505.16133v4",
    "title": "HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation",
    "authors": [
      "Jinyu Guo",
      "Xunlei Chen",
      "Qiyang Xia",
      "Zhaokun Wang",
      "Jie Ou",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) encounters efficiency challenges when scaling to massive knowledge bases while preserving contextual relevance. We propose Hash-RAG, a framework that integrates deep hashing techniques with systematic optimizations to address these limitations. Our queries directly learn binary hash codes from knowledgebase code, eliminating intermediate feature extraction steps, and significantly reducing storage and computational overhead. Building upon this hash-based efficient retrieval framework, we establish the foundation for fine-grained chunking. Consequently, we design a Prompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved hash-indexed propositions and their original document segments through prompt engineering to enhance the LLM's contextual awareness. Experimental evaluations on NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a 90% reduction in retrieval time compared to conventional methods while maintaining considerate recall performance. Additionally, The proposed system outperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.",
    "published": "2025-05-22T02:22:11Z",
    "pdf_url": "https://arxiv.org/pdf/2505.16133v4.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2401.15884v3",
    "title": "Corrective Retrieval Augmented Generation",
    "authors": [
      "Shi-Qi Yan",
      "Jia-Chen Gu",
      "Yun Zhu",
      "Zhen-Hua Ling"
    ],
    "summary": "Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose algorithm is designed for retrieved documents to selectively focus on key information and filter out irrelevant information in them. CRAG is plug-and-play and can be seamlessly coupled with various RAG-based approaches. Experiments on four datasets covering short- and long-form generation tasks show that CRAG can significantly improve the performance of RAG-based approaches.",
    "published": "2024-01-29T04:36:39Z",
    "pdf_url": "https://arxiv.org/pdf/2401.15884v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2410.20598v2",
    "title": "R^3AG: First Workshop on Refined and Reliable Retrieval Augmented Generation",
    "authors": [
      "Zihan Wang",
      "Xuri Ge",
      "Joemon M. Jose",
      "Haitao Yu",
      "Weizhi Ma",
      "Zhaochun Ren",
      "Xin Xin"
    ],
    "summary": "Retrieval-augmented generation (RAG) has gained wide attention as the key component to improve generative models with external knowledge augmentation from information retrieval. It has shown great prominence in enhancing the functionality and performance of large language model (LLM)-based applications. However, with the comprehensive application of RAG, more and more problems and limitations have been identified, thus urgently requiring further fundamental exploration to improve current RAG frameworks. This workshop aims to explore in depth how to conduct refined and reliable RAG for downstream AI tasks.\n  To this end, we propose to organize the first R3AG workshop at SIGIR-AP 2024 to call for participants to re-examine and formulate the basic principles and practical implementation of refined and reliable RAG. The workshop serves as a platform for both academia and industry researchers to conduct discussions, share insights, and foster research to build the next generation of RAG systems. Participants will engage in discussions and presentations focusing on fundamental challenges, cutting-edge research, and potential pathways to improve RAG. At the end of the workshop, we aim to have a clearer understanding of how to improve the reliability and applicability of RAG with more robust information retrieval and language generation.",
    "published": "2024-10-27T21:12:12Z",
    "pdf_url": "https://arxiv.org/pdf/2410.20598v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2004.11045v1",
    "title": "Distilling Knowledge for Fast Retrieval-based Chat-bots",
    "authors": [
      "Amir Vakili Tahami",
      "Kamyar Ghajar",
      "Azadeh Shakery"
    ],
    "summary": "Response retrieval is a subset of neural ranking in which a model selects a suitable response from a set of candidates given a conversation history. Retrieval-based chat-bots are typically employed in information seeking conversational systems such as customer support agents. In order to make pairwise comparisons between a conversation history and a candidate response, two approaches are common: cross-encoders performing full self-attention over the pair and bi-encoders encoding the pair separately. The former gives better prediction quality but is too slow for practical use. In this paper, we propose a new cross-encoder architecture and transfer knowledge from this model to a bi-encoder model using distillation. This effectively boosts bi-encoder performance at no cost during inference time. We perform a detailed analysis of this approach on three response retrieval datasets.",
    "published": "2020-04-23T09:41:37Z",
    "pdf_url": "https://arxiv.org/pdf/2004.11045v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2502.12442v2",
    "title": "HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation",
    "authors": [
      "Hao Liu",
      "Zhengren Wang",
      "Xi Chen",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Qinhan Yu",
      "Wentao Zhang"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) systems often struggle with imperfect retrieval, as traditional retrievers focus on lexical or semantic similarity rather than logical relevance. To address this, we propose \\textbf{HopRAG}, a novel RAG framework that augments retrieval with logical reasoning through graph-structured knowledge exploration. During indexing, HopRAG constructs a passage graph, with text chunks as vertices and logical connections established via LLM-generated pseudo-queries as edges. During retrieval, it employs a \\textit{retrieve-reason-prune} mechanism: starting with lexically or semantically similar passages, the system explores multi-hop neighbors guided by pseudo-queries and LLM reasoning to identify truly relevant ones. Experiments on multiple multi-hop benchmarks demonstrate that HopRAG's \\textit{retrieve-reason-prune} mechanism can expand the retrieval scope based on logical connections and improve final answer quality.",
    "published": "2025-02-18T02:24:42Z",
    "pdf_url": "https://arxiv.org/pdf/2502.12442v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2305.03660v1",
    "title": "Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models",
    "authors": [
      "Mercy Ranjit",
      "Gopinath Ganapathy",
      "Ranjit Manuel",
      "Tanuja Ganu"
    ],
    "summary": "We propose Retrieval Augmented Generation (RAG) as an approach for automated radiology report writing that leverages multimodally aligned embeddings from a contrastively pretrained vision language model for retrieval of relevant candidate radiology text for an input radiology image and a general domain generative model like OpenAI text-davinci-003, gpt-3.5-turbo and gpt-4 for report generation using the relevant radiology text retrieved. This approach keeps hallucinated generations under check and provides capabilities to generate report content in the format we desire leveraging the instruction following capabilities of these generative models. Our approach achieves better clinical metrics with a BERTScore of 0.2865 (\u0394+ 25.88%) and Semb score of 0.4026 (\u0394+ 6.31%). Our approach can be broadly relevant for different clinical settings as it allows to augment the automated radiology report generation process with content relevant for that setting while also having the ability to inject user intents and requirements in the prompts as part of the report generation process to modulate the content and format of the generated reports as applicable for that clinical setting.",
    "published": "2023-05-05T16:28:03Z",
    "pdf_url": "https://arxiv.org/pdf/2305.03660v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.13374v1",
    "title": "Smart Routing for Multimodal Video Retrieval: When to Search What",
    "authors": [
      "Kevin Dela Rosa"
    ],
    "summary": "We introduce ModaRoute, an LLM-based intelligent routing system that dynamically selects optimal modalities for multimodal video retrieval. While dense text captions can achieve 75.9% Recall@5, they require expensive offline processing and miss critical visual information present in 34% of clips with scene text not captured by ASR. By analyzing query intent and predicting information needs, ModaRoute reduces computational overhead by 41% while achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR (speech), OCR (text), and visual indices, averaging 1.78 modalities per query versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips demonstrates that intelligent routing provides a practical solution for scaling multimodal retrieval systems, reducing infrastructure costs while maintaining competitive effectiveness for real-world deployment.",
    "published": "2025-07-12T15:45:03Z",
    "pdf_url": "https://arxiv.org/pdf/2507.13374v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2508.03553v1",
    "title": "MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation",
    "authors": [
      "Wenlong Wu",
      "Haofen Wang",
      "Bohan Li",
      "Peixuan Huang",
      "Xinzhe Zhao",
      "Lei Liang"
    ],
    "summary": "Retrieval Augmented Generation (RAG) has emerged as a promising solution to address hallucination issues in Large Language Models (LLMs). However, the integration of multiple retrieval sources, while potentially more informative, introduces new challenges that can paradoxically exacerbate hallucination problems. These challenges manifest primarily in two aspects: the sparse distribution of multi-source data that hinders the capture of logical relationships and the inherent inconsistencies among different sources that lead to information conflicts. To address these challenges, we propose MultiRAG, a novel framework designed to mitigate hallucination in multi-source retrieval-augmented generation through knowledge-guided approaches. Our framework introduces two key innovations: (1) a knowledge construction module that employs multi-source line graphs to efficiently aggregate logical relationships across different knowledge sources, effectively addressing the sparse data distribution issue; and (2) a sophisticated retrieval module that implements a multi-level confidence calculation mechanism, performing both graph-level and node-level assessments to identify and eliminate unreliable information nodes, thereby reducing hallucinations caused by inter-source inconsistencies. Extensive experiments on four multi-domain query datasets and two multi-hop QA datasets demonstrate that MultiRAG significantly enhances the reliability and efficiency of knowledge retrieval in complex multi-source scenarios. \\textcolor{blue}{Our code is available in https://github.com/wuwenlong123/MultiRAG.",
    "published": "2025-08-05T15:20:52Z",
    "pdf_url": "https://arxiv.org/pdf/2508.03553v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2412.18431v2",
    "title": "GeAR: Graph-enhanced Agent for Retrieval-augmented Generation",
    "authors": [
      "Zhili Shen",
      "Chenxin Diao",
      "Pavlos Vougiouklis",
      "Pascual Merita",
      "Shriram Piramanayagam",
      "Enting Chen",
      "Damien Graux",
      "Andre Melo",
      "Ruofei Lai",
      "Zeren Jiang",
      "Zhongyang Li",
      "YE QI",
      "Yang Ren",
      "Dandan Tu",
      "Jeff Z. Pan"
    ],
    "summary": "Retrieval-augmented Generation (RAG) relies on effective retrieval capabilities, yet traditional sparse and dense retrievers inherently struggle with multi-hop retrieval scenarios. In this paper, we introduce GeAR, a system that advances RAG performance through two key innovations: (i) an efficient graph expansion mechanism that augments any conventional base retriever, such as BM25, and (ii) an agent framework that incorporates the resulting graph-based retrieval into a multi-step retrieval framework. Our evaluation demonstrates GeAR's superior retrieval capabilities across three multi-hop question answering datasets. Notably, our system achieves state-of-the-art results with improvements exceeding 10% on the challenging MuSiQue dataset, while consuming fewer tokens and requiring fewer iterations than existing multi-step retrieval systems. The project page is available at https://gear-rag.github.io.",
    "published": "2024-12-24T13:45:22Z",
    "pdf_url": "https://arxiv.org/pdf/2412.18431v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2405.17602v1",
    "title": "Augmenting Textual Generation via Topology Aware Retrieval",
    "authors": [
      "Yu Wang",
      "Nedim Lipka",
      "Ruiyi Zhang",
      "Alexa Siu",
      "Yuying Zhao",
      "Bo Ni",
      "Xin Wang",
      "Ryan Rossi",
      "Tyler Derr"
    ],
    "summary": "Despite the impressive advancements of Large Language Models (LLMs) in generating text, they are often limited by the knowledge contained in the input and prone to producing inaccurate or hallucinated content. To tackle these issues, Retrieval-augmented Generation (RAG) is employed as an effective strategy to enhance the available knowledge base and anchor the responses in reality by pulling additional texts from external databases. In real-world applications, texts are often linked through entities within a graph, such as citations in academic papers or comments in social networks. This paper exploits these topological relationships to guide the retrieval process in RAG. Specifically, we explore two kinds of topological connections: proximity-based, focusing on closely connected nodes, and role-based, which looks at nodes sharing similar subgraph structures. Our empirical research confirms their relevance to text relationships, leading us to develop a Topology-aware Retrieval-augmented Generation framework. This framework includes a retrieval module that selects texts based on their topological relationships and an aggregation module that integrates these texts into prompts to stimulate LLMs for text generation. We have curated established text-attributed networks and conducted comprehensive experiments to validate the effectiveness of this framework, demonstrating its potential to enhance RAG with topological awareness.",
    "published": "2024-05-27T19:02:18Z",
    "pdf_url": "https://arxiv.org/pdf/2405.17602v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2412.15404v1",
    "title": "A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science",
    "authors": [
      "Ahmet Yasin Aytar",
      "Kemal Kilic",
      "Kamer Kaya"
    ],
    "summary": "In the rapidly evolving field of data science, efficiently navigating the expansive body of academic literature is crucial for informed decision-making and innovation. This paper presents an enhanced Retrieval-Augmented Generation (RAG) application, an artificial intelligence (AI)-based system designed to assist data scientists in accessing precise and contextually relevant academic resources. The AI-powered application integrates advanced techniques, including the GeneRation Of BIbliographic Data (GROBID) technique for extracting bibliographic information, fine-tuned embedding models, semantic chunking, and an abstract-first retrieval method, to significantly improve the relevance and accuracy of the retrieved information. This implementation of AI specifically addresses the challenge of academic literature navigation. A comprehensive evaluation using the Retrieval-Augmented Generation Assessment System (RAGAS) framework demonstrates substantial improvements in key metrics, particularly Context Relevance, underscoring the system's effectiveness in reducing information overload and enhancing decision-making processes. Our findings highlight the potential of this enhanced Retrieval-Augmented Generation system to transform academic exploration within data science, ultimately advancing the workflow of research and innovation in the field.",
    "published": "2024-12-19T21:14:54Z",
    "pdf_url": "https://arxiv.org/pdf/2412.15404v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2509.21237v1",
    "title": "Query-Centric Graph Retrieval Augmented Generation",
    "authors": [
      "Yaxiong Wu",
      "Jianyuan Bo",
      "Yongyue Zhang",
      "Sheng Liang",
      "Yong Liu"
    ],
    "summary": "Graph-based retrieval-augmented generation (RAG) enriches large language models (LLMs) with external knowledge for long-context understanding and multi-hop reasoning, but existing methods face a granularity dilemma: fine-grained entity-level graphs incur high token costs and lose context, while coarse document-level graphs fail to capture nuanced relations. We introduce QCG-RAG, a query-centric graph RAG framework that enables query-granular indexing and multi-hop chunk retrieval. Our query-centric approach leverages Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with controllable granularity, improving graph quality and interpretability. A tailored multi-hop retrieval mechanism then selects relevant chunks via the generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG consistently outperforms prior chunk-based and graph-based RAG methods in question answering accuracy, establishing a new paradigm for multi-hop reasoning.",
    "published": "2025-09-25T14:35:44Z",
    "pdf_url": "https://arxiv.org/pdf/2509.21237v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.11262v1",
    "title": "Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings",
    "authors": [
      "Joanne Affolter",
      "Benjamin Martin",
      "Elena V. Epure",
      "Gabriel Meseguer-Brocal",
      "Fr\u00e9d\u00e9ric Kaplan"
    ],
    "summary": "Music Cover Retrieval, also known as Version Identification, aims to recognize distinct renditions of the same underlying musical work, a task central to catalog management, copyright enforcement, and music retrieval. State-of-the-art approaches have largely focused on harmonic and melodic features, employing increasingly complex audio pipelines designed to be invariant to musical attributes that often vary widely across covers. While effective, these methods demand substantial training time and computational resources. By contrast, lyrics constitute a strong invariant across covers, though their use has been limited by the difficulty of extracting them accurately and efficiently from polyphonic audio. Early methods relied on simple frameworks that limited downstream performance, while more recent systems deliver stronger results but require large models integrated within complex multimodal architectures. We introduce LIVI (Lyrics-Informed Version Identification), an approach that seeks to balance retrieval accuracy with computational efficiency. First, LIVI leverages supervision from state-of-the-art transcription and text embedding models during training to achieve retrieval accuracy on par with--or superior to--harmonic-based systems. Second, LIVI remains lightweight and efficient by removing the transcription step at inference, challenging the dominance of complexity-heavy pipelines.",
    "published": "2026-01-16T13:11:38Z",
    "pdf_url": "https://arxiv.org/pdf/2601.11262v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2505.03452v3",
    "title": "An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation",
    "authors": [
      "Matan Orbach",
      "Ohad Eytan",
      "Benjamin Sznajder",
      "Ariel Gera",
      "Odellia Boni",
      "Yoav Kantor",
      "Gal Bloch",
      "Omri Levy",
      "Hadas Abraham",
      "Nitzan Barzilay",
      "Eyal Shnarch",
      "Michael E. Factor",
      "Shila Ofek-Koifman",
      "Paula Ta-Shma",
      "Assaf Toledo"
    ],
    "summary": "Optimizing Retrieval-Augmented Generation (RAG) configurations for specific tasks is a complex and resource-intensive challenge. Motivated by this challenge, frameworks for RAG hyper-parameter optimization (HPO) have recently emerged, yet their effectiveness has not been rigorously benchmarked. To fill this gap, we present a comprehensive study involving five HPO algorithms over five datasets from diverse domains, including a newly curated real-world product documentation dataset. Our study explores the largest RAG HPO search space to date that includes full grid-search evaluations, and uses three evaluation metrics as optimization targets. Analysis of the results shows that RAG HPO can be done efficiently, either greedily or with random search, and that it significantly boosts RAG performance for all datasets. For greedy HPO approaches, we show that optimizing model selection first is preferable to the common practice of following the RAG pipeline order during optimization.",
    "published": "2025-05-06T11:47:52Z",
    "pdf_url": "https://arxiv.org/pdf/2505.03452v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2509.04820v1",
    "title": "Fishing for Answers: Exploring One-shot vs. Iterative Retrieval Strategies for Retrieval Augmented Generation",
    "authors": [
      "Huifeng Lin",
      "Gang Su",
      "Jintao Liang",
      "You Wu",
      "Rui Zhao",
      "Ziyue Li"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) based on Large Language Models (LLMs) is a powerful solution to understand and query the industry's closed-source documents. However, basic RAG often struggles with complex QA tasks in legal and regulatory domains, particularly when dealing with numerous government documents. The top-$k$ strategy frequently misses golden chunks, leading to incomplete or inaccurate answers. To address these retrieval bottlenecks, we explore two strategies to improve evidence coverage and answer quality. The first is a One-SHOT retrieval method that adaptively selects chunks based on a token budget, allowing as much relevant content as possible to be included within the model's context window. Additionally, we design modules to further filter and refine the chunks. The second is an iterative retrieval strategy built on a Reasoning Agentic RAG framework, where a reasoning LLM dynamically issues search queries, evaluates retrieved results, and progressively refines the context over multiple turns. We identify query drift and retrieval laziness issues and further design two modules to tackle them. Through extensive experiments on a dataset of government documents, we aim to offer practical insights and guidance for real-world applications in legal and regulatory domains.",
    "published": "2025-09-05T05:44:50Z",
    "pdf_url": "https://arxiv.org/pdf/2509.04820v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2307.06985v10",
    "title": "Retrieval Augmented Generation using Engineering Design Knowledge",
    "authors": [
      "L. Siddharth",
      "Jianxi Luo"
    ],
    "summary": "Aiming to support Retrieval Augmented Generation (RAG) in the design process, we present a method to identify explicit, engineering design facts - {head entity :: relationship :: tail entity} from patented artefact descriptions. Given a sentence with a pair of entities (based on noun phrases) marked in a unique manner, our method extracts the relationship that is explicitly communicated in the sentence. For this task, we create a dataset of 375,084 examples and fine-tune language models for relation identification (token classification) and elicitation (sequence-to-sequence). The token classification approach achieves up to 99.7 % accuracy. Upon applying the method to a domain of 4,870 fan system patents, we populate a knowledge base of over 2.93 million facts. Using this knowledge base, we demonstrate how Large Language Models (LLMs) are guided by explicit facts to synthesise knowledge and generate technical and cohesive responses when sought out for knowledge retrieval tasks in the design process.",
    "published": "2023-07-13T17:25:28Z",
    "pdf_url": "https://arxiv.org/pdf/2307.06985v10.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.03479v1",
    "title": "Explainable Information Retrieval in the Audit Domain",
    "authors": [
      "Alexander Frummet",
      "Emanuel Slany",
      "Jonas Amling",
      "Moritz Lang",
      "Stephan Scheele"
    ],
    "summary": "Conversational agents such as Microsoft Copilot and Google Gemini assist users with complex search tasks but often generate misleading or fabricated references. This undermines trust, particularly in high-stakes domains such as medicine and finance. Explainable information retrieval (XIR) aims to address this by making search results more transparent and interpretable. While most XIR research is domain-agnostic, this paper focuses on auditing -- a critical yet underexplored area. We argue that XIR systems can support auditors in completing their complex task. We outline key challenges and future research directions to advance XIR in this domain.",
    "published": "2025-07-04T11:07:20Z",
    "pdf_url": "https://arxiv.org/pdf/2507.03479v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2602.10271v3",
    "title": "MLDocRAG: Multimodal Long-Context Document Retrieval Augmented Generation",
    "authors": [
      "Yongyue Zhang",
      "Yaxiong Wu"
    ],
    "summary": "Understanding multimodal long-context documents that comprise multimodal chunks such as paragraphs, figures, and tables is challenging due to (1) cross-modal heterogeneity to localize relevant information across modalities, (2) cross-page reasoning to aggregate dispersed evidence across pages. To address these challenges, we are motivated to adopt a query-centric formulation that projects cross-modal and cross-page information into a unified query representation space, with queries acting as abstract semantic surrogates for heterogeneous multimodal content. In this paper, we propose a Multimodal Long-Context Document Retrieval Augmented Generation (MLDocRAG) framework that leverages a Multimodal Chunk-Query Graph (MCQG) to organize multimodal document content around semantically rich, answerable queries. MCQG is constructed via a multimodal document expansion process that generates fine-grained queries from heterogeneous document chunks and links them to their corresponding content across modalities and pages. This graph-based structure enables selective, query-centric retrieval and structured evidence aggregation, thereby enhancing grounding and coherence in multimodal long-context question answering. Experiments on datasets MMLongBench-Doc and LongDocURL demonstrate that MLDocRAG consistently improves retrieval quality and answer accuracy, demonstrating its effectiveness for multimodal long-context understanding.",
    "published": "2026-02-10T20:29:10Z",
    "pdf_url": "https://arxiv.org/pdf/2602.10271v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "1908.07590v1",
    "title": "From Text to Sound: A Preliminary Study on Retrieving Sound Effects to Radio Stories",
    "authors": [
      "Songwei Ge",
      "Curtis Xuan",
      "Ruihua Song",
      "Chao Zou",
      "Wei Liu",
      "Jin Zhou"
    ],
    "summary": "Sound effects play an essential role in producing high-quality radio stories but require enormous labor cost to add. In this paper, we address the problem of automatically adding sound effects to radio stories with a retrieval-based model. However, directly implementing a tag-based retrieval model leads to high false positives due to the ambiguity of story contents. To solve this problem, we introduce a retrieval-based framework hybridized with a semantic inference model which helps to achieve robust retrieval results. Our model relies on fine-designed features extracted from the context of candidate triggers. We collect two story dubbing datasets through crowdsourcing to analyze the setting of adding sound effects and to train and test our proposed methods. We further discuss the importance of each feature and introduce several heuristic rules for the trade-off between precision and recall. Together with the text-to-speech technology, our results reveal a promising automatic pipeline on producing high-quality radio stories.",
    "published": "2019-08-20T20:10:05Z",
    "pdf_url": "https://arxiv.org/pdf/1908.07590v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.21125v1",
    "title": "RATE: An LLM-Powered Retrieval Augmented Generation Technology-Extraction Pipeline",
    "authors": [
      "Karan Mirhosseini",
      "Arya Aftab",
      "Alireza Sheikh"
    ],
    "summary": "In an era of radical technology transformations, technology maps play a crucial role in enhancing decision making. These maps heavily rely on automated methods of technology extraction. This paper introduces Retrieval Augmented Technology Extraction (RATE), a Large Language Model (LLM) based pipeline for automated technology extraction from scientific literature. RATE combines Retrieval Augmented Generation (RAG) with multi-definition LLM-based validation. This hybrid method results in high recall in candidate generation alongside with high precision in candidate filtering. While the pipeline is designed to be general and widely applicable, we demonstrate its use on 678 research articles focused on Brain-Computer Interfaces (BCIs) and Extended Reality (XR) as a case study. Consequently, The validated technology terms by RATE were mapped into a co-occurrence network, revealing thematic clusters and structural features of the research landscape. For the purpose of evaluation, a gold standard dataset of technologies in 70 selected random articles had been curated by the experts. In addition, a technology extraction model based on Bidirectional Encoder Representations of Transformers (BERT) was used as a comparative method. RATE achieved F1-score of 91.27%, Significantly outperforming BERT with F1-score of 53.73%. Our findings highlight the promise of definition-driven LLM methods for technology extraction and mapping. They also offer new insights into emerging trends within the BCI-XR field. The source code is available https://github.com/AryaAftab/RATE",
    "published": "2025-07-19T19:00:27Z",
    "pdf_url": "https://arxiv.org/pdf/2507.21125v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2410.15944v1",
    "title": "Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report",
    "authors": [
      "Ayman Asad Khan",
      "Md Toufique Hasan",
      "Kai Kristian Kemell",
      "Jussi Rasku",
      "Pekka Abrahamsson"
    ],
    "summary": "This paper presents an experience report on the development of Retrieval Augmented Generation (RAG) systems using PDF documents as the primary data source. The RAG architecture combines generative capabilities of Large Language Models (LLMs) with the precision of information retrieval. This approach has the potential to redefine how we interact with and augment both structured and unstructured knowledge in generative models to enhance transparency, accuracy, and contextuality of responses. The paper details the end-to-end pipeline, from data collection, preprocessing, to retrieval indexing and response generation, highlighting technical challenges and practical solutions. We aim to offer insights to researchers and practitioners developing similar systems using two distinct approaches: OpenAI's Assistant API with GPT Series and Llama's open-source models. The practical implications of this research lie in enhancing the reliability of generative AI systems in various sectors where domain-specific knowledge and real-time information retrieval is important. The Python code used in this work is also available at: https://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.",
    "published": "2024-10-21T12:21:49Z",
    "pdf_url": "https://arxiv.org/pdf/2410.15944v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2411.06237v2",
    "title": "Leveraging Retrieval-Augmented Generation for Persian University Knowledge Retrieval",
    "authors": [
      "Arshia Hemmat",
      "Kianoosh Vadaei",
      "Mohammad Hassan Heydari",
      "Afsaneh Fatemi"
    ],
    "summary": "This paper introduces an innovative approach using Retrieval-Augmented Generation (RAG) pipelines with Large Language Models (LLMs) to enhance information retrieval and query response systems for university-related question answering. By systematically extracting data from the university official webpage and employing advanced prompt engineering techniques, we generate accurate, contextually relevant responses to user queries.\n  We developed a comprehensive university benchmark, UniversityQuestionBench (UQB), to rigorously evaluate our system performance, based on common key metrics in the filed of RAG pipelines, assessing accuracy and reliability through various metrics and real-world scenarios. Our experimental results demonstrate significant improvements in the precision and relevance of generated responses, enhancing user experience and reducing the time required to obtain relevant answers. In summary, this paper presents a novel application of RAG pipelines and LLMs, supported by a meticulously prepared university benchmark, offering valuable insights into advanced AI techniques for academic data retrieval and setting the stage for future research in this domain.",
    "published": "2024-11-09T17:38:01Z",
    "pdf_url": "https://arxiv.org/pdf/2411.06237v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.13222v1",
    "title": "Incorporating Q&A Nuggets into Retrieval-Augmented Generation",
    "authors": [
      "Laura Dietz",
      "Bryan Li",
      "Gabrielle Liu",
      "Jia-Huei Ju",
      "Eugene Yang",
      "Dawn Lawrie",
      "William Walden",
      "James Mayfield"
    ],
    "summary": "RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",
    "published": "2026-01-19T16:57:33Z",
    "pdf_url": "https://arxiv.org/pdf/2601.13222v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2402.16874v1",
    "title": "Enhancing Retrieval Processes for Language Generation with Augmented Queries",
    "authors": [
      "Julien Pierre Edmond Ghali",
      "Kosuke Shima",
      "Koichi Moriyama",
      "Atsuko Mutoh",
      "Nobuhiro Inuzuka"
    ],
    "summary": "In the rapidly changing world of smart technology, searching for documents has become more challenging due to the rise of advanced language models. These models sometimes face difficulties, like providing inaccurate information, commonly known as \"hallucination.\" This research focuses on addressing this issue through Retrieval-Augmented Generation (RAG), a technique that guides models to give accurate responses based on real facts. To overcome scalability issues, the study explores connecting user queries with sophisticated language models such as BERT and Orca2, using an innovative query optimization process. The study unfolds in three scenarios: first, without RAG, second, without additional assistance, and finally, with extra help. Choosing the compact yet efficient Orca2 7B model demonstrates a smart use of computing resources. The empirical results indicate a significant improvement in the initial language model's performance under RAG, particularly when assisted with prompts augmenters. Consistency in document retrieval across different encodings highlights the effectiveness of using language model-generated queries. The introduction of UMAP for BERT further simplifies document retrieval while maintaining strong results.",
    "published": "2024-02-06T13:19:53Z",
    "pdf_url": "https://arxiv.org/pdf/2402.16874v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2512.14313v1",
    "title": "Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias",
    "authors": [
      "Malika Iratni",
      "Mohand Boughanem",
      "Taoufiq Dkaki"
    ],
    "summary": "Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the \"lost in the middle\" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.",
    "published": "2025-12-16T11:30:40Z",
    "pdf_url": "https://arxiv.org/pdf/2512.14313v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2509.21336v1",
    "title": "HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores",
    "authors": [
      "Guohang Yan",
      "Yue Zhang",
      "Pinlong Cai",
      "Ding Wang",
      "Song Mao",
      "Hongwei Zhang",
      "Yaoze Zhang",
      "Hairong Zhang",
      "Xinyu Cai",
      "Botian Shi"
    ],
    "summary": "Retrieval-augmented generation (RAG) has become a dominant paradigm for mitigating knowledge hallucination and staleness in large language models (LLMs) while preserving data security. By retrieving relevant evidence from private, domain-specific corpora and injecting it into carefully engineered prompts, RAG delivers trustworthy responses without the prohibitive cost of fine-tuning. Traditional retrieval-augmented generation (RAG) systems are text-only and often rely on a single storage backend, most commonly a vector database. In practice, this monolithic design suffers from unavoidable trade-offs: vector search captures semantic similarity yet loses global context; knowledge graphs excel at relational precision but struggle with recall; full-text indexes are fast and exact yet semantically blind; and relational engines such as MySQL provide strong transactional guarantees but no semantic understanding. We argue that these heterogeneous retrieval paradigms are complementary, and propose a principled fusion scheme to orchestrate them synergistically, mitigating the weaknesses of any single modality. In this work we introduce HetaRAG, a hybrid, deep-retrieval augmented generation framework that orchestrates cross-modal evidence from heterogeneous data stores. We plan to design a system that unifies vector indices, knowledge graphs, full-text engines, and structured databases into a single retrieval plane, dynamically routing and fusing evidence to maximize recall, precision, and contextual fidelity. To achieve this design goal, we carried out preliminary explorations and constructed an initial RAG pipeline; this technical report provides a brief overview. The partial code is available at https://github.com/KnowledgeXLab/HetaRAG.",
    "published": "2025-09-12T06:12:59Z",
    "pdf_url": "https://arxiv.org/pdf/2509.21336v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.10644v1",
    "title": "RoutIR: Fast Serving of Retrieval Pipelines for Retrieval-Augmented Generation",
    "authors": [
      "Eugene Yang",
      "Andrew Yates",
      "Dawn Lawrie",
      "James Mayfield",
      "Trevor Adriaanse"
    ],
    "summary": "Retrieval models are key components of Retrieval-Augmented Generation (RAG) systems, which generate search queries, process the documents returned, and generate a response. RAG systems are often dynamic and may involve multiple rounds of retrieval. While many state-of-the-art retrieval methods are available through academic IR platforms, these platforms are typically designed for the Cranfield paradigm in which all queries are known up front and can be batch processed offline. This simplification accelerates research but leaves state-of-the-art retrieval models unable to support downstream applications that require online services, such as arbitrary dynamic RAG pipelines that involve looping, feedback, or even self-organizing agents. In this work, we introduce RoutIR, a Python package that provides a simple and efficient HTTP API that wraps arbitrary retrieval methods, including first stage retrieval, reranking, query expansion, and result fusion. By providing a minimal JSON configuration file specifying the retrieval models to serve, RoutIR can be used to construct and query retrieval pipelines on-the-fly using any permutation of available models (e.g., fusing the results of several first-stage retrieval methods followed by reranking). The API automatically performs asynchronous query batching and caches results by default. While many state-of-the-art retrieval methods are already supported by the package, RoutIR is also easily expandable by implementing the Engine abstract class. The package is open-sourced and publicly available on GitHub: http://github.com/hltcoe/routir.",
    "published": "2026-01-15T18:04:43Z",
    "pdf_url": "https://arxiv.org/pdf/2601.10644v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2506.20844v2",
    "title": "The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers",
    "authors": [
      "Xingyu Deng",
      "Xi Wang",
      "Mark Stevenson"
    ],
    "summary": "Scientific fact-checking aims to determine the veracity of scientific claims by retrieving and analysing evidence from research literature. The problem is inherently more complex than general fact-checking since it must accommodate the evolving nature of scientific knowledge, the structural complexity of academic literature and the challenges posed by long-form, multimodal scientific expression. However, existing approaches focus on simplified versions of the problem based on small-scale datasets consisting of abstracts rather than full papers, thereby avoiding the distinct challenges associated with processing complete documents. This paper examines the limitations of current scientific fact-checking systems and reveals the many potential features and resources that could be exploited to advance their performance. It identifies key research challenges within evidence retrieval, including (1) evidence-driven retrieval that addresses semantic limitations and topic imbalance (2) time-aware evidence retrieval with citation tracking to mitigate outdated information, (3) structured document parsing to leverage long-range context, (4) handling complex scientific expressions, including tables, figures, and domain-specific terminology and (5) assessing the credibility of scientific literature. Preliminary experiments were conducted to substantiate these challenges and identify potential solutions. This perspective paper aims to advance scientific fact-checking with a specialised IR system tailored for real-world applications.",
    "published": "2025-06-25T21:29:33Z",
    "pdf_url": "https://arxiv.org/pdf/2506.20844v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2505.07917v2",
    "title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation",
    "authors": [
      "Linus Stuhlmann",
      "Michael Alexander Saxer",
      "Jonathan F\u00fcrst"
    ],
    "summary": "Biomedical question-answering (QA) systems require effective retrieval and generation components to ensure accuracy, efficiency, and scalability. This study systematically examines a Retrieval-Augmented Generation (RAG) system for biomedical QA, evaluating retrieval strategies and response time trade-offs. We first assess state-of-the-art retrieval methods, including BM25, BioBERT, MedCPT, and a hybrid approach, alongside common data stores such as Elasticsearch, MongoDB, and FAISS, on a ~10% subset of PubMed (2.4M documents) to measure indexing efficiency, retrieval latency, and retriever performance in the end-to-end RAG system. Based on these insights, we deploy the final RAG system on the full 24M PubMed corpus, comparing different retrievers' impact on overall performance. Evaluations of the retrieval depth show that retrieving 50 documents with BM25 before reranking with MedCPT optimally balances accuracy (0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains stable (82ms), while MedCPT incurs the main computational cost. These results highlight previously not well-known trade-offs in retrieval depth, efficiency, and scalability for biomedical QA. With open-source code, the system is fully reproducible and extensible.",
    "published": "2025-05-12T14:51:47Z",
    "pdf_url": "https://arxiv.org/pdf/2505.07917v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2309.12158v1",
    "title": "Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval",
    "authors": [
      "Luis Carvalho",
      "Gerhard Widmer"
    ],
    "summary": "A range of applications of multi-modal music information retrieval is centred around the problem of connecting large collections of sheet music (images) to corresponding audio recordings, that is, identifying pairs of audio and score excerpts that refer to the same musical content. One of the typical and most recent approaches to this task employs cross-modal deep learning architectures to learn joint embedding spaces that link the two distinct modalities - audio and sheet music images. While there has been steady improvement on this front over the past years, a number of open problems still prevent large-scale employment of this methodology. In this article we attempt to provide an insightful examination of the current developments on audio-sheet music retrieval via deep learning methods. We first identify a set of main challenges on the road towards robust and large-scale cross-modal music retrieval in real scenarios. We then highlight the steps we have taken so far to address some of these challenges, documenting step-by-step improvement along several dimensions. We conclude by analysing the remaining challenges and present ideas for solving these, in order to pave the way to a unified and robust methodology for cross-modal music retrieval.",
    "published": "2023-09-21T15:11:16Z",
    "pdf_url": "https://arxiv.org/pdf/2309.12158v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2511.01386v1",
    "title": "RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets",
    "authors": [
      "Muhammed Yusuf Kartal",
      "Suha Kagan Kose",
      "Korhan Sevin\u00e7",
      "Burak Aktas"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) quality depends on many interacting choices across retrieval, ranking, augmentation, prompting, and generation, so optimizing modules in isolation is brittle. We introduce RAGSmith, a modular framework that treats RAG design as an end-to-end architecture search over nine technique families and 46{,}080 feasible pipeline configurations. A genetic search optimizes a scalar objective that jointly aggregates retrieval metrics (recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic similarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law, Finance, Medicine, Defense Industry, Computer Science), each with 100 questions spanning factual, interpretation, and long-answer types. RAGSmith finds configurations that consistently outperform naive RAG baseline by +3.8\\% on average (range +1.2\\% to +6.9\\% across domains), with gains up to +12.5\\% in retrieval and +7.5\\% in generation. The search typically explores $\\approx 0.2\\%$ of the space ($\\sim 100$ candidates) and discovers a robust backbone -- vector retrieval plus post-generation reflection/revision -- augmented by domain-dependent choices in expansion, reranking, augmentation, and prompt reordering; passage compression is never selected. Improvement magnitude correlates with question type, with larger gains on factual/long-answer mixes than interpretation-heavy sets. These results provide practical, domain-aware guidance for assembling effective RAG systems and demonstrate the utility of evolutionary search for full-pipeline optimization.",
    "published": "2025-11-03T09:36:27Z",
    "pdf_url": "https://arxiv.org/pdf/2511.01386v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2506.22210v1",
    "title": "UiS-IAI@LiveRAG: Retrieval-Augmented Information Nugget-Based Generation of Responses",
    "authors": [
      "Weronika \u0141ajewska",
      "Ivica Kostric",
      "Gabriel Iturra-Bocaz",
      "Mariam Arustashvili",
      "Krisztian Balog"
    ],
    "summary": "Retrieval-augmented generation (RAG) faces challenges related to factual correctness, source attribution, and response completeness. The LiveRAG Challenge hosted at SIGIR'25 aims to advance RAG research using a fixed corpus and a shared, open-source LLM. We propose a modular pipeline that operates on information nuggets-minimal, atomic units of relevant information extracted from retrieved documents. This multistage pipeline encompasses query rewriting, passage retrieval and reranking, nugget detection and clustering, cluster ranking and summarization, and response fluency enhancement. This design inherently promotes grounding in specific facts, facilitates source attribution, and ensures maximum information inclusion within length constraints. In this challenge, we extend our focus to also address the retrieval component of RAG, building upon our prior work on multi-faceted query rewriting. Furthermore, for augmented generation, we concentrate on improving context curation capabilities, maximizing the breadth of information covered in the response while ensuring pipeline efficiency. Our results show that combining original queries with a few sub-query rewrites boosts recall, while increasing the number of documents used for reranking and generation beyond a certain point reduces effectiveness, without improving response quality.",
    "published": "2025-06-27T13:29:25Z",
    "pdf_url": "https://arxiv.org/pdf/2506.22210v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2511.05494v1",
    "title": "Customized Retrieval-Augmented Generation with LLM for Debiasing Recommendation Unlearning",
    "authors": [
      "Haichao Zhang",
      "Chong Zhang",
      "Peiyu Hu",
      "Shi Qiu",
      "Jia Wang"
    ],
    "summary": "Modern recommender systems face a critical challenge in complying with privacy regulations like the 'right to be forgotten': removing a user's data without disrupting recommendations for others. Traditional unlearning methods address this by partial model updates, but introduce propagation bias--where unlearning one user's data distorts recommendations for behaviorally similar users, degrading system accuracy. While retraining eliminates bias, it is computationally prohibitive for large-scale systems. To address this challenge, we propose CRAGRU, a novel framework leveraging Retrieval-Augmented Generation (RAG) for efficient, user-specific unlearning that mitigates bias while preserving recommendation quality. CRAGRU decouples unlearning into distinct retrieval and generation stages. In retrieval, we employ three tailored strategies designed to precisely isolate the target user's data influence, minimizing collateral impact on unrelated users and enhancing unlearning efficiency. Subsequently, the generation stage utilizes an LLM, augmented with user profiles integrated into prompts, to reconstruct accurate and personalized recommendations without needing to retrain the entire base model. Experiments on three public datasets demonstrate that CRAGRU effectively unlearns targeted user data, significantly mitigating unlearning bias by preventing adverse impacts on non-target users, while maintaining recommendation performance comparable to fully trained original models. Our work highlights the promise of RAG-based architectures for building robust and privacy-preserving recommender systems. The source code is available at: https://github.com/zhanghaichao520/LLM_rec_unlearning.",
    "published": "2025-09-10T08:49:58Z",
    "pdf_url": "https://arxiv.org/pdf/2511.05494v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2503.23013v1",
    "title": "DAT: Dynamic Alpha Tuning for Hybrid Retrieval in Retrieval-Augmented Generation",
    "authors": [
      "Hsin-Ling Hsu",
      "Jengnan Tzeng"
    ],
    "summary": "Hybrid retrieval techniques in Retrieval-Augmented Generation (RAG) systems enhance information retrieval by combining dense and sparse (e.g., BM25-based) retrieval methods. However, existing approaches struggle with adaptability, as fixed weighting schemes fail to adjust to different queries. To address this, we propose DAT (Dynamic Alpha Tuning), a novel hybrid retrieval framework that dynamically balances dense retrieval and BM25 for each query. DAT leverages a large language model (LLM) to evaluate the effectiveness of the top-1 results from both retrieval methods, assigning an effectiveness score to each. It then calibrates the optimal weighting factor through effectiveness score normalization, ensuring a more adaptive and query-aware weighting between the two approaches. Empirical results show that DAT consistently significantly outperforms fixed-weighting hybrid retrieval methods across various evaluation metrics. Even on smaller models, DAT delivers strong performance, highlighting its efficiency and adaptability.",
    "published": "2025-03-29T08:35:01Z",
    "pdf_url": "https://arxiv.org/pdf/2503.23013v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2005.12992v1",
    "title": "Evaluating Information Retrieval Systems for Kids",
    "authors": [
      "Ashlee Milton",
      "Maria Soledad Pera"
    ],
    "summary": "Evaluation of information retrieval systems (IRS) is a prominent topic among information retrieval researchers--mainly directed at a general population. Children require unique IRS and by extension different ways to evaluate these systems, but as a large population that use IRS have largely been ignored on the evaluation front. In this position paper, we explore many perspectives that must be considered when evaluating IRS; we specially discuss problems faced by researchers who work with children IRS, including lack of evaluation frameworks, limitations of data, and lack of user judgment understanding.",
    "published": "2020-05-21T18:10:21Z",
    "pdf_url": "https://arxiv.org/pdf/2005.12992v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2508.09460v1",
    "title": "Towards Self-cognitive Exploration: Metacognitive Knowledge Graph Retrieval Augmented Generation",
    "authors": [
      "Xujie Yuan",
      "Shimin Di",
      "Jielong Tang",
      "Libin Zheng",
      "Jian Yin"
    ],
    "summary": "Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) significantly enhances the reasoning capabilities of LargeLanguage Models by leveraging structured knowledge. However, existing KG-RAG frameworks typically operate as open-loop systems, suffering from cognitive blindness, an inability to recognize their exploration deficiencies. This leads to relevance drift and incomplete evidence, which existing self-refinement methods, designed for unstructured text-based RAG, cannot effectively resolve due to the path-dependent nature of graph exploration. To address this challenge, we propose Metacognitive Knowledge Graph Retrieval Augmented Generation (MetaKGRAG), a novel framework inspired by the human metacognition process, which introduces a Perceive-Evaluate-Adjust cycle to enable path-aware, closed-loop refinement. This cycle empowers the system to self-assess exploration quality, identify deficiencies in coverage or relevance, and perform trajectory-connected corrections from precise pivot points. Extensive experiments across five datasets in the medical, legal, and commonsense reasoning domains demonstrate that MetaKGRAG consistently outperforms strong KG-RAG and self-refinement baselines. Our results validate the superiority of our approach and highlight the critical need for path-aware refinement in structured knowledge retrieval.",
    "published": "2025-08-13T03:35:32Z",
    "pdf_url": "https://arxiv.org/pdf/2508.09460v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.09188v1",
    "title": "Retrieval-Augmented Recommendation Explanation Generation with Hierarchical Aggregation",
    "authors": [
      "Bangcheng Sun",
      "Yazhe Chen",
      "Jilin Yang",
      "Xiaodong Li",
      "Hui Li"
    ],
    "summary": "Explainable Recommender System (ExRec) provides transparency to the recommendation process, increasing users' trust and boosting the operation of online services. With the rise of large language models (LLMs), whose extensive world knowledge and nuanced language understanding enable the generation of human-like, contextually grounded explanations, LLM-powered ExRec has gained great momentum. However, existing LLM-based ExRec models suffer from profile deviation and high retrieval overhead, hindering their deployment. To address these issues, we propose Retrieval-Augmented Recommendation Explanation Generation with Hierarchical Aggregation (REXHA). Specifically, we design a hierarchical aggregation based profiling module that comprehensively considers user and item review information, hierarchically summarizing and constructing holistic profiles. Furthermore, we introduce an efficient retrieval module using two types of pseudo-document queries to retrieve relevant reviews to enhance the generation of recommendation explanations, effectively reducing retrieval latency and improving the recall of relevant reviews. Extensive experiments demonstrate that our method outperforms existing approaches by up to 12.6% w.r.t. the explanation quality while achieving high retrieval efficiency.",
    "published": "2025-07-12T08:15:05Z",
    "pdf_url": "https://arxiv.org/pdf/2507.09188v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2511.05385v1",
    "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework",
    "authors": [
      "Chao Zhang",
      "Yuhao Wang",
      "Derong Xu",
      "Haoxin Zhang",
      "Yuanjie Lyu",
      "Yuhao Chen",
      "Shuochen Liu",
      "Tong Xu",
      "Xiangyu Zhao",
      "Yan Gao",
      "Yao Hu",
      "Enhong Chen"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur substantial token overhead from search and reasoning processes. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, a token-efficient agentic RAG framework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at https://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
    "published": "2025-11-07T16:08:34Z",
    "pdf_url": "https://arxiv.org/pdf/2511.05385v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2404.10981v2",
    "title": "A Survey on Retrieval-Augmented Text Generation for Large Language Models",
    "authors": [
      "Yizheng Huang",
      "Jimmy Huang"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) merges retrieval methods with deep learning advancements to address the static limitations of large language models (LLMs) by enabling the dynamic integration of up-to-date external information. This methodology, focusing primarily on the text domain, provides a cost-effective solution to the generation of plausible but possibly incorrect responses by LLMs, thereby enhancing the accuracy and reliability of their outputs through the use of real-world data. As RAG grows in complexity and incorporates multiple concepts that can influence its performance, this paper organizes the RAG paradigm into four categories: pre-retrieval, retrieval, post-retrieval, and generation, offering a detailed perspective from the retrieval viewpoint. It outlines RAG's evolution and discusses the field's progression through the analysis of significant studies. Additionally, the paper introduces evaluation methods for RAG, addressing the challenges faced and proposing future research directions. By offering an organized framework and categorization, the study aims to consolidate existing research on RAG, clarify its technological underpinnings, and highlight its potential to broaden the adaptability and applications of LLMs.",
    "published": "2024-04-17T01:27:42Z",
    "pdf_url": "https://arxiv.org/pdf/2404.10981v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2503.02922v1",
    "title": "Optimizing open-domain question answering with graph-based retrieval augmented generation",
    "authors": [
      "Joyce Cahoon",
      "Prerna Singh",
      "Nick Litombe",
      "Jonathan Larson",
      "Ha Trinh",
      "Yiwen Zhu",
      "Andreas Mueller",
      "Fotis Psallidas",
      "Carlo Curino"
    ],
    "summary": "In this work, we benchmark various graph-based retrieval-augmented generation (RAG) systems across a broad spectrum of query types, including OLTP-style (fact-based) and OLAP-style (thematic) queries, to address the complex demands of open-domain question answering (QA). Traditional RAG methods often fall short in handling nuanced, multi-document synthesis tasks. By structuring knowledge as graphs, we can facilitate the retrieval of context that captures greater semantic depth and enhances language model operations. We explore graph-based RAG methodologies and introduce TREX, a novel, cost-effective alternative that combines graph-based and vector-based retrieval techniques. Our benchmarking across four diverse datasets highlights the strengths of different RAG methodologies, demonstrates TREX's ability to handle multiple open-domain QA types, and reveals the limitations of current evaluation methods.\n  In a real-world technical support case study, we demonstrate how TREX solutions can surpass conventional vector-based RAG in efficiently synthesizing data from heterogeneous sources. Our findings underscore the potential of augmenting large language models with advanced retrieval and orchestration capabilities, advancing scalable, graph-based AI solutions.",
    "published": "2025-03-04T18:47:17Z",
    "pdf_url": "https://arxiv.org/pdf/2503.02922v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2408.02545v1",
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "authors": [
      "Daniel Fleischer",
      "Moshe Berchansky",
      "Moshe Wasserblat",
      "Peter Izsak"
    ],
    "summary": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently complex, requiring deep understanding of data, use cases, and intricate design decisions. Additionally, evaluating these systems presents significant challenges, necessitating assessment of both retrieval accuracy and generative quality through a multi-faceted approach. We introduce RAG Foundry, an open-source framework for augmenting large language models for RAG use cases. RAG Foundry integrates data creation, training, inference and evaluation into a single workflow, facilitating the creation of data-augmented datasets for training and evaluating large language models in RAG settings. This integration enables rapid prototyping and experimentation with various RAG techniques, allowing users to easily generate datasets and train RAG models using internal or specialized knowledge sources. We demonstrate the framework effectiveness by augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG configurations, showcasing consistent improvements across three knowledge-intensive datasets. Code is released as open-source in https://github.com/IntelLabs/RAGFoundry.",
    "published": "2024-08-05T15:16:24Z",
    "pdf_url": "https://arxiv.org/pdf/2408.02545v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2404.13781v1",
    "title": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
    "authors": [
      "Alireza Salemi",
      "Hamed Zamani"
    ],
    "summary": "Evaluating retrieval-augmented generation (RAG) presents challenges, particularly for retrieval models within these systems. Traditional end-to-end evaluation methods are computationally expensive. Furthermore, evaluation of the retrieval model's performance based on query-document relevance labels shows a small correlation with the RAG system's downstream performance. We propose a novel evaluation approach, eRAG, where each document in the retrieval list is individually utilized by the large language model within the RAG system. The output generated for each document is then evaluated based on the downstream task ground truth labels. In this manner, the downstream performance for each document serves as its relevance label. We employ various downstream task metrics to obtain document-level annotations and aggregate them using set-based or ranking metrics. Extensive experiments on a wide range of datasets demonstrate that eRAG achieves a higher correlation with downstream RAG performance compared to baseline methods, with improvements in Kendall's $\u03c4$ correlation ranging from 0.168 to 0.494. Additionally, eRAG offers significant computational advantages, improving runtime and consuming up to 50 times less GPU memory than end-to-end evaluation.",
    "published": "2024-04-21T21:22:28Z",
    "pdf_url": "https://arxiv.org/pdf/2404.13781v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.08275v1",
    "title": "Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval Augmented Generation Systems",
    "authors": [
      "Laura Caspari",
      "Kanishka Ghosh Dastidar",
      "Saber Zerhoudi",
      "Jelena Mitrovic",
      "Michael Granitzer"
    ],
    "summary": "The choice of embedding model is a crucial step in the design of Retrieval Augmented Generation (RAG) systems. Given the sheer volume of available options, identifying clusters of similar models streamlines this model selection process. Relying solely on benchmark performance scores only allows for a weak assessment of model similarity. Thus, in this study, we evaluate the similarity of embedding models within the context of RAG systems. Our assessment is two-fold: We use Centered Kernel Alignment to compare embeddings on a pair-wise level. Additionally, as it is especially pertinent to RAG systems, we evaluate the similarity of retrieval results between these models using Jaccard and rank similarity. We compare different families of embedding models, including proprietary ones, across five datasets from the popular Benchmark Information Retrieval (BEIR). Through our experiments we identify clusters of models corresponding to model families, but interestingly, also some inter-family clusters. Furthermore, our analysis of top-k retrieval similarity reveals high-variance at low k values. We also identify possible open-source alternatives to proprietary models, with Mistral exhibiting the highest similarity to OpenAI models.",
    "published": "2024-07-11T08:24:16Z",
    "pdf_url": "https://arxiv.org/pdf/2407.08275v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2411.11895v1",
    "title": "Deploying Large Language Models With Retrieval Augmented Generation",
    "authors": [
      "Sonal Prabhune",
      "Donald J. Berndt"
    ],
    "summary": "Knowing that the generative capabilities of large language models (LLM) are sometimes hampered by tendencies to hallucinate or create non-factual responses, researchers have increasingly focused on methods to ground generated outputs in factual data. Retrieval Augmented Generation (RAG) has emerged as a key approach for integrating knowledge from data sources outside of the LLM's training set, including proprietary and up-to-date information. While many research papers explore various RAG strategies, their true efficacy is tested in real-world applications with actual data. The journey from conceiving an idea to actualizing it in the real world is a lengthy process. We present insights from the development and field-testing of a pilot project that integrates LLMs with RAG for information retrieval. Additionally, we examine the impacts on the information value chain, encompassing people, processes, and technology. Our aim is to identify the opportunities and challenges of implementing this emerging technology, particularly within the context of behavioral research in the information systems (IS) field. The contributions of this work include the development of best practices and recommendations for adopting this promising technology while ensuring compliance with industry regulations through a proposed AI governance model.",
    "published": "2024-11-07T22:11:51Z",
    "pdf_url": "https://arxiv.org/pdf/2411.11895v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.03995v1",
    "title": "RAG-Check: Evaluating Multimodal Retrieval Augmented Generation Performance",
    "authors": [
      "Matin Mortaheb",
      "Mohammad A. Amir Khojastepour",
      "Srimat T. Chakradhar",
      "Sennur Ulukus"
    ],
    "summary": "Retrieval-augmented generation (RAG) improves large language models (LLMs) by using external knowledge to guide response generation, reducing hallucinations. However, RAG, particularly multi-modal RAG, can introduce new hallucination sources: (i) the retrieval process may select irrelevant pieces (e.g., documents, images) as raw context from the database, and (ii) retrieved images are processed into text-based context via vision-language models (VLMs) or directly used by multi-modal language models (MLLMs) like GPT-4o, which may hallucinate. To address this, we propose a novel framework to evaluate the reliability of multi-modal RAG using two performance measures: (i) the relevancy score (RS), assessing the relevance of retrieved entries to the query, and (ii) the correctness score (CS), evaluating the accuracy of the generated response. We train RS and CS models using a ChatGPT-derived database and human evaluator samples. Results show that both models achieve ~88% accuracy on test data. Additionally, we construct a 5000-sample human-annotated database evaluating the relevancy of retrieved pieces and the correctness of response statements. Our RS model aligns with human preferences 20% more often than CLIP in retrieval, and our CS model matches human preferences ~91% of the time. Finally, we assess various RAG systems' selection and generation performances using RS and CS.",
    "published": "2025-01-07T18:52:05Z",
    "pdf_url": "https://arxiv.org/pdf/2501.03995v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2503.15191v1",
    "title": "Optimizing Retrieval Strategies for Financial Question Answering Documents in Retrieval-Augmented Generation Systems",
    "authors": [
      "Sejong Kim",
      "Hyunseo Song",
      "Hyunwoo Seo",
      "Hyunjun Kim"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising framework to mitigate hallucinations in Large Language Models (LLMs), yet its overall performance is dependent on the underlying retrieval system. In the finance domain, documents such as 10-K reports pose distinct challenges due to domain-specific vocabulary and multi-hierarchical tabular data. In this work, we introduce an efficient, end-to-end RAG pipeline that enhances retrieval for financial documents through a three-phase approach: pre-retrieval, retrieval, and post-retrieval. In the pre-retrieval phase, various query and corpus preprocessing techniques are employed to enrich input data. During the retrieval phase, we fine-tuned state-of-the-art (SOTA) embedding models with domain-specific knowledge and implemented a hybrid retrieval strategy that combines dense and sparse representations. Finally, the post-retrieval phase leverages Direct Preference Optimization (DPO) training and document selection methods to further refine the results. Evaluations on seven financial question answering datasets-FinDER, FinQABench, FinanceBench, TATQA, FinQA, ConvFinQA, and MultiHiertt-demonstrate substantial improvements in retrieval performance, leading to more accurate and contextually appropriate generation. These findings highlight the critical role of tailored retrieval techniques in advancing the effectiveness of RAG systems for financial applications. A fully replicable pipeline is available on GitHub: https://github.com/seohyunwoo-0407/GAR.",
    "published": "2025-03-19T13:21:49Z",
    "pdf_url": "https://arxiv.org/pdf/2503.15191v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2507.06838v2",
    "title": "Shifting from Ranking to Set Selection for Retrieval Augmented Generation",
    "authors": [
      "Dahyun Lee",
      "Yongrae Jo",
      "Haeju Park",
      "Moontae Lee"
    ],
    "summary": "Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved passages are not only individually relevant but also collectively form a comprehensive set. Existing approaches primarily rerank top-k passages based on their individual relevance, often failing to meet the information needs of complex queries in multi-hop question answering. In this work, we propose a set-wise passage selection approach and introduce SETR, which explicitly identifies the information requirements of a query through Chain-of-Thought reasoning and selects an optimal set of passages that collectively satisfy those requirements. Experiments on multi-hop RAG benchmarks show that SETR outperforms both proprietary LLM-based rerankers and open-source baselines in terms of answer correctness and retrieval quality, providing an effective and efficient alternative to traditional rerankers in RAG systems. The code is available at https://github.com/LGAI-Research/SetR",
    "published": "2025-07-09T13:35:36Z",
    "pdf_url": "https://arxiv.org/pdf/2507.06838v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2404.08628v1",
    "title": "Accessibility in Information Retrieval",
    "authors": [
      "Leif Azzopardi",
      "Vishwa Vinay"
    ],
    "summary": "This paper introduces the concept of accessibility from the field of transportation planning and adopts it within the context of Information Retrieval (IR). An analogy is drawn between the fields, which motivates the development of document accessibility measures for IR systems. Considering the accessibility of documents within a collection given an IR System provides a different perspective on the analysis and evaluation of such systems which could be used to inform the design, tuning and management of current and future IR systems.",
    "published": "2024-04-12T17:46:13Z",
    "pdf_url": "https://arxiv.org/pdf/2404.08628v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2502.09891v3",
    "title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation",
    "authors": [
      "Shu Wang",
      "Yixiang Fang",
      "Yingli Zhou",
      "Xilin Liu",
      "Yuchi Ma"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has proven effective in integrating external knowledge into large language models (LLMs) for solving question-answer (QA) tasks. The state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. However, existing graph-based RAG approaches cannot accurately identify the relevant information from the graph and also consume large numbers of tokens in the online retrieval process. To address these issues, we introduce a novel graph-based RAG approach, called Attributed Community-based Hierarchical RAG (ArchRAG), by augmenting the question using attributed communities, and also introducing a novel LLM-based hierarchical clustering method. To retrieve the most relevant information from the graph for the question, we build a novel hierarchical index structure for the attributed communities and develop an effective online retrieval method. Experimental results demonstrate that ArchRAG outperforms existing methods in both accuracy and token cost.",
    "published": "2025-02-14T03:28:36Z",
    "pdf_url": "https://arxiv.org/pdf/2502.09891v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2512.20781v1",
    "title": "Soft Filtering: Guiding Zero-shot Composed Image Retrieval with Prescriptive and Proscriptive Constraints",
    "authors": [
      "Youjin Jung",
      "Seongwoo Cho",
      "Hyun-seok Min",
      "Sungchul Choi"
    ],
    "summary": "Composed Image Retrieval (CIR) aims to find a target image that aligns with user intent, expressed through a reference image and a modification text. While Zero-shot CIR (ZS-CIR) methods sidestep the need for labeled training data by leveraging pretrained vision-language models, they often rely on a single fused query that merges all descriptive cues of what the user wants, tending to dilute key information and failing to account for what they wish to avoid. Moreover, current CIR benchmarks assume a single correct target per query, overlooking the ambiguity in modification texts. To address these challenges, we propose Soft Filtering with Textual constraints (SoFT), a training-free, plug-and-play filtering module for ZS-CIR. SoFT leverages multimodal large language models (LLMs) to extract two complementary constraints from the reference-modification pair: prescriptive (must-have) and proscriptive (must-avoid) constraints. These serve as semantic filters that reward or penalize candidate images to re-rank results, without modifying the base retrieval model or adding supervision. In addition, we construct a two-stage dataset pipeline that refines CIR benchmarks. We first identify multiple plausible targets per query to construct multi-target triplets, capturing the open-ended nature of user intent. Then guide multimodal LLMs to rewrite the modification text to focus on one target, while referencing contrastive distractors to ensure precision. This enables more comprehensive and reliable evaluation under varying ambiguity levels. Applied on top of CIReVL, a ZS-CIR retriever, SoFT raises R@5 to 65.25 on CIRR (+12.94), mAP@50 to 27.93 on CIRCO (+6.13), and R@50 to 58.44 on FashionIQ (+4.59), demonstrating broad effectiveness.",
    "published": "2025-12-23T21:29:45Z",
    "pdf_url": "https://arxiv.org/pdf/2512.20781v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.15748v1",
    "title": "MoRSE: Bridging the Gap in Cybersecurity Expertise with Retrieval Augmented Generation",
    "authors": [
      "Marco Simoni",
      "Andrea Saracino",
      "Vinod P.",
      "Mauro Conti"
    ],
    "summary": "In this paper, we introduce MoRSE (Mixture of RAGs Security Experts), the first specialised AI chatbot for cybersecurity. MoRSE aims to provide comprehensive and complete knowledge about cybersecurity. MoRSE uses two RAG (Retrieval Augmented Generation) systems designed to retrieve and organize information from multidimensional cybersecurity contexts. MoRSE differs from traditional RAGs by using parallel retrievers that work together to retrieve semantically related information in different formats and structures. Unlike traditional Large Language Models (LLMs) that rely on Parametric Knowledge Bases, MoRSE retrieves relevant documents from Non-Parametric Knowledge Bases in response to user queries. Subsequently, MoRSE uses this information to generate accurate answers. In addition, MoRSE benefits from real-time updates to its knowledge bases, enabling continuous knowledge enrichment without retraining. We have evaluated the effectiveness of MoRSE against other state-of-the-art LLMs, evaluating the system on 600 cybersecurity specific questions. The experimental evaluation has shown that the improvement in terms of relevance and correctness of the answer is more than 10\\% compared to known solutions such as GPT-4 and Mixtral 7x8.",
    "published": "2024-07-22T15:53:27Z",
    "pdf_url": "https://arxiv.org/pdf/2407.15748v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2406.14162v4",
    "title": "DIRAS: Efficient LLM Annotation of Document Relevance in Retrieval Augmented Generation",
    "authors": [
      "Jingwei Ni",
      "Tobias Schimanski",
      "Meihong Lin",
      "Mrinmaya Sachan",
      "Elliott Ash",
      "Markus Leippold"
    ],
    "summary": "Retrieval Augmented Generation (RAG) is widely employed to ground responses to queries on domain-specific documents. But do RAG implementations leave out important information when answering queries that need an integrated analysis of information (e.g., Tell me good news in the stock market today.)? To address these concerns, RAG developers need to annotate information retrieval (IR) data for their domain of interest, which is challenging because (1) domain-specific queries usually need nuanced definitions of relevance beyond shallow semantic relevance; and (2) human or GPT-4 annotation is costly and cannot cover all (query, document) pairs (i.e., annotation selection bias), thus harming the effectiveness in evaluating IR recall. To address these challenges, we propose DIRAS (Domain-specific Information Retrieval Annotation with Scalability), a manual-annotation-free schema that fine-tunes open-sourced LLMs to consider nuanced relevance definition and annotate (partial) relevance labels with calibrated relevance scores. Extensive evaluation shows that DIRAS enables smaller (8B) LLMs to achieve GPT-4-level performance on annotating and ranking unseen (query, document) pairs, and is helpful for real-world RAG development. All code, LLM generations, and human annotations can be found in \\url{https://github.com/EdisonNi-hku/DIRAS}.",
    "published": "2024-06-20T10:04:09Z",
    "pdf_url": "https://arxiv.org/pdf/2406.14162v4.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2206.14759v2",
    "title": "How Train-Test Leakage Affects Zero-shot Retrieval",
    "authors": [
      "Maik Fr\u00f6be",
      "Christopher Akiki",
      "Martin Potthast",
      "Matthias Hagen"
    ],
    "summary": "Neural retrieval models are often trained on (subsets of) the millions of queries of the MS MARCO / ORCAS datasets and then tested on the 250 Robust04 queries or other TREC benchmarks with often only 50 queries. In such setups, many of the few test queries can be very similar to queries from the huge training data -- in fact, 69% of the Robust04 queries have near-duplicates in MS MARCO / ORCAS. We investigate the impact of this unintended train-test leakage by training neural retrieval models on combinations of a fixed number of MS MARCO / ORCAS queries that are highly similar to the actual test queries and an increasing number of other queries. We find that leakage can improve effectiveness and even change the ranking of systems. However, these effects diminish as the amount of leakage among all training instances decreases and thus becomes more realistic.",
    "published": "2022-06-29T16:44:43Z",
    "pdf_url": "https://arxiv.org/pdf/2206.14759v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.05475v1",
    "title": "Retrieval-Augmented Generation by Evidence Retroactivity in LLMs",
    "authors": [
      "Liang Xiao",
      "Wen Dai",
      "Shuai Chen",
      "Bin Qin",
      "Chongyang Shi",
      "Haopeng Jing",
      "Tianyu Guo"
    ],
    "summary": "Retrieval-augmented generation has gained significant attention due to its ability to integrate relevant external knowledge, enhancing the accuracy and reliability of the LLMs' responses. Most of the existing methods apply a dynamic multiple retrieval-generating process, to address multi-hop complex questions by decomposing them into sub-problems. However, these methods rely on an unidirectional forward reasoning paradigm, where errors from insufficient reasoning steps or inherent flaws in current retrieval systems are irreversible, potentially derailing the entire reasoning chain. For the first time, this work introduces Retroactive Retrieval-Augmented Generation (RetroRAG), a novel framework to build a retroactive reasoning paradigm. RetroRAG revises and updates the evidence, redirecting the reasoning chain to the correct direction. RetroRAG constructs an evidence-collation-discovery framework to search, generate, and refine credible evidence. It synthesizes inferential evidence related to the key entities in the question from the existing source knowledge and formulates search queries to uncover additional information. As new evidence is found, RetroRAG continually updates and organizes this information, enhancing its ability to locate further necessary evidence. Paired with an Answerer to generate and evaluate outputs, RetroRAG is capable of refining its reasoning process iteratively until a reliable answer is obtained. Empirical evaluations show that RetroRAG significantly outperforms existing methods.",
    "published": "2025-01-07T08:57:42Z",
    "pdf_url": "https://arxiv.org/pdf/2501.05475v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2108.13934v2",
    "title": "Robust Retrieval Augmented Generation for Zero-shot Slot Filling",
    "authors": [
      "Michael Glass",
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Alfio Gliozzo"
    ],
    "summary": "Automatically inducing high quality knowledge graphs from a given collection of documents still remains a challenging problem in AI. One way to make headway for this problem is through advancements in a related task known as slot filling. In this task, given an entity query in form of [Entity, Slot, ?], a system is asked to fill the slot by generating or extracting the missing value exploiting evidence extracted from relevant passage(s) in the given document collection. The recent works in the field try to solve this task in an end-to-end fashion using retrieval-based language models. In this paper, we present a novel approach to zero-shot slot filling that extends dense passage retrieval with hard negatives and robust training procedures for retrieval augmented generation models. Our model reports large improvements on both T-REx and zsRE slot filling datasets, improving both passage retrieval and slot value generation, and ranking at the top-1 position in the KILT leaderboard. Moreover, we demonstrate the robustness of our system showing its domain adaptation capability on a new variant of the TACRED dataset for slot filling, through a combination of zero/few-shot learning. We release the source code and pre-trained models.",
    "published": "2021-08-31T15:51:27Z",
    "pdf_url": "https://arxiv.org/pdf/2108.13934v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2506.16988v2",
    "title": "RAGentA: Multi-Agent Retrieval-Augmented Generation for Attributed Question Answering",
    "authors": [
      "Ines Besrour",
      "Jingbo He",
      "Tobias Schreieder",
      "Michael F\u00e4rber"
    ],
    "summary": "We present RAGentA, a multi-agent retrieval-augmented generation (RAG) framework for attributed question answering (QA) with large language models (LLMs). With the goal of trustworthy answer generation, RAGentA focuses on optimizing answer correctness, defined by coverage and relevance to the question and faithfulness, which measures the extent to which answers are grounded in retrieved documents. RAGentA uses a multi-agent architecture that iteratively filters retrieved documents, generates attributed answers with in-line citations, and verifies completeness through dynamic refinement. Central to the framework is a hybrid retrieval strategy that combines sparse and dense methods, improving Recall@20 by 12.5% compared to the best single retrieval model, resulting in more correct and well-supported answers. Evaluated on a synthetic QA dataset derived from the FineWeb index, RAGentA outperforms standard RAG baselines, achieving gains of 1.09% in correctness and 10.72% in faithfulness. These results demonstrate the effectiveness of our multi-agent RAG architecture and hybrid retrieval strategy in advancing trustworthy QA with LLMs.",
    "published": "2025-06-20T13:37:03Z",
    "pdf_url": "https://arxiv.org/pdf/2506.16988v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.09136v3",
    "title": "Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG",
    "authors": [
      "Aditi Singh",
      "Abul Ehtesham",
      "Saket Kumar",
      "Tala Talaei Khoei"
    ],
    "summary": "Large Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real time queries, resulting in outdated or inaccurate outputs. Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by integrating real time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional RAG systems are constrained by static workflows and lack the adaptability required for multistep reasoning and complex task management.\n  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflection, planning, tool use, and multiagent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows to meet complex task requirements. This integration enables Agentic RAG systems to deliver unparalleled flexibility, scalability, and context awareness across diverse applications.\n  This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG architectures, highlights key applications in industries such as healthcare, finance, and education, and examines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic RAG.",
    "published": "2025-01-15T20:40:25Z",
    "pdf_url": "https://arxiv.org/pdf/2501.09136v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.04695v1",
    "title": "Re-ranking the Context for Multimodal Retrieval Augmented Generation",
    "authors": [
      "Matin Mortaheb",
      "Mohammad A. Amir Khojastepour",
      "Srimat T. Chakradhar",
      "Sennur Ulukus"
    ],
    "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge to generate a response within a context with improved accuracy and reduced hallucinations. However, multi-modal RAG systems face unique challenges: (i) the retrieval process may select irrelevant entries to user query (e.g., images, documents), and (ii) vision-language models or multi-modal language models like GPT-4o may hallucinate when processing these entries to generate RAG output. In this paper, we aim to address the first challenge, i.e, improving the selection of relevant context from the knowledge-base in retrieval phase of the multi-modal RAG. Specifically, we leverage the relevancy score (RS) measure designed in our previous work for evaluating the RAG performance to select more relevant entries in retrieval process. The retrieval based on embeddings, say CLIP-based embedding, and cosine similarity usually perform poorly particularly for multi-modal data. We show that by using a more advanced relevancy measure, one can enhance the retrieval process by selecting more relevant pieces from the knowledge-base and eliminate the irrelevant pieces from the context by adaptively selecting up-to-$k$ entries instead of fixed number of entries. Our evaluation using COCO dataset demonstrates significant enhancement in selecting relevant context and accuracy of the generated response.",
    "published": "2025-01-08T18:58:22Z",
    "pdf_url": "https://arxiv.org/pdf/2501.04695v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2108.11601v2",
    "title": "Retrieval Augmented Code Generation and Summarization",
    "authors": [
      "Md Rizwan Parvez",
      "Wasi Uddin Ahmad",
      "Saikat Chakraborty",
      "Baishakhi Ray",
      "Kai-Wei Chang"
    ],
    "summary": "Software developers write a lot of source code and documentation during software development. Intrinsically, developers often recall parts of source code or code summaries that they had written in the past while implementing software or documenting them. To mimic developers' code or summary generation behavior, we propose a retrieval augmented framework, REDCODER, that retrieves relevant code or summaries from a retrieval database and provides them as a supplement to code generation or summarization models. REDCODER has a couple of uniqueness. First, it extends the state-of-the-art dense retrieval technique to search for relevant code or summaries. Second, it can work with retrieval databases that include unimodal (only code or natural language description) or bimodal instances (code-description pairs). We conduct experiments and extensive analysis on two benchmark datasets of code generation and summarization in Java and Python, and the promising results endorse the effectiveness of our proposed retrieval augmented framework.",
    "published": "2021-08-26T06:48:13Z",
    "pdf_url": "https://arxiv.org/pdf/2108.11601v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2410.14609v2",
    "title": "DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search",
    "authors": [
      "Simon Lupart",
      "Mohammad Aliannejadi",
      "Evangelos Kanoulas"
    ],
    "summary": "Conversational Search (CS) involves retrieving relevant documents from a corpus while considering the conversational context, integrating retrieval with context modeling. Recent advancements in Large Language Models (LLMs) have significantly enhanced CS by enabling query rewriting based on conversational context. However, employing LLMs during inference poses efficiency challenges. Existing solutions mitigate this issue by distilling embeddings derived from human-rewritten queries, focusing primarily on learning the context modeling task. These methods, however, often separate the contrastive retrieval task from the distillation process, treating it as an independent loss term. To overcome these limitations, we introduce DiSCo (Distillation of Sparse Conversational retrieval), a novel approach that unifies retrieval and context modeling through a relaxed distillation objective. Instead of relying exclusively on representation learning, our method distills similarity scores between conversations and documents, providing more freedom in the representation space and better leveraging the contrastive nature of document relevance. Extensive experiments on Learned Sparse Retrieval (LSR) across five CS datasets demonstrate that DiSCo achieves substantial improvements in both in-domain and out-of-domain retrieval tasks, achieving up to a six-point gain in recall for out-of-domain datasets over state-of-the-art methods. Additionally, DiSCo employs a multi-teacher distillation strategy, using multiple LLMs as teachers, further enhancing performance and surpassing the individual teachers in in-domain settings. Furthermore, analysis of model sparsity reveals that DiSCo allows for more effective control over the sparsity of the trained models.",
    "published": "2024-10-18T17:03:17Z",
    "pdf_url": "https://arxiv.org/pdf/2410.14609v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2502.02464v3",
    "title": "Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation",
    "authors": [
      "Abdelrahman Abdallah",
      "Bhawna Piryani",
      "Jamshid Mozafari",
      "Mohammed Ali",
      "Adam Jatowt"
    ],
    "summary": "Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical components of modern applications in information retrieval, question answering, or knowledge-based text generation. However, existing solutions are often fragmented, lacking a unified framework that easily integrates these essential processes. The absence of a standardized implementation, coupled with the complexity of retrieval and re-ranking workflows, makes it challenging for researchers to compare and evaluate different approaches in a consistent environment. While existing toolkits such as Rerankers and RankLLM provide general-purpose reranking pipelines, they often lack the flexibility required for fine-grained experimentation and benchmarking. In response to these challenges, we introduce Rankify, a powerful and modular open-source toolkit designed to unify retrieval, re-ranking, and RAG within a cohesive framework. Rankify supports a wide range of retrieval techniques, including dense and sparse retrievers, while incorporating state-of-the-art re-ranking models to enhance retrieval quality. Additionally, Rankify includes a collection of pre-retrieved datasets to facilitate benchmarking, available at Huggingface (https://huggingface.co/datasets/abdoelsayed/reranking-datasets-light). To encourage adoption and ease of integration, we provide comprehensive documentation (http://rankify.readthedocs.io/), an open-source implementation on GitHub (https://github.com/DataScienceUIBK/rankify), and a PyPI package for easy installation (https://pypi.org/project/rankify/). As a unified and lightweight framework, Rankify allows researchers and practitioners to advance retrieval and re-ranking methodologies while ensuring consistency, scalability, and ease of use.",
    "published": "2025-02-04T16:33:25Z",
    "pdf_url": "https://arxiv.org/pdf/2502.02464v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.18365v1",
    "title": "RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects",
    "authors": [
      "Yiteng Tu",
      "Weihang Su",
      "Yujia Zhou",
      "Yiqun Liu",
      "Qingyao Ai"
    ],
    "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge retrieved from a knowledge base. However, its effectiveness is fundamentally constrained by the reliability of both the retriever and the knowledge base. In real-world scenarios, imperfections in these components often lead to the retrieval of noisy, irrelevant, or misleading counterfactual information, ultimately undermining the trustworthiness of RAG systems. To address this challenge, we propose Robust Fine-Tuning (RbFT), a method designed to enhance the resilience of LLMs against retrieval defects through two targeted fine-tuning tasks. Experimental results demonstrate that RbFT significantly improves the robustness of RAG systems across diverse retrieval conditions, surpassing existing methods while maintaining high inference efficiency and compatibility with other robustness techniques.",
    "published": "2025-01-30T14:15:09Z",
    "pdf_url": "https://arxiv.org/pdf/2501.18365v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2410.22353v3",
    "title": "RuleRAG: Rule-Guided Retrieval-Augmented Generation with Language Models for Question Answering",
    "authors": [
      "Zhongwu Chen",
      "Chengjin Xu",
      "Dingmin Wang",
      "Zhen Huang",
      "Yong Dou",
      "Xuhui Jiang",
      "Jian Guo"
    ],
    "summary": "Retrieval-augmented generation (RAG) has shown promising potential in knowledge intensive question answering (QA). However, existing approaches only consider the query itself, neither specifying the retrieval preferences for the retrievers nor informing the generators of how to refer to the retrieved documents for the answers, which poses a significant challenge to the QA performance. To address these issues, we propose Rule-guided Retrieval-Augmented Generation with LMs, which explicitly introduces rules for in-context learning (RuleRAG-ICL) to guide retrievers to recall related documents in the directions of rules and uniformly guide generators to reason attributed by the same rules. Moreover, most existing RAG datasets were constructed without considering rules and Knowledge Graphs (KGs) are recognized as providing high-quality rules. Therefore, we construct five rule-aware RAG benchmarks for QA, RuleQA, based on KGs to stress the significance of retrieval and reasoning with rules. Experiments on RuleQA demonstrate RuleRAG-ICL improves the retrieval quality of +89.2% in Recall@10 and answer accuracy of +103.1% in Exact Match, and RuleRAG-FT yields more enhancement. In addition, experiments on four existing RAG datasets show RuleRAG is also effective by offering rules in RuleQA to them, further proving the generalization of rule guidance in RuleRAG.",
    "published": "2024-10-15T14:51:45Z",
    "pdf_url": "https://arxiv.org/pdf/2410.22353v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "1906.00041v1",
    "title": "Table2Vec: Neural Word and Entity Embeddings for Table Population and Retrieval",
    "authors": [
      "Li Deng",
      "Shuo Zhang",
      "Krisztian Balog"
    ],
    "summary": "Tables contain valuable knowledge in a structured form. We employ neural language modeling approaches to embed tabular data into vector spaces. Specifically, we consider different table elements, such caption, column headings, and cells, for training word and entity embeddings. These embeddings are then utilized in three particular table-related tasks, row population, column population, and table retrieval, by incorporating them into existing retrieval models as additional semantic similarity signals. Evaluation results show that table embeddings can significantly improve upon the performance of state-of-the-art baselines.",
    "published": "2019-05-31T19:22:29Z",
    "pdf_url": "https://arxiv.org/pdf/1906.00041v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2406.19150v1",
    "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
    "authors": [
      "Varun Nagaraj Rao",
      "Siddharth Choudhary",
      "Aditya Deshpande",
      "Ravi Kumar Satzoda",
      "Srikar Appalaraju"
    ],
    "summary": "The scaling of large language models to encode all the world's knowledge in model parameters is unsustainable and has exacerbated resource barriers. Retrieval-Augmented Generation (RAG) presents a potential solution, yet its application to vision-language models (VLMs) is under explored. Existing methods focus on models designed for single tasks. Furthermore, they're limited by the need for resource intensive pre training, additional parameter requirements, unaddressed modality prioritization and lack of clear benefit over non-retrieval baselines. This paper introduces RAVEN, a multitask retrieval augmented VLM framework that enhances base VLMs through efficient, task specific fine-tuning. By integrating retrieval augmented samples without the need for additional retrieval-specific parameters, we show that the model acquires retrieval properties that are effective across multiple tasks. Our results and extensive ablations across retrieved modalities for the image captioning and VQA tasks indicate significant performance improvements compared to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a +3\\% accuracy on specific VQA question types. This underscores the efficacy of applying RAG approaches to VLMs, marking a stride toward more efficient and accessible multimodal learning.",
    "published": "2024-06-27T13:08:35Z",
    "pdf_url": "https://arxiv.org/pdf/2406.19150v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2412.18378v3",
    "title": "RaSeRec: Retrieval-Augmented Sequential Recommendation",
    "authors": [
      "Xinping Zhao",
      "Baotian Hu",
      "Yan Zhong",
      "Shouzheng Huang",
      "Zihao Zheng",
      "Meng Wang",
      "Haofen Wang",
      "Min Zhang"
    ],
    "summary": "Although prevailing supervised and self-supervised learning augmented sequential recommendation (SeRec) models have achieved improved performance with powerful neural network architectures, we argue that they still suffer from two limitations: (1) Preference Drift, where models trained on past data can hardly accommodate evolving user preference; and (2) Implicit Memory, where head patterns dominate parametric learning, making it harder to recall long tails. In this work, we explore retrieval augmentation in SeRec, to address these limitations. Specifically, we propose a Retrieval-Augmented Sequential Recommendation framework, named RaSeRec, the main idea of which is to maintain a dynamic memory bank to accommodate preference drifts and retrieve relevant memories to augment user modeling explicitly. It consists of two stages: (i) collaborative-based pre-training, which learns to recommend and retrieve; (ii) retrieval-augmented fine-tuning, which learns to leverage retrieved memories. Extensive experiments on three datasets fully demonstrate the superiority and effectiveness of RaSeRec. The implementation code is available at https://github.com/HITsz-TMG/RaSeRec.",
    "published": "2024-12-24T12:07:48Z",
    "pdf_url": "https://arxiv.org/pdf/2412.18378v3.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2509.21325v1",
    "title": "PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation",
    "authors": [
      "Baiqiang Wang",
      "Qian Lou",
      "Mengxin Zheng",
      "Dongfang Zhao"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) has become a foundational component of modern AI systems, yet it introduces significant privacy risks by exposing user queries to service providers. To address this, we introduce PIR-RAG, a practical system for privacy-preserving RAG. PIR-RAG employs a novel architecture that uses coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol. This design allows for the efficient retrieval of entire document clusters, uniquely optimizing for the end-to-end RAG workflow where full document content is required. Our comprehensive evaluation against strong baseline architectures, including graph-based PIR and Tiptoe-style private scoring, demonstrates PIR-RAG's scalability and its superior performance in terms of \"RAG-Ready Latency\"-the true end-to-end time required to securely fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly efficient solution for privacy in large-scale AI systems.",
    "published": "2025-09-01T07:28:35Z",
    "pdf_url": "https://arxiv.org/pdf/2509.21325v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2407.09394v2",
    "title": "PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with User-Centric Agents",
    "authors": [
      "Saber Zerhoudi",
      "Michael Granitzer"
    ],
    "summary": "Large Language Models (LLMs) struggle with generating reliable outputs due to outdated knowledge and hallucinations. Retrieval-Augmented Generation (RAG) models address this by enhancing LLMs with external knowledge, but often fail to personalize the retrieval process. This paper introduces PersonaRAG, a novel framework incorporating user-centric agents to adapt retrieval and generation based on real-time user data and interactions. Evaluated across various question answering datasets, PersonaRAG demonstrates superiority over baseline models, providing tailored answers to user needs. The results suggest promising directions for user-adapted information retrieval systems.",
    "published": "2024-07-12T16:18:00Z",
    "pdf_url": "https://arxiv.org/pdf/2407.09394v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2009.08553v4",
    "title": "Generation-Augmented Retrieval for Open-domain Question Answering",
    "authors": [
      "Yuning Mao",
      "Pengcheng He",
      "Xiaodong Liu",
      "Yelong Shen",
      "Jianfeng Gao",
      "Jiawei Han",
      "Weizhu Chen"
    ],
    "summary": "We propose Generation-Augmented Retrieval (GAR) for answering open-domain questions, which augments a query through text generation of heuristically discovered relevant contexts without external resources as supervision. We demonstrate that the generated contexts substantially enrich the semantics of the queries and GAR with sparse representations (BM25) achieves comparable or better performance than state-of-the-art dense retrieval methods such as DPR. We show that generating diverse contexts for a query is beneficial as fusing their results consistently yields better retrieval accuracy. Moreover, as sparse and dense representations are often complementary, GAR can be easily combined with DPR to achieve even better performance. GAR achieves state-of-the-art performance on Natural Questions and TriviaQA datasets under the extractive QA setup when equipped with an extractive reader, and consistently outperforms other retrieval methods when the same generative reader is used.",
    "published": "2020-09-17T23:08:01Z",
    "pdf_url": "https://arxiv.org/pdf/2009.08553v4.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2401.14826v1",
    "title": "Expressivity-aware Music Performance Retrieval using Mid-level Perceptual Features and Emotion Word Embeddings",
    "authors": [
      "Shreyan Chowdhury",
      "Gerhard Widmer"
    ],
    "summary": "This paper explores a specific sub-task of cross-modal music retrieval. We consider the delicate task of retrieving a performance or rendition of a musical piece based on a description of its style, expressive character, or emotion from a set of different performances of the same piece. We observe that a general purpose cross-modal system trained to learn a common text-audio embedding space does not yield optimal results for this task. By introducing two changes -- one each to the text encoder and the audio encoder -- we demonstrate improved performance on a dataset of piano performances and associated free-text descriptions. On the text side, we use emotion-enriched word embeddings (EWE) and on the audio side, we extract mid-level perceptual features instead of generic audio embeddings. Our results highlight the effectiveness of mid-level perceptual features learnt from music and emotion enriched word embeddings learnt from emotion-labelled text in capturing musical expression in a cross-modal setting. Additionally, our interpretable mid-level features provide a route for introducing explainability in the retrieval and downstream recommendation processes.",
    "published": "2024-01-26T12:52:56Z",
    "pdf_url": "https://arxiv.org/pdf/2401.14826v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2408.00798v1",
    "title": "Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base",
    "authors": [
      "Zhiyu An",
      "Xianzhong Ding",
      "Yen-Chun Fu",
      "Cheng-Chung Chu",
      "Yan Li",
      "Wan Du"
    ],
    "summary": "This paper introduces Golden-Retriever, designed to efficiently navigate vast industrial knowledge bases, overcoming challenges in traditional LLM fine-tuning and RAG frameworks with domain-specific jargon and context interpretation. Golden-Retriever incorporates a reflection-based question augmentation step before document retrieval, which involves identifying jargon, clarifying its meaning based on context, and augmenting the question accordingly. Specifically, our method extracts and lists all jargon and abbreviations in the input question, determines the context against a pre-defined list, and queries a jargon dictionary for extended definitions and descriptions. This comprehensive augmentation ensures the RAG framework retrieves the most relevant documents by providing clear context and resolving ambiguities, significantly improving retrieval accuracy. Evaluations using three open-source LLMs on a domain-specific question-answer dataset demonstrate Golden-Retriever's superior performance, providing a robust solution for efficiently integrating and querying industrial knowledge bases.",
    "published": "2024-07-20T06:10:46Z",
    "pdf_url": "https://arxiv.org/pdf/2408.00798v1.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2601.05254v2",
    "title": "TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation",
    "authors": [
      "Wenbiao Tao",
      "Xinyuan Li",
      "Yunshi Lan",
      "Weining Qian"
    ],
    "summary": "Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average winning rate of 78.36% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG.",
    "published": "2025-10-18T08:24:49Z",
    "pdf_url": "https://arxiv.org/pdf/2601.05254v2.pdf",
    "topic_query": "retrieval augmented generation"
  },
  {
    "id": "2501.02226v2",
    "title": "Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation",
    "authors": [
      "Shijie Wang",
      "Wenqi Fan",
      "Yue Feng",
      "Shanru Lin",
      "Xinyu Ma",
      "Shuaiqiang Wang",
      "Dawei Yin"
    ],
    "summary": "Recommender systems have become increasingly vital in our daily lives, helping to alleviate the problem of information overload across various user-oriented online services. The emergence of Large Language Models (LLMs) has yielded remarkable achievements, demonstrating their potential for the development of next-generation recommender systems. Despite these advancements, LLM-based recommender systems face inherent limitations stemming from their LLM backbones, particularly issues of hallucinations and the lack of up-to-date and domain-specific knowledge. Recently, Retrieval-Augmented Generation (RAG) has garnered significant attention for addressing these limitations by leveraging external knowledge sources to enhance the understanding and generation of LLMs. However, vanilla RAG methods often introduce noise and neglect structural relationships in knowledge, limiting their effectiveness in LLM-based recommendations. To address these limitations, we propose to retrieve high-quality and up-to-date structure information from the knowledge graph (KG) to augment recommendations. Specifically, our approach develops a retrieval-augmented framework, termed K-RagRec, that facilitates the recommendation generation process by incorporating structure information from the external KG. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed method.",
    "published": "2025-01-04T08:16:23Z",
    "pdf_url": "https://arxiv.org/pdf/2501.02226v2.pdf",
    "topic_query": "retrieval augmented generation"
  }
]