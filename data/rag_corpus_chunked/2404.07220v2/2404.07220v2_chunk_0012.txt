sluggish querying performance. Conversely, sparse vector indexing, despite its slower indexing process, offers expeditious querying advantages. Furthermore, a stark contrast in storage requirements is observed; for instance, the sparse vector index of the HotPotQA corpus occupied a mere 10.5GB as opposed to the 50GB required for the dense vector equiv- alent. In such cases, we recommend sparse encoder indexes. Furthermore, for enterprises with this volume, we found it better to use multi-tenancy with federated search queries. B. Blended Retrievers without Metadata When datasets are enriched with metadata or other relevant informational facets, they improve the efficacy of blended retrievers. Conversely, for datasets devoid of metadata, such TABLE VI: Top-5 retrieval accuracy CoQA Dataset COQA BM25+MQ BM25+BF KNN+MQ KNN+BF SE+MQ SE+BF Top-5 45.3 45.3 47.56 47.56 49.94 49.94 as CoQA, it is not as impressive. You can see the results in Table VI. The absence of metadata in the CoQA dataset resulted in hybrid queries offering no improvement over basic queries. This limitation underscores the critical role of metadata in enhancing the efficacy of complex query structures. However, Sparse Encoder-based semantic searches still yield the most favorable outcomes than traditional methods. Additionally, we would like to note that while NDCG@10 scores for Retriever and F1,EM scores for RAG are commonly used metrics, we found them to be poor proxies of Generative Q&A systems for human alignment. Better metrics to evaluate the RAG system is a key area of future work. VII. C ONCLUSION Blended RAG pipeline is highly effective across multiple datasets despite not being specifically trained on them. No- tably, this approach does not necessitate exemplars for prompt engineering which are often required in few-shot learning, indicating a robust generalization capability within the zero- shot paradigm. This study demonstrated: â€¢ Optimization of R with Blended Search: Incorporating Semantic Search, specifically