that a methodological pivot towards more nuanced blended search, particularly those that effectively utilize the Best Fields, can significantly enhance retrieval outcomes in information retrieval (IR) systems. 3) Top-10 Retrieval Accuracy on the HotPotQA dataset : The HotPotQA [8] dataset, with its extensive corpus of over 5M documents and a query set comprising 7,500 items, presents a formidable challenge for comprehensive evaluation due to compute requirements. Consequently, the assessment was confined to a select subset of hybrid queries. Despite these constraints, the analysis provided insightful data, as reflected in the accompanying visualization in Figure 5. Figure 5 shows that hybrid queries, specifically those utiliz- ing Cross Fields and Best Fields search strategies, demonstrate superior performance. Notably, the hybrid query that blends Sparse EncodeR with Best Fields queries achieved the highest efficiency, of 65.70% on the HotPotQA dataset. Fig. 6: NQ dataset Benchmarking using NDCG@10 Metric TABLE II: Retriever Benchmarking using NDCG@10 Metric Dataset Model/Pipeline NDCG@10 Trec-covid COCO-DR Large 0.804 Trec-covid Blended RAG 0.87 NQ dataset monoT5-3B 0.633 NQ dataset Blended RAG 0.67 A. Retriever Benchmarking Now that we have identified the best set of combinations of Index + Query types, we will use these sextet queries on IR datasets for benchmarking using NDCG@10 [9] scores (Normalised Discounted Cumulative Gain metric). 1) NQ dataset benchmarking: The results for NDCG@10 using sextet queries and the current benchmark on the NQ dataset are shown in the chart Figure 7. Our pipeline provides the best NDCG@10 score of 0.67, which is 5.8% higher than the current benchmark score of 0.633 achieved by the monoT5-3B model. Table II shows that all semantic search- based hybrid queries outperform the current benchmark score, which indicates that our hybrid queries are a better candidate for developing the RAG pipeline. 2) TREC-Covid Dataset Benchmarking : In our research, the