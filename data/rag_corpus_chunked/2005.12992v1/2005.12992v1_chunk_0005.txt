evaluat ion; and ground truth requires a unique perspective of relevance and that is just not the case when it comes to IRS for children. The se is- sues showcase not only the importance of developing framewo rks without the need for massive amounts of data but also why in- volving the larger community to create it is key. The reason f or engaging with the IR community (and beyond) is two-fold. Fir st, if the community is involved, they will become aware of the issu es attached to the development and evaluation of IRS for childr en. Second, the researchers and practitioners can bring in thei r expe- riences on evaluation, especially from other areas working with protected populations. Working together we can learn from e ach other and hopefully come up with ways to facilitate the devel op- ment of evaluation in diﬀerent areas of study and bring the is sues of evaluation of IRS for kids into the spotlight. REFERENCES [1] Dania Bilal and Meredith Boehm. 2017. Towards new method ologies for assess- ing relevance of information retrieval from web search engines on childrenâĂŹs queries. Qualitative and Quantitative Methods in Libraries 2, 1 (2017), 93–100. [2] Dania Bilal and Joe Kirby. 2002. Diﬀerences and similari ties in information seek- ing: children and adults as Web users. Information processing & management 38, 5 (2002), 649–670. [3] Jamie Callan. 2020. Better Representation of Search Tas ks. Available at: https://www.youtube.com/watch?v=eHJTkFUxJgg&feature=youtu.be&t=18047. (2020). (accessed May 6). [4] Rocío Cañamares, Pablo Castells, and Alistair Moﬀat. 20 20. Oﬄine evaluation options for recommender systems. Information Retrieval Journal (2020), 1–24. [5] Cyril Cleverdon. 1967. The Cranﬁeld tests on index langu age devices. In Aslib proceedings. MCB UP Ltd. [6] Federal Trade Commission and others. 1998. ChildrenâĂŹ s online privacy pro- tection act of 1998. (1998).