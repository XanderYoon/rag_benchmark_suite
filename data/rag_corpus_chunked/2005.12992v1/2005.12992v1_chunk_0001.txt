mong researchers and practitioners, with the focus being on metr ics and their applicability for diﬀerent tasks (e.g., multilingua l IR), diﬀer- ent domain (e.g., medical and legal), and applicability concepts like bias and fairness [4, 14, 16, 21, 22]. The target users of thes e explo- rations on evaluation have been a traditional user [3]. Thus , the frameworks and benchmarks used to evaluate IRS only account for a general user, who are not the only stakeholders. It is our stance that the lack of evaluation frameworks for ch il- dren’s IRS is a problem that needs to be addressed by not only researchers working with children but the IR community. Eva lu- ating IRS for children presents new challenges that have yet to be fully addressed. There have been a few evaluation frameworks presented in recent years that attempt to create structure t o en- able assessment for kids’ IRS [1, 15]. Unfortunately, they a re not always general enough to be applied to the varying IRS that ar e available for children. Even when these frameworks can be us ed, there is an overlying issue of data. Data from children is hard to get in several respects including collecting, accessing, a nd storing due to laws protecting children [6, 19, 20]. Even though some data "Copyright Âľ 2020 for this paper by its authors. Use permitt ed under Creative Com- mons License Attribution 4.0 International (CC BY 4.0). " may be accessible, how children judge IRS diﬀers from the general population [11–13, 24]. We aim at showcasing (i) issues that our- selves and other researchers and practitioners face with da ta, user judgments, and frameworks, as well as (ii) the fact that eval uation that involves protected users is an issue with bigger implic ations that requires