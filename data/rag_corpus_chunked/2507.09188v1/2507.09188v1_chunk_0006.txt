item characteristics. Therefore, incorporating and summarizing fragmented human-written reviews using natural language as user and item profiles can enhance the richness and usefulness of the constructed profiles, providing better supporting inputs for LLM to generate persuasive and comprehensive recommendation explanations. Existing LLM-based ExRec methods XRec and G-Refer utilize LLM as the summarizer. Since processing all the reviews of a popular item may exceed the context length of LLM, they randomly sample a few reviews for constructing profiles, losing quite a lot of information beneficial for generating explanations. Furthermore, randomly sampled reviews lack connections to each other, making it more difficult for LLM to summarize and produce comprehensive and correct profiles. Despite that LLMs with a longer context window can be applied for profile summarization, the lost-in-middle issue [15] still affects profile construction. To conquer the above problem, we opt to construct user and item profiles via hierarchical aggregating their reviews instead of feeding reviews together to LLM. REXHA compresses and summarizes reviews layer by layer in parallel, and finally constructs a refined and informative profile. 2.2.1 Raw Review Summarization Given a user-item interaction, we conduct hierarchical aggregation twice: one for user profile and the other for item profile. At the bottom of the hierarchical aggregation tree, each leaf contains one raw item review and each review is randomly placed in a leaf node. When constructing a user profile, the raw review comes from one item interacted by that user. When constructing an item profile, we use this itemâ€™s reviews as raw reviews. As shown in Fig. 1, the first step is to aggregate reviews of two adjacent sibling nodes and use LLM to summarize the two raw reviews. The primary motivation for employing LLM to summarize raw item reviews lies in addressing two critical challenges: excessive information redundancy and semantic