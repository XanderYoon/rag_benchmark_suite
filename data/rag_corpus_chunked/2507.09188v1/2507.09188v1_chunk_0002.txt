to generate human-like explanations. This paradigm shift has gained momentum with the rise of large language models (LLMs), whose extensive world knowledge and nuanced language understanding enable the generation of human-like, contextually grounded explanations [10–12]. XRec is one representative LLM-based ExRec [11]. It enables LLMs to better understand complex user-item interaction patterns and offer explanations via integrating collaborative filtering (CF) signals. Building on this foundation, G-Refer [ 12] introduces a hybrid graph retrieval method to enhance ExRec by extracting both structural and semantic CF information from the user-item interaction graph. Despite these notable advancements, two critical limitations persist in LLM- powered ExRec: (C1) Profile Deviation. To assist with explanation generation, XRec and G-Refer construct user/item profiles by randomly sampling a small subset of user/item reviews, neglecting the broader contextual information embedded in the remaining data. This selective sampling introduces information bias, causing LLMs to generate explanations misaligned with holistic user preferences or item characteristics. (C2) High Retrieval Overhead. G-Refer employs the Dijkstra algorithm in path-level retrieval and can only be calculated on the CPU. It is not friendly to parallelism and has a high time complexity of O(N 2), resulting in a prohibitive retrieval cost. To alleviate the limitations of existing ExRec works, we presentRetrieval-Augmented Recommen- dation Explanation Generation with Hierarchical Aggregation (REXHA ), a framework designed to improve the credibility and efficiency of recommendation explanation generation. The contributions of this work are summarized as follows: • Holistic User/Item Profiling: Unlike prior methods (e.g., XRec and G-Refer) that con- struct incomplete profiles via random review sampling, we propose a hierarchical review aggregation module to systematically encode all user/item review data. This approach miti- gates profile deviation (C1) by capturing nuanced user preferences and item characteristics through multi-layered summarization, ensuring LLMs generate explanations grounded in comprehensive contextual signals. • Efficient Retrieval