while small chunks could lead to incomplete knowledge. In addition, multi-hop document ret rieval is also a challenge. The above three issues need to be further inves- tigated to conduct R 3AG. Reliable Retrieval for RAG. The inclusion of noisy or contradic- tory information during retrieval can signiﬁcantly impair the per- formance of existing RAG models. There has been growing interest in improving the resilience of RAG against harmful or counte rfac- tual inputs, which is now considered a crucial performance i ndi- cator in recent studies [5, 20, 21]. Meanwhile, current rese arch [9] reveals that including irrelevant documents can unexpecte dly in- crease accuracy by more than 30%, challenging the initial be lief that it would degrade quality. These ﬁndings inspire us to organize R3AG for developing specialized strategies for eﬀective retr ieval and to emphasize the ongoing need for further investigation into RAG’s robustness and reliability. Response Evaluation and Reﬁnement. While RAG enhances LLMs by providing additional information, LLMs may still fa ce challenges with unreliable or inaccurate response generation. These challenges may arise from incorrect information in the cont ext [6] or issues with hallucinations [2]. Unfortunately, there is a notice- able gap in understanding how these challenges impact the ou tput quality of RAG, as well as in developing strategies for model s to mitigate these issues and reﬁne their responses. As such, R 3AG is dedicated to comprehensively evaluating and enhancing t he re- sponse quality of RAG-based LLMs across multiple dimension s, such as relevance, faithfulness, negative rejection, info rmation in- tegration, creative generation, and error correction. Multimodal R3AG. Most current research focuses on textual RAG, despite the need for multimodality in many applications. Re cent large-scale models like Flamingo [3], and GPT-4 [1] show sig nif- icant multimodal capability when scaled to