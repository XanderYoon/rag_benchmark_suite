on Research and Development i n Informa- tion Retrieval in the Asia Paciﬁc Region (SIGIR-AP ’24), December 9–12, 2024, Tokyo, Japan.ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3673791.3698435 1 BACKGROUND AND MOTIV ATIONS RAG (Retrieval-Augmented Generation) has emerged as a new par- adigm for using information retrieval (IR) to improve the generated response from large language models (LLMs). On the one hand, traditional IR systems may encounter diﬃculties to handle m ore and more complex information seeking queries. On the other hand, LLM has shown notable natural language understanding capab il- ity while suﬀering from ﬁctitious or inaccurate generation , also known as the hallucination problem. To this end, RAG has emerged to combine the best of IR and LLM generation. RAG has made sig- niﬁcant progress in improving response quality by ﬁrst retr ieving relevant knowledge from external knowledge base and then ge n- erating responses based on the knowledge retrieval. RAG’s a dvan- tages in handling information queries include but not limit ed to enhanced user experience, enriched information return, im proved response accuracy, and multi-round conversational searchfor com- plex queries. Through integrating IR and language generation, RAG has become the keystone for various AI applications. Existing RAG techniques [7, 14] focused on enhancing language models by integrating additional textual knowledge from ex ter- nal knowledge database. Transformer-based [18] language models have shown great promise in language generation, leading to no- table LLMs like GPTs. LLMs owe their success to advanced arch i- tectures with billions of parameters, pre-trained on vast c orpora from diverse sources, enabling remarkable generalization across SIGIR-AP ’24, December 9–12, 2024, Tokyo, Japan Zihan Wang e t al. various AI applications [4, 8, 12]. However, LLMs also suﬀer from model hallucination [13] and diﬃculty in handling dynamic k nowl- edge updates [19]. RAG alleviates