success to advanced arch i- tectures with billions of parameters, pre-trained on vast c orpora from diverse sources, enabling remarkable generalization across SIGIR-AP ’24, December 9–12, 2024, Tokyo, Japan Zihan Wang e t al. various AI applications [4, 8, 12]. However, LLMs also suﬀer from model hallucination [13] and diﬃculty in handling dynamic k nowl- edge updates [19]. RAG alleviates the hallucination proble m by providing LLMs with relevant knowledge using IR techniquesto re- trieve from external databases, achieving more accurate responses for knowledge-intensive generation. The decoupled databa se also supports more lightweight knowledge dynamic updates. For exam- ple, [15] integrates a RAG pipeline in an end-to-end generation sys- tem to improve the factual correctness of LLMs for domain-speciﬁc and time-sensitive queries. While RAG has achieved great advancement, we recognize that there still exists challenges to conduct reﬁned and reliabl e RAG (R3AG). A typical RAG pipeline often includes user intent compr e- hension, knowledge parsing, knowledge retrieval, and resp onse generation. Each pipeline step has speciﬁc challenges and p lays an essential role to accomplish user queries. For example, h ow to understand user query intention under long and complex dialogue context; how to parse complex knowledge documents including ta- bles and ﬁgures; how to conduct reliable knowledge retrieva l; and how to reﬁne the generated response. The workshop is expecte d to help researchers to conduct further investigation on R 3AG. Topic. The topic of this workshop includes interesting points re- lated to the RAG pipelines, i.e., user intent comprehension , knowl- edge parsing, knowledge retrieval, and response generatio n. The detailed topics are described in section 2. Relevance. On the one hand, generative LLMs are hot research topics in the IR communities. The capability of LLMs enriche s the scope of IR and has changed the process