unique set. This list is then checked against a user-defined, domain-specific list of prohibited or overly generic terms, allowing for user-defined exclusion of tech- nologies. Subsequently, an acronym-priority deduplication was performed to manage instances where both an acronym and its full expanded form exists, retaining the more concise version if they refer to the same base concept. The final remaining technology terms are then sorted alphabetically, yielding the refined list of technologies extracted from each paper. D. Output Evaluation To evaluate the performance of the RATE pipeline, a ground truth dataset was established. First, 70 scientific papers were randomly selected from the 678 collected documents. Then, three domain experts independently reviewed the title, abstract, and author keywords for each of these papers to manually compile a gold-standard list of technologies. In the next step, same technologies extracted by all experts were added to the final list and the remaining technologies were debated whether to be omitted or to be added to the final list. The result was a final gold standard list approved by all experts. Following this, the list of technologies extracted by the RATE pipeline for these same 70 papers was presented to each expert. They were then tasked with identifying True Positives (TP), False Positives (FP), and False Negatives (FN) by comparing RATE’s output against the final curated gold- standard list. Based on experts’ assessment, Precision and Recall were calculated. In the next step the comparison of the proposed model with another state-of-the-art model was required. Therefore, a supervised machine learning model has been trained for the task of the technology extraction from text so its results would be compared with RATE’s output and the gold standard list of technologies. E. BERT baseline for technology extraction Bidirectional Encoder Representations from Transformers (BERT) is a pretrained transformer with