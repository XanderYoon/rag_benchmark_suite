= {(se, p, oe)|se, oe ϵ Ie, p ϵ R} where, Ie ϵ I and R denote the instances relevant to query e and relations stored in G (Equation (1). The determination of the narrative plot points in G′ retrieved from G, is imple- mented using the SPARQL Protocol and RDF Query Language templates executed on FABULA’s EPG G. The narrative prompt set serves as input to the fine-tuned GPT-Neo LLM that outputs the intelligence report Y . Each component of our approach is further described in the rest of this section. A. Fine-Tuning GPT-Neo Fine-tuning is an example of transfer learning, a method that seeds additional domain knowledge to a pre-trained Large Language Model, without training all parameters from scratch. We fine-tune the 1.3B parameter GPT-Neo decoder [16]. The original GPT-Neo model was trained with the Pile dataset [26], which is an 800GB English text corpus that consists of 22 high quality datasets. Fine-tuning GPT-Neo using D + IR (Section IV-A) augments the existing vocabulary of GPT-Neo (VGP T −N eo) with the vocabulary of the news intelligence corpus (VD+IR) and allows GPT-Neo to model the format and syntactic style of known intelligence reporting, such as that available in set IR, which closely follows the IPP narrative structure. During fine-tuning, we divide the training set in a 35% train and test split. We use batch size 16 and learning rate 0.0001, trained for 12 hours. The output of the model is a conditional probability of each word in the target text given the input and the previously generated words. We report a perplexity value (the exponential of the cross-entropy loss) of 11.14. Fig. 4. FABULA’s Retrieval-Augmented Generation (RAG) of Intelligence Report about event e. B. Prefix-tuning with Narrative Prompt Sets Traditionally, an autoregressive decoder like GPT-Neo re- quires a