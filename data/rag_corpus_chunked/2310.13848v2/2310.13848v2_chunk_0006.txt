text for a given KG [14], [15]. State of the art methods fine-tune text-to-text and generative decoder pre-trained models with KG-to-text datasets. One approach to this problem is Retrieval Augmented Generation (RAG), a method that aims to seed external data is a technique that uses retrieved data that is stored externally (like in a KG) from the foundation model, which is used to augment LLM prompting by injecting relevant retrieved information. III. M ETHODOLOGY Fig. 1. FABULA System Architecture and Data Flow. This work is guided by the following research question: Does incorporating narrative-based features during Retrieval- Augmented Generation (RAG) produce intelligence reports with high semantic relevance, high event coherency, and little to no hallucination? Our approach is applied and evaluated specifically in the context of narrative construction for news events represented in open sourced news articles. Suppose we have a set of randomly ordered articles d1, d2..., dn, retrieved by a keyword search query about an event e, which contain several plot points p1, p2..., pn. Each plot point is extracted, ranked, and ordered into a chronological sequence. Consider a real-world example where an intelligence analyst requires information about a critical event e. The analyst will input a query about e, retrieve relevant information from a multiple set of sources (news blogs, social media posts) to write a condensed intelligence report. We develop FAB- ULA, an analyst-augmentation framework that integrates real- time news event retrieval, narrative schema-based information extraction and representation of event concept information, and retrieval-augmented generation (RAG) of intelligence reports. Our approach is displayed in Figure 1. We begin by creating a news intelligence corpus from popular news sources and publicly available U.S Intelligence Community (IC) reports, described in Section IV-A. This corpus is further condensed through information extraction of plot points contained within news articles and