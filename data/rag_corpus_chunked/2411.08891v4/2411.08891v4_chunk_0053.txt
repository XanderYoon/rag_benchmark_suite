limitations of the model’s understanding of numerical relationships and improved calibration. D.4 Ablation on user modelU We additionally conduct an ablation evaluation on various user modelsU, considering that human users may make different decisions depending on their knowledge background in real-world sce- narios. We evaluated the performance of CalibRAG and baseline methods on the NQ and WebQA datasets using two retriever models, BM25 and Contriever. For this, we compare the performance ofPhi-4[58] andDeepSeek-Distill[59], which represent state-of-the-art user models. As shown in Fig. 6 and Fig. 7, our results demonstrate that CalibRAG consistently achieves better accuracy and calibration error across different user models compared to other baselines. 26 CT CT-Probe Linguistic Number CalibRAG 1-ROC ( ) 1-ACC ( ) ECE ( ) BS ( ) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Phi4: BM25 with NQ (a) 1-ROC ( ) 1-ACC ( ) ECE ( ) BS ( ) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Phi4: BM25 with WebQA (b) 1-ROC ( ) 1-ACC ( ) ECE ( ) BS ( ) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Phi4: Contriever with NQ (c) 1-ROC ( ) 1-ACC ( ) ECE ( ) BS ( ) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Phi4: Contriever with WebQA (d) Figure 6: Evaluation results of the baselines and CalibRAG utilizing two retriever models: BM25 (a, b) and Contriever (c, d) on NQ (a, c) and WebQA (b, d). Here, we utilizePhi-4[58] as our user modelU. We report four metrics—1-AUROC, 1-ACC, ECE, and Brier Score—where lower values indicate better performance. CT CT-Probe Linguistic Number CalibRAG 1-ROC ( ) 1-ACC ( ) ECE ( ) BS ( ) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Deepseek: BM25 with NQ (a) 1-ROC ( ) 1-ACC