Letx∈ Xrepresent the question or task for which a user needs to make a decision (e.g., “Should I take melatonin to help with jet lag after a long flight?”), and lety∈ Ydenote the corresponding true answer (e.g., “Yes, if taken at a local bedtime.”). Here,XandYare the set of all possible questions and answers, respectively. Given the questionx, the user provides an open-ended queryq(x)(e.g., “Write a paragraph about the effects of melatonin on jet lag.”) to an LLM as a prompt to gather information for the decision making aboutx. The LLM, denoted asM, generates a long-form response to the query, i.e.,z∼ 2 1 3 5 7 9 Top K Doc 0.5 0.6 0.7 0.8 0.9 1.0Cumulative Accuracy Contriever CalibRAG (a) 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Bin 0.0 0.2 0.4 0.6 0.8 1.0Accuracy in Bin ECE: 0.1085 ACC: 33.76 Base Model (b) 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Bin 0.0 0.2 0.4 0.6 0.8 1.0Accuracy in Bin ECE: 0.2500 ACC: 37.27 Base+RAG Model (c) Figure 1:(a) Cumulative accuracy with the top-K documents on our synthetic validation set (see Sec. 3.3). contriever-msmarcogains 11% compared to top-1 when the top-9 documents are used, showing that the top-1 hit is often not optimal. CalibRAG reaches a higher top-1 accuracy and gains little from additional documents.(b, c) Reliability diagrams on NaturalQA.ForLlama-3.1-8Btrained under the Number baseline (see Sec. 4), adding the retrieved document (c) raises accuracy relative to the no-document baseline (b) but also increases ECE, indicating greater over-confidence. Bar height is the mean accuracy in each confidence bin; darker shading marks bins with more predictions. M(z|q(x)), which serves as the guidance for the decision-making process. For the sake of notational simplicity, unless specified otherwise, we will useqin place ofq(x). Given the questionxand the generated responsez, the user leverages a forecasting functionf:X × Z