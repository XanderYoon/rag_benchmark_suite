that predicts the probability of whether the user’s decision based on the guidance provided by RAG will be correct. We empirically validate that our CalibRAG significantly improves calibration performance as well as accuracy, compared to other relevant baselines across several datasets. Our contributions can be summarized as follows: • We propose the CalibRAG framework, which enables well-calibrated decision-making based on the guidance provided by RAG. • We construct a new dataset by creating labels that indicate how much decisions made using re- trieved documents correctly answer the questions, essential for training the forecasting function. • We outperform existing uncertainty calibration baselines across various tasks involving RAG con- text in decision-making scenarios. 2 Preliminaries 2.1 Decision Calibration of Long Form Generation As discussed in Sec. 1, since human decision-makers tend to over-rely on the outputs of LLMs during the decision-making process, it is crucial to ensure that the confidence in LLMs’ outputs is well-calibrated. To address this problem, Band et al. [6] proposesdecision calibration, which aims to align the confidence of the model’s predicted output with the accuracy of the user’s decision based on the model output. This allows the user to make a reliable decision based on the model’s confidence. Thus, to achieve this goal, we need to ensure that the model not only generates factual information but also its confidence in the generated responses accurately reflects the likelihood of correctness. To formalize the problem, we introduce the following notations. Letx∈ Xrepresent the question or task for which a user needs to make a decision (e.g., “Should I take melatonin to help with jet lag after a long flight?”), and lety∈ Ydenote the corresponding true answer (e.g., “Yes, if taken at a local bedtime.”). Here,XandYare the set of all possible questions and answers, respectively. Given the questionx, the user provides