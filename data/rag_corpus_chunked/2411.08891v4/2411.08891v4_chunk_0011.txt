head,b head,W p, and the LoRA parametersW LoRA are all learnable. This formulation allowsfto condition its prediction on both the semantic compatibility of theq-dpair and the user-specific behavior encoded byt, providing an uncertainty-aware estimate of decision correctness. Then we trainfby minimizing the following log-likelihood loss: L=− 1 |S| X (t,q,d,b)∈S [blogf(t, q, d) + (1−b) log(1−f(t, q, d))](4) whereSis the training dataset andb∈[0,1]is the soft label derived from self-consistency sam- pling. This objective encourages the predicted confidencef(t, q, d)to match the empirical correct- ness probability, enabling the model to generalize across varying decision behaviors encoded byt, while leveraging the LLM’s latent representations for calibrated prediction. Although the primary formulation uses soft binary labels, we also investigate a multi-class variant where the correctness distribution is discretized into histogram bins and trainfusing a categorical objective. Full experi- mental results and comparisons are provided in Sec. 4. Remark.Among various scoring rules [35, 36, 6] used to measure the forecast quality of functions predicting the true probabilityp, thestrictly proper scoring rulehas the advantage that itsunique maximizeris the true probabilityp. Consequently, training a forecast function using a strictly proper scoring rule as the training objective ensures that the forecasts are learned to be as close as possible to the true probabilitypas the number of training examples increases. Note that the loss in Equation 4 to train our forecast functionfis an example of a strictly proper scoring rule, the logarithmic score. This makes our loss function crucial for trainingfto produce well-calibrated predictions. 5 3.3 Synthetic Supervision Data Generation To conduct the supervised learning discussed in Sec. 3.2, it is essential to construct an appropriate synthetic training datasetSconsisting of the triples(t, q, d, b). We first extract the(x, y)decision- making task pairs from the following three Question Answering datasets: 1) TriviaQA [37], 2) SQuAD2.0 [38], and 3)