high- lights the dual advantage of CalibRAG in both performance and computational cost. 28 Table 12: Comparison of zero-shot evaluation of calibration baselines onBioASQ-Y/N,MMLU-Med, and PubMedQAdatasets. Results are averaged over three random seeds. Methods Dataset AUROC ACC ECE BS CT-LoRABioASQ-Y/N 65.20±2.3254.31±0.730.5167±0.0120.5099±0.0146 MMLU-Med 66.94±0.6847.20±1.520.4293±0.00880.4262±0.0084 PubMedQA 56.67±3.1643.80±0.910.4307±0.00990.4300±0.0094 CT-probeBioASQ-Y/N 59.73±4.2757.98±1.450.5664±0.0090.5630±0.0094 MMLU-Med 55.39±3.2449.49±5.000.4771±0.03840.4758±0.0375 PubMedQA 54.56±0.6146.60±1.880.4506±0.0120.4510±0.0121 Linguistic-LoRABioASQ-Y/N 48.24±2.2657.82±0.500.3193±0.00270.3464±0.0030 MMLU-Med 51.30±0.9355.43±0.940.3262±0.00780.3544±0.0049 PubMedQA 49.13±0.7947.13±2.250.4047±0.03360.4225±0.021 Number-LoRABioASQ-Y/N 52.43±2.1953.72±1.690.4664±0.03550.4659±0.0332 MMLU-Med 53.47±2.5441.44±1.010.3394±0.01680.3541±0.0135 PubMedQA 50.34±0.2543.60±0.590.3866±0.00290.3954±0.0032 CalibRAGBioASQ-Y/N66.66±1.3470.82±3.340.2414±0.04270.2606±0.0386 MMLU-Med68.93±1.3257.20±0.210.0625±0.06530.2226±0.0112 PubMedQA66.57±2.0062.20±3.530.2250±0.03530.2691±0.0072 Figure 8: Qualitative comparison of original retrieval model from CalibRAG. D.8 Full numerical results for main experiments Table 10, Table 11 and Table 12 present the complete numerical results from the primary experi- ments. For theBasemodel, we utilized a pretrained model, sampling sentences across three different seeds. For the other methods, training was conducted across three random seeds to ensure robust evaluation. We highlight the best-performing value inboldand the second-best in underline . D.9 Qualitative Results While quantitative metrics alone may not fully capture all the benefits of CalibRAG, we present examples highlighting its ability to identify relevant documents and assign calibrated confidence scores. Given the query “Write a paragraph about the kind of bug that uses the American Sweetgum as a host plant.", the base retriever focuses only on the keyword “American Sweetgum,", retrieving 29 loosely relevant content and marking its confidence as ‘Confident’ (10/11) as illustrated in Fig. 8. This led to the incorrect conclusion that the sweetgum is the host plant of Parcoblatta divisa, the southern wood cockroach. In contrast, CalibRAG captures the full context, retrieving documents specifically about the gypsy moth, which uses the sweetgum as a host plant, and correctly assigns a confidence level of 81.41. This demonstrates the capability of CalibRAG to find a relevant docu- ment and assign a confidence level correlated with the accuracy of the downstream surrogate user. Additional examples can be found in §