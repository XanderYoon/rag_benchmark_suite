measure the uncertainty calibration of the response. As baselines, we consider two variants:CT-probe, which adds a classifier head to estimate the probability of correctness, andCT-LoRA, which utilizes the normalized token probability between the tokens “Yes” and “No.” (2)Verbalized Confidence Fine-tuning[40, 41, 6] utilizes verbalized tokens to represent the model’s confidence. In this case, we also consider two baseline variants:Number- LoRA, which expresses confidence as an integer between 0 and 10, andLinguistic-LoRA, which uses linguistic terms (e.g., “Doubtful” or “Likely”) to indicate confidence. For all uncertainty cal- ibration baselines, guidance and confidence are generated based on the top-1 document retrieved by the retriever. •Reranking and Robust RAG baselines:Although CalibRAG is primarily designed to enable well-calibrated decision-making in RAG-guided scenarios, it can also be interpreted as a rerank- ing approach for retrieved documents in downstream tasks as a consequence ofStage 2during inference. Accordingly, we compare CalibRAG against two reranking baselines and one robust RAG baseline: (1)Cross-encoderwith MiniLM-L6-v2, which reranks documents based on the similarity score of the jointly embedded query and documents with cross attention. (2)LLM- rerank[42], which prompts the LLM,GPT-3.5-turbo, to rerank documents by leveraging the relationship between the queryqand the documentd. (3)SelfRAG[43], a robust RAG base- line that dynamically determines the necessity of retrieval and self-evaluates the relevance of a retrieved documentdto the queryq, as well as the usefulness of the generated guidancezforq, using special tokens such as “Retrieve”, “IsREL”, “IsSup”, and “ISUSE”. CalibRAG.Unless otherwise specified, CalibRAG reranks the top-20 documents at inference. The forecasting function is evaluated by marginalizing over a set of six decoding temperatures t∈ {1.0,1.1, . . . ,1.5}. This is because, in the absence of explicit information about a user’s prefer- ence, the forecasting function cannot accurately model the user’s behavior under a single decoding temperature. To reflect this variation, we approximate marginalization by averaging