whether the user’s response matches the correct answery. To construct supervision signals forf, we sample responses fromUacross various decoding tem- peraturest∈ Tto simulate a range of user behaviors. This temperature reflects behavioral traits of the userU, such as risk tolerance or decision urgency. For instance, if the user needs to make a decision quickly and prefers reliability, they can choose a lowert. On the other hand, if the user has more time and is open to exploring diverse alternatives, they may opt for a highert. For each combination(t, q, d), we collectRresponses and use the proportion of correct ones as a soft label 4 for trainingf. As a result, the label is represented as a probability between[0,1], used as a soft label for binary modeling or extended to a multi-class histogram to support finer-grained calibration. Then, our final goal is to satisfy the following binary calibration condition: Pr [y=U(x, z, f(t, q, d))|f(t, q, d) =β] =β,∀β∈[0,1],(1) which means that the predicted confidenceβshould match the actual accuracy of user decisions. As discussed in Sec. 1 and illustrated in Fig. 1c, asking the RAG model to provide its own confidence often leads to excessively high confidence scores, which can cause users to overtrust inaccurate information. In this work, to overcome this limitation, we train a forecasting functionf(t, q, d) instead to satisfy the calibration condition in Eq. 1, using supervision signals derived from self- consistency sampling guided byU. This approach enables better modeling of real user behavior and allows for more effective confidence calibration, ultimately resulting in a safer and more trustworthy decision-making system. 3.2 Modeling and Training To model the forecasting functionf, it is essential to have the capacity to sufficiently analyze the impact of the generated guidancezon the actual decision. For this reason, we use a pre-trained LLMM, responsible