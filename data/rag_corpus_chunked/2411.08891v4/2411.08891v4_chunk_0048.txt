Retrieval-Augmented Generation Evaluation (MIRAGE) [49] and a textbook corpus. B.2 Hyperparameters Table 2 outlines the hyperparameters used for training the base model and LoRA, including key parameters such as learning rate, batch size, and LoRA-specific settings like rank and alpha. B.3 Evaluation metrics To evaluate long-form text, we utilizedgpt-4o-minito compare the ground-truth answers with the predicted answers in all cases. Based on this comparison, we labeled each instance as correct or incorrect accordingly. B.3.1 Calibration metrics •Expected Calibration Error[ECE; 44]: ECE= MX m=1 |Bm| n |acc(Bm)−conf(B m)| 7https://github.com/Teddy-XiongGZ/MedRAG 8https://github.com/activatedgeek/calibration-tuning 9https://github.com/huggingface/datasets 23 Table 2: Hyperparameters for LLM Training Base Model Hyperparameters LoRA Hyperparameters Hyperparameter Value Hyperparameter Value Learning Rate{10 −4,10 −5}LoRA Rank 8 Batch Size{1,4}LoRA Alpha 16 Max Steps 10,000 LoRA Dropout 0.1 Optimizer AdamW Dropout Rate 0.0 Gradient Accumulation Steps [1, 4] Weight Decay 0.01 Gradient Clipping 1.0 Warmup Steps 500 Scheduler Linear whereB m is the set of predictions in binm, acc(B m)is the accuracy, and conf(B m)is the average confidence of the predictions in that bin. ECE measures how well the model’s predicted probabilities are calibrated. •Brier Score[BS; 45]: BS= 1 N NX i=1 (fi −y i)2 wheref i is the predicted probability andyi is the true label. BS combines both the accuracy and confidence of the predictions, penalizing overconfident and underconfident predictions. •Negative Log Likelihood (NLL): NLL=− 1 N NX i=1 logp(y i |x i) wherep(y i |x i)is the probability assigned to the correct classy i given inputx i. NLL evaluates the model’s probabilistic predictions and lower values indicate better calibration. B.4 CalibRAG Details Feature extraction details.To extract features for the forecasting function, we use the hidden state of the last token from the second-to-last layer of the LLMM, as it empirically yielded bet- ter calibration performance than other layers. This hidden state serves as the