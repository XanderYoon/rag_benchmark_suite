increases ECE, indicating greater over-confidence. Bar height is the mean accuracy in each confidence bin; darker shading marks bins with more predictions. M(z|q(x)), which serves as the guidance for the decision-making process. For the sake of notational simplicity, unless specified otherwise, we will useqin place ofq(x). Given the questionxand the generated responsez, the user leverages a forecasting functionf:X × Z →∆ |Y| to assess all possible answersy∈ Y, where∆ |Y| denotes a simplex over the setYandZis the space of all possible responses fromM. The goal is to use the forecasting functionfto ensure that, given the long-form generated LLM responsez, the user makes calibrated decisions on the question-answer pairs(x, y). Based on this, Band et al. [6] introduces formal definitions for three types of calibrations with varying conditions. For instance, the LLM isconfidence calibrated[25] with respect to the forecasting functionfiffis calibrated on the joint distributionp(x, y, z), that is, for anyβ∈[0,1] Pr  y= arg max j∈|Y| f(x, z) j |max j∈|Y| f(x, z) j =β  =β, wheref(x, z) j denotes thej th element of vectorf(x, z). However, the method proposed by Band et al. [6] to tackle this calibration problem has three major limitations. 1) It requires supervised fine-tuning for three different LLMs, including the LLM re- sponsible for generating a responsezand the forecasting functionfparameterized with two LLMs. 2) it further needs proximal policy optimization [PPO; 26] for fine-tuning the LLM for response generation, which is known to suffer from training instability [27]. 3) It cannot be directly applied to calibrate the probabilities associated with the user decisions based on the guidance by RAG. 2.2 Retrieval Augmented Generation (RAG) RAG [13] employs Dense Passage Retrieval [DPR; 28] to retrieve relevant documents for question answering. DPR encodes questions and documents independently, enabling precomputation and in- dexing of document embeddings. At