44.96 0.1605 Linguistic 45.03 0.1585 For the experiments, we followed the standard retrieval pipeline, retrieving documents using BM25 and reranking the top-100 results. We compared CalibRAG with the Cross-Encoder baseline, and the results, presented in Table 5, demonstrate that CalibRAG consistently outperforms the Cross- Encoder. These findings validate that CalibRAG not only enables well-calibrated decision-making but also enhances retrieval performance, reinforcing its utility in relevant scenarios. D.3 Analysis of Verbalized Confidence Representations CalibRAG does not rely on linguistic or numerical confidence in its primary approach. Instead, it provides confidence scores based on the probability predictions generated by the forecasting func- tion. Verbalized confidence, however, was used as a baseline in comparative models. Verbalized confidence is typically expressed as a continuous number within the range [0, 100] Tian et al. [40] and Xiong et al. [52], but LLMs often struggle to interpret these numerical values precisely. To address this limitation, alternative representations were explored in the baselines: (1) linguistic expressions (e.g., “likely”), and (2) discrete numerical values ranging from 0 to 10. These ap- proaches were termed Linguistic and Number, respectively, with detailed prompt designs provided in Appendix E. To further analyze verbalized confidence, we conducted experiments on the MMLU dataset using the Llama-3-8B model. We evaluated the effectiveness of three confidence representations: continuous number, discrete number, and linguistic. As shown in Table 6, both discrete number and linguistic representations outperformed the continuous number baseline. Linguistic confidence, in particular, addressed the limitations of the model’s understanding of numerical relationships and improved calibration. D.4 Ablation on user modelU We additionally conduct an ablation evaluation on various user modelsU, considering that human users may make different decisions depending on their knowledge background in real-world sce- narios. We evaluated the performance of CalibRAG and baseline methods on the NQ and WebQA datasets using two