containing ’first impeached,’ included the phrase ’first being.’ It set a confidence level of 92.32%, allowing the user to arrive at the correct answer. Figure 13:CalibRAG vs CT-LoRA.In the case of CalibRAG, the top-20 confidence score is 20.95 for incorrect information, causing the user to hesitate in making a decision. However, with the CT-LoRA model, incorrect information is assigned a confidence score of 96.83, leading the user to make an incorrect decision. 33 G Prompt Examples In this section, we present prompt examples used during training and inference. Figure 14a shows the prompt that encourages the user modelUto act like a human decision-maker, leading it to over- rely on the guidance provided by the LLM. Figure 14b displays the prompt that generates the open- ended queryqfrom the decision taskx. Figure 14c presents the prompt that induces the generation of guidancezfromMbased on the retrieved documentd. Figure 15a is used when grading the user modelU’s decision against the true answer usingG. Figure 16a, Figure 16b, and Figure 16c are prompts used to instructMto generate confidence in terms of linguistic or numerical calibration. Lastly, Figure 15b is the prompt used duringStage 3of the inference process. Decision prompt The task is to answer questions based on a context generated by a language model in response to a question about relevant information, along with the model’s confidence level in the provided answer. Context: {context} Question: {question} Model Confidence: {confidence} Answer: (a) Prompt designed to guide the user modelUin making decisions based on the LLM-generated guidancez and confidencec. Prompt that generates open-ended queryqfrom the decision taskx You are an automated assistant tasked with rephrasing specific questions into open-ended queries to encourage detailed exploration and discussion of the key topics mentioned. Your goal is to prompt someone to write a paragraph exploring the topic without directly revealing