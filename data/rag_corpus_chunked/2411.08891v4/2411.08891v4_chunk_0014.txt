its predicted confidence. Concretely, we sort the documents in descending order of the probabilities{f(t, q ∗, d∗ i )}K i=1, which represent the chance that the user will reach a correct decision if guidancezis generated from each document. The top-ranked document is selected for the next stage. Here, if the predicted probability for the highest-ranked documentd ∗ falls below a predefined thresholdϵ(defaulted to 0.5, with further details provided in § D.1), we consider the guidancezinsufficient for a reliable decision at temperaturet. In this case, we move on to Stage 3, where we retrieve a new set ofKcandidate documents to search for documents that provide higher confidence. If this condition is not met, we move forward to Stage 4. Stage 3: Reformulating the query (Optional).If the predicted probability for the highest-ranked documentd ∗ is lower than a pre-defined thresholdϵin Stage 2, to retrieve a new set ofKcandidate documents, we reformulate our open-ended queryq ∗ intoq ∗∗ by emphasizing more important con- tent from the questionx. This reformulation focuses on extracting key aspects of the original task, ensuring that the next retrieval attempt targets more relevant and helpful documents. After reformu- lating the query, we repeat Stage 1 and Stage 2 once again. Examples of query reformulation are shown in § C. Stage 4: Final decision.After retrieving the documentd ∗, we generate the guidancez ∗ using the RAG modelM. Then, the user modelUmakes a decisionU(x ∗, z∗, f(q ∗, d∗, t)), with the 6 CT CT-Probe Linguistic Number CalibRAG CalibRAG-multi 1-ROC 1-ACC ECE BS 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (a) BM25 w/ NQ 1-ROC 1-ACC ECE BS 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (b) BM25 w/ WebQA 1-ROC 1-ACC ECE BS 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 (c) Contriever w/ NQ 1-ROC 1-ACC ECE BS