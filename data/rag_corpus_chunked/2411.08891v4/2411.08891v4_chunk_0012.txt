crucial for trainingfto produce well-calibrated predictions. 5 3.3 Synthetic Supervision Data Generation To conduct the supervised learning discussed in Sec. 3.2, it is essential to construct an appropriate synthetic training datasetSconsisting of the triples(t, q, d, b). We first extract the(x, y)decision- making task pairs from the following three Question Answering datasets: 1) TriviaQA [37], 2) SQuAD2.0 [38], and 3) WikiQA [39] datasets. Then, for everyxin the training dataset, we generate an open-ended queryqbased on eachx, using theGPT-4o-minimodel. At this point, it is important to note that instead of retrieving only the single top documentdwith the highest similarity score from the retriever model for each queryq, we retrieve the top 20 documents. There are two reasons for this. First, as illustrated in Fig. 1a, a large number of low-ranked documents actually help the surrogate user make a correct decision. If we only include the top-1 documents, many of which would be labeled as incorrect, the synthetic dataset would be highly biased to negative samples. Second, using only onedper(x, y)pair for labeling and training could result in the model overfitting to the label without learning the relationship betweenqanddadequately. By pairing the sameqwith variousd’s, the model can learn from positive and negative samples, improving its ability to generalize. After retrieving multiple documents, we provide each(q, d)pair to the RAG modelM, which generates the guidancezbased ond. Then, the user modelUreceives the taskxand guidancez, and samples responses with the decoding temperaturet, which reflects behavioral variation during sampling. To estimate the reliability of the generated decision, we sampleR= 10fromUat the same temperature and evaluate each using the correctness functionG, which compares the decision with the ground truth answery. The soft labelb∈[0,1]is then computed as the proportion of correct responses among theRsamples. Thus, for each(x, y)pair, we generate multiple training quadruples(t, q, d, b), each corresponding