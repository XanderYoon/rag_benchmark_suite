for pre-training, we ap- plied to the snippets: horizontal and vertical shifts, resizing and rotation, additive Gaussian and Perlin noises, and small and large elastic deformations. Figure 2 shows examples of two pairs of augmented sheet music snippets when ap- plying all transforms randomly. The augmentations used on the audio excerpts are: time shift, polarity inversion, addi- tive Gaussian noise and gain change, time and frequency masking, time stretching, and a 7-band equaliser. 1https://www.lilypond.org Figure 2. Examples of data augmentation. In order to investigate the effect of self-supervised con- trastive pre-training on generalisation from synthetic to real data, we prepare three evaluation datasets: (I) a fully arti- ficial one, using the MSMD; (II) a partially real one com- bining the MSMD with scans of real sheet music; and (III) an entirely real set with audio recordings and scanned sheet music images. We conduct experiments on snippet retrieval as in Section 2.2, in both search directions (audio-to-sheet and sheet-to-audio) and compare the baseline model purely trained with MSMD as in [8], with fine-tuned versions of it when the audio and sheet music convolutional pathways were pre-trained. To pre-train the individual pathways, we used raw data acquired from the web and public datasets: 200 hours of piano recordings were obtained from the MAESTRO dataset [11] and 7,000 pages of sheet music were collected from the IMSLP online platform2. Table 2.3 provides a summary of the main snippet re- trieval results in the audio-to-sheet direction. The base- line model (BL) is compared to its fine-tuned version when both audio and sheet music CNN pathways were pre-trained using self-supervised contrastive learning (BL+A+S). The pre-trained models outperform the baseline in all scenar- ios for all evaluation metrics. In [4] the same trend is re- ported for the sheet-to-audio direction, indicating that self- supervised pre-training is