excerpt and focusing on the important information that should be embedded. In [2] we conducted a series of quantitative and qualita- tive experiments on synthesised piano music data, with the results indicating that the attention mechanism is capable of increasing the robustness of the audioâ€“sheet music retrieval system. Table 1 summarises the main experimental results for a snippet-wise retrieval scenario: given an audio frag- Figure 1. (a) Illustration of the retrieval application. (b) Architecture of the embedding learning network. (c) Simplified visualisation of the embedding space. Model R@1 R@5 R@25 MRR MR BL1-2s 19.12 44.16 66.63 0.31 8 BL2-2s 48.91 67.22 78.27 0.57 2 BL2-8s 43.46 68.38 82.84 0.55 2 BL2-2s + AT 55.43 72.64 81.05 0.63 1 BL2-8s + AT 66.71 84.43 91.19 0.75 1 Table 1. Retrieval results of attention-based models. (R@k = Recall at k, MRR = Mean Reciprocal Rank, MR = Median Rank) ment as a search query, we desire to retrieve the matching sheet music snippet within a pool of 10,000 candidates from the MSMD dataset [8]. We compare the baseline network BL1 from [8] with an upgraded version BL2 of it (which replaces the last global pooling layer of each modality path- way with a dense layer) and check for retrieval improve- ments when adding the attention mechanism (+AT) and in- creasing the duration of the audio excerpts from a short con- text (SC, 2.1 sec) to a long context (LC, 8.4 sec). No improvement is at first observed when only expand- ing the temporal context of the second baseline (from BL2- SC to BL2-LC). However, when appending the attention mechanism to BL2, we notice a boost in retrieval perfor- mance, with the MRR increasing from 0.63 to 0.75. When comparing the main baseline BL1-SC with our best model configuration, we observe a substantial