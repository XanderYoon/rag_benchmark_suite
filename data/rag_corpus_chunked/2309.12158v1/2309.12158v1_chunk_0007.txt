improvement is at first observed when only expand- ing the temporal context of the second baseline (from BL2- SC to BL2-LC). However, when appending the attention mechanism to BL2, we notice a boost in retrieval perfor- mance, with the MRR increasing from 0.63 to 0.75. When comparing the main baseline BL1-SC with our best model configuration, we observe a substantial improvement in all evaluation metrics (MRR increases by 0.44 points). 2.2 Strongly-aligned data constraint In addition to the fixed-size snippet issues discussed above, another limitation of the deep learning approach pro- posed in [8] relates to its supervised nature. In order to gen- erate a large number of matching pairs of short audio and sheet music snippets for training, one requires big collec- tions of music data with strong labels (alignment annota- tions), which means fine-detailed mappings between note onsets in the audio recordings and their respective note co- ordinates in sheet music images. Since obtaining such data is labour-consuming and not trivial, the embedding learn- ing models rely on synthesised data (this limitation will be re-visited in the upcoming subsections). In [6] we propose to address both shortcomings in one, by designing a recurrent network that is can learn com- pact and fixed-sized embeddings from longer and variable- length passages of audio and sheet music. The key motiva- tion for this is twofold: by operating with variable-length passages, the cross-modal pairs can span the same music content leading to more robust representations; and by al- lowing longer excerpts, we could relax the required anno- tations from strong to weak labels, meaning that now only the corresponding passage boundaries are needed. We per- formed quantitative and qualitative experiments in diverse retrieval scenarios with artificial and real data, with the re- sults indicating a superior performance of the recurrent ar- chitectures