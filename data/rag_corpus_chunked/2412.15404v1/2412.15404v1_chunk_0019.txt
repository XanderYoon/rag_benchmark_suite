5 yielded 4,132 pairs (altogether 30,337 pairs). As the number of textbooks increased between Experiments 1 and 2, the number 10 of Q-A pairs grew substantially due to the greater volume of available data. However, when GROBID was applied in Experiments 3 and 4, a significant reduction in Q-A pairs was observed, as GROBID systematically removes extraneous content and focuses on the core textual material relevant for model fine-tuning. When the Semantic Node Splitter was introduced in Experiment 5, the number of Q-A pairs remained relatively consistent by adjusting the similarity threshold during node splitting to provide the optimal balance between quantity and the meaningfulness of the Q-A pairs. Since there is no established standard for the optimal number of Q-A pairs required for fine-tuning an embedding model, these varied experiments are designed to generate datasets of different sizes and structures for fine-tuning. This variability allows us to explore how different data formats influence the modelâ€™s performance and gain insights into the relationship between dataset size, content quality, and the resulting fine-tuned embeddings [22]. 3.4. Semantic Chunking In the third stage, we employed semantic chunking to build the vector database [14]. Un- like traditional methods that rely on recursive chunking based on a fixed token size, semantic chunking preserves the contextual integrity of the text by grouping sentences that are se- mantically related. The process begins by splitting the text into individual sentences, which are then converted into vector embeddings. By calculating the cosine similarity between these embeddings, we grouped sentences into semantically coherent chunks. A similarity threshold was needed to be chosen to separate the chunks so that they were neither too fragmented nor overly broad. Also, achieving a comparable word count was crucial to ensure that the metrics were fair and directly comparable across different experiments. Through careful