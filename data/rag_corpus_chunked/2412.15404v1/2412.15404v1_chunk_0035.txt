in CR. This suggests that while GROBID’s document structuring is beneficial, it must be paired with ample training data to ensure that critical context is not inadvertently removed during preprocessing. The combination of GROBID with fine-tuning on larger datasets restored CR to higher levels, as observed in Experiments 4 and 5, indicating that the issues introduced by GROBID can be mitigated with appropriate data preparation [22]. Semantic Chunking also played a significant role in improving CR, particularly in the final stages of the pipeline. By grouping text into semantically coherent chunks, this technique ensured that the model retrieved more meaningful and contextually relevant information. However, the trade-off between longer retrieved contexts and Faithfulness suggests that future work could explore ways to balance chunk size with the system’s ability to generate precise answers from the retrieved information. This is evident in the slight reduction in Faithfulness observed when Semantic Chunking was introduced. The Abstract-First strategy introduced in the pipeline further refined the retrieval process by focusing on abstracts to filter relevant content before conducting a more in-depth full-text search. This approach led to notable improvements in CR, achieving the highest scores across all configurations. Interestingly, the use of abstracts challenges the conventional assumption that broader searches yield better results. The findings suggest that a more focused search using abstract-level information can be equally, if not more, effective than full-text searches. This method not only reduced the average word count but also demonstrated that a concise, abstract-based search can still maintain high relevance in context retrieval. However, it remains to be seen whether this strategy is as effective in other domains where abstracts may not fully capture the nuances of the article’s content, presenting an area for future research. The Enhanced Prompting Technique, while not affecting CR directly, improved An- swer Relevance