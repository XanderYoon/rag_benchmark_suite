and RAG pipelines, respectively [21, 5]. Addition- ally, OpenAI’s GPT-4o model was employed as the LLM throughout the study, chosen for its cost-effectiveness and efficiency. To validate the effectiveness of our application, we employed the RAGAS (Retrieval Augmented Generation for Academic Search) framework and conducted tests with 50 sample questions covering various domains and problem types [7]. This rigorous testing process confirmed the application’s capability to deliver high-quality, relevant responses, highlighting its potential as a useful tool for data scientists. By integrating these advanced techniques, our application significantly enhances the traditional RAG pipeline, providing data scientists with a practical tool that simplifies academic exploration and supports informed decision- making. To validate the effectiveness of our application, we employed the RAGAS (Retrieval Augmented Generation for Academic Search) framework and conducted tests with 50 sam- ple questions covering various domains and problem types [7]. This rigorous testing process confirmed the application’s capability to deliver high-quality, relevant responses, highlight- ing its potential as a useful tool for data scientists. Although all metrics in the RAGAS framework—Context Relevance, Faithfulness, and Answer Relevance—are important, our primary focus was on improving Context Relevance. This metric serves as the main indi- cator of the system’s ability to retrieve pertinent academic content, which aligns with the central objective of this study: enhancing the retrieval process for relevant information in academic literature for data scientists. The other metrics, such as Faithfulness and Answer Relevance, assess the quality of answers generated using the retrieved context, but since the language model used for answer generation remained unchanged, these metrics are less indicative of improvements brought by the fine-tuning process and other retrieval enhance- ments. Therefore, Context Relevance serves as the most appropriate measure to demonstrate advancements in retrieval capabilities across different configurations. This paper makes two primary contributions. First, it introduces