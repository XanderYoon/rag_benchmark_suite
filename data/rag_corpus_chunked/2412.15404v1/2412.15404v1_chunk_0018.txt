The textbooks, listed in Appendix B and Appendix C, cover the same topics as our ques- tion set, ensuring that the fine-tuned models were well-aligned with the content they were intended to process. The fine-tuning process involved converting each textbook into nodes —coherent segments of text—and then generating question-answer pairs for each node us- ing the OpenAI API. GROBID, which specialized in processing academic content, was also employed to clean the fine-tuning dataset before creating these Q-A pairs. GROBID’s appli- cation to the textbooks resulted in well-prepared text for subsequent stages. As emphasized by [9], the importance of high-quality data in the context of fine-tuning cannot be overstated. This insight drove our decision to use GROBID for data cleaning, ensuring the integrity and relevance of the academic content used in our experiments [22]. Additionally, by incorporat- ing the Semantic Node Splitter, which operates similarly to semantic chunking, we were able to segment nodes based on the semantic similarity of sentences rather than arbitrary text lengths [14]. This approach allowed us to create nodes that were more semantically coherent instead of using preset token size to create nodes, which resulted in more meaningful Q-A pairs and a fine-tuned model better aligned with the complexities of academic content. The number of Q-A pairs for each experiment is as follows: Experiment 1 produced 4,819 pairs, Experiment 2 resulted in 15,326 pairs, Experiment 3 generated 1,600 pairs, Experiment 4 created 4,460 pairs, and Experiment 5 yielded 4,132 pairs (altogether 30,337 pairs). As the number of textbooks increased between Experiments 1 and 2, the number 10 of Q-A pairs grew substantially due to the greater volume of available data. However, when GROBID was applied in Experiments 3 and 4, a significant reduction in Q-A pairs was observed, as GROBID systematically removes extraneous content and focuses