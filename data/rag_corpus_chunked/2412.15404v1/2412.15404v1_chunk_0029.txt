from Experiment 3, as shown in Table 3, illustrate how various enhancements affect the retrieval process. Adding GROBID (B + G) significantly improved Context Relevance (CR) from 0.031 to 0.302, demonstrating its effectiveness in structuring the data. Faithful- ness increased to 0.687, while Answer Relevance slightly declined to 0.888, indicating some variability in the use of the retrieved context. The average word count also rose to 853.88, reflecting broader context retrieval with GROBID. Combining GROBID with fine-tuning (B + G + FT) further improved CR to 0.372, with higher Faithfulness (0.756) and Answer Relevance (0.902). This configuration had the highest Faithfulness, suggesting efficient use of the relevant context. The average word count dropped to 836.10, reflecting a more refined retrieval process. Semantic Chunking (B + G + FT + SC) raised CR to 0.456, improving retrieval of semantically coherent chunks, though Faithfulness dropped to 0.599, likely due to the larger average word count (947.94). Adding the Abstract-First strategy (B + G + FT + SC + AF) slightly reduced CR to 0.447 but improved Faithfulness to 0.606, with a lower average word count of 915.80, indicating more concise retrieval. The final configuration (B + G + FT + SC + AF + EPT) maintained a high CR (0.454) and improved Answer Relevance to 0.887. Faithfulness slightly decreased to 0.588, suggesting the potential for better alignment between context and generated responses. Overall, the fine- tuning model from Experiment 2 performed best when GROBID, fine-tuning, and Semantic Chunking were combined, while Enhanced Prompting improved the quality of responses. 16 Table 4: Significant pairwise comparisons for different metrics using Tukeyâ€™s HSD test for Table 3. (CR = Context Relevance, F = Faithfulness, AR = Answer Relevance) Metric Comparison Mean Difference p-value Significant? Context Relevance 1 vs. 2 0.2713 <0.001 Yes 2 vs. 3