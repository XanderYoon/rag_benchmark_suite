recent studies, which highlight the importance of adapting models to the specific contexts in which they are applied. For instance, [28] demonstrated how domain- specific fine-tuning significantly improved retrieval accuracy for technical documentation in Electronic Design Automation (EDA) tools by benchmarking the performance of various models. Similarly, [25] combined fine-tuning with iterative reasoning in a Q&A system, allowing for progressively refined answers, especially in complex scenarios. Natural Language Inference (NLI) to fine-tune embedding models is employed in [6], enhancing their ability to understand nuanced domain-specific language, thereby improving the relevance and accuracy of retrieved content. Therefore, by incorporating these embedding fine-tuning techniques, we hypothesized that the RAG application would be better equipped to handle specialized and intricate queries common in data science workflows, ensuring that the information provided is both precise and contextually appropriate. In the third stage of our approach, we apply semantic chunking to improve the coher- ence and relevance of the data used in our RAG application [14]. This technique enables breaking down complex information into semantically meaningful units, which are then more effectively mapped to relevant knowledge sources. The application of semantic chunking has demonstrated significant usefulness in specific fields. For example, [41] applied semantic chunking to organize medical knowledge into graph-based structures, ensuring the safe and contextually appropriate retrieval of medical information—a critical feature in healthcare where accuracy is essential. Additionally, [42] utilized semantic chunking in Visual Question Answering (VQA), where it was used to decompose complex visual questions into simpler, semantically coherent parts. This approach significantly enhanced the model’s ability to interpret and respond accurately by linking these chunks to external knowledge sources. Consequently in the enhanced RAG architecture we considered integrating a similar seman- tic chunking technique to maintain high levels of contextual accuracy and relevance, ensuring that the information retrieved and presented