of gaze depth estimation from eye tracking in augmented reality. In ACM Symposium on Eye Tracking Research and Applications, pp. 1–5, 2020. 2 [29] V . Paelke. Augmented reality in the smart factory: Supporting workers in an industry 4.0. environment. In Proceedings of the 2014 IEEE emerging technology and factory automation (ETFA), pp. 1–4. IEEE, 2014. 4 [30] H. M. Park, S. H. Lee, and J. S. Choi. Wearable augmented reality system using gaze interaction. In 2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality , pp. 175–176. IEEE, 2008. 2, 3 [31] N. Pathmanathan, M. Becher, N. Rodrigues, G. Reina, T. Ertl, D. Weiskopf, and M. Sedlmair. Eye vs. head: Comparing gaze meth- ods for interaction in augmented reality. In ACM Symposium on Eye Tracking Research and Applications, pp. 1–5, 2020. 3 [32] N. Petersen, A. Pagani, and D. Stricker. Real-time modeling and tracking manual workflows from first-person vision. In 2013 IEEE International symposium on mixed and augmented reality (ISMAR), pp. 117–124. IEEE, 2013. 2 [33] V . Peysakhovich, O. Lefrançois, F. Dehais, and M. Causse. The neu- roergonomics of aircraft cockpits: The four stages of eye-tracking integration to enhance flight safety. Safety, 4(1), 2018. doi: 10.3390/ safety4010008 3 [34] K. Pfeuffer, Y . Abdrabou, A. Esteves, R. Rivu, Y . Abdelrahman, S. Meitner, A. Saadi, and F. Alt. Artention: A design space for gaze- adaptive user interfaces in augmented reality. Computers & Graphics, 95:1–12, 2021. 1 [35] R. Piening, K. Pfeuffer, A. Esteves, T. Mittermeier, S. Prange, P. Schröder, and F. Alt. Looking for info: Evaluation of gaze based information retrieval in augmented reality. In IFIP Conference on Human-Computer Interaction, pp. 544–565. Springer, 2021. 1, 2 [36] J. Qian, J. Ma, X. Li, B. Attal, H. Lai, J. Tompkin, J. F. Hughes, and J. Huang. Portal-ble: Intuitive