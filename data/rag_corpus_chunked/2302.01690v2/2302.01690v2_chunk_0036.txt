size, and the positioning of the visual hints should be discussed and compared to make the proof-of-concept more robust. 7 C ONCLUSIONS AND FUTURE WORK In this paper, we have described an AR approach for visual search tasks with supported visual/audio hints and gaze-assisted instant post-task feedback based on mobile HMD. Previous research had given us an incentive to investigate the effect of hints and feedback. Based on our hypotheses, we designed and conducted a case study of visual book-searching where the gaze playback acted as the instant post-task feedback based. The experimental procedure consisted of a comprehensive user study (n=96) with two comparative sub-studies. The resulting analysis was founded mainly on collected NASA TLX answers with TCT measurement as a preliminary analytic metric. We partially verified H1: both visual and audio hints have a positive effect in facilitating task performance. The combination of the two hints works better than either individually, under the condition that there is instant post-task feedback.H2 was completely verified: instant post-task feedback has the capacity to bring about better performance. We pointed out the high generalizability and convertibility of our research output in making advantage of the general AR searching processes. Our research is novel because it fills the gaps of combining visual and audio hints in the same AR context, the integration of feedback and gaze assistance. More importantly, it not only focuses on the AR hints and instant post-task feedback, but places them in the same context and generates meaningful conclusions for universal AR visual search tasks. In future work, we will make our app more adjustable for human eyes and thereby user-friendly by shortening users’ adaptation time. We will also improve our system by adding adaptive support which can react to users’ gaze by giving additional help to users focusing too long