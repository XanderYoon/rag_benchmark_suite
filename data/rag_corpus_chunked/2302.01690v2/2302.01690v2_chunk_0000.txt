See or Hear? Exploring the Effect of Visual/Audio Hints and Gaze-assisted Instant Post-task Feedback for Visual Search Tasks in AR Y uchong Zhang* Chalmers University of T echnology , Sweden Adam Nowak † Lodz University of T echnology , Poland Y ueming Xuan‡ Chalmers University of T echnology , Sweden Andrzej Romanowski § Lodz University of T echnology , Poland Morten Fjeld ¶ Chalmers University of T echnology , Sweden University of Bergen, Norway Figure 1: Case study: Visual book-searching task with the aid of AR using HMD. a): Our AR app gives a book title as a search stimulus. b): Instant post-task feedback is provided by a dot smoothly following the eye trajectory. (Note: the dot is bright and highly visible in AR but is dim and difficult to see in print; here, it is located between the first and second shelves of the bookcase).c): The visual hint, as a bright purple arrow, supports the task. The timer is designed for measuring the task time (at the top of this figure). Both the gaze playback and visual hints are rendered in real world space for precise displacement. Please check our supplementary video for the demonstration of the book-searching task. ABSTRACT Augmented reality (AR) is emerging in visual search tasks for in- creasingly immersive interactions with virtual objects. We pro- pose an AR approach providing visual and audio hints along with gaze-assisted instant post-task feedback for search tasks based on mobile head-mounted display (HMD). The target case was a book- searching task, in which we aimed to explore the effect of the hints together with the task feedback with two hypotheses. H1: Since visual and audio hints can positively affect AR search tasks, the combination outperforms the individuals. H2: The gaze-assisted instant post-task feedback can positively affect AR search tasks.