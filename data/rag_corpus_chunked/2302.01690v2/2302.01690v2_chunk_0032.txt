the effects of visual/audio hints in either single or combined se- tups for AR search tasks. We also studied the influence of instant post-task feedback in the same context. To resolve the assump- tions, we developed an AR approach engaging two modules of the hints and gaze-assisted instant post-task feedback separately. We designed a case study for a visual book-searching task which in- volved the use of a mobile AR headset. An AR app was installed in Microsoft HoloLens 2. We first ran a pre-testing session to assure the functionality of our AR solution, as well as to gain early-stage feedback. After some adjustments, we designed and implemented a more comprehensive, larger-scale user study, where 96 partici- pants were allocated in Study I (n=48) and II (n=48) and placed randomly four groups (control (n=12), audio (n=12), visual (n=12), and combined (n=12)) in each sub-study. The user study was based on the between-subject principle with within-subject factor and the collected results were analyzed correspondingly. Participants were extensively engaged in searching tasks within two distinct bookcases, each containing a diverse range of totally different books, ensuring the adequacy of the study for deriving meaningful results. More- over, we have taken into account the exposure time of participants to experimental conditions, assuring that it does not compromise the validity of the results. Throughout the entire study and data analysis, H1 was partially verified, while H2 was completely verified. Our proposed solution proves to be advantageous for increasing AR visual search task performance and simultaneously reducing the perceived workload on users. We found that the combination of visual and audio hints can ameliorate both task performance and perceived workload when coupled with instant post-task feedback. We think that participants were mentally self-reflected and guided by the feedback regarding their searching modes during the tasks,