summarization of individual papers. Then the evaluation is performed using ROUGE scores and the model is saved for further utilization later in the system pipeline. The training overview of the Transformer Model is given in Figure 3. Figure 3: Training of Transformer Model The next step is to implement a system pipeline by using the transformer -based model to generate a literature review segment automatically. The system takes the DOI and PDF of multiple papers as input. It uses the Requests library to collect the paper titles and first author names from DOIs. Then it uses PYPDF2 and Regular Expression (RE) libraries to collect each PDF’s abstract, introduction, and conclusion. Then it merges 3 of these sections to get the final model input. Later it uses the previously trained and saved T5 model to get a summary of each paper. In the next step, it performs post -processing and merges all summaries to produce a coherent literature review segment. The system pipeline overview of the Transformer Model is given in Figure 4. Figure 4: Pipeline using Transformer Model D. The Procedure Utilizing the Large Language Model: GPT- 3.5-TURBO-0125 The third procedure utilizes the RAG -based approach by using the Large Language Model: GPT-3.5-TURBO-0125. The first task is to create a custom OpenAI Assistant. Firstly, the SciTLDR dataset is collected, and then the GPT -3.5-TURBO- 0125 model is selected for the OpenAI assistant. The retrieval is turned on and the dataset is added for the knowledge of the LLM. Now some prompt engineering is performed to produce the required output. Then the LLM results are evaluated using ROUGE SCORE. The overview of the creation of the OpenAI assistant is given in figure 5. Figure 5: Creation of Custom OpenAI Assistant The used prompt: “The user will give you a pdf file