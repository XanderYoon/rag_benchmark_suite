necessitating further investigation. Recently, Samarinas and Zamani [56] intro- duced a large-scale benchmark for proactive interactions to ongoing multi-party human conversations and proposed normalized proactive discounted cumulative gain (npDCG) for end-to-end evaluation of such systems. In a separate inves- tigation, Sen et al. [62] suggested evaluating proactive recommendation within search sessions by aggregating a correlation measure over the session. This mea- sure assesses the relationship between the expected outcome—comprising the list of documents retrieved with a true user query—and the predicted outcome, representing the list of documents recommended by a proactive search system. In the realm of online evaluation, conventional A/B tests can serve as a valuable tool for assessing the system’s efficacy. Additionally, interpreting user feedback—both positive and negative—can provide valuable insights into system performance. 7 Explanation Explanation can be seen as a critical tool in search result presentation in gener- ative systems, as users are interested in comprehensive justification and expla- nation of the presented results [28, 14]. Also, it can lead to more user trust in the results, potentially aiding the user to distinguish between a low-quality and a high-quality response. 7.1 An Overview of Explanation in IR Zhao et al. [94] provide a survey on the explainability of LLMs where they provide a taxonomy of explanations, together with methods for explaining Transformer- 5 https://trec.nist.gov/ based LLMs. Also, they discuss various methods for evaluating explanations for both local and global explanations. Krishna et al. [39] show that not only are explanations useful in user–system interactions, but they also improve the per- formance of LLMs. They study automatic rationale generation in a chain of thought (CoT) manner. Deng et al. [24] show that rephrasing the user input leads to a better understanding of the user request which in turn results in bet- ter performance of the LLM, which