requested by the system, for example in the form of clarifying questions or preference elicitation [5, 82, 52, 49]. Section 5 discusses these aspects in more detail. Feedback can be also requested for assessing the quality of the system at the end or in the middle of a conversation. For instance, Amazon’s Alexa Prize Challenge [51] has sought explicit rating feedback from users upon the completion of the conversation. Zamani et al. [85] introduce the possibility of improving this simple approach by asking context-aware questions for feedback and making natural language interactions within the conversation. Feedback can be provided proactively by the user, which is the focus of this section. Perhaps the simplest type of feedback that users provide can be in the form of repeating or reformulating the user’s need in the same search session . If detected, this often means that the user’s need has not been addressed yet. Besides such simple scenarios, users may provide explicit positive or negative feedback. Explicit positive feedback are often easier to identify and interpret. They are often in the form of appreciation and hold a positive sentiment. Ex- plicit negative feedback, on the other hand, is more challenging, more diverse, and perhaps more important for system designers as they help the system to improve and identify its limitations. Pointing out what parts of the system’s response is inaccurate, why it is does not satisfy the user’s needs, or express- ing frustration and disappointment are examples of explicit negative feedback. Current state-of-the-art technologies often cannot successfully take advantage of explicit negative feedback and often limit themselves to acknowledging the system’s limitations and apologizing from the users. There are huge potentials in successfully comprehending negative feedback from users. In generative IR systems, grounding as relevance feedback is also relevant to the concept of