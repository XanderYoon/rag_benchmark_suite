top results [57]. However, in a generative scenario, usually, a single answer is provided to the user, limiting the information that can be exchanged between the user and the system. 5.1 An Overview of Search Clarification Clarifying questions have been studied extensively [34] in the context of conver- sational question-answering [52], information-seeking conversations [5], and web search [82]. Another line of research studies the role of mixed-initiative interactions for user preference elicitation [49, 37]. The goal here is to understand the user pref- erence when multiple documents (items) can be deemed relevant to their infor- mation need. Radlinski et al. [49] study this problem for movie recommendation, where the user information need is typically generic (e.g., “romantic movies”) with multiple potentially relevant items. The dialogue system’s goal in this set- ting is to engage in a conversation to elicit user preference in a more fine-grained way. There has been a body of research studying the effect of mixed-initiative in- terventions such as clarifying questions on user experience [35, 84, 95, 98]. Kiesel et al. [35] study the effect of voice query clarification on user experience and find even in cases where the system performance is not improved, users have better experience. In web search, Zamani et al. [84] study the effect of incorporating a clarification pane on the search result page, implemented in Bing.com. Analyz- ing the click logs, they find that the clarification pane improves user experience. More specifically, among the seven templates they use to generate the clarifying questions, they find clear preference towards certain question templates in terms of user engagement. Zou et al. [95] study the effect of the clarification pane in the same setting in a controlled experimental setup where they introduce three quality levels and measure user satisfaction and performance. They find that asking