states the necessary context (i.e., ˆ/u1D45E1 = /u1D45E1). Next, we discuss how to utilize multiple query rewrites in va ri- ous components of a retrieval pipeline. 3.2 Sparse Retrieval Sparse retrieval relies on a bag-of-words text representat ion, where each query term contributes to the document relevance es- timate according to some scoring function, which is general ly of the form /u1D460/u1D450/u1D45C/u1D45F/u1D452( /u1D45E, /u1D451) = /summationtext.1 /u1D461∈/u1D45E /u1D464/u1D461,/u1D45E × /u1D464/u1D461,/u1D451 , where /u1D464/u1D461,/u1D45E and /u1D464/u1D461,/u1D451 are the term weights associated with query /u1D45Eand document /u1D451, respec- tively. Our interest is in setting the term query weights, /u1D464/u1D461,/u1D45E . In the most commonly used retrieval scoring functions (e.g., B M25), this weight is taken to be the frequency of the term in the quer y, i.e., /u1D464/u1D461,/u1D45E = /u1D450( /u1D461, /u1D45E) . In our approach, we construct a weighted bag- of-words query from all /u1D45Brewrites, where we set the weights for each term as the beam search score, i.e., /u1D445/u1D446( ˆ/u1D45E/u1D457 /u1D456) . For each unique term in such obtained collection of terms, the term weights f rom all rewrites are summed up and normalized. Eﬀectively, the method performs both query expansion and a re- estimation of term importance based on multiple query rewri tes. A similarity can be drawn to relevance feedback algorithms l ike RM3 [16], where two weighted queries are interpolated: the o rigi- nal query and the relevance language model query. The diﬀere nce is, here, we interpolate diﬀerent queries extracted from co nversa- tional context instead of retrieved documents and do not ass ign a pre-determined portion of the total weight mass to the orig inal query terms. Importantly, our method is seen as complementa ry to relevance feedback and can be combined with it. 3.3 Dense Retrieval Dense retrieval diﬀers from sparse retrieval in that