There- fore, the recall metric is not perfectly correlated with accu- racy. • Metrics for abstract QA tasks. Following exist- ing works, we use an LLM to generate abstract questions, with the prompts shown in Figure 13, defining ground truth for abstract questions, particularly those involving complex high-level semantics, poses significant challenges. We build on existing works (Edge et al. 2024; Guo et al. 2024) to address this and adopt an LLM-based multi-dimensional comparison method (including comprehensiveness, diver- sity, empowerment, and overall). We employ a robust LLM, specifically GPT-4o, to rank each baseline against our method. Figure 14 shows the evaluation prompt we use. • Metrics of community quality. We select the follow- ing metrics to evaluate the quality of the community: 1. Calinski-Harabasz Index (CHI) (Cali´nski and Harabasz 1974): A higher value of CHI indicates better cluster- ing results because it means that the data points are more spread out between clusters than they are within clusters. It is an internal evaluation metric where the assessment of the clustering quality is based solely on the dataset and the clustering results and not on external ground-truth la- bels. The CHI is calculated by between-cluster separation and within-cluster dispersion: CHI = N − C C − 1 PC i=1 ni||ci − c||2 PC i=1 P x∈Ci ||x − ci||2 . (3) N is the number of nodes. C is the number of clusters.ni is the number of nodes in clusteri. Ci is the i−th cluster. ci is the centroid of cluster Ci. c is the overall centroid of the datasets. x is the feature of the target node. 2. Cosine Similarity (Sim) (Charikar 2002): Cosine similar- ity is a measure of similarity between two non-zero vec- tors defined in an inner product space. In this paper, for each cluster, we calculate