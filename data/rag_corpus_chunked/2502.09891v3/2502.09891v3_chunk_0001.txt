RAG has been widely adopted across a broad range of applications (2024a; 2024a; 2024; 2024; 2023; 2024; 2024b). Current state-of-the-art RAG approaches often use graph-structured data as exter- nal knowledge, due to its ability to capture the rich seman- tics and relationships. Given a question Q, the key idea of graph-based RAG is to retrieve relevant information (e.g., nodes, subgraphs, or textual information) from the graph, incorporate them with Q as the prompt, and feed them into the LLM, as illustrated in Figure 1. Several recent meth- ods (2024; 2024; 2024; 2024a; 2024c; 2024; 2024) address two common question answering (QA) tasks: abstract ques- tions, which require reasoning over high-level themes (e.g., “What are the potential impacts of LLMs on education?”), and specific questions, which focus on entity-centric factual details (e.g., “Who won the Turing Award in 2024?”). Copyright © 2026, Association for the Advancement of Artificial Figure 1: The general workflow of graph-based RAG, which retrieves relevant information (e.g., nodes, subgraphs, or tex- tual information) to facilitate the LLM generation. In the past year, a surge of graph-based RAG meth- ods (2025; 2024c; 2024; 2024; 2024; 2023) has emerged, each proposing different retrieval strategies to extract de- tailed information for response generation. Among them, GraphRAG (2024), proposed by Microsoft, is the most prominent and the first to leverage community summariza- tion for abstract QA. It builds a knowledge graph (KG) from the external corpus, detects communities using Lei- den (2019), and generates a summary for each community using LLMs. For abstract questions that require high-level information, it adopts a Global Search approach, traversing all communities and using LLMs to retrieve the most rel- evant summaries. In contrast, for specific questions, it em- ploys a Local Search method to retrieve entities, relevant text chunks, and low-level communities, providing the multi-hop