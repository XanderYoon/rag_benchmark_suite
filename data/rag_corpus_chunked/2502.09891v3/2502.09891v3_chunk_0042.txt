ef Construction = 100. Importantly, our method maintains comparable retrieval ac- curacy to Base-HNSW, with recall of 0.5537 and 0.6058, respectively. We compare our hierarchical search based on C-HNSW with a baseline approach (Base-HNSW), which indepen- dently builds a vector index for attributed communities at each layer and performs retrieval separately for each. As shown in Figure 5, on the large-scale synthetic dataset, C- HNSW achieves up to a 5.4× speedup (On level 1, C-HNSW takes 1.861 seconds, while Base-HNSW takes 10.125 sec- onds.) and is on average 3.5× faster than Base-HNSW. Ad- ditional details are provided in the appendix. Base-HNSW C-HNSW 0 1 2 3 4 5 6 7 8 9 10Avg.051015 Level time (s) Figure 5: C-HNSW and Base-HNSW query efficiency. We also conducted experiments on a synthetic dataset of 1024-dimensional vectors, keeping all other parameters un- changed. The results are shown in Figure 6. As 1024 di- mensions are more representative of commonly used high- dimensional embeddings, our method still achieves over 5× speedup in the best case and an average speedup of 3× com- pared to the baseline. Base-HNSW C-HNSW 0 1 2 3 4 5 6 7 8 9 10Avg.051015 Level time (s) Figure 6: C-HNSW and Base-HNSW query efficiency on 1024-dimensional vector dataset. • Efficiency of indexing phrase. Figure 7 shows the in- dex construction time and token usage for different methods. The cost of building an index for ArchRAG is similar to that of GraphRAG, but due to the need for community summa- rization, both take a higher time cost and token usage than HippoRAG. RAPTOR HippoRAG LightRAG GraphRAG ArchRAG Multihop-RAGHotpotQA103 104 OOTtime (s) (a) Time cost Multihop-RAGHotpotQA1 10 100 OOT token (M) (b) Token cost Figure 7: Comparison of indexing efficiency. Table 5: Comparing ArchRAG with other RAG methods on the specific