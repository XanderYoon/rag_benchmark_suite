to the constraints of commu- nity clustering, L is typically constant, usually no greater than 5. Next, we analyze the time complexity and token usage in the online query process of the ArchRAG. Lemma 3. Given a C-HNSW withL layers constructed from a large text corpus or a large set of text documents, the time complexity of a sequentially executed single online retrieval query in ArchRAG is O(e + LkI + Lk log(n)), where I is the generation time of the LLM for a single inference, e is the time cost of computing the query embedding, k is the number of nodes retrieved at each layer, andn is the number of nodes at the lowest layer in C-HNSW. Proof. ArchRAG first computes the embedding of the query, which takes O(e) time. For each layer, querying one nearest neighbor takes no more thanO(log(n)) time, similar to the proof in (Malkov and Yashunin 2018). In the Adap- tive filtering-based generation, the content of each query is analyzed and inferred, requiring O(LkI) time. Therefore, the total time for the online retrieval query is O(e + LkI + Lk log(n)). Lemma 4. Given a C-HNSW withL layers constructed from a large text corpus or a large set of text documents, the number of tokens used for a single online retrieval query in ArchRAG is O(kL(c + P ))), where k is the number of neighbors retrieved at each layer, c is the average token of the retrieved content, and P is the token of the prompt. Proof. The token consumption for analyzing all retrieved in- formation is O(kL(c + P ))), while the token consumption for generating the final response is of constant order. There- fore, the total token consumption for the online retrieval is O(kL(c + P ))). In practice, multiple retrieved contents