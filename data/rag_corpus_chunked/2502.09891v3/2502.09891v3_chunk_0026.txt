Li, D.; Yang, S.; Tan, Z.; Baik, J. Y .; Yun, S.; Lee, J.; Chacko, A.; Hou, B.; Duong-Tran, D.; Ding, Y .; et al. 2024. DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer’s Disease Questions with Scientific Literature. arXiv preprint arXiv:2405.04819. Li, Y .; Wang, S.; Ding, H.; and Chen, H. 2023. Large lan- guage models in finance: A survey. In Proceedings of the fourth ACM international conference on AI in finance, 374– 382. Li, Z.; Yuan, H.; Wang, H.; Cong, G.; and Bing, L. 2025. LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency.Proceedings of the VLDB Endowment, 1(18): 53–65. Liu, L.; Yang, X.; Lei, J.; Liu, X.; Shen, Y .; Zhang, Z.; Wei, P.; Gu, J.; Chu, Z.; Qin, Z.; et al. 2024a. A Survey on Medical Large Language Models: Technology, Applica- tion, Trustworthiness, and Future Directions. arXiv preprint arXiv:2406.03712. Liu, N. F.; Lin, K.; Hewitt, J.; Paranjape, A.; Bevilacqua, M.; Petroni, F.; and Liang, P. 2024b. Lost in the middle: How language models use long contexts.Transactions of the Association for Computational Linguistics, 12: 157–173. Luo, L.; Li, Y .-F.; Haffari, G.; and Pan, S. 2023. Reasoning on graphs: Faithful and interpretable large language model reasoning. arXiv preprint arXiv:2310.01061. Ma, S.; Xu, C.; Jiang, X.; Li, M.; Qu, H.; Yang, C.; Mao, J.; and Guo, J. 2024. Think-on-Graph 2.0: Deep and Faith- ful Large Language Model Reasoning with Knowledge- guided Retrieval Augmented Generation. arXiv preprint arXiv:2407.10805. Malkov, Y . A.; and Yashunin, D. A. 2018. Efficient and ro- bust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence, 42(4): 824–836. Mallen, A.; Asai, A.; Zhong, V .; Das, R.; Khashabi, D.; and Hajishirzi, H. 2022. When not to trust language models: Investigating