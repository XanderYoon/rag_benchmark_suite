of GraphRAG, but due to the need for community summa- rization, both take a higher time cost and token usage than HippoRAG. RAPTOR HippoRAG LightRAG GraphRAG ArchRAG Multihop-RAGHotpotQA103 104 OOTtime (s) (a) Time cost Multihop-RAGHotpotQA1 10 100 OOT token (M) (b) Token cost Figure 7: Comparison of indexing efficiency. Table 5: Comparing ArchRAG with other RAG methods on the specific QA tasks under different LLM backbone models. LLM backbone Methods Multihop-RAG HotpotQA (Accuracy) (Recall) (Accuracy) (Recall) Llama3.1-8B Vanilla RAG 58.6 31.4 50.6 56.1 HippoRAG 38.9 19.1 51.3 56.8 RAPTOR 59.1 34.1 N/A N/A ArchRAG 68.8 37.2 65.4 69.2 GPT-3.5-turbo Vanilla RAG 65.9 32.8 60.7 65.9 HippoRAG 68.9 31.4 58.0 62.3 RAPTOR 64.4 34.6 N/A N/A ArchRAG 67.2 31.5 62.8 65.0 GPT-4o-mini Vanilla RAG 71.4 32.8 68.2 70.1 HippoRAG 70.5 31.6 65.0 68.5 RAPTOR 70.1 32.6 N/A N/A ArchRAG 77.3 33.8 69.9 73.8 To further demonstrate the effectiveness of ArchRAG, we conduct the following experiments: • Effectiveness of LLM backbones. Given the limited budget, we restrict our evaluation to GPT-4o-mini and GPT- 3.5-turbo as the LLM backbones, and compare a representa- tive subset of strong RAG methods on the HotpotQA and Multihop-RAG datasets. As strong LLMs with hundreds of billions of parameters (e.g., GPT-3.5-turbo) possess en- hanced capabilities, our proposed ArchRAG may also ben- efit from performance improvement. As shown in Table 5, the results of Llama 3.1-8B are similar to those of GPT-3.5- turbo, as Llama3.1’s capabilities are comparable to those of GPT-3.5-turbo (Dubey et al. 2024). GPT-4o-mini performs better than other LLM backbones because of its exceptional reasoning capabilities. Besides, we have compared several strong RAG baselines under different LLM backbones. As LLMs’ parameters and reasoning capabilities increase, all RAG approaches benefit from performance gains, especially HippoRAG. ArchRAG consistently achieves state-of-the-art performance across most settings. • Community quality of