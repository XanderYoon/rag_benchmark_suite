part of HippoRAG’s suboptimal performance to entity recognition issues. HippoRAG first extracts relevant entities from questions and then retrieves chunks based on these entities. How- ever, it sometimes fails to identify appropriate entities (Entity Recognition Errors, ER Errors), and we conduct corresponding experiments, as shown in Table 8. For ex- ample, on HotpotQA, HippoRAG fails to detect entities in 5.0% of questions and identifies low-quality ones in 15.8% (e.g., less than 3 characters, numeric-only terms, or sentence entities with more than 5 words). These is- sues make it difficult to match accurate entities in the KG, resulting in irrelevant retrieval and suboptimal per- formance. Similar issues also impair LightRAG’s perfor- mance because it requires accurate topic identification from questions. We also observe that as the LLM’s ca- pability improves, the performance of these methods in- creases significantly, as shown in the experiment Effec- tiveness of LLM backbone. Question & Ground-truth Question: Who is the individual associated with generative AI technology that was reportedly ousted from a leading AI organization, but is recognized for brilliance and generosity in the industry, and is currently planning to launch a new venture according to reports from TechCrunch and Fortune? Ground-truth: Sam Altman Responses of Different Methods Zero-shot Jesse Schell. He is the CTO of Calm and was the lead designer on the “Star Wars” theme park ride at Disney. Vanilla RAG It seems like there are multiple articles and topics discussed in this text. Here’s a brief summary of each section: 1.Robotics predictions. The article discusses the future of robotics, with predictions made by Brian Heater. · · · 2.TechCrunch’s Week in Review.This section summarizes various tech industry happenings. · · · 3.Bumble gets a new CEO. Bumble announces a change in leadership. · · · HippoRAG There is no question in the provided