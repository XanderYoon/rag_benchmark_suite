pre-processing, failure per- ception, root cause analysis, and auto remediation (Zhang et al. 2024). Historically and currently, many of these tasks including both incident triage and auto remediation have been treated as classification problems: for example, Ahmed et al. (2023a) treats incident resolution as a classification task matching incident tickets to a relatively small number of possible resolutions using the BERT model and embeddings. With the rise of better performing generative AI models, re- searchers have moved towards using these models to gener- ate solutions in the auto remediation task using prompting strategies (Ahmed et al. 2023b; Liu et al. 2024) or creating a model fine-tuned for a variety of IT tasks such as question- answering (Guo et al. 2023). Our use case can be considered an example of Zhang et al. (2024)’s ”Assisted Questioning”, an auto remediation task that involves utilizing LLMs to aid operations personnel in answering system-related queries. As far as we are aware, no current work exists that leverages a RAG-based approach to solve this task, although one does exist for a similar IT task of root cause analysis (Chen et al. 2024). The RAG- based approach was taken in lieu of fine-tuning such as in Guo et al. (2023)’s OWL model because of issues in real- world deployment due to its resource-intensive nature which requires significant computational resources and the inter- pretation of model decisions. Likewise, we discounted us- ing a simple prompting approach without retrieval because of client limitations in model choice that prevented us from using larger models. Retrieval and Retrieval Augmented Generation Methods for finding the relevant documents or pas- sages to answer a user query are typically divided into sparse (Robertson and Zaragoza 2009) and dense retrieval systems (Zhao et al. 2024). Our retrieval starts with a Mil- vus (Wang et