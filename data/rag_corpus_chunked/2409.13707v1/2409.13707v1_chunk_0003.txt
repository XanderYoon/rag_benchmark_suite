re-ranking based on a new model, IBM Slate 125m (IBM Research 2024) â€¢ A comparison of answer generation performance across diverse model sizes that shows smaller models can match or even beat the performance of very large models in the RAG incident remediation use case. Figure 1: System architecture 2 Architecture Given a support case subject, description, and product name, our system generates recommended solutions based on cor- pora of support documents. Our system consists of four ma- jor components as illustrated in Figure 1: an encoder-only transformer classifier, a query generation system, a retriever system, and an answer generator system. Preprocessing: Support cases are ingested with unstruc- tured text data fields of case subject, case description, prod- uct name, and product version number. The escape and non- ASCII characters are removed from the case subject and description, and the two fields are concatenated. We pre- process the product name by matching it to a dictionary of known product acronyms or alternative names to append to the query used in retrieval. Case Turn Classifier:The cleaned and concatenated case subject and description are fed into the classifier which de- termines if the support case is a single turn. ingle-turn cases are defined as those that can be resolved using only the infor- mation present in the case subject and description, without requiring any additional information or clarification from the customer. The classifier is an encoder-only transformer model IBM Slate 125m (IBM Research 2024) that was fine- tuned on almost 14,000 examples labeled by subject matter experts. If the case is predicted to be single turn, the case continues to the next step in the pipeline. Question Generator: The question generator summarizes the often vague case subjects and verbose, convoluted de- scriptions into concise text queries suitable for the retrieval system. The