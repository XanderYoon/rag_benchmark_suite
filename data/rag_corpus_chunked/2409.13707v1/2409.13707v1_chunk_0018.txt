retrieval because of client limitations in model choice that prevented us from using larger models. Retrieval and Retrieval Augmented Generation Methods for finding the relevant documents or pas- sages to answer a user query are typically divided into sparse (Robertson and Zaragoza 2009) and dense retrieval systems (Zhao et al. 2024). Our retrieval starts with a Mil- vus (Wang et al. 2021) vector database that has indexed the software support documentation with a general purpose dense embedding that serves multiple services. In our so- lution, we then make use of a popular optimization by re- ranking the first-pass result to obtain a more appropriate ranking for our particular application (Nogueira and Cho 2020; Han et al. 2020), giving us the results of a special- purpose index while still retaining the benefits of a central indexing service. Other popular improvement methods in- clude combining sparse and dense embeddings into a hybrid system (Luan et al. 2021). Retrieval augmented generation was developed to address cases in which large language models have not learned and stored domain knowledge through pre-training. Originally implemented by combining dense retrieval and a fine-tuned BART model, the method generalizes well to larger genera- tive models (Fan et al. 2024). The quality of the answer gen- eration can be improved through prompt engineering, refin- ing how the specific generative model is prompted with the context, question, and other instructions. (Liu et al. 2023). However, it has been noted that the retrieval component in RAG has been understudied in comparison to the genera- tion component despite its substantial impact on the final performance of such hybrid systems. (Petroni et al. 2024; Cuconasu et al. 2024) 8 Conclusion We were able to deliver a first working version of an IT product solution recommendation system employing RAG. To our knowledge, this is