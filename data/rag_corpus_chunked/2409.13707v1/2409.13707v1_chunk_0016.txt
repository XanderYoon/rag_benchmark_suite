necessarily wrong. This suggests that for ground truth data, we should consider a list of correct links instead of a single ground truth link for each question. The low agree- ment of single-turn vs. multi-turn labels also potentially ex- plains the lower performance of the classifier model if the model is attempting to learn from potentially conflicting in- formation. RAG Bottlenecks The major bottleneck in RAG systems is the retrieval com- ponent. As shown in Table 4, when given the correct con- text, LLMs can typically generate responses that match the ground truth answers. However, we cannot expect to gen- erate the correct answer if given the wrong contexts which happens for around 60% of the cases (Figure 2). For compar- ison, Google search limited to the corresponding domains indexed by the Milvus database performed worse at 30% R@3 compared to our method at 43% R@3 (See Figure 2). This implies, as other researchers have suggested, that the retrieval component in RAG is not a solved problem by any means. (Petroni et al. 2024; Cuconasu et al. 2024) 7 Related Work LLM-Based AIOps As software systems become more complex, Artificial In- telligence for IT Operations (AIOps) methods are widely used to manage software system failures and ensure the high availability and reliability of large-scale distributed software systems (Zhang et al. 2024). Machine learning and natural language processing methods such as LLMs have been used in AIOps for incident triage, data pre-processing, failure per- ception, root cause analysis, and auto remediation (Zhang et al. 2024). Historically and currently, many of these tasks including both incident triage and auto remediation have been treated as classification problems: for example, Ahmed et al. (2023a) treats incident resolution as a classification task matching incident tickets to a relatively small number of possible resolutions using the