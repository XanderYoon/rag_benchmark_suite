Score: 4/5. This produced α = 3/(3 + 4) = 0.43 (rounded to 0.4), appropriately weighting toward the more relevant result. These examples demonstrate how DAT’s scoring mechanism effectively balances retrieval methods based on result quality rather than relying on predefined query categories. By evaluating the specific relationship between each query and the retrieved contents, the system adapts to diverse information needs. 7 Conclusion We introduced DAT, a framework that dynamically adjusts the weighting between sparse and dense retrieval for each query by leveraging LLMs to evaluate document effectiveness. Unlike static weighting schemes, DAT adaptively selects the optimalα per query, achieving a balance between performance and efficiency—even with smaller models. Experiments show 9 Preprint. Under review. that DAT consistently outperforms fixed-weight hybrids, especially on hybrid-sensitive queries, and remains robust across different LLM sizes. These results underscore the limitations of static approaches and highlight the value of query-adaptive strategies. References Asma Ben Abacha, Wen wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, and Thomas Lin. Medec: A benchmark for medical error detection and correction in clinical notes. arXiv preprint arXiv:2412.19260, 2025. Alec Berntson. Azure ai search: Outperforming vector search with hybrid retrieval and reranking. https://techcommunity.microsoft.com/blog/azure-ai-services-blog/az ure-ai-search-outperforming-vector-search-with-hybrid-retrieval-and-reranki ng/3929167, 2023. Sebastian Bruch, Siyu Gai, and Amir Ingber. An analysis of fusion functions for hybrid retrieval. ACM T ransactions on Information Systems, 42(1):1–35, August 2023. ISSN 1558- 2868. doi: 10.1145/3596512. URL http://dx.doi.org/10.1145/3596512. DeepSeek-AI. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL https://arxiv.org/abs/2501.12948. Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, Yuanzhuo Wang, and Jian Guo. A survey on llm-as-a-judge. arXiv preprint arXiv: 2411.15594 , 2024. Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, and Jong Park. Adaptive- RAG: Learning to adapt retrieval-augmented large language models through