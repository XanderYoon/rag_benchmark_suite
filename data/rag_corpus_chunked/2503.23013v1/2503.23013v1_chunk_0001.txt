overall performance of RAG systems, making it a critical area for optimization. Hybrid retrieval (Ma et al., 2020; Sawarkar et al., 2024; Berntson, 2023) approaches combining sparse (e.g., BM25) and dense methods have demonstrated superior performance compared to either method alone. BM25 (Robertson et al., 1994) excels at precise keyword matching through term frequency calculations, while dense retrieval (Karpukhin et al., 2020) captures semantic relationships that may not involve direct lexical overlap. While the complementary strengths of these methods are well established, effectively balancing their contributions remains challenging. Current approaches (Bruch et al., 2023) typically employ a fixed weighting parameter (α) determined through offline tuning on validation datasets. This static weighting scheme, however, fails to account for the diverse nature of user queries, where the optimal balance between keyword matching and semantic similarity varies significantly based on query characteristics and knowledge base structure. Recent efforts to address this limitation include approaches that assign different α values based on query types (e.g., fact-seeking, concept-seeking, etc.) (Theja, 2024). However, these methods still rely on predetermined categories with fixed weights and often overlook the complex interplay between individual queries and the knowledge base. If this assumption holds—that many queries benefit more from extreme values (i.e., pure BM25 or pure dense ∗Corresponding author 1 arXiv:2503.23013v1 [cs.IR] 29 Mar 2025 Preprint. Under review. retrieval)—then using a compromise value such as α = 0.5, while seemingly optimal on average, may in fact lead to suboptimal performance for most individual queries. This would pose a significant challenge to hybrid retrieval optimization. These limitations and opportunities motivate our research questions: • How can we effectively combine sparse and dense retrieval methods to maximize retrieval performance? • How can a retrieval system adapt to the specific relationship between each query and the knowledge base to determine optimal retrieval parameters?