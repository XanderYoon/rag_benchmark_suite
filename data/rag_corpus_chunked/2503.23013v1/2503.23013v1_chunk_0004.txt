complementary strengths of multiple retrieval meth- ods. BM25 (Robertson et al., 1994), the predominant sparse retrieval algorithm, calculates relevance based on term frequency and inverse document frequency, efficiently handling exact keyword matching. Meanwhile, dense retrieval approaches (Karpukhin et al., 2020) leverage vector embeddings to capture semantic relationships beyond lexical overlap. The effectiveness of combining sparse and dense methods has been comprehensively demon- strated in hybrid RAG systems, where improved retrieval quality significantly enhances generation accuracy (Ma et al., 2020; Sawarkar et al., 2024; Berntson, 2023). The challenge of determining optimal weighting coefficients has traditionally been ad- dressed through offline tuning (Bruch et al., 2023), where experiments on validation sets establish a fixed weight that is then applied universally to all future queries, regardless of their characteristics. Some approaches (Jeong et al., 2024) attempt refinement by classify- ing queries into predefined types. LlamaIndex (Theja, 2024) proposed assigning different weights based on predefined query categories, though this approach still relies on static weights per category. Our work differs by leveraging LLMs’ reasoning capabilities to dynamically assess retrieval quality and calibrate weighting parameters per query, without relying on predefined cate- gories or fixed weights from offline tuning. This approach aligns with recent trends in using LLMs as judges (Gu et al., 2024) but applies this concept specifically to adaptive hybrid retrieval optimization. Unlike previous approaches that optimize parameters across entire query sets, DAT addresses the limitations of fixed-weight systems by dynamically adapting to each query’s unique characteristics and its relationship to the knowledge base. 3 Preprint. Under review. 3 Hybrid Retrieval Hybrid retrieval combines sparse and dense retrieval to leverage both keyword matching and semantic understanding. Sparse methods like BM25 score documents based on lexical overlap: BM25(q, d) = n ∑ i=1 IDF(qi) · f (qi, d) · (k1 + 1) f (qi,