each query’s unique characteristics and its relationship to the knowledge base. 3 Preprint. Under review. 3 Hybrid Retrieval Hybrid retrieval combines sparse and dense retrieval to leverage both keyword matching and semantic understanding. Sparse methods like BM25 score documents based on lexical overlap: BM25(q, d) = n ∑ i=1 IDF(qi) · f (qi, d) · (k1 + 1) f (qi, d) + k1 · (1 − b + b · |d| avgdl ) (1) Dense retrieval encodes queries and documents into vectors using embedding functions Eq and Ed, with similarity computed via cosine similarity: Simdense(q, d) = cos(Eq(q), Ed(d)) = Eq(q) · Ed(d) ||Eq(q)|| · || Ed(d)|| (2) To combine these methods, hybrid systems typically use techniques such as the rela- tiveScoreFusion algorithm (Kulawiak & Hwang, 2023) which balances the influence of different retrieval approaches. First, we normalize the similarity scores from both retrieval methods using min-max scaling: ˜Sdense(q, d) = Simdense(q, d) − mind′∈Ddense(q)(Simdense(q, d′)) maxd′∈Ddense(q)(Simdense(q, d′)) − mind′∈Ddense(q)(Simdense(q, d′)) (3) ˜SBM25(q, d) = BM25(q, d) − mind′∈DBM25(q)(BM25(q, d′)) maxd′∈DBM25(q)(BM25(q, d′)) − mind′∈DBM25(q)(BM25(q, d′)) (4) where ˜Sdense(q, d) and ˜SBM25(q, d) are normalized scores in the range [0, 1]. Hybrid systems typically combine these normalized scores using a fixed weighting parameter α: R(q, d) = α · ˜Sdense(q, d) + (1 − α) · ˜SBM25(q, d) (5) This fixed α is determined via offline tuning on validation data and then applied uniformly to all queries. However, such a static strategy fails to account for the varying nature of user queries, limiting retrieval effectiveness across diverse scenarios. 4 DAT To overcome the limitations of static weighting in hybrid retrieval, we introduce DAT, a query-adaptive framework that dynamically adjusts the retrieval weighting coefficient based on the effectiveness of each method for a given query. The central intuition is that different queries