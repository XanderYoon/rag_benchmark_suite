not aid the LLM and may instead become redundant information for the generation. (2) As the number of docu- ments increases, it is natural to observe a decline 48 document1 193 document2 (relevant) 326 document3 486 document4 635 32 28 24 20 16 12 8 4 Layer 63 eR 1 document1 214 eR 2 document2 (relevant) 353 eR 3 document3 519 eR 4 document4 674 eR 5 32 28 24 20 16 12 8 4 Layer Figure 6: Heatmaps of self-attention distribution of the last token, broken out by token position (X-axis) and layer (Y-axis). Each attention layer comprises 8 heads, and the attention weights are the mean of all the heads. Darker yellow means higher attention weights. eR i is the retrieval information embedding for i-th document. performance. Surprisingly, learnable tokens sig- nificantly enhance the performance of the LLM. These findings demonstrate that the retrieval-aware prompting strategy effectively assists LLMs in pro- cessing multiple documents, especially when those documents include irrelevant information. 4.5 Discussions The Impact of Performance of Retrievers and LLMs. As mentioned in Section 1, the quality of retrieved documents can heavily influence the performance of LLMs in RAG. From the main re- sults, R 2AG achieves improvements even when the retrieval performance is poor, as observed in MuSiQue and DuReader datasets. Further- more, we conduct experiments on NQ-10 dataset with five non-trained retrievers, specifically BGE- Reranker (Xiao et al., 2023), BERT (Devlin et al., 2019), Contriever (Izacard et al., 2022), and Ope- nAI Embedding models (small and large) (Nee- lakantan et al., 2022), with 1024, 768, 768, 1536, and 3072 dimensions, respectively. Note that Ope- nAI Embedding models are closed-source. From the results presented in Figure 4, we easily observe that a stronger retriever leads to better performance, both standard RAG and R2AG. Importantly, R2AG significantly