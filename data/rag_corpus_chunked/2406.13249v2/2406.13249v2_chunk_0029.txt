Dou, and Ji rong Wen. 2023b. Large language models for infor- mation retrieval: A survey. ArXiv, abs/2308.07107. Datasets Language # Query # Train/Test # Tokens # Rel/Docs MAP NQ-10 English 2655 2124/531 ∼2k 1/10 0.9602 NQ-20 English 2655 2124/531 ∼4k 1/20 0.9287 NQ-30 English 2655 2124/531 ∼6k 1/30 0.9215 HotpotQA English 97852 90447/7405 ∼2k 2.36/10 0.9138 MuSiQue English 22355 19938/2417 ∼3k 2.37/20 0.5726 2Wiki English 180030 167454/12576 ∼2k 2.42/10 0.9637 DuReader Chinese 200 160/40 ∼16k 1.82/20 0.7169 Table 4: Statistics of datasets. “# Rel/Docs” denotes the number of relevant documents and the total number of documents for each query. “MAP” represents the Mean Average Precision, a common retrieval metric. A Retrieval Feature Extraction Details Formally, the relevance between the query and the i-th document is calculated as: ri = sim  xq, xd i  , (10) where sim is a similarity function such as dot prod- uct or cosine similarity, xq and xd i are representa- tions of query and i-th document, respectively. The precedent similarity computes the simi- larity score between case representation and its precedent-weighted representations in the ranking list as follows: γi=sim  xd i , i−1X j=1 wj · xd j   , wj= exp(rj)Pk ℓ=1 exp(rℓ) , (11) where γi is the precedent similarity between i-th document and its precedents in the ranking list, and ri is relevance between the query and i-th docu- ment. Neighbor similarity represents the average simi- larity of i-th document to its adjacent documents. Specifically, the neighbor similarity of a case in the ranking list is given by: ζi = (sim(xd 1, xd 2), i = 1 [sim(xd i−1, xd i ) + sim(xd i , xd i+1)]/2, i ∈ [2, k) sim(xd k−1, xd k), i = k , (12) where ζi represents the average similarity of