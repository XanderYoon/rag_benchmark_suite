fG, is ex- pected to generate the output ˆy. The pipeline can be expressed as: ˆy = fG (P (q, D)) , (1) where P is a predefined prompt template. It shows the retrievers and LLMs are couple in a simplistic prompt-based method, which will lead to miscom- munication and the semantic gap. Figure 2 illustrates the overall framework of R2AG. Initially, given a query and retrieved docu- ments, R2AG processes representations modeled by a retriever into unified-format features. These list-wise features consider nuanced relationships both between the query and documents and among the documents themselves. Then, a R 2-Former is designed to capture retrieval information for LLM usage. It allows unified features to interact with each other via self-attention mechanism, enabling it to understand complex dependencies. To integrate retrieval information into the LLM’s generation process, R2AG adopts a retrieval-aware prompting strategy to insert the retrieval information into the LLM’s input embedding space without causing in- formation loss or increasing much complexity. Be- sides, R2AG is flexible to be applied in low-source scenarios where LLMs are frozen. 3.2 Retrieval Feature Extraction Before generation, it is necessary to obtain high- quality retrieval features. In R 2AG, we first get semantic representations from the retrieverfR. For- mally, a query q and document d are encoded into representations as xq=fR(q) and xd=fR(d), re- spectively. However, these representations can not be directly used because a single representation can not capture interactive features for LLM’s gen- eration. Moreover, to suit various retrievers, it is intuitive to transform representations in different spaces into unified format features. Inspired by works in retrieval downstream tasks (Ma et al., 2022; Ye and Li, 2024), we align these representations into retrieval features by com- puting relevance, precedent similarity, and neigh- Query & Documents Query <R> Document1, ... , <R> Documentk