et al., 2018) is a well-known multi-hop question answering dataset based on Wikipedia. This dataset involves questions requir- ing finding and reasoning over multiple supporting facts from 10 documents. There are two reasoning types of questions: bridging and comparison. MuSiQue (Trivedi et al., 2021) has questions that involve 2-4 hops and six types of reasoning chains. The dataset is constructed through a bot- tom–up process by carefully selecting and compos- ing single-hop questions. The final answer to each question in the distractor setting is extracted from 20 documents. 2WikiMultiHopQA (2Wiki) (Ho et al., 2020) consists of up to 5-hop questions, each associated with 10 documents. Unlike HotpotQA, this dataset needs to evaluate the interpretability of models not only with supporting evidence but also with entity- relation tuples. DuReader (He et al., 2018) is a Chinese dataset developed based on Baidu Search and Baidu Zhi- dao. To adapt it for assessing long context ability, for each question, Bai et al. (2023b) arbitrarily se- lect several documents from the total corpus as distractors until each question is associated with 20 candidate documents. The ground truth labels are provided in original datasets. Detailed statistics can be found in Table 4. D Implementation Details Unlike some works (Li et al., 2023b; Zhu et al., 2023a) built on LA VIS (Li et al., 2022), we com- pletely implement R2AG on PyTorch (Paszke et al., 2019) and Transformers (Wolf et al., 2020) libraries for easy usage. For the retrieval task, we utilize the Sentence- Transformer (Reimers and Gurevych, 2019) to fine- tune a BERT (Devlin et al., 2019) model as the re- triever, which is a siamese dual encoder with shared parameters. The models “bert-base-uncased” and “bert-base-chinese”are used for English datasets and the Chinese dataset, respectively. All retrievers adopt default hyper-parameter settings with 768 embedding dimensions.