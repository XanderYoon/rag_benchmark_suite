“GT”means only retaining ground-true documents. boosts their capabilities in handling provided doc- uments. (2) Compared with other LLMs using standard RAG, R2AG generally achieves better per- formance except for closed-source LLMs. GPT4 shows superior results in most datasets, establish- ing it as a strong baseline. Notably, R 2AG ex- cels ChatGPT in NQ and HotpotQA datasets. Us- ing LLaMA27B as the foundational LLM, R2AG competes well with LLaMA38B and LLaMA213B across most metrics. (3) It is clear that R 2AG significantly surpasses other enhanced RAG meth- ods in most results, underscoring the importance of incorporating retrieval information. Although CRAG has a good result in NQ datasets, its perfor- mance significantly declines in multi-hop datasets. That is because CRAG’s simplistic approach of fil- tering out documents irrelevant to the query can omit crucial connections needed for understanding complex queries. Additionally, our method outper- forms compression-based methods (RECOMP and LongLLMLingua). Our case studies reveal their poor performance is mainly because the coordi- nation between the compressors and LLMs tends to result in substantial information loss and even severe hallucinations. (4) RAFT can significantly improve the performance. When combined with R2AG, the results are the best overall, suggesting that a deeper understanding acquired through train- ing benefits generation capabilities. 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Retrieval Metric 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7Generation Metric 0.401 0.356 0.292 0.296 0.298 0.303 BGE-Ranker BERT Contriever OpenAIsmall OpenAIlarge BERT-FT R2AG LLaMA27B Figure 4: Performance comparison of R2AG with vari- ous retrievers on NQ-10 dataset. HotpotQA 2Wiki MuSiQue 0.0 0.2 0.4 0.6Acc 4.51% 8.14% 38.95% Acc F1 0.0 0.1 0.2 0.3 0.4 F1 24.05% 1.68% 3.08% Figure 5: Performance of R 2AG7B and R 2AG13B. Darker parts mean the difference values of R2AG13B. 4.4 Ablation Studies To demonstrate the effectiveness of R 2AG,