documents using a computationally efficient retriever, followed by a second stage where these documents are re-ranked using a stronger, typically, neural network-based model. This re- ranking step enhances retrieval quality by considering deeper se- mantic relationships between the query and documents. While effective, re-ranking models vary significantly in their architec- tures, trade-offs, and implementations, making it challenging for users to select the most suitable method for their specific needs. To address this, Rankify provides a unified interface for re- ranking, enabling users to effortlessly switch between different models with minimal modifications. The framework supports a diverse set of 24 primary re-ranking models with 41 sub-methods, spanning different re-ranking strategies such as pointwise, pair- wise, and listwise approaches. The implemented models include MonoBERT [64], MonoT5 [65], RankT5 [ 115], ListT5 [ 110], Col- BERT [83], RankGPT [90], and various transformer-based re-rankers. Users can apply these models to re-rank retrieved documents using a simple interface, as demonstrated in Listing 6. 1 from rankify . dataset . dataset import Document , Question , Answer 2 from rankify . retrievers . retriever import Retriever 3 from rankify . rerankers . reranker import Reranker 4 # Define sample documents 5 documents = [ 6 Document ( question = Question ( " the cast of a good day to die hard ? " ) , 7 answers = Answer ([ " Jai Courtney " , " Bruce Willis " ]) , contexts =[]) , 8 Document ( question = Question ( " Who wrote Hamlet ? " ) , 9 answers = Answer ([ " Shakespeare " ]) , contexts =[]) 10 ] 11 # Initialize a retriever 12 retriever = Retriever ( method = " colbert " , model = " colbert - ir / colbertv2 .0 " , n_docs =5 , index_type = "