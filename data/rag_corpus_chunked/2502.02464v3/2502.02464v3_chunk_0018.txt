of models, includ- ing cross-encoders, T5-based ranking models, and late-interaction retrieval models like ColBERT. The flexibility to switch between different re-ranking strategies allows researchers and practitioners to optimize ranking performance based on their task requirements. 3.5 Retrieval-Augmented Generation (RAG) Models Retrieval-Augmented Generation (RAG) enhances language models by integrating retrieval mechanisms, allowing them to generate responses based on dynamically retrieved documents rather than relying solely on pre-trained knowledge. This approach is particu- larly effective for knowledge-intensive tasks such as open-domain question answering, fact verification, and knowledge-based text generation. Rankify provides a modular and extensible interface for applying multiple RAG methods, including zero-shot generation, Fusion-in-Decoder (FiD) [38], and in-context learning [77]. In Rankify, the Generator module enables seamless integration of RAG techniques, allowing users to experiment with different gen- erative approaches. Users can specify the desired RAG method and model, applying generation strategies across retrieved documents. Users can apply these methods to generate responses based on retrieved documents. Listing 7 demonstrates how to use Rankifyâ€™s RAG module with an in-context learning approach. 1 from rankify . dataset . dataset import Document , Question , Answer , Context 2 from rankify . generator . generator import Generator 3 # Sample question and contexts 4 question = Question ( " What is the capital of France ? " ) 5 answers = Answer ([ " Paris " ]) 6 contexts = [ 7 Context ( id =1 , title = " France " , text = " The capital of France is Paris . " , score =0.9) , 8 Context ( id =2 , title = " Germany " , text = " Berlin is the capital of Germany . " , score =0.5) 9 ] 10 # Create a Document 11 doc = Document ( question = question , answers = answers