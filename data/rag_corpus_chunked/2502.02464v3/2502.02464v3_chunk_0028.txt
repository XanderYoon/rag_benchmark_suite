67.83 75.87 41.97 65.64 72.98LiT5-Distill-xl-v247.92 69.03 76.17 41.53 65.69 73.27 SentenceTransformerReranker GTR-base [63] 39.41 65.95 76.03 36.56 64.32 73.62GTR-large 40.63 68.25 76.73 38.97 65.30 73.57T5-base [75] 31.19 63.60 76.06 29.77 62.84 73.52T5-large 30.80 63.35 76.37 30.51 61.71 73.37all-MiniLM-L6-v2 [100]33.35 65.37 76.01 30.95 62.10 73.52GTR-xl 41.55 67.78 76.81 38.92 66.04 74.01GTR-xxl 42.93 68.55 77.00 39.41 65.89 74.01T5-xxl 38.89 67.78 76.64 35.82 65.20 74.01Bert-co-condensor30.96 61.91 75.20 32.43 62.20 73.08Roberta-base-v2 32.60 63.24 75.42 31.34 62.64 73.37 4.3 Comparison with Original Implementations To validate the correctness and reliability of theRankify’s retrieval module, we compare its performance against original implementa- tions and Pyserini-based baselines for multiple retrievers. Specif- ically, we evaluate DPR, Contriever, BM25, and ColBERT across three open-domain QA datasets: NQ, TriviaQA, and WebQ. The retrieval performance is measured using Top-20 and Top-100 accu- racy. Table 5 presents the results of our Rankify implementation alongside the original models and Pyserini-based implementations. Our results show thatRankify achieves retrieval performance iden- tical to Pyserini for DPR, BM25 as we utilize Pyserini as the back- end for indexing and retrieval. However, for Contriever BGE, and ColBERT, we implemented their methods independently, and our Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and RAG SIGIR ’25, July 13–18, 2025, Padova, IT BM25 Contriever DPR Retriever 0 10 20 30 40 50 60 70 80EM Score 14.90 15.29 28.08 12.82 13.24 23.21 14.02 13.96 13.99 19.81 19.78 19.78 21.14 20.47 21.94 11.19 11.08 11.11 NQ - EM Comparison Language Model LLama V3 8B LLama V3.1 8B Gemma-2-2b Gemma-2-9b Llama-2-13b-hf Mistral-7B-v0.1 BM25 Contriever DPR Retriever 42.10 36.25 45.88 40.13 35.29 43.62 43.28 33.05 33.05 57.55 50.93 50.93 57.90 42.69 51.07 52.85 42.69 42.69 TriviaQA - EM Comparison Language Model LLama V3 8B LLama V3.1 8B Gemma-2-2b Gemma-2-9b Llama-2-13b-hf Mistral-7B-v0.1 BM25 Contriever DPR Retriever 10.23 10.67 19.83 9.25 9.35 14.32 14.71