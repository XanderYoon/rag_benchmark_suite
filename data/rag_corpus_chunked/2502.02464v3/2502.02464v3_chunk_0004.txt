vance. However, this approach treats all document pairs equally, sometimes improving lower-ranked results at the expense of top- ranked ones. (3) Listwise reranking [71, 90, 110] considers the en- tire document list, prompting LLMs with the query and a subset of candidates for reranking. Due to input length limitations, these methods tend to employ a sliding window strategy, progressively refining rankings from back to front. Retrieval-Augmented Generation (RAG) [27, 51] enhances lan- guage models by integrating retrieval and generation, making them more effective in knowledge-intensive tasks. Rather than relying solely on pre-trained knowledge, RAG dynamically retrieves rele- vant documents from external sources during inference, incorpo- rating them into the generation process. The growing complexity and diversity of retrieval, re-ranking, and RAG methods pose significant challenges for benchmarking, re- producibility, and integration. Existing toolkits, such as Pyserini [52], Rerankers [19] and RankLLM [ 70] often lack flexibility, enforce rigid implementations, and require extensive preprocessing, mak- ing them less suitable for research-driven experimentation. Addi- tionally, retrieval and re-ranking datasets are scattered across differ- ent sources, complicating evaluation and comparison. To address these challenges, we introduce Rankify, an open-source frame- work that unifies retrieval, re-ranking, and RAG into a modular and extensible ecosystem (logo shown in Figure 1). Rankify sup- ports diverse retrieval techniques, integrates the state-of-the-art re-ranking models, and provides curated pre-retrieved datasets to streamline experimentation. Designed for maximizing flexibility, it enables researchers to efficiently build, evaluate, and extend re- trieval pipelines while ensuring consistency in benchmarking. The main contributions of this paper are as follows: • Curated retrieval datasets and precomputed embed- dings: Rankify provides 40 datasets, each with 1,000 pre- retrieved documents per query, across various domains (QA, dialogue, entity linking, etc.). It also includes pre-computed Wikipedia and MS MARCO corpora for multiple retrievers, eliminating preprocessing overhead. • Diverse retriever