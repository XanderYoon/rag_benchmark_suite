Each addresses a distinct bottleneck in the retrieval pipeline, offering trade-offs in latency, scalability, and faithfulness. Adaptive retrieval dynamically adjusts when to retrieve based on model uncertainty or predictive confidence. TA-ARE replaces static thresholds with a learned estimator, reducing redundant retrievals by 14.9% in short-form tasks. DRAGIN takes this further by applying retrieval at the token level, using entropy signals to detect knowledge gaps and triggering retrieval through a self-attentive query formulation process. Though it improves multi-hop QA precision, DRAGIN introduces notable inference costs, mitigated through adaptive frequency thresholds. FLARE proactively anticipates knowledge needs before uncertainty arises, improving faithfulness but requiring careful thresholding to avoid excessive retrieval. Multi-source retrieval targets adaptability across evolving corpora or specialized domains. AU-RAG introduces agent-based retrieval, dynamically selecting sources based on metadata heuristics. This improves domain coverage but necessitates hierarchical pipelines to manage source prioritization. SimRAG enhances retrieval precision using self-supervised learning on synthetic QA pairs, filtered via round-trip consistency. While it achieves 1.2–8.6% accuracy gains across datasets, it risks overfitting, mitigated by human-in-the-loop validation. Query refinement techniques enhance retrieval relevance by modifying ambiguous or underspecified queries. RQ-RAG uses perplexity-driven decomposition and rewriting to improve relevance, especially in multi-fact scenarios. However, this incurs inference overhead, mitigated through selective refinement based on query ambiguity. R2AG improves post-retrieval alignment by injecting retrieval metadata into prompts, bridging the retriever–generator semantic gap. Though effective, it adds computational cost, addressed by only enabling metadata prompting when retrieval scores fall below a relevance threshold. Hybrid and structured retrieval approaches improve coherence by integrating unstructured and structured sources. M-RAG clusters knowledge into semantic partitions, with dual agents selecting and refining content. It reduces noise but introduces latency, mitigated by dynamic partition expansion. KRAGEN retrieves subgraphs from knowledge graphs, using Graph-of-Thoughts prompting for relational reasoning. This reduces hallucinations by 20–30%, though it increases