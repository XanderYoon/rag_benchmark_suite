arXiv:2506.00054v1 [cs.IR] 28 May 2025 This is a preprint under review at ACM TOIS. Do not redistribute the final version without permission. Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers CHAITANYA SHARMA, Independent Researcher, United States Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to enhance large language models (LLMs) by conditioning generation on external evidence retrieved at inference time. While RAG addresses critical limitations of parametric knowledge storage—such as factual inconsistency and domain inflexibility—it introduces new challenges in retrieval quality, grounding fidelity, pipeline efficiency, and robustness against noisy or adversarial inputs. This survey provides a comprehensive synthesis of recent advances in RAG systems, offering a taxonomy that categorizes architectures into retriever-centric, generator-centric, hybrid, and robustness-oriented designs. We systematically analyze enhancements across retrieval optimization, context filtering, decoding control, and efficiency improvements, supported by comparative performance analyses on short-form and multi-hop question answering tasks. Furthermore, we review state-of-the-art evaluation frameworks and benchmarks, highlighting trends in retrieval-aware evaluation, robustness testing, and federated retrieval settings. Our analysis reveals recurring trade-offs between retrieval precision and generation flexibility, efficiency and faithfulness, and modularity and coordination. We conclude by identifying open challenges and future research directions, including adaptive retrieval architectures, real-time retrieval integration, structured reasoning over multi-hop evidence, and privacy-preserving retrieval mechanisms. This survey aims to consolidate current knowledge in RAG research and serve as a foundation for the next generation of retrieval-augmented language modeling systems. CCS Concepts: •Information systems → Retrieval models and ranking; Evaluation of retrieval results; Information retrieval query processing; Retrieval tasks and goals ; Document representation. Additional Key Words and Phrases: Retrieval-Augmented Generation, Query Reformulation, Context Filtering, Reranking, Multi-hop Reasoning, Hallucination Mitigation, Robustness, Dynamic Retrieval, Evaluation Benchmarks, Federated Retrieval, Faithfulness, Efficiency Optimization, Document Ranking, LLM Alignment, Open-Domain QA 1 Introduction Large Language Models (LLMs) have demonstrated impressive generalization