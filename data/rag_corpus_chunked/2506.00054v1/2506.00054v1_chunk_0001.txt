models and ranking; Evaluation of retrieval results; Information retrieval query processing; Retrieval tasks and goals ; Document representation. Additional Key Words and Phrases: Retrieval-Augmented Generation, Query Reformulation, Context Filtering, Reranking, Multi-hop Reasoning, Hallucination Mitigation, Robustness, Dynamic Retrieval, Evaluation Benchmarks, Federated Retrieval, Faithfulness, Efficiency Optimization, Document Ranking, LLM Alignment, Open-Domain QA 1 Introduction Large Language Models (LLMs) have demonstrated impressive generalization across natural language tasks, but their reliance on static, parametric knowledge remains a fundamental limitation. This restricts their ability to handle queries requiring up-to-date, verifiable, or domain-specific information, often resulting in hallucinations or factual inconsistencies [19, 40]. Retrieval-Augmented Generation (RAG) addresses this issue by coupling pretrained language models with non- parametric retrieval modules that fetch external evidence during inference. By conditioning generation on retrieved documents, RAG systems offer greater transparency, factual grounding, and adaptability to evolving knowledge bases. These properties have made RAG central to tasks such as open-domain QA, biomedical reasoning, knowledge-grounded dialogue, and long-context summarization. However, integrating retrieval with generation introduces unique challenges: retrieval noise and redundancy can degrade output quality; misalignment between retrieved evidence and generated text can lead to hallucinations; and pipeline inefficiencies and latency make deployment costly at scale. Moreover, balancing modularity with tight retrieval–generation interaction remains an open architectural trade-off. In this survey, we first present a high-level taxonomy of RAG architectures based on where core innovations occur—within the retriever, the generator, or through their joint coordination (Section 3). We begin with a background Author’s Contact Information: Chaitanya Sharma, Independent Researcher, United States. Manuscript submitted to ACM 1 Retrieval-Augmented Generation: A Survey 2 Fig. 1. Retrieval-Augmented Generation (RAG) workflow. A user query is processed by the retriever, which may perform query expansion before retrieving documents from external knowledge sources (e.g., databases, APIs, or document stores). Retrieved documents are re-ranked by relevance, and the Top-K