prompting strategies, and evaluation protocols. This approach enables a meaningful comparison across diverse experimental setups. Among generator-based RAG systems primarily optimized for accuracy, SELF-RAG consistently demonstrates substantial gains across multiple datasets. It achieves over a 270% improvement from the raw LLM baseline on PopQA [42] and over 200% on ARC-Challenge [12], illustrating the effectiveness of deep context integration for enhancing short- form factual recall. FiD-Light, although also a generator-side enhancement, adopts a different optimization philosophy centered on lightweight, efficient fusion of retrieved documents during decoding, yielding more moderate improvements of 18–27% across TriviaQA [35] and NQ [37]. R2AG, another generator-based approach, shows promising gains, with over 80% improvement from the baseline on NQ, further validating the benefits of integrating retrieval signals within generation. We note that generator-based frameworks primarily designed for efficiency, such as xRAG, are discussed separately due to their distinct optimization focus. Retriever-based frameworks such as RQ-RAG and SimRAG also demonstrate notable gains. RQ-RAG achieves a 288% improvement on PopQA and over 210% on ARC-Challenge, reaffirming the importance of retrieval quality in evidence-centric QA. SimRAG also shows strong improvements on ARC, although gains are more modest (approximately 14%). Additionally, retriever-side re-ranking approaches like FILCO deliver moderate but meaningful gains, with 5–30% improvements across NQ and TriviaQA, further highlighting the incremental value of retrieval refinement strategies. Hybrid frameworks exhibit a more heterogeneous pattern. CRAG and Self-CRAG achieve impressive gains, with Self-CRAG delivering a 320% improvement on PopQA and a 208% improvement on ARC-Challenge, suggesting that combining retrieval refinement with generation adaptation can be highly effective when well aligned. However, TA-ARE, despite achieving a significant 28× improvement over raw baselines on RetrievalQA, occasionally underperforms relative to the standard retrieval baseline, indicating that retrieval frequency reduction strategies, while efficient, may introduce trade-offs. Stochastic RAG frameworks, meanwhile, display relatively modest gains (typically