to improve MRR/nDCG while reducing retrieval noise by 15%. ToolRerank further adapts reranking depth based on familiarity with seen vs. unseen tools, boosting recall by 12% in hierarchical retrieval tasks. These methods optimize computation by avoiding unnecessary reranking in low-complexity scenarios. Unified reranking pipelines combine retrieval, document ranking, and generation within a single architecture. RankRAG fine-tunes a language model to jointly score documents and generate answers, improving MRR@10 by 7.8% while reducing latency. uRAG extends this to multiple tasks—like QA and fact verification—using shared reranking logic and user-feedback signals, improving cross-task generalization by 8% MRR@10. These approaches eliminate the overhead of separate ranking modules and increase retrieval consistency. Fusion-based reranking strategies aggregate evidence from multiple query variants to improve answer robustness. RAG-Fusion generates multiple subqueries and applies reciprocal rank fusion, improving answer accuracy by 9%.R2AG refines these rankings iteratively, reducing irrelevant retrievals by 15% through recursive feedback. These models are especially effective for multi-hop and ambiguous tasks. Reranking methods significantly boost the efficiency and faithfulness of RAG systems. Future work may explore hybrid approaches combining adaptive truncation with fusion-based aggregation, as well as domain-adaptive reranking for enterprise scalability. As RAG expands to more tasks and domains, reranking will remain essential to enabling context-aware, trustworthy generation. Manuscript submitted to ACM Retrieval-Augmented Generation: A Survey 12 Table 1. Summary of RAG System Enhancements. This table categorizes enhancements across five dimensions—retrieval, filtering, efficiency, robustness, and reranking. Each entry specifies the enhancement type, method, mechanism, key strengths, known limitations, and ideal use cases. Enhancement Type Category Method Mechanism Strengths Limitations Best Use Case Retrieval Adaptive TA-ARE Dynamic confidence estima- tion Reduces redundant retrieval Estimator latency Short-form QA Adaptive DRAGIN Token-level entropy-based trig- gers Improves multi-hop QA preci- sion High inference cost Multi-hop QA Adaptive FLARE Preemptive uncertainty detec- tion Enhances faithfulness Risk of over-retrieval