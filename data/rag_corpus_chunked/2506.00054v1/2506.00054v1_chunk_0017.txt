reduce retrieval precision. Speculative Pipelining [71] further reduces latency by overlapping retrieval and generation. It incrementally processes top-ùëò candidates before retrieval completes, lowering time-to-first-token (TTFT) by 20‚Äì30%. However, it risks speculative hallucinations unless controlled by fallback mechanisms and selective decoding checkpoints. This line of work opens the door for future speculative decoding architectures‚Äîdiscussed in Section 8‚Äîthat balance responsiveness and reliability in low-latency applications. Caching and redundancy reduction techniques aim to eliminate recomputation overhead in repetitive or high- throughput workloads. RAGCache [33] introduces a hierarchical caching system that stores key-value tensors from prior retrievals. PGDSF extends this with prefix-aware eviction that prioritizes frequent and important documents. While these methods significantly improve efficiency in common-query settings, their impact diminishes on long-tail distributions and introduces cache complexity. Retrieval faithfulness and answer relevance methods go beyond lexical similarity to ensure that retrieved documents are factually aligned with the generated output. Rich Answer Encoding (RAE) addresses this using a Retriever-as-Answer Classifier (RAC) and Dense Knowledge Similarity (DKS), which rescore documents based on their plausibility. RAE reduces hallucinations and improves grounding but requires retriever retraining, increasing cost. Taken together, these optimization strategies enhance efficiency across the RAG pipeline: Sparse RAG andR2AG improve alignment between retrieved documents and generation; FiD-Light and Speculative Pipelining reduce latency during inference; RAGCache and PGDSF minimize recomputation in high-throughput environments; and RAE advances retrieval faithfulness. Collectively, they represent a move toward more scalable, accurate, and computationally efficient RAG systems. 4.4 Enhancing Robustness RAG systems improve factual accuracy in language models by retrieving external information. However, they remain vulnerable to retrieval noise, hallucinations, and adversarial attacks. While past research has addressed these challenges separately‚Äîsuch as noise resilience, hallucination control, and retrieval security‚Äîa unified perspective is essential. This section groups robustness techniques into three areas: noise mitigation, hallucination reduction, and security defenses. Empirical studies