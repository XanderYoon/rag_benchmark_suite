affect both answer accuracy and model certainty. Adversarial Robustness and Security: Emerging work also highlights new vulnerabilities. BadRAG [ 78] and TrojanRAG [8] demonstrate that adversarially poisoned passages can serve as semantic backdoors, triggering spe- cific behaviors in LLM outputs even when base models remain unmodified. These attacks rely on stealthy corpus manipulations that are hard to detect and pose significant threats in open-domain or API-exposed RAG systems. Collectively, these systems complement retrieval- and generation-oriented architectures by offering essential safety guarantees in real-world deployments. Their robustness strategies—ranging from retrieval verification and context compression to constrained generation—are modular and often integrable into existing RAG pipelines. Manuscript submitted to ACM Retrieval-Augmented Generation: A Survey 8 4 Enhancements in RAG Recent advancements in Retrieval-Augmented Generation (RAG) increasingly focus on targeted enhancements across the retrieval–generation pipeline. Beyond architectural baselines, these enhancements address key limitations in retrieval quality, context integration, computational efficiency, robustness to perturbations, and ranking precision. This section delineates five core areas of optimization—retrieval, filtering, efficiency, robustness, and reranking—each contributing to the development of more reliable and performant RAG systems, and collectively summarized in Table 1, which compares representative methods based on their mechanisms, strengths, limitations, and ideal use cases. 4.1 Retrieval Enhancement RAG systems have increasingly adopted smarter retrieval strategies to mitigate inefficiencies such as redundant lookups, irrelevant context, and computational overhead. These improvements can be categorized into four major families: adaptive retrieval, multi-source retrieval, query refinement, and hybrid or structured retrieval. Each addresses a distinct bottleneck in the retrieval pipeline, offering trade-offs in latency, scalability, and faithfulness. Adaptive retrieval dynamically adjusts when to retrieve based on model uncertainty or predictive confidence. TA-ARE replaces static thresholds with a learned estimator, reducing redundant retrievals by 14.9% in short-form tasks. DRAGIN takes this further by applying retrieval at the token level, using entropy signals