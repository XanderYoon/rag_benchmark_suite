a relevance threshold. Hybrid and structured retrieval approaches improve coherence by integrating unstructured and structured sources. M-RAG clusters knowledge into semantic partitions, with dual agents selecting and refining content. It reduces noise but introduces latency, mitigated by dynamic partition expansion. KRAGEN retrieves subgraphs from knowledge graphs, using Graph-of-Thoughts prompting for relational reasoning. This reduces hallucinations by 20–30%, though it increases memory overhead, controlled via selective node expansion. Extending hybrid retrieval designs, the Dual-Pathway KG-RAG framework [ 74] combines structured retrieval from knowledge graphs with unstructured corpus retrieval in parallel, enhancing factual consistency and reducing hallucinations by 18% in biomedical QA tasks. Similarly, Graph RAG [16] constructs entity-centric graphs from retrieved passages and uses community summarization to scale RAG to large corpora, improving multi-hop QA recall by 6.4 Manuscript submitted to ACM Retrieval-Augmented Generation: A Survey 9 points compared to baseline retrieval. Likewise, Customer Service QA [77] integrates RAG with knowledge graphs constructed from issue-tracking tickets, achieving a 77.6% improvement in retrieval MRR and a 28.6% reduction in resolution time when deployed at LinkedIn’s customer service team. In a complementary direction, Doan et al. [ 15] propose a lightweight hybrid retrieval strategy that combines unstructured text embeddings with structured knowledge graph embeddings without requiring complex retriever re-training, achieving up to 13.1% improvements in retrieval correctness and ranking precision in domain-specific RAG deployments. 4.2 Enhancing Context Relevance through Filtering Despite advances in retrieval models, RAG systems often integrate irrelevant, redundant, or semantically noisy docu- ments that degrade generation quality. Filtering techniques aim to reduce hallucinations and improve answer relevance by selecting only contextually appropriate content. These methods vary in supervision, granularity, and efficiency, and can be categorized into three groups: lexical/statistical filters, information-theoretic optimizers, and self-supervised passage scoring. Lexical filters such as FILCO apply word overlap and statistical relevance scoring. Using STRINC