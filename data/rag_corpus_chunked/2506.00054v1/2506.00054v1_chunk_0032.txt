the strongest FactScore gain (+0.456), while SELF-RAG on ASQA achieves the best precision (+29.56%) and recall (+18.81%) improvements. Flare-Direct, outperforming Flare-Instruct by over 20% on 2Wiki, highlights the sensitivity of robustness to prompt design. At the lower end, Stochastic RAG on FEVER [65] records the smallest impact ( ≤+0.008 FactScore), reinforcing the necessity of combining retrieval strategies with downstream verification to enhance factual fidelity. Collectively, these findings affirm that retrieval alone is insufficient for robust generation. The most effective frameworks tightly couple retrieval, generation, and verification in iterative loops, ensuring that generation is guided by critique and alignment rather than treated as a terminal step. Manuscript submitted to ACM Retrieval-Augmented Generation: A Survey 17 Table 3. Comparative Robustness Analysis of RAG Frameworks Across Architectures.Relative improvements in precision, recall, and FactScore over retrieval-augmented baselines across multiple datasets. A dash (–) denotes missing values in the original paper. Taxonomy Framework Backbone Dataset Precision Recall FactScore Retriever-based RAG Re2G KGI0 NQ 0.096984 0.074569 – Re2G KGI1 TriviaQA 0.177981 0.159062 – Re2G KGI2 Fever 0.120986 0.073732 – FILCO RAG Fever 3.25 – – Generation-based RAG SELF-RAG LLaMA2-7B ASQA 22.06897 15.95 0.041026 SELF-RAG LLaMA2-7B ASQA 29.56522 18.80556 0.034839 Rich Answer Encoding RAG MSMARCO – 0.086957 – Rich Answer Encoding RAG KILT-WoW – 0.107293 – DRAGIN LLaMA2-13B HotPotQA 0.185934 0.09893 – DRAGIN VICUNA-13B HotPotQA 0.222447 0.105114 – GenRT RAG NQ – 0.023232 – GenRT RAG TriviaQA – 0.026239 – Hybrid RAG CRAG LLaMA2-7B Biography – – 0.251689 Self-CRAG LLaMA2-7B Biography – – 0.456081 Flare-Instruct GPT-3.5 2Wiki 0.010288 0.019417 – Flare-Direct GPT-3.5 2Wiki 0.216049 0.215534 – Stochastic RAG FiD-Light (T5-Base) Fever – – 0.008685 Stochastic RAG FiD-Light (T5-XL) Fever – – 0.00355 5.4 Ablation Studies Ablation studies serve as a crucial methodological lens for disentangling the contributions of individual components in Retrieval-Augmented Generation (RAG) frameworks. Across the