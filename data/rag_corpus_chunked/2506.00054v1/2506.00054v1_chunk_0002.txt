Authorâ€™s Contact Information: Chaitanya Sharma, Independent Researcher, United States. Manuscript submitted to ACM 1 Retrieval-Augmented Generation: A Survey 2 Fig. 1. Retrieval-Augmented Generation (RAG) workflow. A user query is processed by the retriever, which may perform query expansion before retrieving documents from external knowledge sources (e.g., databases, APIs, or document stores). Retrieved documents are re-ranked by relevance, and the Top-K are passed to the generator as factual context. The generator synthesizes a response conditioned on both the query and retrieved content. An optional post-processing step (e.g., ranking, rewriting, or fact-checking) may further refine the output, enhancing factual consistency, real-time adaptability, and overall response quality in large language models (LLMs). on RAGâ€™s mathematical formulation and components (Section 2.2), and then explore advances in retrieval strategies, filtering, and control mechanisms (Section 4). We further analyze how RAG systems are benchmarked (Section 6), compare prominent frameworks (Section 5), and conclude with open research challenges and future directions (Section 7). 2 Background and foundations of retrieval-augmented generation Retrieval-Augmented Generation (RAG) is a framework that augments large language models (LLMs) with external knowledge access via document retrieval. It builds on the intuition that generating grounded and verifiable responses requires not only parametric knowledge stored in model weights, but also non-parametric access to a dynamic evidence corpus. This section outlines the core components of RAG systems and presents the mathematical formulation that underpins their design. 2.1 Components of a RAG System At a high level, a RAG system consists of three modules: Manuscript submitted to ACM Retrieval-Augmented Generation: A Survey 3 Query Encoder: Encodes the input ğ‘¥ into a query representation ğ‘, which is used to retrieve relevant documents. This can be either a neural encoder or a rule-based template. Retriever: Given the query ğ‘, the retriever fetches a ranked list of documents ğ‘‘1, ğ‘‘2, .