retrieval-guided generation. Hybrid systems are organized by retrieval dynamics (e.g., multi-round, utility-driven), and robustness-oriented models address challenges such as noise, hallucination, and adversarial vulnerabilities. This structure highlights the diverse innovations shaping the RAG landscape. Query-Driven Retrieval: A prominent strategy focuses on refining and structuring user intent before retrieval to maximize alignment with relevant corpus segments. This includes decomposition, rewriting, generative reformulation, and the incorporation of structured priors to guide retrieval. Notable examples include RQ-RAG (Refine Query for RAG) [6], which decomposes multi-hop queries into latent sub-questions, and GMR (Generative Multi-hop Retrieval) [38], which uses a generative LLM to autoregressively formulate complex multi-hop queries. RAG-Fusion [ 50] further improves recall by combining results from multiple reformulated queries through reciprocal rank fusion [13]. Structured approaches have also emerged: KRAGEN (Knowledge Retrieval Augmented Generation ENgine) [43] introduces graph-of- thoughts prompting to decompose complex queries into subproblems, retrieving relevant subgraphs to guide multi-hop reasoning. Additionally, LQR (Layered Query Retrieval) [25] implements hierarchical planning over multi-hop questions, while Sparse Context Selection [90] emphasizes efficient sparse reformulations for both recall and speed. Manuscript submitted to ACM Retrieval-Augmented Generation: A Survey 5 Retriever-Centric Adaptation: Another line of work modifies the retriever itself through architectural enhance- ments or task-specific learning. Re2G (Retrieve, Rerank, Generate) [20] blends symbolic and neural retrieval via reranking layers, while SimRAG (Self-Improving RAG) [73] employs self-training over synthetic QA pairs to improve domain generalization. Frameworks like RankRAG [83] and uRAG (unified RAG) [57] emphasize retriever versatilityâ€”either by unifying reranking and generation within a single backbone or by training general-purpose retrievers across varied downstream tasks. Additionally, systems such as ToolRerank [88] dynamically adapt retrieval strategies based on query semantics, optimizing tool selection in specialized retrieval settings. Relatedly, SEER (Self-Aligned Evidence Extraction for RAG) [87] focuses on post-retrieval adaptation, advancing corpus-based evidence extraction by aligning evidence