mechanism, key strengths, known limitations, and ideal use cases. Enhancement Type Category Method Mechanism Strengths Limitations Best Use Case Retrieval Adaptive TA-ARE Dynamic confidence estima- tion Reduces redundant retrieval Estimator latency Short-form QA Adaptive DRAGIN Token-level entropy-based trig- gers Improves multi-hop QA preci- sion High inference cost Multi-hop QA Adaptive FLARE Preemptive uncertainty detec- tion Enhances faithfulness Risk of over-retrieval Long-form generation Multi-source AU-RAG Agent-based source selection High domain adaptability Source management overhead Evolving corpora Multi-source SimRAG Synthetic QA + round-trip fil- tering Cross-domain accuracy gains Overfitting risk Specialized domains Query RQ-RAG Perplexity-based query rewrit- ing Improves query clarity and rel- evance Additional inference steps Multi-fact queries Query R 2AG Retrieval-aware prompt injec- tion Enhances factual grounding Prompt expansion overhead Low-confidence queries Hybrid M-RAG Semantic partitioning + dual agents Reduces retrieval noise Partition latency Context-heavy reasoning Hybrid KRAGEN Knowledge graph subgraph re- trieval Improves structured reasoningMemory and compute inten- sive Biomedical, graph-based tasks Filtering Lexical FILCO STRINC + CXMI scoring +8.6 EM, 64% hallucination re- duction Query-style bias Structured QA Info-Theoretic IB Filtering Bottleneck-based compression +3.2 EM, 2.5% compression Computation overhead High-precision QA Info-TheoreticStochastic Filtering Utility-maximizing re-ranking Improves effectiveness Needs custom scoring Lightweight retrieval tasks Self-Supervised SEER Pseudo-relevance via self- training +13.5% F1, 9.25x context reduc- tion High training cost Open-domain QA Self-Supervised RAG-Ex Generation perturbation com- parison 76.9% human-aligned faithful- ness Multiple inference passes Faithful generation Efficiency Sparse Selection Sparse RAG Retains high-signal tokensReduces memory, improves rel- evance May discard useful docs Long-context tasks Sparse Selection R2AG Context-aware retrieval injec- tion Enhances coherence, lowers re- dundancy Retriever fine-tuning needed Knowledge-intensive QA Inference Acceler- ation FiD-Light Compresses passages Faster decoding Slight loss in recall Low-latency applications Caching Speculative Pipelining Overlaps retrieval and genera- tion 20â€“50% TTFT reduction Risk of hallucination Real-time applications Caching RAGCache Hierarchical cache w/ PGDSF Eliminates recomputation