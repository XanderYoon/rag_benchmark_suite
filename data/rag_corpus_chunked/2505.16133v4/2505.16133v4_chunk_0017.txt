42.6 0.679 28.7 Table 5: The effectiveness of the information bottleneck theory on the filtering data compression rate and concise mutual information in the test sets of the PGCC module for NQ and HotpotQA. The proposition-level chunking in Hash-RAG, combined with the PGCC module guiding LLMs to focus on the correspondence between propositions and documents, is theoretically optimized and experimentally validated as the optimal trade-off between efficiency and accuracy. Figure 3: Prompt Guidance Attention Heat Map ficiency, thereby degrading generation accuracy. Prompt Guidance on Attention To investigate how prompts influence attention mechanisms dur- ing LLM text generation, we employ Recall@1 to identify a document providing optimal factual sup- port, thereby validating the effectiveness of prompt optimization. We generate comparative attention heatmaps (Figure 3) illustrating model behavior with versus without prompts. The prompt-free con- dition exhibits concentrated self-referential atten- tion along the diagonal axis. In contrast, prompted generation demonstrates vertical attention patterns focusing on proposition tokens Pj, accompanied by significant off-diagonal highlights indicating strengthened long-range dependencies between an- swer generation positions and critical propositions. 5.2 Training of deep hashing algorithms Time Complexity We compare our hash method to other deep hashing baselines on NQ dataset, with the training time results illustrated in Figure 4. In our evaluation framework, DSH (Liu et al., 2016) and DHN (Zhu et al., 2016) represent conventional Figure 4: Training time on NQ dataset. deep hashing baselines trained on 10,000 sampled data points, while DSH-D and DHN-D denote their full-database counterparts. The result reveals that full-database training of baselines needs over 80 minutes for convergence, which inspires the sam- pled training of the large-scale datasets. Moreover, our method achieves significantly faster conver- gence than both sampled and full-database base- lines while maintaining the highest accuracy. Sensitivity to Parameters Figure 5 illustrates the hashing hyperparameter Î³ sensitivity on