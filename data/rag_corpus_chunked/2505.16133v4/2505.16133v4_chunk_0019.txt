Chengdu Scicnce and Technology Burcau Project with ID 2024-YF09-00041-SN,and the National Natural Science Foundation of China Project with ID W2433163. Limitations The focus of this paper is to deeply integrate deep hashing techniques with the RAG model. The ex- perimental framework assumes that the external knowledge base is static. If incremental updates are required, such as adding new documents or revising content, the hash encoder needs to be retrained to incorporate the new data, which is computationally expensive. In the future, developing an efficient adaptation strategy for dynamic hashing encoding remains an open challenge. References Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen- liang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023. A multi- task, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023. Erik Bernhardsson. 2015. Annoy (approx- imate nearest neighbors oh yeah). URL https://github.com/spotify/annoy. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901. Riccardo Cantini, Fabrizio Marozzo, Giovanni Bruno, and Paolo Trunfio. 2021. Learning sentence-to- hashtags semantic mapping for hashtag recommen- dation on microblogs. ACM Transactions on Knowl- edge Discovery from Data (TKDD), 16(2):1–26. Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Philip S Yu. 2017. Hashnet: Deep learning to hash by continuation. In Proceedings of the IEEE inter- national conference on computer vision, pages 5608– 5617. Moses S Charikar. 2002. Similarity estimation tech- niques from rounding algorithms. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing, pages 380–388. Qi Chen, Bing Zhao, Haidong Wang, Mingqin Li, Chuanjie Liu, Zengzhong Li, Mao Yang, and Jing- dong Wang. 2021. Spann: Highly-efficient billion- scale approximate nearest neighborhood search. Ad- vances