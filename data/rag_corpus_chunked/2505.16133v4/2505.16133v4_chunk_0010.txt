through mutual information: I(eX; Y ) = Z eX Z Y p(ex, y) log p(ex, y) p(ex)p(y) dexdy (9) The compression objective minimizes LIB = I(eX; X) − βI(eX; Y ), where the Lagrange multi- plier β balances information retention and compres- sion. Unlike conventional sentence/paragraph units (Karpukhin et al., 2020), we adopt proposition units (Min et al., 2023) that capture atomic semantic ex- pressions. Proposition extraction occurs during the knowledge base preprocessing phase (i.e., index construction). So for document Doc, we extract k interrelated propositions X = [ x1, . . . , xk], with relevance scores computed through hybrid scoring: Xf = αXdoc + (1 − α) nX k=1 wkxk (10) where Xdoc and xk denote document-level and BERT-based proposition scores respectively, with α and wk optimized via cross-validation. Hash-based retrieval optimizes proposition se- lection through Hamming distance relationships: distH(hqi, hpj) = 1 2(d − ⟨hqi, hpj ⟩) (11) where d is the binary code dimension. We itera- tively expand the Hamming radius until selecting the top α propositions, α denotes the approximate candidate set retrieved via Hamming distance cal- culations on hash codes: Top Pj = arg max i∈{1,...,α} ⟨vqi, hpj ⟩ (12) Deduplication over proposition-document map- pings yields the final top k retrieved documents {Doc1, . . . , Dock} = Duplicates(P1 ∪ . . . ∪ Pj). This dual optimization of semantic compression and hash-based retrieval ensures maximal informa- tion extraction with minimal noise. Prompt Optimization We employ LLAMA2 as the generator with optimized prompts. The Hash-Retriever identifies top-j propositions Pj = {P1, . . . , Pj} and their corresponding document indices Dock, forming the generator’s context through three key components: (1) Additional Prompt instructing semantic integration of propo- sitions and indexed documents for precise re- sponses, (2) Retrieved Segments containing similarity-ranked propositions Pj