(Embedding) utilize BERT base, large, AL- Model Top 5 Top 20 Top 100 Index Query NQ TQA HQA NQ TQA HQA NQ TQA HQA size time BM25 45.2 55.7 - 59.1 66.9 - 73.7 76.7 - 7.4 913.8 SimCSE 28.8 44.9 26.7 44.3 59.4 44.1 47.0 62.4 46.1 64.6 548.2 Contriever 47.8 59.4 42.5 67.8 74.2 67.4 82.1 83.2 76.9 64.6 608.0 PQ 50.7 63.0 43.7 72.2 73.2 64.3 81.2 80.4 62.1 2.0 46.2 MEVI† 75.5 - - 82.8 - - 87.3 - - 151.0 222.5 DPR 66.0 71.6 54.4 78.4 79.4 73.0 85.4 85.0 80.3 64.6 456.9 LSH‡ 43.2 48.0 38.4 63.9 65.2 60.5 77.2 76.9 71.1 2.0 28.8 DSH‡ 57.2 64.7 44.2 77.9 77.9 66.2 85.7 84.5 80.4 2.2 38.1 HbR(Ours) 72.4 78.3 57.7 80.3 87.0 80.2 87.5 88.4 81.4 4.6 42.3 ±0.2 ±0.2 ±0.1 ±0.2 ±0.1 ±0.1 ±0.3 ±0.1 ±0.1 Table 1: Top k recall on test sets with the index size(GB) and query time(ms) of HbR and baselines. † Model selected is MEVI Top-100 & HNSW from the main experiments and HNSW backbone retrieval method results in a multiplicative increase in index size, and the retrieval time of MEVI is not SOTA.‡ Integration of hash with the encoder, selecting DPR, DSH model selected is hash table lookup with candidate = 1000. Model LLAMA2-7B LLAMA2-13B NQ TQA HQA NQ TQA HQA ToolFormer♢ 17.7 48.8 14.5 22.1 51.7 19.2 RRR 25.2 54.9 19.8 27.1 59.7 24.4 FILCO 25.8 55.0 19.4 27.3 60.4 23.9 REPLUG♦ 27.1 57.1 20.5 29.4 62.7 26.8 Hash-RAG 28.5 ±0.1 57.1±0.1 22.1±0.2 34.9±0.2 64.5±0.1 31.1±0.3 Table 2: EM of open-domain QA. ♢ Generation models in this experiment involve the GPT series, all of which are modified to the LLAMA2 series and w/o train reader in this experiment. ♦ Contriever and a zero-shot setting are selected.