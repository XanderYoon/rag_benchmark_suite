denote their full-database counterparts. The result reveals that full-database training of baselines needs over 80 minutes for convergence, which inspires the sam- pled training of the large-scale datasets. Moreover, our method achieves significantly faster conver- gence than both sampled and full-database base- lines while maintaining the highest accuracy. Sensitivity to Parameters Figure 5 illustrates the hashing hyperparameter γ sensitivity on NQ dataset. Our method shows stability across a broad range (1 < γ < 500), with Mean Average Precision (MAP) fluctuating within 0.01. It could potentially be attributed to NQ’s hierarchical semantic struc- ture, which exhibits tolerance to hash-induced local perturbations. This parameter invariance reduces deployment optimization complexity while ensur- ing multi-scenario reliability. Figure 5: Hyperparameter γ on NQ dataset. Conclusion We bridge deep hashing with retrieval-augmented generation for efficient, fine-grained knowledge retrieval and context-augmented generation, bal- ancing the trade-off between the query processing time and recall. Not only as an evaluation frame- work for hash retrievers, Our proposed PGCC mod- ule further improves the accuracy and relevance of retrieval by optimizing the chunking strategy and addressing contextual information limitations. Experimental results demonstrate that our hash re- triever significantly outperforms baseline methods and achieves impressive metrics in the generator. In future work, we plan to explore the application of hash techniques to other tasks and structures, such as the knowledge graph. Acknowledgments This rescarch is supported by the Sichuan In- ternational Science and Technology Innovation Coopcration Project with ID 2024YFHZ0317,the Chengdu Scicnce and Technology Burcau Project with ID 2024-YF09-00041-SN,and the National Natural Science Foundation of China Project with ID W2433163. Limitations The focus of this paper is to deeply integrate deep hashing techniques with the RAG model. The ex- perimental framework assumes that the external knowledge base is static. If incremental updates are required, such as adding new documents or