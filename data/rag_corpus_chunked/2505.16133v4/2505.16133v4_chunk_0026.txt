ilarity retrieval. In Proceedings of the AAAI confer- ence on Artificial Intelligence, volume 30. A Prompt Template Open-domain QA for LLaMA-2-7B Please consider all relevant details in the retrieved segments and offer a concise, in- formative, and contextually appropriate response. If necessary, carefully review the corresponding indexed documents to support your answer with just a few words: IdxID:23 Title: Mount Everest Propositions: Mount Everest is Earth’s highest mountain above sea level. IdxID:23 Title: Mount Everest Propositions: Mount Everest is known in Tibetan as Chomolungma. IdxID:59 Title: Lhasa Tibetan Propositions: Verbs in Tibetan always come at the end of the clause. .... ID=23 Title: Mount Everest Doc: Mount Everest, known locally as Sagarmatha or Qomolangma,[note 4] is Earth’s highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas. The China–Nepal border .... Question: What is the highest mountain in the world? The answer is: Mount Everest B Dataset B.1 Dataset statistics Dataset # Examples train dev test NQ 79.2 8.7 3.6 TQA 78.8 8.8 11.3 HOTPOTQA 88.9 5.6 5.6 Table 6: Dataset statistics We use three datasets built from Wikipedia arti- cles as supporting documents for answer, response, and judgment generation, as listed in Table 6. B.2 Units of Wikipedia # units Avg. # words Passages 41,393,528 58.5 Sentences 114,219,127 21.0 Propositions 261,125,423 23.2 Table 7: Statistics of text units in the English Wikipedia. We refer to the processed corpus as Prop-WIKI. The statistics of Prop-WIKI are shown in Table 7. Notably, the values presented here correspond to the average segment length of the processed Wikipedia corpus, while Table 5 specifically re- ports the average input sequence length fed into the text generator during inference.