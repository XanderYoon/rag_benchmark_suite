capture subtle semantic dependencies that independent encodings miss. This richness in feature modeling makes cross-encoders particularly effective for reranking small sets of candidates with high precision. However, their computational cost scales with the number of pairs, which is why they are typically used only in a second-stage reranking step following an efficient first-stage retriever. Recent work also explores “shallow” cross-encoders to balance latency and effectiveness. [96] 2. LLM Reranking: LLM-based rerankers employ large language models to refine the ordering of retrieved passages by assessing their relevance to a given query. Instead of relying on additional training or fine-tuning, these approaches typically leverage prompt engineering to guide the model in comparative judgment, ranking candidate passages according to contextual fit and semantic alignment. This makes them flexible and adaptable across domains, as they can harness the reasoning and comprehension abilities of LLMs without the cost of retraining. By directly incorporating natural language understanding into the reranking stage, LLM-based rerankers enhance retrieval pipelines with improved precision and context-awareness. [97] 3. Hybrid Reranking (Cross-Encoder + LLM): A Hybrid Reranker integrates both cross- encoder and LLM reranking into a unified pipeline to benefit from their complementary strengths. In such a design, an initial cross-encoder stage provides precise token-level scoring for a narrowed candidate set, while a subsequent LLM stage reorders or refines that ranking using broader reasoning, context awareness, or listwise criteria. By cascading these techniques, hybrid rerankers can achieve higher overall accuracy without incurring the full computational cost of applying LLM reasoning to large candidate sets. Empirical studies show this combined strategy reduces ranking errors, especially in out-of-domain scenarios, and balances precision, flexibility, and efficiency in reranking systems. [98] 3.2.5 Passage Filter Passage filter is simply the policy on how to limit the number of chunks that will be sent to the generation component.