product/version strings and a dense encoder handles paraphrastic complaints, then late-fusion ranks them jointly [43–45]. Answer generation is also specialized: instead of encyclopedic “factual” style, the target is often task-oriented (“Tell the user to reboot and open Settings”), and organizations frequently enforce grounded response templates to avoid hallucinated promises in support channels. Accordingly, post- retrieval control often includes citation-style or even verbatim-span quoting from internal support playbooks, plus refusal logic if no relevant policy snippet is found (to avoid agents inventing policy) [46, 47]. In short, RAG in noisy, informal domains emphasizes conversational-window retrieval, SKU/time-aware lexical hooks, and policy-constrained decoding; this is already a very different profile than “vanilla RAG” on Wikipedia. 2.5.2 RAG for Formal / Encyclopedic / Regulatory Text When the corpus is long-form, well-edited, and mostly self-contained (e.g., Wikipedia, manuals, SOP documents, standards, compliance policies, technical PDFs), the failure modes change. Documents are longer, internally coherent, and terminology is relatively stable. Here, the main bottleneck is not noise butgranularity: how to segment dense, formally written material into retrievable units without either (i) diluting relevance with huge chunks or (ii) losing cross-sentence reasoning needed for correct answers [9, 17, 48]. A standard tactic in these settings is hierarchical or structured chunking: split long manuals or policies into semantically coherent sections (e.g., subsubsection-level or paragraph-level), index those sections, and then retrieve multiple sections per query. Retrieved sections are then reranked (e.g., using ColBERT late interaction) and either concatenated or fused via a generator architecture such as Fusion-in-Decoder (FiD), which encodes each passage independently and lets the decoder attend across them [9, 17]. FiD-like aggregation is particularly effective for dense, reference-style corpora, where relevant evidence may be scattered over multiple distant paragraphs (e.g., “safety override” is described in §2.3 and exceptions in Appendix B). In compliance and policy QA, another