60]. Legal / regulatory QA.In legal RAG, “hallucinating” a precedent or misquoting a clause can be sanctionable. Accordingly, systems often force extractive answers: the model must produce a span copied from retrieved statutes or case law, optionally followed by a short natural-language 13 paraphrase. Retrievers for this domain are commonly fine-tuned on statute-to-clause relevance and trained to respect jurisdictional boundaries (federal vs. provincial, etc.), which is information absent from generic retrievers [61, 62]. Across these proprietary domains, we again observe bespoke recipes: recency-aware indexing, ACL-aware retrieval, domain-specialized encoders, and legally/auditably constrained decoding. 2.5.5 Why This Matters for Automated RAG Design Across all four settings, practitioners donotsimply reuse a “reference RAG” implementation from the literature. Instead, they iteratively hand-tune: •How to use chunks / window documents (sliding conversational windows vs. semantically segmented PDF sections vs. clause-level statutes). •How to post-filter and rerank (recency, access control, policy compliance). •How to force grounding at generation time (citation copying in compliance, extractive spans in legal and biomedical, refusal when no policy exists). These knobs aredomain-specificbecause the failure modes are domain-specific: informality and coreference in chat logs, long-tail jargon in biomed, morphology and code-switching in Turkish, auditability in policy QA, hierarchical structure in manuals. However—and this is the gap our work addresses—there is currently no unified, data-driven framework thatautomatically discoversthe best RAG configuration for a new corpus. State-of- practice is still largely heuristic: an engineer guesses a chunk size, picks BM25 + some dense retriever, bolts on FiD or naive concatenation, and hopes it generalizes. This is especially limiting in under-resourced languages (e.g., Turkish) and in siloed proprietary domains, where there is neither extensive prior art nor abundant supervised labels to guide intuition [42, 51, 56]. In summary, domain adaptation in RAG today is manual, fragmented, and expert-driven. 2.6 RAG Tooling, Orchestration Frameworks, and Auto-RAG