Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation, yet they face persistent challenges with factual accuracy, knowledge currency, and domain-specific expertise. Retrieval-Augmented Generation (RAG) [1] has emerged as a powerful paradigm to address these limitations by augmenting LLM generation with relevant information retrieved from external knowledge sources. By grounding responses in retrieved evidence, RAG systems can provide more accurate, up-to-date, and verifiable answers while mitigating hallucinationâ€”a critical concern in deploying LLMs for knowledge-intensive tasks. The basic RAG architecture comprises three stages: retrieval of relevant documents from a knowledge base, augmentation of the query context with retrieved passages, and generation of responses conditioned on both the original query and retrieved information. However, this simple pipeline has evolved substantially. Advanced RAG techniques now encompass sophisticated components including query expansion [2], multi-stage reranking [3], contextual embeddings [4], and iterative refinement strategies [5]. These techniques aim to enhance retrieval precision, improve 1 arXiv:2511.01386v1 [cs.CL] 3 Nov 2025 context utilization, and refine generated responses, collectively pushing RAG performance beyond naive implementations. Despite this proliferation of advanced RAG components, a fundamental challenge remains: optimizing RAG pipelines has largely followed a greedy, per-module approach. Existing work typically evaluates retrieval methods, reranking strategies, and generation techniques independently, then combines the individually best-performing components into a final system. For instance, researchers might compare embedding models in isolation, select the top performer, then separately evaluate rerankers to find the best option [6]. While this modular evaluation provides insights into individual technique effectiveness, it fundamentally ignores potential synergies and conflicts between components. A retrieval method that excels with one reranker may underperform with another; an augmentation strategy beneficial for one generation approach may hinder another. The assumption that locally optimal choices yield globally optimal configurations is untenable when components interact in complex, non-linear ways. This