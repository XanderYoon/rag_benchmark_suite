they enhance overall system performance. We apply RAGSmith to six domain-specific datasets derived from Wikipedia articles (Mathe- matics, Law, Finance, Medicine, Defense Industry, and Computer Science), each containing 100 questions across three categories:factual,interpretation, andlong-answer. Through comprehensive evaluation comparing optimized configurations against naive RAG baseline, we demonstrate con- sistent improvements averaging +3.8% overall performance (ranging from +1.2% to +6.9% across domains), with retrieval improvements up to +12.5% and generation improvements up to +7.5%. Our contributions are as follows: •Holistic Pipeline Optimization: We introduce an evolutionary approach that optimizes complete RAG configurations rather than independently selecting per-module "best" compo- nents, accounting for inter-component synergies and conflicts that greedy optimization ignore. Moreover, since exhaustive grid search is computationally prohibitive given the substantial runtime of end-to-end RAG pipelines, we adopt a genetic search strategy to efficiently explore the configuration space and rapidly identify high-performing RAG settings. •Question Type Sensitivity Framework: We establish that question type distribution significantly influences both optimal configuration and improvement potential, withlong-answer andfactual-heavy datasets achieving larger gains (+5–7%) thaninterpretation-heavy datasets (+1–4%), revealing fundamental limitations in current RAG techniques’ ability to enhance inferential reasoning. 2 •Domain-Specific Optimization Guidelines: We identify empirically-grounded patterns mapping dataset characteristics to effective technique combinations—chunk density determines reranker selection, information density uniformity guides augmentation strategy choice, and hierarchical content structure motivates pre-embedding enrichment. •Robust RAG Backbone: Across all evaluated datasets, we observe thatvector_retrieval (as the retrieval component) andreflection_revising (as the post-generation refinement component) consistently yield the strongest performance among the explored RAG techniques. This suggests that these two components constitute a robust, subject-agnostic backbone. In contrast, other modules—such as query expansion, reranking, and prompt maker—exhibit more subject-dependent behavior and operate as adaptive extensions that can be tuned to the specifics of a given task or dataset. The remainder of this paper is organized as follows: Section 2 reviews