middle" problem for long context windows, ensuring relevant information is positioned optimally for the LLMâ€™s attention mechanism. 5.6 Dataset-Specific Analysis and Insights Computer Science (+6.9% overall, +12.5% retrieval).The Computer Science dataset achieved the largest improvements, driven by a synergistic combination of low chunk density (34.4 chunks/article, lowest among all datasets) and balanced question distribution (30%factual, 37%interpretation, 33%long-answer). Wikipedia Computer Science articles are typically concise and focused on specific concepts (e.g., individual algorithms, data structures, or programming paradigms), resulting in fewer but more focused chunks per article. This low chunk density makes multi-query expansion particularly effective, as semantic diversification can thoroughly cover the compact search space without introducing excessive noise. The combination withhybrid_rerank and prev_next_augmenter proves especially effective because Computer Science encyclopedia entries often explain concepts through sequential progression (defining a concept, explaining how it works, then providing examples). The dramatic mAP improvement (+14.1%) indicates that the optimized pipeline significantly improves ranking quality, moving the most relevant conceptual explanations to 31 top positions. Mathematics (+5.1% overall, +5.4% retrieval).Mathematics dataset uniquely employs contextual_chunk_headers, a choice directly motivated by its highest proportion oflong-answer questions (41%). Wikipedia mathematics articles typically organize content hierarchically, with main topics subdivided into definitions, properties, examples, and applications. When these sections are chunked, the semantic relationship between them (e.g., that an "Example" section refers to concepts defined earlier) can be lost. Contextual chunk headers address this by enriching each chunk with its section context, helping the retrieval system understand that a chunk about "Ap- plications of Fourier Transform" is related to chunks about "Fourier Transform." The synergy between contextual_chunk_headers, multi-query expansion , and long_context_reorder cre- ates a pipeline optimized for retrieving and organizing related mathematical concepts. The substantial LLM score improvement (+7.5%) validates that these techniques help the model generate coherent explanations that properly connect definitions to their properties