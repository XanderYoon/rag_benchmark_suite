density necessitated sophisticated reranking strategies (hybrid_rerank) to efficiently process large candidate sets and identify the most relevant passages among many potentially relevant sections. 5.3 Generation Performance Analysis The generation metrics reveal that improvements are primarily driven by enhanced LLM scoring rather than semantic similarity, as shown in Table 5. Mathematics demonstrates the most significant LLM score improvement (+7.5%), which directly correlates with its high proportion oflong-answer questions (41%). The combination of contextual_chunk_headers and long_context_reorder prompt maker proved particularly effective for mathematical encyclopedia articles. Wikipedia mathematics articles often explain concepts through hierarchical relationships (e.g., how a theorem relates to lemmas, corollaries, and applications), and contextual chunk headers help preserve these conceptual dependencies when chunks are retrieved separately. This is crucial for generating coherent explanations that connect abstract definitions to their properties and applications. This pattern is reinforced by Computer Science’s strong LLM score gains (+3.1%), which also benefits from contextual augmentation throughprev_next_augmenter. Wikipedia Computer Science articles often explain concepts sequentially (e.g., describing an algorithm’s steps, or explaining how data structures work through examples), making contiguous context particularly valuable for maintaining logical flow in generated explanations. Conversely, datasets with highinterpretationquestion ratios (Medicine: 53%, Finance: 51%, Law: 49%) show smaller LLM score improvements (+5.3%, +2.3%, +3.7% respectively), suggesting that current RAG optimization techniques are less effective for questions requiring inferential reasoning beyond direct information retrieval. 5.4 Retrieval Module Analysis The retrieval phase in our modular pipeline comprises five stages:Pre-Embedding, Query Expansion, Retrieval, Reranking,andPassage Filtering. Their optimal selections for each dataset are shown in 29 Table 6: Best-performingRetrieval-sidemodule combinations discovered by RAGSmith for each dataset. The retrieval pipeline includes Pre-Embedding, Query Expansion, Retrieval, Reranking, and Passage Filtering. "–" indicates the module was not applied in that configuration. Dataset Pre-Embedding Query Expansion Retrieval Rerank Passage Filter Finance – multi_query vector_retrieval cross_encoder similarity_threshold Law – multi_query