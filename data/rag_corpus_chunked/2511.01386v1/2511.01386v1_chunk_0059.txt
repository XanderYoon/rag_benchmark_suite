that a chunk about "Ap- plications of Fourier Transform" is related to chunks about "Fourier Transform." The synergy between contextual_chunk_headers, multi-query expansion , and long_context_reorder cre- ates a pipeline optimized for retrieving and organizing related mathematical concepts. The substantial LLM score improvement (+7.5%) validates that these techniques help the model generate coherent explanations that properly connect definitions to their properties and applications. Law (+3.5% overall, +5.4% retrieval) and Finance (+4.4% overall, +7.9% retrieval). Both domains exhibit highinterpretationquestion ratios (Law: 49%, Finance: 51%), which lim- its the effectiveness of retrieval-focused optimizations. However, moderate improvements are achieved through precision-focused strategies. Wikipedia legal and financial articles tend to use domain-specific terminology consistently, making terminology matching relatively straight- forward for baseline retrieval. The combination ofmulti-query expansion , vector_retrieval, and cross_encoder reranking improves precision, with moderate chunk densities (Law: 37.3, Finance: 43.5 chunks/article) permitting thorough cross-encoder evaluation. Law uniquely employsrelevant_segment_extractor, reflecting the variable information density in Wikipedia legal articles. These articles often contain sections of vastly different lengths and relevance densities—for instance, a lengthy historical background section might be followed by a brief but information-dense section on legal provisions, or vice versa. The adaptive context window allows the system to expand or contract the retrieved segment based on where the relevant information is concentrated, rather than using a fixed window that might include excessive irrelevant historical context or miss relevant adjacent legal interpretations. Thelong_context_reorder prompt maker helps manage relatively lengthy chunks (182.2 tokens/chunk average) by positioning the most relevant segments optimally. Finance’s configuration usesprev_next_augmenter, reflecting that Wikipedia finance articles often explain concepts through connected principles (e.g., explaining how interest rates affect various economic indicators in sequence). The modest semantic similarity improvement (+0.1%) suggests that financial terminology is already well-captured by baseline embeddings, with gains primarily from improved LLM reasoning about relationships between concepts (+2.3% LLM