positioning the most relevant segments optimally. Finance’s configuration usesprev_next_augmenter, reflecting that Wikipedia finance articles often explain concepts through connected principles (e.g., explaining how interest rates affect various economic indicators in sequence). The modest semantic similarity improvement (+0.1%) suggests that financial terminology is already well-captured by baseline embeddings, with gains primarily from improved LLM reasoning about relationships between concepts (+2.3% LLM score). Medicine (+1.9% overall) and Defense Industry (+1.2% overall).Both datasets display the smallest improvements, despite different underlying reasons. Medicine’s high baseline perfor- mance (0.872) and highestinterpretationratio (53%) suggest the naive RAG already performs well. Wikipedia medical articles follow highly standardized structures (symptoms, causes, diagnosis, treatment, epidemiology) with consistent medical terminology, making even simple retrieval effective. The highest chunk density (50.9 chunks/article) and token count (106,552 total tokens) reflect the encyclopedic comprehensiveness of medical articles, providing abundant information where most chunks are potentially relevant. This reduces the marginal benefit of sophisticated retrieval 32 optimization. The configuration’s omission of query expansion reinforces this: medical terminology is sufficiently standardized that single-query retrieval suffices. Defense Industry’s modest improvement (+1.2%) correlates with its highinterpretationratio (46%) and high chunk density (50.6 chunks/article). Wikipedia military and defense articles are often comprehensive, covering historical development, technical specifications, operational use, and variants within single articles, with highly variable section lengths. Therelevant_segment_extractorproves valuable here by adaptively determining context window size—for instance, expanding to include multiple chunks when technical specifications are spread across several sections, or contracting when a single chunk contains concentrated relevant information. 5.7 Question Type Impact on Technique Effectiveness Our analysis reveals a strong inverse correlation betweeninterpretationquestion ratio and overall improvement magnitude. Datasets withinterpretationratios above 45% (Medicine: 53%, Finance: 51%, Law: 49%, Defense: 46%) show average improvement of +2.8%, while those below 40% (Computer Science: 37%, Mathematics: 34%) show average improvement of +6.0%. This pattern suggests that current