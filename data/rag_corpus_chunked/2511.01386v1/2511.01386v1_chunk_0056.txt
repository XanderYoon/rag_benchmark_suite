content from general concepts to specific applications (e.g., a calculus article moving from definitions to theorems to examples), and enriching chunks with their section context helps maintain these conceptual relationships during retrieval. This aligns with Mathematics having the highest proportion oflong-answerquestions (41%), which benefit from understanding how different parts of an article relate to each other. Reranking proved essential across all domains, withcross_encoder selected for lower-density datasets (Finance: 43.5, Law: 37.3 chunks/article) andhybrid_rerank (hybrid reranker) for higher- density datasets (Medicine: 50.9, Defense Industry: 50.6 chunks/article). This pattern reflects a trade-off: cross-encoders provide more thorough evaluation suitable when candidate sets are smaller, while parallel hybrid reranking maintains competitive performance when processing larger candidate sets. 5.5 Generation Module Analysis Following retrieval, generation involvesPassage Augmentation, Passage Compression, Prompt Making,andPost-Generationphases. Their corresponding best-performing modules are listed in Table 7. The selection ofreflection_revising across all domains highlights its general utility in improv- ing factual consistency and narrative coherence through iterative self-refinement. This post-generation module acts as a dynamic correction mechanism, proving particularly effective forlong-answerques- tions. Notably, passage compression was never selected by the evolutionary search, implying that compression-induced information loss outweighed any gain in input efficiency. This finding is 30 Table 7: Best-performingGeneration-sidemodule combinations discovered by RAGSmith for each dataset. The generation pipeline includes Passage Augmentation, Passage Compression, Prompt Making, and Post-Generation phases. "–" indicates the module was not applied in that configuration. Dataset Passage Augment Passage Compression Prompt Maker Post-Generation Finance prev_next_augmenter – – reflection_revising Law relevant_segment_extractor – long_context_reorder reflection_revising Mathematics prev_next_augmenter – long_context_reorder reflection_revising Medicine prev_next_augmenter – long_context_reorder reflection_revising Defense Industry relevant_segment_extractor – long_context_reorder reflection_revising Computer Science prev_next_augmenter – – reflection_revising significant: it demonstrates that the genetic algorithm correctly learned to prune ineffective design branches, and suggests that for current LLM context window sizes, information enrichment strategies are more valuable than reduction techniques.