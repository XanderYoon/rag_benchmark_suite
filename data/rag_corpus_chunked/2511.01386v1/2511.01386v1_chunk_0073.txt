Empirical Methods in Natural Language Processing (EMNLP), 2018. 39 [28] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, S. Narayanan, K. Chen, S. Narang, Y. Zhou, and Q. V. Le, “React: Synergizing reasoning and acting in language models,” inarXiv preprint arXiv:2210.03629, 2022. [29] R. Nogueira and K. Cho, “Passage re-ranking with BERT,” inarXiv:1901.04085, 2019. [30] J. Carbonell and J. Goldstein, “The use of MMR, diversity-based reranking for reordering documents and producing summaries,” inSIGIR, 1998. [31] H. Trivedi, V. Kumar, T. Khot, A. Sabharwal,et al., “Interleaving retrieval with chain-of- thought reasoning for knowledge-intensive multi-step questions,” inarXiv:2212.10509, 2022. IRCoT: iterative retrieve–reason–retrieve for multi-hop QA. [32] J. Menick, M. Trebacz, V. Mikulik, J. Aslanides, F. Song, M. Chadwick, M. Glaese, S. Young, L. Campbell-Gillingham, G. Irving, and N. McAleese, “Teaching language models to support answers with verified quotes,” inarXiv:2203.11147, 2022. “GopherCite”: open-book QA with explicit quoted evidence. [33] H. Rashkin, V. Nikolaev, M. Lamm, L. Aroyo, M. Collins, D. Das, S. Petrov, G. S. Tomar, I. Turc, and D. Reitter, “Measuring attribution in natural language generation models,” Computational Linguistics, vol. 49, no. 4, pp. 777–840, 2023. AIS: “Attributable to Identified Sources” evaluation framework. [34] A. Slobodkin, E. Hirsch, A. Cattan, T. Schuster, and I. Dagan, “Attribute first, then generate: Locally-attributable grounded text generation,” inarXiv:2403.17104, 2024. Sentence-level planning and fine-grained citations for each claim. [35] L. Gaoet al., “Riches / retrieval-augmented research-and-revise style decoding (cascaded retrieval, constrained decoding),” inarXiv, 2024. Multi-step retrieve–verify–edit loop to reduce hallucination. [36] S. Dhuliawala and M. et al., “Chain-of-verification reduces hallucination in large language models,” inFindings of ACL, 2024. Plan verification questions, fact-check draft answers, then revise. [37] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, “Self-rag: Learning to retrieve, generate, and critique through self-reflection,” inarXiv:2310.11511, 2023. Single model that adaptively retrieves, cites, and