concrete retrieval and generation design choices (indexing strategy, retriever type, fusion strategy, number of passages, etc.) actually work best in practice? The work in this study builds on the RAG foundations summarized here and treats them as the starting point for systematic comparison. 2.2 Retrieval Methods and Indexing Strategies Before generation, there is already a large design space in how we (i) score relevance between a query and a candidate passage, and (ii) store and access those passages efficiently. This section surveys common retrieval paradigms and indexing strategies used in modern RAG systems. We emphasize that there is no single “best” retrieval configuration: different domains, query styles, latency constraints, and corpus characteristics favor different design choices. This motivates the need for systems that can automatically discover or select high-performing retrieval configurations for a given setting. Cross-encoder rerankers.Another common pattern is a two-stage pipeline: a fast first-stage retriever (sparse, dense, or hybrid) retrieves the top-k candidates, and then a more expensive cross-encoder reranker re-scores those candidates [12]. A cross-encoder takes the full query and a single candidate passage as joint input to a transformer, and directly predicts a relevance score. Because it can attend across all query and passage tokens simultaneously, it typically achieves higher precision than dual-encoders. The drawback is cost: cross-encoders cannot be run exhaustively over the entire corpus, so they act only on a shortlist. Cross-encoder reranking has become a standard recipe in open-domain QA and web search: retrieve k∈ [20, 100]candidates using BM25 or DPR, then apply a cross-encoder BERT ranker to produce the final ordering [12]. For RAG, this increases the chance that truly relevant passages 4 appear in the top few contexts fed into the generator, which in turn improves grounding and factual accuracy. Hybrid sparse + dense retrieval.Hybrid retrieval fuses lexical and dense signals,