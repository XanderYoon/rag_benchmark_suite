smaller deltas (+1.9%–+4.4%). This highlights a persistent gap in current RAG methods for inference-heavy reasoning. Domain-Specific Optimization Guidelines.We provide actionable mappings from data characteristics to technique choicesandsummarize the recurring design patterns surfaced by search. High chunk density/length favors cross-encoder or hybrid rerankers; non-uniform or hier- archical content benefits from adaptive windowing or segment extraction; and the question-type distribution dictates the balance between retrieval tuning and generation refinement. In prac- tice, strong configurations repeatedly include contextual augmentation (prev_next_augmenter or relevant_segment_extractor) together with sophisticated reranking—offering a concrete recipe for practitioners. Robust RAG Backbone.Across various subjects, vector_retrieval (retriever) paired with reflection_revising (post-generation refinement) consistently anchors the best pipelines, forming a subject-agnostic backbone. Other modules—query expansion, reranking, passage augmentation, and prompt maker—serve as adaptive attachments selected by evolutionary search to match dataset- specific characteristics, enabling scalable multi-domain deployment. 35 6 Conclusion This work presents a comprehensive investigation into domain-specific optimization of modular RAG pipelines through evolutionary search. By applying RAGSmith to six diverse Wikipedia-based datasets spanning Mathematics, Law, Finance, Medicine, Defense Industry, and Computer Science, we demonstrate that automated configuration discovery can consistently outperform naive RAG baselines, achieving an average improvement of +3.8% overall (ranging from +1.2% to +6.9% across domains). Our experimental results reveal several critical insights into RAG system design. First, we establish that question type distribution serves as a strong predictor of optimization potential: datasets dominated byfactualandlong-answerquestions (Computer Science: 63%, Mathematics: 66%) achieve substantially larger improvements (+6.9% and +5.1%) compared tointerpretation- heavy datasets (Medicine: 53%, Finance: 51%, Law: 49%) which show more modest gains (+1.9% to +4.4%). This pattern suggests that current RAG optimization techniques excel at improving information retrieval and contextual organization but have limited impact on enhancing inferential reasoning capabilities—a finding that highlights important directions for future research. Second, we identify a "robust RAG backbone" consisting ofvector_retrieval retrieval and