LLM-based judges can guide tuning [63, 70, 73]. But existing systems usually optimize one slice at a time: iterative retrieval control [64], prompt templates [66], or evaluator-driven suggestions [73]. They rarely provide asystematic, corpus-driven search across the full pipeline design space(chunking granularity, hybrid vs. dense retrievers, rerankers, generator style, etc.) and thenrankthose pipelines with objective task metrics. 15 2.6.2 Agentic and Feedback-Loop Retrieval Control A third thread teaches the model to reason about its own retrieval. Instead of assuming a static retriever that runs once, these methods let the LLM introspect: “Do I need to retrieve? Did I retrieve the right thing? Do my claims match the evidence?” Self-RAG / self-reflective RAG.Self-RAG (“Self-Reflective Retrieval-Augmented Generation”) explicitly trains an LLM to (i) decidewhenretrieval is necessary, (ii) request additional evidence mid-generation, and (iii) critique its own output for factual support [75, 76]. The model emits special control tokens (e.g., to trigger retrieval, to judge whether a passage is relevant, to assess whether a claim is supported) and uses those signals both to ground its answer and to provide inline “is this supported?” self-checks [75, 76]. Empirically, Self-RAG improves factuality and citation accuracy over vanilla RAG baselines and even outperforms larger instruction-tuned models that lack retrieval [75, 76]. Conceptually, Self-RAG blurs the boundary between “retriever” and “generator”: retrieval is no longer a pre-processing step, but a tool the model can call and then audit. Agentic RAG in orchestration libraries.Modern orchestration frameworks have begun to expose similar behavior as “agentic RAG”: an agent (LLM) has retrieval as a callable tool and can iteratively reformulate queries, gather more evidence, and only then answer [64, 77]. This is structurally close to Self-RAG, but usually implemented without specialized fine-tuning: the agent is instructed (via prompting) to reason step-by-step, retrieve when uncertain, and verify answers against retrieved context