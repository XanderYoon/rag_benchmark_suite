whether to escalate to a full long-context read [40]. This hybrid view—“RAG first, escalate to LC only when needed”—suggests that post-retrieval generation is not a solved one-size-fits-all problem. Rather, it is a decision policy conditioned on domain, latency budget, and acceptable risk of hallucination. The generator side of RAG is highly configurable. Systems differ inhowthey admit evidence (FiD vs. concatenation vs. iterative CoT-driven retrieval),howthey police factuality (citation enforcement, attribution-first planning, constrained decoding, self-critique), and evenwhetherthey rely on retrieval at all versus routing to a long-context model. Therefore, “optimal RAG” cannot be a single static architecture. Instead, it is an orchestration problem: given a domain and a query, choosewhich aggregation strategy, factuality control, and context budget to invoke. 2.5 Domain Adaptation and Specialized RAG A central assumption behind retrieval-augmented generation (RAG) is that one can “just” retrieve relevant context and condition a generator on it [7, 9]. In practice, this assumption fails uniformly across domains: the retrieval model, the indexing granularity, the chunking strategy, the negative sampling regime, and even how the final answer is phrased are all tuned differently for noisy social media logs, corporate knowledge bases, biomedical literature, or multilingual low-resource collections. Empirically, RAG is not a single pipeline; it is a family ofdomain-shapeddesign choices [17, 41, 42]. This section surveys how RAG configurations systematically diverge across four representative settings: (i) short, informal text, (ii) formal/encyclopedic material, (iii) low-resource and non-English languages, and (iv) proprietary/internal corpora such as enterprise or biomedical QA. We argue that the community currently discovers effective pipelines by manual, domain-specific intuition, rather than via a principled, automated search. This motivates the need for frameworks thatlearn which RAG variant is optimal for a given domain, especially for languages and sectors that lack expert-curated recipes. 2.5.1 RAG for Noisy, Informal, Short Text Many real deployments of RAG