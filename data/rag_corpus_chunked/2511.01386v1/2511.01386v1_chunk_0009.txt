quantization, inverted file (IVF) lists, and hierarchical clustering [14]. Other widely used ANN structures include graph-based methods such as Hierarchical Navigable Small World (HNSW) graphs, which enable logarithmic-time approximate search with strong recall in practice [15]. Indexchoice directly affectslatency, memoryfootprint, andrecall. Forexample, highlycompressed product-quantized indexes are memory-efficient but may degrade fine-grained similarity; HNSW-style graphs provide excellent recall but can consume more RAM. In RAG deployments, these trade-offs become part of system design: Do we optimize for sub-50ms retrieval? For minimal GPU usage? For highest recall at any cost? Single-vector vs. multi-vector storage.Classical dense retrievers such as DPR or SBERT store one fixed-size embedding per passage [8, 16]. This enables simple inner-product search: each passage corresponds to a single vector in the ANN index. Late-interaction models such as ColBERT instead storemultiplecontextualized token embeddings per passage [17]. This “multi-vector” representation increases index size but supports more expressive matching at retrieval time, because the query can selectively attend to different parts of the passage without having to compress all semantics into a single vector. Many modern multi-vector indexes exploit inverted-list or asymmetric distance computations to keep query-time cost tractable, but the memory/latency trade-off is still nontrivial [17]. Document chunking and granularity.RAG systems almost never index full raw documents; instead, they indexchunks—typically contiguous text windows of some fixed length (e.g., 200–512 tokens) with stride and overlap [8, 10]. Chunking controls a precision–recall trade-off: •Smaller chunks: higher precision, because retrieved passages are more focused and can be fed directly to the generator without much irrelevant context. 5 •Larger chunks: higher recall, because a single retrieved unit is more likely to contain the answer somewhere inside it, but it may also contain distracting or noisy text. Overlap (sliding windows with stride< window size) is often used so that information spanning a boundary is not lost. Chunk