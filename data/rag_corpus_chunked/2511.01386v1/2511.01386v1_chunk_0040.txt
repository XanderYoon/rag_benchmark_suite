out-of -domain settings. By fusing their scores—through methods such as convex combinations or reciprocal rank fusion—Hybrid Search achieves more robust and effective retrieval, improving both recall and ranking quality across diverse domains. [94] 4. Graph Retrieval: Graph Retrieval enriches retrieval-augmented generation by representing documents and their relationships as a graph structure rather than treating them as isolated chunks. In this framework, nodes may correspond to text passages, entities, or concepts, while edges encode semantic or relational links across the corpus. Retrieval then operates not only on direct text similarity but also on traversals of the graph, enabling multi-hop reasoning and the discovery of context that spans multiple documents. This approach improves the system’s ability to handle complex queries requiring synthesis of dispersed information, thereby offering more coherent and contextually grounded retrieval outcomes. [95] 5. Complete Hybrid Retrieval: Currently three methods are present in RAGSmith. Complete Hybrid Retrieval aims to fuse all these methods —through methods such as convex combinations or reciprocal rank fusion—to obtain a more robust retrieval for adapting various queries and datasets. 3.2.4 Reranking Reranking is a process where the retrieved chunks are reranked according to their relevance to the query as an extra step. 1. Cross-Encoder Reranking: A cross-encoder reranker refines a preliminary set of retrieved candidates by jointly encoding each query–document pair and producing a relevance score via full 20 cross-attention. Because it models interactions between query and passage tokens in a unified representation, it can capture subtle semantic dependencies that independent encodings miss. This richness in feature modeling makes cross-encoders particularly effective for reranking small sets of candidates with high precision. However, their computational cost scales with the number of pairs, which is why they are typically used only in a second-stage reranking step following an efficient first-stage retriever. Recent work also explores “shallow” cross-encoders