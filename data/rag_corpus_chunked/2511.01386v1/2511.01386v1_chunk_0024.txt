fused via a generator architecture such as Fusion-in-Decoder (FiD), which encodes each passage independently and lets the decoder attend across them [9, 17]. FiD-like aggregation is particularly effective for dense, reference-style corpora, where relevant evidence may be scattered over multiple distant paragraphs (e.g., “safety override” is described in §2.3 and exceptions in Appendix B). In compliance and policy QA, another common layer isgrounded justification: the answer must quote or cite the specific clause of the regulation for auditability. As a result, decoding is often constrained or guided to copy normative language from retrieved passages and to output inline citations [49, 50]. These domains therefore bias toward: domain-aware segmentation of long PDFs, passage-level fusion architectures, and legally/auditably grounded decoding. 2.5.3 RAG in Low-Resource and Non-English Settings Much of the early RAG literature is implicitly Anglocentric: DPR, FiD, and many popular instruction- tuned LLMs assume English Wikipedia-scale supervision [7–9]. However, for low-resource or mid- resource languages (e.g., Turkish, Swahili, Bengali), the situation is qualitatively different: (i) publicly available corpora are smaller or noisier, (ii) pretrained dense retrievers may not cover the language at all, and (iii) morphologically rich languages (including Turkish) exhibit agglutinative surface forms that hurt naive lexical matching [42, 51, 52]. 12 Two broad adaptation strategies appear in multilingual / low-resource RAG: Cross-lingual and multilingual retrievers.Multilingual bi-encoders such as mDPR and mContriever are trained via translation pairs, parallel QA, or distillation from English retrievers into other languages, allowing semantically aligned dense embeddings across dozens of languages without per-language supervision [41, 53, 54]. Benchmarks like Mr.TyDi and MIRACL explicitly evaluate retrieval in typologically diverse, often low-resource languages [42, 51]. These works show that (a) training purely on English data and zero-shot transferring often underperforms, and (b) modest in-language supervision (or even high-quality machine translation of questions) can substantially boost recall, indicating