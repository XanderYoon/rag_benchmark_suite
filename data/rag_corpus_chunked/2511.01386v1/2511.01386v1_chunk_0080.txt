J. Vičič, and A. Tošić, “Bridging the question-answer gap in retrieval-augmented generation: Hypothetical prompt embeddings,”SSRN Electronic Journal, 2024. Available at SSRN, accessed 2025-08-12. [86] “How to use the multiqueryretriever.” https://python.langchain.com/docs/how_to/ MultiQueryRetriever/, 2024. [Accessed: 2025-08-12]. [87] Z. Rackauckas, “Rag-fusion: a new take on retrieval-augmented generation,”arXiv preprint arXiv:2402.03367, 2024. [88] C.-M. Chan, C. Xu, R. Yuan, H. Luo, W. Xue, Y. Guo, and J. Fu, “Rq-rag: Learning to refine queries for retrieval augmented generation,”arXiv preprint arXiv:2404.00610, 2024. [89] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V. Le, and D. Zhou, “Take a step back: Evoking reasoning via abstraction in large language models,”arXiv preprint arXiv:2310.06117, 2023. [90] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval without relevance labels,” inProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1762–1777, 2023. [91] X. Ma, Y. Gong, P. He, H. Zhao, and N. Duan, “Query rewriting in retrieval-augmented large language models,” inProceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 5303–5315, 2023. [92] W. X. Zhao, J. Liu, R. Ren, and J.-R. Wen, “Dense text retrieval based on pretrained language models: A survey,”arXiv preprint arXiv:2211.14876, 2022. [93] S. Robertson and H. Zaragoza, “The probabilistic relevance framework: Bm25 and beyond,” Foundations and Trends®in Information Retrieval, vol. 3, no. 4, pp. 333–389, 2009. [94] S. Bruch, S. Gai, and A. Ingber, “An analysis of fusion functions for hybrid retrieval,”ACM Trans. Inf. Syst., vol. 42, Aug. 2023. [95] H. Han, Y. Wang, H. Shomer, K. Guo, J. Ding, Y. Lei, M. Halappanavar, R. A. Rossi, S. Mukherjee, X. Tang,et al., “Retrieval-augmented generation with graphs (graphrag),”arXiv preprint arXiv:2501.00309, 2025. [96] A. V. Petrov, S. MacAvaney, and C. Macdonald, “Shallow cross-encoders for low-latency retrieval,”arXiv preprint arXiv:2403.20222, 2024. [97]