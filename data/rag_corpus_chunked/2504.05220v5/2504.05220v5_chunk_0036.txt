retriever training. 2.Exclusion: Human-an- notated positives are explicitly excluded during re- triever training. Sepcifically, passages for each query during training are randomly selected from Annotation Top20 Top40 Top60 Top80 Top100 Human (First1LH) 81.9 85.0 86.5 87.0 87.8 UtilSel (First1LH) 81.2 84.5 86.4 87.3 88.2 UtilSel (SumMargLH) 81.6 84.8 86.4 87.2 88.0 Table 9: Retrieval performance (%) of different annotation methods on the NQ dataset using Qwen3-32B annotation. All three groups of results do not have significant differences with p < 0.05. the LLM annotations which excluding human-an- notated passages. 3.Inclusion: Human-annotated positives for each query are always included during training, the rest are randomly sampled from the remaining LLM-labeled passages. Tables 7 and 8 report in-domain and out-of- domain retrieval performance under three sampling strategies. We draw three main observations: 1. Ex- cluding human positives substantially degrades per- formance, highlighting their importance as high- -quality signals. As shown in Table 1, LLMs con- sistently recall human positives, indicating their strong alignment with human judgments. Remov- ing them reduces annotation quality and hinders retriever training. Conversely, explicitly including human positives in each batch yields the best re- sults. 2. Despite the initial performance gap under theExclusionsetting, introducing 30% human-la- beled data in the second stage of curriculum learn- ing effectively closes the gap. The resulting model performs on par with those trained using the full human set, suggesting that LLM-generated nega- tives and non-human positives still provide valu- able learning signals when combined with even par- tial human supervision. 3. For OOD performance, theExclusionsetting outperforms the model trained purely on human labels, consistent with the main findings under theRandomsetting. B.2 Positive Sampling Strategies LLM annotations might yield multiple positive in- stances. If the loss function is SumMargLH or JointLH, for their positive selection during train- ing for each query, we devised