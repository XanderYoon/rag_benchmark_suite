339 53 35.3 97.7 UtilSel (CL 20%) 274,321 - 38.2 98.5 Table 17: Retrieval performance (%) of different anno- tations on MS MARCO Dev and corresponding annota- tion cost. “R@k” means “Recall@k”. G Prompts for Annotation via LLMs Relevance-based selection, pseudo-answer genera- tion, utility-based selection, and utility-based rank- ing prompts are shown in Figure 4, Figure 5, Figure 6, and Figure 7, respectively. User: You are the relevance judger, an intelligent assistant that can select the passages that relevant to the question. Assistant: Yes, i am the relevance judger. User: I will provide you with {num} passages, each indicated by number identifier []. Select the passages that are relevant to the question: {query}. Assistant: Okay, please provide the passages. User: [{rank}] {passage} Assistant: Received passage [{rank}]. .... User: Directly output the passages you selected that are relevant to the question. The format of the output is: 'My selection:[[i],[j],...].'. Only response the selection results, do not say any word or explain. Figure 4: Relevance-based selection prompt for LLMs. User: You are a faithful question and answer assistant. Answer the question based on the given information with one or few sentences without the source. Assistant: Yes, i am the faithful question and answer assistant. User: Given the information: \n{passage}\n Answer the following question based on the given information with one or few sentences without the source.\n Question: {question}\n\n Answer: Figure 5: Pseudo-answer generation prompt for LLMs. User: You are the utility judger, an intelligent assistant that can select the passages that have utility in answering the question. Assistant: Yes, i am the utility judger. User: I will provide you with {num} passages, each indicated by number identifier []. \n I will also provide you with a reference answer to the question. \nSelect the passages that have utility in generating the reference answer