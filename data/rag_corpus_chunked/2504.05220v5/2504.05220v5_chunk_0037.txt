when combined with even par- tial human supervision. 3. For OOD performance, theExclusionsetting outperforms the model trained purely on human labels, consistent with the main findings under theRandomsetting. B.2 Positive Sampling Strategies LLM annotations might yield multiple positive in- stances. If the loss function is SumMargLH or JointLH, for their positive selection during train- ing for each query, we devised three strategies: 1.Pos-one: randomly select one annotated positive instance, and sample the remaining examples from other positives and negatives; 2.Pos-avg: compute the average number of positive instances per query from LLM annotations, then sample this number of positives randomly for each query, with the rest sampled from negatives; 3.Pos-all: include all an- notated positive instances whenever available, and sample the remaining examples from negatives (en- suring at least one negative instance is included). As shown in Table 10, these positive sampling strategies have limited effect on standard retriever training using LLM annotations, but show a more noticeable impact in the curriculum learning set- ting. This may be because human-labeled data typically contain fewer positive examples, making thePos-onestrategy more aligned with their distri- bution thanPos-all, thereby reducing distribution mismatch during curriculum learning. Sampling MRR@10 Recall@1000 Pos-one35.1 97.7 Pos-avg35.1 97.7 Pos-all35.3 97.7 Pos-one(CL) 38.2 98.5 Pos-all(CL) 37.8 98.5 Table 10: Effect of positive sampling strategies in train- ing, evaluated under the UtilSel annotations. C Additional Analyses on NQ Dataset We conduct annotations on a more realistic scenario for NQ to show the efficacy of our utility-focused annotation pipeline: (a) We constructed annotation candidates using unsupervised (BM25) and two out-of-domain retrievers trained on MS MARCO, i.e., our UtilSel trained on MS MARCO (Retro- MAE backbone) and LLM-QL (Zhang et al., 2025). (b) We annotated candidates via Qwen3-32B (Yang et al., 2025) (a state-of-the-art open-source LLM) to build the training set. We trained retrievers