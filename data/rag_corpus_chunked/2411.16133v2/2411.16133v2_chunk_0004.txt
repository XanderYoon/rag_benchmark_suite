systems to mali- cious passages injected into the knowledge database. Conflict- Disentangle Contrastive Decoding (CD2) [20] proposes a 2The CRSB dataset is available at: https://huggingface.co/datasets/ heydariAI/CRSB framework to reconcile conflicts between an LLMâ€™s internal knowledge and external knowledge stored in a database. Yu et al. (2024) [21] argue that simply adding more context to the LLM input prompt does not necessarily improve performance. In a recent study, Wang et al. (2024) [11] show that when retrieval precision is below 20%, RAG is not beneficial for QA systems. They highlight that when retrieval precision approaches zero, the RAG pipeline performs significantly worse than a pipeline without RAG. As a relevant method to our work, Adaptive-RAG [16] uses a smaller language model to adaptively switch the pipeline inputs whether it needs context retrieval for RAG or the question answering language model itself can answer the input query based on its internal knowledge. III. A PPROACH To address the challenges associated with retrieving irrele- vant information [11], we propose the Context Awareness Gate (CAG) architecture, which utilizes Vector Candidates as its primary statistical method for query classification. CAG sig- nificantly improves the performance of open-domain question- answering systems by dynamically adjusting the input prompt for the LLM, transitioning from RAG-based context prompts to Few Shot, Chain-of-Thought (CoT) [4], [5], and other methodologies. Consequently, the LLM responds to user queries based on its internal knowledge base. A. Context Awareness Gate (CAG) To address the issue of retrieving irrelevant data chunks for each input query, one solution is to ask a supervising large language model (LLM) to classify whether the query should prompt a retrieval-augmented generation (RAG) or a RAG-free response [16]. This involves determining whether the input query falls within the scope of the local database. However, a significant limitation of this approach is