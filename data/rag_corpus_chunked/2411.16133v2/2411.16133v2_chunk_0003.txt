the domain arXiv:2411.16133v2 [cs.LG] 6 Jan 2025 accessibility of RAG systems. CAG leverages both query transformation and dynamic prompting to enhance the reliability of RAG pipelines in both open-domain and closed-domain question answering tasks. • Vector Candidates (VC) : We propose a statistical se- mantic analysis algorithm that improves semantic search and routing by utilizing the concept of pseudo-queries and in-dataset embedding distributions. • Context Retrieval Supervision Benchmark (CRSB) Dataset: Alongside our technical and statistical investiga- tions, we introduce the CRSB dataset, which consists of data from 17 diverse fields. We study the inner context- query distributions of this rich dataset and demonstrate the effectiveness and scalability of Vector Candidates on practical QA systems 2 . Fig. 1. Context Awareness Gate (CAG) architecture for open domain questions answering II. R ELATED WORK improving both retrieval quality and the outputs of large language models. Query2Doc [18] and HyDE [6] generate pseudo-documents based on the input query and utilize these for semantic search instead of the query itself. RQ-RAG [19] decomposes complex queries into simpler sub-queries, enhancing retrieval performance. The Rewrite-Retrieve-Read framework [7] employs query rewriting to improve the match between queries and relevant documents. Additionally, some studies suggest that for queries answerable by the large lan- guage model (LLM) based on its internal knowledge, query classification using a smaller language model can benefit overall pipeline performance [10]. In terms of improving model output quality, RobustRAG [3] investigates the vulnerability of RAG-based systems to mali- cious passages injected into the knowledge database. Conflict- Disentangle Contrastive Decoding (CD2) [20] proposes a 2The CRSB dataset is available at: https://huggingface.co/datasets/ heydariAI/CRSB framework to reconcile conflicts between an LLM’s internal knowledge and external knowledge stored in a database. Yu et al. (2024) [21] argue that simply adding more context to the LLM input prompt does not