B. Vector Candidates To address the issues of using a LLM for context su- pervision , we propose a statistical approach based on the distributions of emmbedings of contexts and pseudo-queries. Algorithm 1 Vector Candidates Algorithm Require: Contexts C, Pseudo Queries Q, Policy P , Threshold T , Input Query q Ensure: A classification (True or False) 1: Compute dataset distributions based on cosine similarity: D ← C · Q ∥C∥∥Q∥ 2: Compute input query similarities with contexts: d ← C · q ∥C∥∥q∥ 3: if max(d) > P (D) − T then 4: return True 5: else 6: return False 7: end if Based on the proposed method in Algorithm (1), we first calculate the cosine similarity distributions between the con- texts and pseudo-queries. Then, we compute the similarity between the user’s original query and each context in the dataset. If the maximum similarity found between the orig- inal query and the contexts falls within the distribution of context-pseudo-query similarities, this suggests that retrieval- augmented generation (RAG) might be beneficial. Otherwise, it is more efficient to exclude RAG from the pipeline. This approach is grounded in our statistical analysis and the results presented by Wang et al. [11]. To measure the relevancy between the described distribu- tions and the user query, we apply a policy P , which is a hyperparameter derived from common statistical metrics such as minimum, mean, median, or quartiles. Additionally, we define a threshold T , which serves as another hyperparameter, to create a risk range for decision-making. This threshold helps in determining the confidence level for whether context retrieval should be applied, balancing the trade-off between precision and recall in the retrieval process. C. Context Retrieval Supervision Bench (CRSB) We introduce the Context Retrieval Supervision Bench (CRSB) dataset, which can be used to evaluate