suc- cessfully enhance the pipeline’s ability to dynamically adjust the input to the language model, either by incorporating external context or by relying solely on the internal knowledge of the model, depending on the query’s nature. However, a close examination of the computational costs associated with each approach reveals key differences. While Adaptive-RAG [16] relies on an additional large language model (LLM) to supervise the decision of whether context re- trieval is needed, this introduces significant overhead in terms of memory usage and inference time. As detailed in previous works, such LLM-based supervision requires additional model loading, which can considerably slow down the pipeline and increase resource consumption. On the other hand, our CAG method offers a more efficient and scalable solution by eliminating the need for LLM super- vision. Instead, CAG uses a statistical approach based on the distributions of the local database, allowing it to make context retrieval decisions in a highly efficient manner. This method is LLM-free and leverages a lightweight, statistical computation that can be hundreds or even thousands of times faster than LLM-based adaptations, offering significant advantages in both speed and scalability without compromising accuracy. Thus, the results not only demonstrate the effectiveness of CAG in addressing the challenges of open-domain question answering, but also highlight its computational efficiency, making it a highly scalable solution for practical deployments of RAG-based systems. VI. F UTURE DIRECTION This work opens up several promising avenues for further research and enhancement of Context Awareness Gate (CAG) in open-domain question answering systems: • Incorporating Best Practices in Information Retrieval: Future work could focus on integrating the methodologies outlined in [15] to refine CAG’s information retrieval pipeline. Specifically, these practices could optimize how CAG filters and ranks relevant information, leading to even more precise data selection. By enhancing the gran- ularity