into the predictions, which is beneficial for similarity calculations to take into account minor variations between sentences. Thistemperature of 0.5alsogivethemodelsomeflexibilitytotakeintoaccount the language nuances and the implicit meanings that might be related to certain phrasing constructs. The risk to use high temperature values, however, concerns the risk of overstepping the formalism of Figure 2. Evolution of similarity results with temperature the response provided by the model, underlining the importance of the choice of terms used in the prompt as explained in paragraph 2.3. 3.2. Influence of the number of examples given to the prompt The results now focuses on the sensitivity of the model concerning the number of examples provided in thesystem prompt. These examples are extracted from the train dataset and added next to the user prompt using the following formalism: The sentence "The oncogenic activity of mutant Kras appears dependent on functional Craf." and the sentence "Oncogenic KRAS mutations are common in cancer" have a similarty score of2.2 Similar to the temperature parameter evaluation, an iteration is constructed over different sample sizes of examples ingested in the system prompt, allowing the measurement of thePearson coefficient. A scatter plot for each sample size of examples from 0 to 60 with a step of 10 is then plotted to compare thereference similarity score to the similarity obtained by the model. The highest Pearson correlation is equal to0.89 and is obtained for a sample size in the system prompt of 20 examples. As showed by Marvin et al., 2024, the inclusion of examples within the prompt improves the response accuracy by helping the model to precisely J. Bertin, 2024 Adv ancing Similarity Search with GenAI 5 Figure 3. Evolution of similarity results with the number of examples given to the prompt understand the expected task. This consideration is related to the adversarial