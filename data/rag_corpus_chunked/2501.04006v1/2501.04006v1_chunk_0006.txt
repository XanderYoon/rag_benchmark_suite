You will find below some examples to help you determine this similarity score with the best accuracy: ... The proposed method allows then to add directly after this prompt a set of examples extracted from the training dataset to be included in thesystem prompt. It is actually not always relevant to integrate the largest possible number of examples since the model has already been trained over billions of parameters, and there is a 1The LLM Index : list of large language models, including open- source and commercial offerings(https://sapling.ai/llm/index) risk of confusion and misinterpretation when providing an overly extensive prompt: a sensitivity study of the model in relation to this criterion is therefore proposed in Section 3. RESULTS. Since the generative models are already trained on billions of parameters and may also provide accurate responses even without anyfine-tuning, the article also include a similarity analysis without any training examples being injected on thesystem prompt. The user prompt allows then to provide the model with a specific problem-solving scenario using the test dataset. Theuser promptis defined as follows: Please give me the similarity score from 0 to 4 between those sentences: Sentence1 and Sentence2. Always respond using strictly and only the following format: Similarity score : ... Sentence1 and Sentence2 corresponds to the sentence pairs for which the similarity score must be retrieved. The second phrase of theuser promptis crucial as it defines the expected output format of the response provided by the generative model. Since the similarity score can be further processed only if the right formalism has been delivered, it is important to restrict the modelâ€™s freedom regarding the expected form of results. The words always,strictly, and only are precisely employed on that purpose. 2.4. Implementation of the conversational chain The conversational chain can easily be set up using a