combine information retrieval with generative language modeling) can be used to create more accurate response in the context of similarity search. It should be noted that the presented results serve more as a starting point than an absolute performance assessment of this method, as not all generative models and prompt configurations could be tested : alongside the results, which are likely to evolve in the coming years with the improvements of Large Language Models (LLMs), this article primarily emphasizes the research direction and the innovative methodology proposed. 2. METHOD Most of recent similarity search techniques would traditionally use an embedding model to create a vector database on the sentences to be compared: the similarity degree between these sentences is then retrieved using a metric to calculate the distances between vectors. As pointed out by Dayton F., 2023, most of the string-based methods mentioned in the introduction, such asJaccard, Cosine, or even a basicEuclidean norm are in that case well suited to calculate distances between vectors. While Chen et al., 2018 already compared the performance of different embedding models on the BIOSSES dataset, this article focuses on examining resultsusingthe Retrieval Augmented Generation method: instead of basing the similarity search on a distance computation method between vectors, the article propose to build aconversational chainto evaluate each sentence pair similarity from the BIOSSES test dataset. The optimization of the prompt with the search for a perfect phrasing will therefore be equivalent to build the most optimized and personalized distance metric suited to the use case under study. Using the appropriate phrasing, the proposed Retrieval Augmented Generation method enables consequently to spell out what distinguishes a small distance (i.e. the two phrases have very similar meanings) from a larger distance (i.e. the two sentences have more distant meanings). 2.1. Presentation of the BIOSSES dataset