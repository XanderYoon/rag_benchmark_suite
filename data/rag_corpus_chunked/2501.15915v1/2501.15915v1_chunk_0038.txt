(2023). [28] Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023. When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 9802–9822. https: //doi.org/10.18653/v1/2023.acl-long.546 [29] Meta. 2024. Llama-3.2-1B-Instruct. https://huggingface.co/meta-llama/Llama- 3.2-1B-Instruct Accessed: 2024-09. [30] Meta. 2024. Meta-Llama-3-8B-Instruct. https://huggingface.co/meta-llama/Meta- Llama-3-8B-Instruct Accessed: 2024-04. [31] Neel Nanda, Senthooran Rajamanoharan, János Kramár, and Rohin Shah. 2023. Fact Finding: Attempting to Reverse-Engineer Factual Recall on the Neuron Level. https://www.lesswrong.com/posts/iGuwZTHWb6DFY3sKB/fact-finding- attempting-to-reverse-engineer-factual-recall Accessed: 2025-01-24. [32] Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, and Siliang Tang. 2024. Graph retrieval-augmented generation: A survey. arXiv preprint arXiv:2408.08921 (2024). [33] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented language models. arXiv preprint arXiv:2302.00083 (2023). [34] Stephen Robertson, Hugo Zaragoza, et al . 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends® in Information Retrieval 3, 4 (2009), 333–389. [35] Alireza Salemi and Hamed Zamani. 2024. Towards a search engine for machines: Unified ranking for multiple retrieval-augmented large language models. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval . 741–751. [36] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. 2022. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100 (2022). [37] Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023. Replug: Retrieval-augmented black-box language models. arXiv preprint arXiv:2301.12652 (2023). [38] Craig Silverstein, Hannes Marais, Monika Henzinger, and Michael Moricz. 1999. Analysis