sequence (document, question, and answer)5. This design inherently encourages the LLM to internalize the factual details in the documents into its parameters during training. Al- though the generated question-answer pairs do not directly cover all the facts within the document, repeated training on the docu- mentsâ€™ tokens allows the model to reinforce its understanding of the textual content. Consequently, once the training is complete, the parametric representation Î”ğœƒ serves as a lightweight document- specific knowledge representation that can be directly added to the original model L at inference time. Notably, this entire process can be conducted offline, as each document (or batch of documents) is processed to produce its re- spective low-rank representation Î”ğœƒ. At inference time, we only need to load the LoRA parameters corresponding to the specific document(s) rather than appending the document directly into the LLMâ€™s context. The computational cost of loading these parametric representations constitutes only a minimal portion, approximately 1% of the computation required to decode a single token. 3.2.3 Discussion on LoRA Initialization. In our proposed training framework, the LoRA parameters for each document ğ‘‘ğ‘– are initial- ized randomly without any warm-up stage. This choice is delib- erate and aligns with our goal of developing a general-purpose parametric knowledge injection method rather than one tailored to specific downstream tasks. If not explicitly mentioned other- wise, we initialize LoRA with random values. However, randomized LoRA initialization is not necessarily the most effective way to train parametric document representations. For example, we could pre-train the random LoRA with a couple of few-shot examples following the same method described with Eq. (5) and save the LoRA weight ğ‘Šğ‘¤ğ‘ğ‘Ÿğ‘š âˆ’ğ‘¢ğ‘ to initialize the training of each docu- mentâ€™s LoRA (i.e., the documentâ€™s parametric representation). Our experiment (Section Â§ 5.2) demonstrates that this warm-up process can significantly improve the