0.3025 0.2165 0.1885 0.3280 P-RAG Warm. 0.3542 0.2718 0.2418 0.5018 LLaMA-8B P-RAG Rand. 0.3932 0.3563 0.2413 0.4541 P-RAG Warm. 0.4201 0.4499 0.2952 0.5591 knowledge more effectively. Furthermore, since these gains are observed in models from different series and parameter sizes, the results underscore the robustness and broad applicability of P-RAG. (2) Comparison with DA-RAG. DA-RAG incorporates all the content generated during the Document Augmentation phase into the context, whereas our proposed P-RAG consistently outperforms DA-RAG across all settings. This result demonstrates that the per- formance improvement observed in Parametric RAG does not stem from the document augmentation phase, but from the in-parameter knowledge injection paradigm. (3) Impact of Model Scale on P-RAG. The performance gap between P-RAG and other RAG baselines is noticeably more significant when moving from the LLaMA-1B model to LLaMA-8B. This discrepancy indicates that parametric injection becomes even more beneficial in larger-scale models because larger models can better leverage internalized docu- ment knowledge. (4) Combine In-context RAG and P-RAG. The combined use of parametric and in-context RAG methods (Combine Both) yields the highest overall performance across various datasets and base LLMs. This result highlights that in-parameter knowledge injection is not in conflict with traditional RAG methods based on in-context knowledge injection. Consequently, our proposed doc- ument parameterization approaches can be seamlessly integrated for downstream tasks, allowing Parametric RAG to enhance ex- isting RAG systems without disrupting their pipelines. (5) Other Findings. Both DRAGIN and FLARE underperform significantly when applied to Qwen-2.5-1.5B. Our analysis suggests that Qwen- 2.5-1.5B tends to produce highly confident answers regardless of uncertainty. Since these dynamic RAG frameworks rely on confi- dence to trigger retrieval, they rarely activate on Qwen-2.5-1.5B. This highlights a key limitation of uncertainty-based triggers and underscores the need for more robust mechanisms in dynamic RAG frameworks. 5.2 Impact of LoRA