time per question by 29% to 36% compared to Standard RAG. Notably, the Combine Both baseline, which showed the best performance and significant improvements in the main experiment, requires almost the same online computation time as the Standard RAG method. In contrast, multi-round RAG frameworks like DRAGIN and FLARE exhibit significantly higher latency for answering a question compared to single-round methods. For both P-RAG and Combine Both baselines, we present the inference times separately from the time required for merging and loading the LoRA (0.32s). This distinction arises because, in our current implementation, the time spent on merging and loading the LoRA significantly exceeds theoretical expectations. The floating-point operations involved in the LoRA operation step contribute less than 1% to the total computational cost of generat- ing a response [14], but the latency of memory loading and data communications in our current implementation is far from perfect. We believe this latency can potentially be addressed through en- gineering optimizations. It is important to note that our analysis primarily emphasizes the relative time ratios and trends across the different methods, as actual application times and latencies can vary depending on hardware configurations, such as CPU, GPU, memory, and storage. Conference, Under Review, Su, et al. Table 4: The average time required by the LLaMA3-8B model to answer a question on the 2WikiMultihopQA (2WQA) and ComplexWebQuestions (CWQ) datasets. The "+0.32" footnote for P-RAG and Combine Both indicates the total time needed for merging and loading the LoRA adapter. 2WQA CWQ Time(s) Speed Up Time(s) Speed Up P-RAG 2.34+0.32 1.29x 2.07+0.32 1.36x Combine Both 3.08+0.32 0.98x 2.84+0.32 0.99x Standard RAG 3.03 1.00x 2.82 1.00x FLARE 10.14 0.25x 11.31 0.25x DRAGIN 14.60 0.21x 16.21 0.17x 6 Conclusion and Future Directions This work introduces Parametric RAG, a novel framework that addresses the limitations of in-context