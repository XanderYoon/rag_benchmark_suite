is more crucial for pushing the model to recall and apply factual information while rewriting offers valuable diversity in phrasing and structure and benefits the overall performance. (3) Incorporating both rewriting and QA results in the strongest overall performance on most of the evaluated tasks and models. These findings reinforce that rewriting and QA generation play complementary roles. In general, this ablation study indicates that both rewriting and QA generation significantly enhance the performance of document parameterizing. Their integration produces the best performance. Rewriting expands the coverage and diversity of context, while QA explicitly encourages the model to encode the knowledge of the selected document in a necessary way to apply the knowledge for downstream tasks. Therefore, it is advisable to incorporate both components of our document augmentation for effective internal- ization of knowledge. 5.4 Impact of Data-augmentation Model To evaluate the impact of the choice of LLM in the Document Augmentation phase, we conducted an ablation study comparing different configurations of the model used for document rewriting and QA pair generation. In our default setting, we use the same LLM for both the document augmentation process and the down- stream task. However, to explore whether the performance of our method is sensitive to this choice, we tested alternative configu- rations. Specifically, we tested different model sizes by using both smaller and larger LLMs for document augmentation and QA pair generation. The experimental results are shown in Table 3, indi- cating that our framework demonstrates an insensitivity to the Table 3: Ablation study comparing different document aug- mentation models. GenLM indicates the generator LLM and AugLM indicates the LLM for document augmentation. LLaMA indicates LLaMA-3.2-1B, and Qwen indicates Qwen- 2.5-1.5B. The best results are in bold. The metric used in the table is F1 Score. GenLM AugLM Dataset 2WQA HQA