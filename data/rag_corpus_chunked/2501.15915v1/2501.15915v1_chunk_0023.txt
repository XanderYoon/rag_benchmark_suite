0.4920 0.3994 0.2185 0.1334 0.2764 0.1602* 0.4493 0.1999* 0.2205* 0.3482* Combine Both 0.5046 0.4595 0.2399 0.1357 0.3237 0.2282 0.4217 0.2689 0.2961 0.4101 Qwen-1.5B Standard RAG 0.3875†* 0.3884†* 0.1187†* 0.0568†* 0.2431†* 0.1619* 0.3713†* 0.2073* 0.0999†* 0.2823* DA-RAG 0.3418†* 0.4015 0.1269†* 0.0514†* 0.2156†* 0.1182†* 0.3041†* 0.1683* 0.1197†* 0.2718†* FLARE 0.1896†* 0.1282†* 0.0852†* 0.0437†* 0.1004†* 0.0750†* 0.1229†* 0.0698†* 0.0641†* 0.1647†* DRAGIN 0.2771†* 0.1826†* 0.1025†* 0.0680†* 0.1538†* 0.0801†* 0.1851†* 0.0973†* 0.0548†* 0.1788†* P-RAG (Ours) 0.4529 0.4494 0.2072 0.1372 0.3025 0.1720 0.4623 0.2165* 0.1885 0.3280 Combine Both 0.4053 0.4420 0.1705 0.1154 0.2627 0.2383 0.5037 0.2942 0.2261 0.3495 LLaMA-8B Standard RAG 0.5843†* 0.4794†* 0.1833†* 0.0991†* 0.3372†* 0.1823†* 0.3493†* 0.2277†* 0.1613†* 0.3545†* DA-RAG 0.4921†* 0.3344†* 0.1523†* 0.0670†* 0.2396†* 0.1587†* 0.2860†* 0.1996†* 0.2255* 0.3481†* FLARE 0.4293†* 0.3769†* 0.3086 0.1627* 0.3492* 0.2493†* 0.4324†* 0.2771†* 0.2393* 0.3084†* DRAGIN 0.5185†* 0.4480†* 0.2664 0.1833 0.3544* 0.2618* 0.6116* 0.2924* 0.1772†* 0.3101†* P-RAG (Ours) 0.6353 0.5437 0.2471* 0.1992 0.3932 0.3115* 0.6557 0.3563* 0.2413* 0.4541 Combine Both 0.6432 0.5556 0.3160 0.2339 0.4258 0.4025 0.6918 0.4559 0.3059 0.4728 comparison, we ensured that P-RAG and all the baselines share the same prompt template6 under the same dataset. 4.3 Implementation Details In this subsection, we introduce the specific implementation of our experiments: Base Models We implement Parametric RAG using open-source pre-trained LLMs. To ensure the broad effectiveness of P-RAG across different models, we selected LLMs of varying scales and from different series, including Qwen2.5-1.5B-Instruct [55], LLaMA- 3.2-1B-Instruct [29], and Llama-3-8B-Instruct [30]. All experiments were conducted using PyTorch on NVIDIA A100 GPUs with 40GB of memory. Preprocessing and Parameterization. Consistent with prior works [19, 20, 44, 45], we utilize Wikipedia dumps as our external knowledge corpus, specifically adopting the dataset7 proposed by DPR [20]. For document augmentation, each document is rewritten once, and three QA pairs are generated based on the document 8 (using the downstream LLM, if not