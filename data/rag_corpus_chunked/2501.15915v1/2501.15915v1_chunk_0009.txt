ğ¾ğ‘ƒ . Specifically, we define: ğ¾ğ‘ƒ = {ğ‘ğ‘– | ğ‘ğ‘– = ğ‘“ğœ™ (ğ‘‘ğ‘– ), ğ‘– = 1, 2, . . . , ğ‘}, (1) where ğ‘“ğœ™ is a mapping function that converts each document ğ‘‘ğ‘– into its corresponding parametric representation ğ‘ğ‘–. We define parametric representations ğ‘ğ‘– to possess the following properties: (1) The parameters ğ‘ğ‘– can be plugged into the feed-forward net- work weights of the LLM. (2) After inserting the parametric representationğ‘ğ‘– into ğ¿, the LLM can effectively comprehend the knowledge contained within the corresponding document ğ‘‘ğ‘–. (3) Different document parameters ğ‘ğ‘– can be merged through spe- cific algorithms, and after merging, the LLM can grasp the combined knowledge corresponding to the merged documents. Online Inference. During the online inference process, our method first merges the parametric representations corresponding to the retrieved top-k documents and then plugs the merged parameters into the LLM. Subsequently, the updated LLM is used to answer the userâ€™s question. This overall framework allows for more efficient and effective knowledge injection, overcoming the limitations of traditional RAG by leveraging parameterized representations of external knowledge. 3.2 Offline Document Parameterization In this subsection, we describe the detailed process of offline param- eterizing each document in the corpus ğ¾ during the pre-processing phase. Given a document ğ‘‘ğ‘– and an LLM L, our objective is to construct a parametric representation ğ‘ğ‘– of the document. This representation enables L to effectively comprehend and utilize the knowledge contained in ğ‘‘ğ‘– during inference. To achieve this, we propose a two-step approach: Document Augmentation and Parametric Document Encoding . These steps are combined to generate robust and informative parametric representations for each document. Conference, Under Review, Su, et al. LLMWeight:ğœ½ Input Fine-tuningUsingğ‘«ğ’Š Random LoRAWeightParametricRepresentationofğ’…ğ’Š ğ’…ğ’Š ğ’‘ğ’Š ParametricDocumentEncoding Rewrite ğ’’ğŸğ’‚ğŸğ’’ğŸğ’‚ğŸğ’’ğ’ğ’‚ğ’ LLMWeight:ğœ½ â€¦ğ’’ğŸ, ğ’‚ğŸ GenerateQAPairs â€¦ ğ’’ğ’ ,ğ’‚ğ’â€¦ ğ€ğ®ğ ğ¦ğğ§ğ­ğğ ğƒğ¨ğœğ®ğ¦ğğ§ğ­ ğ‘«ğ’Š DocumentAugmentation Figure 2: An