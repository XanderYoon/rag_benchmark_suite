Nt nodes {rt i = (ht i , ct i )}Nt i=1. If two adjacent nodes rt i and rt i+1 are selected to be merged, then we can utilize the above-mentioned TreeL- STM to compute the representation of the parent node rt +1 i = TreeLSTM(rt i , rt i+1) at the t + 1 layer. The representations of the unselected nodes are directly copied to the corresponding positions at the t + 1 layer. Memory-augmented Node Scoring and Selection. The key step to the building of LST is how to accurately select the parent node at each layer. Previous work [4] proposed to enumerate all adjacent two nodes (e.g., rt i and rt i+1 ) to compose the parent node candidates {rt +1 i }Nt +1 i=1 and compute their representations by feeding the two consecutive child nodes into the TreeLSTM, and then select the best parent node candidate based on a node scoring module. Choi et al. [4] implemented the scoring module by first introducing a global query vector and then computing the inner-product between the query vector and the hidden states of parent node candidates, followed by a softmax operation. Despite its simplicity, it is still difficult to effectively decide the best candidate, due to the ambi- guity of language and the limited capacity of hidden state [5, 48] to remember the input history, especially when the given query is very long. To address this issue, we design a memory-augmented scoring module fscor e (· ; Θscor e ) to select the parent node: st +1 i = fscor e  rt +1 i , ut +1 i ; Θscor e  , (4) where st +1 i denotes the probability of thei-th parent node candidate being selected and ut +1 i is a node-specific context