training, we sample a batch of query-video pair X = {(Qi , Vi )}B i=1. We wish to enforce that, for any given (Qi , Vi ), the similarity score s (Qi , Vi ) between a query Qi and its ground truth video Vi is larger than the score of any negative pairs s Qi , Vj  by a large margin, when video Vj does not match with query Qi . The loss on the batch is defined as L (X) = 1 |N h | BÕ i=1 Õ j ∈N h max 0,δ+ s Qi , Vj  − s (Qi , Vi ) , (16) whereδis the margin (δ∈ ( 0, 1) ). |N h | denotes the number of hard negative videos in the set N h. We found that the hardest negative sample may result in unstable training especially in a large batch, but averaging the costs on all negative samples in a batch will result in slow training. Therefore, in this work, we use a trade-off strategy: we just take into consideration the top |N h | negative samples (e.g., 5) and average the costs for stable and efficient training. 4 EXPERIMENT A key contribution of this work is to develop a new complex-query video retrieval approach with a tree-augmented cross-modal encod- ing method. We aim to answer the following research questions via extensive experiments: (1) R1: How does the proposed method per- form compared with state-of-the-art methods? (2)R2: What are the impacts of different components on the overall performance of our approach? (3) R3: How does the proposed method perform on dif- ferent types of complex queries (e.g., different lengths and different categories)? Can the latent semantic tree help to better understand the complex query and drive stronger query representation? 4.1 Experimental