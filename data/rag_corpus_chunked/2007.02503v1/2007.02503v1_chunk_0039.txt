Dahua Lin. 2018. Find and Focus: Retrieve and Localize Video Events with Natural Language Queries. In ECCV. 200–216. [36] Haoyue Shi, Jiayuan Mao, Kevin Gimpel, and Karen Livescu. 2019. Visually Grounded Neural Syntax Acquisition. In ACL. [37] Cees GM Snoek, Marcel Worring, et al . 2009. Concept-based video retrieval. Foundations and Trends® in Information Retrieval 2, 4 (2009), 215–322. [38] C. G. M. Snoek, X. Li, C. Xu, and D. C. Koelma. 2017. University of Amsterdam and Renmin University at TRECVID 2017: Searching Video, Detecting Events and Describing Video. In Proceedings of TRECVID 2017 . [39] Kai Sheng Tai, Richard Socher, and Christopher D Manning. 2015. Improved Semantic Representations From Tree-Structured Long Short-Term Memory Net- works. In ACL. 1556–1566. [40] Atousa Torabi, Niket Tandon, and Leonid Sigal. 2016. Learning language-visual embedding for movie understanding with natural-language. arXiv preprint arXiv:1609.08124 (2016). [41] K. Ueki, K. Hirakawa, K. Kikuchi, T. Ogawa, and T. Kobayashi. 2017. Waseda_Meisei at TRECVID 2017: Ad-hoc Video Search. In TRECVID Workshop. [42] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS. 5998–6008. [43] Michael Wray, Diane Larlus, Gabriela Csurka, and Dima Damen. 2019. Fine- Grained Action Retrieval Through Multiple Parts-of-Speech Embeddings. In ICCV. IEEE, 450–459. [44] J. Xu, T. Mei, T. Yao, and Y. Rui. 2016. MSR-VTT: A Large Video Description Dataset for Bridging Video and Language. In CVPR. IEEE, 5288–5296. [45] R. Xu, C. Xiong, W. Chen, and J. J. Corso. 2015. Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework. In AAAI. [46] Xun Yang, Meng Wang, Richang Hong, Qi Tian, and Yong Rui. 2017. Enhanc- ing person re-identification in a self-trained subspace. ACM Transactions on Multimedia Computing, Communications, and Applications 13,