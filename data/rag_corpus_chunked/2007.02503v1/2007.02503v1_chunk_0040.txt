[45] R. Xu, C. Xiong, W. Chen, and J. J. Corso. 2015. Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework. In AAAI. [46] Xun Yang, Meng Wang, Richang Hong, Qi Tian, and Yong Rui. 2017. Enhanc- ing person re-identification in a self-trained subspace. ACM Transactions on Multimedia Computing, Communications, and Applications 13, 3 (2017), 1–23. [47] Xun Yang, Meng Wang, and Dacheng Tao. 2018. Person re-identification with met- ric learning using privileged information. IEEE Transactions on Image Processing 27, 2 (2018), 791–805. [48] Dani Yogatama, Yishu Miao, Gabor Melis, Wang Ling, Adhiguna Kuncoro, Chris Dyer, and Phil Blunsom. 2018. Memory architectures in recurrent neural network language models. In ICLR. [49] Youngjae Yu, Jongseok Kim, and Gunhee Kim. 2018. A joint sequence fusion model for video question answering and retrieval. In ECCV. 471–487. [50] Youngjae Yu, Hyungjin Ko, Jongwook Choi, and Gunhee Kim. 2016. Video Captioning and Retrieval Models with Semantic Attention. ArXiv abs/1610.02947 (2016). [51] Youngjae Yu, Hyungjin Ko, Jongwook Choi, and Gunhee Kim. 2017. End-to-end concept word detection for video captioning, retrieval, and question answering. In CVPR. IEEE, 3165–3173. [52] Jin Yuan, Zheng-Jun Zha, Yao-Tao Zheng, Meng Wang, Xiangdong Zhou, and Tat-Seng Chua. 2011. Learning concept bundles for video search with complex queries. In MM. ACM, 453–462. [53] Jin Yuan, Zheng-Jun Zha, Yan-Tao Zheng, Meng Wang, Xiangdong Zhou, and Tat- Seng Chua. 2011. Utilizing related samples to enhance interactive concept-based video search. IEEE Transactions on Multimedia 13, 6 (2011), 1343–1355.