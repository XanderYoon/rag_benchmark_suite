golden evidence. To address this, following [66], we create a memory vector for each type of intermediate step. This vector stores the maximum similarity score achieved between each piece of evidence and any step in the reasoning path Pğ‘˜. This score serves as a metric to evaluate whether the model successfully integrated the required evidence. Specifically, we denote the subquery memory vector as Mğ‘ =[ğ‘š ğ‘ 1, . . . , ğ‘šğ‘ ğ‘™ ]. Here, ğ‘šğ‘ ğ‘¡ records the maximum similarity between the golden evidence ğ‘”ğ‘¡ and any subqueryğ‘ ğ‘– in the reasoning path (where1â‰¤ğ‘¡â‰¤ğ‘™): ğ‘šğ‘ ğ‘¡ = ğ‘˜ max ğ‘–=1 simğœƒ (ğ‘”ğ‘¡, ğ‘ğ‘– ),(9) where simğœƒ () is a similarity function based on a reranker model ğœƒ, which uses a sigmoid function to normalize the score to the range[0,1]. Similarly, we define the context memory vectorM ğ‘ and the summary memory vector Mğ‘ . The corresponding memory elements, ğ‘šğ‘ ğ‘¡ and ğ‘šğ‘  ğ‘¡ , are calculated as follows: ğ‘šğ‘ ğ‘¡ = ğ‘˜ max ğ‘–=1 max ğ‘ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡âˆˆ C ğ‘ğ‘– simğœƒ (ğ‘”ğ‘¡, ğ‘ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡),(10) ğ‘šğ‘  ğ‘¡ = ğ‘˜ max ğ‘–=1 simğœƒ (ğ‘”ğ‘¡, ğ‘ ğ‘– ).(11) These calculations yield three memory vectors, Mğ‘,M ğ‘,andM ğ‘ , for the LLMâ€™s reasoning process. For a multi-hop question with ğ‘™ pieces of golden evidence, an ideal path might decompose the problem into approximately ğ‘™ subqueries. For a reasoning path Pğ‘˜ with ğ‘˜ steps, a value of ğ‘˜â‰¤ğ‘™ suggests a concise reasoning process without redundant retrievals. Conversely, whenğ‘˜>ğ‘™ , it may indicate inefficiencies such as overthinking or repetitive searches. To promote conciseness and , V ol. 1, No. 1, Article . Publication date: November 2018. TeaRAG : A Token-Efficient Agentic Retrieval-Augmented Generation Framework 15 penalize inefficiency, we normalize the summed memory scores by the number of steps,ğ‘˜. The final rewards are calculated as follows: ğ‘Ÿğ‘ (Pğ‘˜ )= Ã Mğ‘ ğ‘˜