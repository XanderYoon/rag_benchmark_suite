and </Reference> are special tokens for wrapping retrieved information. (b) shows the meaning of symbol in (c). (c) shows an example of partial KAG. The answer is highlighted by pink text. The red number on nodes is the ranking of the content selected in PPR. Consequently, we implement the pipeline of TeaRAG as shown in Fig. 3. We redesign the structure of the agentâ€™s reasoning path as Pğ‘˜ =[ğ‘† 1, . . . , ğ‘†ğ‘˜ ], where ğ‘†ğ‘– denotes the ğ‘–-th reasoning step. The structure of a reasoning step is illustrated in Fig. 4 (a). Specifically, TeaRAG first identifies the key entities central to the current reasoning step. Based on these entities, it formulates the subquery required for the step. Subsequently, TeaRAG performs context retrieval using a hybrid approach, extracting relevant information from both the chunk corpus and the knowledge graph, and constructs a KAG to enable PPR filtering for precise and concise context. TeaRAG then summarizes the core content from this context with respect to the subquery. Finally, leveraging the previous reasoning steps, TeaRAG decides whether to proceed with further reasoning or directly generate the final answer. Next, we present the detailed design of a reasoning step. 4.2.1 Important Entity Recognition.Before LLMs perform question decomposition and gen- eration, they need to first identify what the current important anchor entity is. By focusing on the key entities in the question, they can generate more targeted questions [43] and facilitate subsequent PPR filtering of irrelevant information. The key entities recognized by LLMs at step ğ‘– are denoted as ğ‘£ğ‘– 1, . . . , ğ‘£ğ‘– ğ‘—. 4.2.2 Subquery Generation.Based on current key entities and previous reasoning information, the LLM decomposes the original question, generating the current subquery ğ‘ğ‘– to be solved. The retrieval algorithmsA R then acquire relevant context centered around