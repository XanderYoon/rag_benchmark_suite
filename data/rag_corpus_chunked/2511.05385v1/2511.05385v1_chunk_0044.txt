et al. 1 2 3 4 5 Reasoning Steps 0 10 20 30 40 50 60 70 80Proportion (%) 12.24 64.38 17.48 4.33 0.56 21.96 25.87 30.02 17.67 4.48 73.18 23.47 2.48 0.69 0.18 R1-Searcher-Qwen-7B Search-R1-base-7B T eaRAG-8B 1 2 3 4 5 Reasoning Steps 0 10 20 30 40 50 60 70 80Proportion (%) 2.81 48.10 36.26 8.97 3.86 3.44 50.85 33.80 8.74 3.16 72.52 24.79 2.47 0.20 0.01 Search-R1-base-14B Search-R1-base-14B+R T eaRAG-14B Fig. 6. Comparison of reasoning step distributions between TeaRAG and other agentic RAG baselines. The figure on the left depicts the comparative results for TeaRAG-8B, while the figure on the right depicts those for TeaRAG-14B. (2) Stronger information retrieval capabilities slightly improve reasoning efficiency.For in- stance, by enhancing retrieval capabilities in the reranking stage, Search-R1-base-14B+R shows an increase in the proportion of reasoning completed in one or two steps to 54.3%, up from 50.9% for Search-R1-base-14B. This finding indirectly validates the effectiveness of TeaRAG’s re- trieval strategy, which leverages KAG construction to improve information accuracy and prevent repetitive searches that occur when critical information is not retrieved. (3) The distribution of reasoning path lengths for TeaRAG is stable across different base models. In contrast, for the Search-R1 baseline, the proportion of one-step reasoning drops from 22.0% with Search-R1-base-7B+R to just 3.4% with Search-R1-base-14B+R. This suggests that the Search-R1 algorithm is highly sensitive to model scale. Conversely, the reasoning path lengths of TeaRAG remain remarkably stable across both 8B and 14B model scales, demonstrating our method’s robustness and generalizability. 5.3.2 Analysis of T oken Usage of Reasoning Paths.To analyze the token usage of the LLM’s reasoning path more clearly, we measure four key metrics. (1)Thinking tokens, which are used for the LLM’s thought processes like planning, problem decomposition, and summarization. (2) Retrieved Content tokens, which represent the