PPR filtering of irrelevant information. The key entities recognized by LLMs at step ğ‘– are denoted as ğ‘£ğ‘– 1, . . . , ğ‘£ğ‘– ğ‘—. 4.2.2 Subquery Generation.Based on current key entities and previous reasoning information, the LLM decomposes the original question, generating the current subquery ğ‘ğ‘– to be solved. The retrieval algorithmsA R then acquire relevant context centered around this subqueryğ‘ ğ‘–. 4.2.3 Context Retrieval.The context retrieval process of TeaRAG consists of semantic retrieval and graph retrieval. The first component is semantic retrieval. The retriever, R, retrieves relevant chunks Dğ‘ğ‘– from the document corpus D based on their similarity to the subquery ğ‘ğ‘–. This is denoted as: Dğ‘ğ‘– =R (ğ‘ ğ‘–,D) . , V ol. 1, No. 1, Article . Publication date: November 2018. 10 Zhang et al. The second component is graph retrieval, which retrieves a set of knowledge triplets Eğ‘ğ‘– from the knowledge graph G. However, retrieving triplets based solely on identified key entities without considering detailed relationships risks collecting irrelevant triplets, whereas directly searching for relevant triplets from the entire set can be hampered by excessive noise from similar entries. To address these issues, we propose a two-stage graph retrieval method to perform graph retrieval in a more fine-grained manner. The first stage retrieves relevant entities from the entity set V using the retriever R. For the set of key entities {ğ‘£ğ‘– 1, . . . , ğ‘£ğ‘– ğ‘— } from the current reasoning step ğ‘–, we generate entity queries by pairing each entity ğ‘£ğ‘– ğ‘¡ with the subquery ğ‘ğ‘– in the format: â€œKey entity: ğ‘£ğ‘– ğ‘¡. Query: ğ‘ğ‘–.â€ The union of all entities returned by the retriever for these entity queries forms the set Vğ‘ğ‘– . We then collect all one-hop triplets connected to the entities in Vğ‘ğ‘– from the knowledge graph, forming the set