both 8B and 14B model scales, demonstrating our method’s robustness and generalizability. 5.3.2 Analysis of T oken Usage of Reasoning Paths.To analyze the token usage of the LLM’s reasoning path more clearly, we measure four key metrics. (1)Thinking tokens, which are used for the LLM’s thought processes like planning, problem decomposition, and summarization. (2) Retrieved Content tokens, which represent the token count for all externally retrieved information in the reasoning path. (3)Total tokens, which denote the tokens for the complete reasoning path including both Thinking tokens and Retrieved Content tokens. (4)Content per Retrieval, which is the average number of content tokens input to the LLM per retrieval. The results are shown in Fig. 7. Based on these results, we can draw the following conclusions: (1) TeaRAG demonstrates superior token efficiency compared to the other baselines across all four metrics.This is primarily because introducing signals from process supervision enhances the LLM’s reasoning efficiency, which in turn reduces ineffective reasoning and redundant retrievals, thereby significantly improving token efficiency. Furthermore, our adoption of the KAG retrieval method also reduces the number of tokens required per retrieval. (2) TeaRAG’s retrieval method effectively reduces the number of external content tokens per retrieval.This is achieved by PPR to replace redundant and irrelevant chunks with high- information-density triplets. As a result, TeaRAG-8B reduces the average tokens per retrieval by 23.80%compared to Search-R1-base-7B+R. , V ol. 1, No. 1, Article . Publication date: November 2018. TeaRAG : A Token-Efficient Agentic Retrieval-Augmented Generation Framework 21 Content per Retrieval Thinking Retrieved Content T otal 500 1000 1500 2000 2500 3000Average T oken Count 810 325 1,749 2,074 811 189 2,091 2,281 618 81 803 884 R1-Searcher-Qwen-7B+R Search-R1-base-7B+R T eaRAG-8B Content per Retrieval Thinking Retrieved Content T otal 500 1000 1500 2000 2500 3000Average T oken Count 806 214 2,126 2,341