Effects of Generation T emperature.Because the sampling temperature has a pronounced impact on LLM performance [4], we vary the generation temperature for TeaRAG-8B and Search-R1- base-7B+R to probe robustness. The results are shown in Fig. 13. We have the following observations: (1) Agentic RAG methods are not sensitive to temperature.This is because agentic RAG not only requires the LLM to generate content, but also to ground its generation in retrieved external information, which reduces uncertainty. (2) TeaRAG-8B consistently outperforms Search-R1-base-7B+R across different temperatures, further demonstrating the effectiveness and robustness of TeaRAG.We performed a two- sided paired t-test on the overall QA results, andğ‘<0.05 indicates that our method is significantly better than Search-R1-base-7B+R. (3) As temperature increases, the performance of TeaRAG-8B exhibits a slight decline.A likely reason is that higher temperature induces more diverse reasoning paths, which increases variance , V ol. 1, No. 1, Article . Publication date: November 2018. TeaRAG : A Token-Efficient Agentic Retrieval-Augmented Generation Framework 27 and can occasionally lead to deviations from the retrieved evidence or extra, unnecessary steps, thereby reducing answer accuracy and consistency. 5.6 Training and Inference Efficiency Analysis Table 9. Training overhead of different methods. The experiments are conducted on 8 NVIDIA A100 (80G) GPUs. Method Overall Training Time Training Time Inference Time Reward Time Training Steps Time/Step Memory Usage per GPU TeaRAG-8B681m 85m 376m 220m 1,688 0.40m 42G Search-R1-base-7B2,944m 1,320m 1,624m - 1,005 2.93m 79G TeaRAG-14B752m 115m 417m 220m 1,513 0.49m 61G Search-R1-base-14B4,958m 2,462m 2,496m - 1,005 4.93m 80G In this section, we provide an in-depth analysis of the training and inference efficiency of TeaRAG. For the training overhead, the statistics are summarized in the Table 9. First, TeaRAG requires less total training time compared to Search-R1, primarily because the IP-DPO framework decouples the training and sampling stages, thereby enhancing overall training