Search-R1-base-14B4,958m 2,462m 2,496m - 1,005 4.93m 80G In this section, we provide an in-depth analysis of the training and inference efficiency of TeaRAG. For the training overhead, the statistics are summarized in the Table 9. First, TeaRAG requires less total training time compared to Search-R1, primarily because the IP-DPO framework decouples the training and sampling stages, thereby enhancing overall training efficiency. Furthermore, TeaRAG achieves lower memory consumption through LoRA training and without reliance on auxiliary models such as PPO critics. Table 10. Inference efficiency tested on the 2WikiMultiHopQA development dataset, which consists of 12,576questions. Method Semantic Retrieval Graph Retrieval KAG+PPR Retrieval Time Generation Time Overall Time TeaRAG-8B270s 282s 24s 578s 482s 1,061s Search-R1-base-7B+R601s - - 601s 1,641s 2,243s TeaRAG-14B281s 334s 22s 639s 495s 1,136s Search-R1-base-14B+R525s - - 525s 2,655s 3,181s Furthermore, we assess the inference efficiency of TeaRAG in comparison with Search-R1, using the 2WikiMultiHopQA dataset as the evaluation benchmark. The inference time for each stage is presented in Table 10. Our analysis yields three key observations: (1) The overall inference time of TeaRAG is significantly lower than that of Search-R1.This reduction can be attributed to the IP-DPO training method, which reduces the reasoning steps, thereby avoiding overthinking and redundant retrieval steps. Consequently, the generation time is substantially reduced. (2) The introduction of graph retrieval slightly increases retrieval latency.However, more concise triplets retrieved by graph retrieval effectively shortens the retrieved content, relieving the generation burden on the LLM. Moreover, graph retrieval and semantic retrieval can run in parallel, thereby shortening the total retrieval time. Nevertheless, parallel retrieval is not implemented in our current work, as it is not the focus of our work. (3) Both KAG construction and PPR filtering are efficient.This confirms that TeaRAG can efficiently leverage co-occurrence relationships to produce higherâ€“information-density retrieval content. 5.7 Case Study In this