ğ‘)= ( 1,if the format is followed 0,otherwise, (6) The third part is the process reward, which assesses the rationality of the LLMâ€™s reasoning process. The process rewards include two components: entity-subquery consistency reward and knowledge matching rewards. The first component is the entity-subquery consistency reward, intended to align the entities identified by the LLM with the anchor of the subsequent subquery. This alignment enables more targeted question decomposition and more precise PPR filtering. We implement a cover exact match (CEM) mechanism that mandates complete inclusion of key entities within the subquery. The corresponding reward function is defined as follows: ğ‘Ÿconsistency(Pğ‘˜ )= 1 ğ‘˜ ğ‘˜âˆ‘ï¸ ğ‘–=1 ğ‘Ÿ ğ‘– CEM( [ğ‘£ğ‘– 1, . . . , ğ‘£ğ‘– ğ‘— ], ğ‘ğ‘– ),(7) ğ‘Ÿ ğ‘– CEM( [ğ‘£ğ‘– 1, . . . , ğ‘£ğ‘– ğ‘— ], ğ‘ğ‘– )= ( 1,ifğ‘£ ğ‘– 1 âŠ†ğ‘ ğ‘– âˆ§. . .âˆ§ğ‘£ ğ‘– ğ‘— âŠ†ğ‘ ğ‘– 0,otherwise .(8) The second component is the knowledge matching rewards. These rewards evaluate the correctness of the LLMâ€™s reasoning process by assessing whether its intermediate steps successfully capture the golden evidence. We evaluate three types of intermediate steps: subqueries, retrieved contexts, and summaries. We denote the set of golden evidence for an overall question as ğº=[ğ‘” 1, . . . , ğ‘”ğ‘™ ], where ğ‘™ is the number of golden evidence pieces. The non-deterministic nature of the reasoning process makes it difficult to pre-assign which specific step should capture a particular piece of golden evidence. To address this, following [66], we create a memory vector for each type of intermediate step. This vector stores the maximum similarity score achieved between each piece of evidence and any step in the reasoning path Pğ‘˜. This score serves as a metric to evaluate whether the model successfully integrated the required evidence. Specifically, we denote the subquery