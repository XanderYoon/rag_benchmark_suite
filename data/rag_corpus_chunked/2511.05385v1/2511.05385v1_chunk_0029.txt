to repeatedly generate ğ‘… reasoning paths. For each reasoning path, both the reasoning process and the final answer are recorded for subsequent evaluation. Reward design.To better guide the LLMâ€™s reasoning process and encourage more concise reasoning steps, we design a process-aware reward based on knowledge matching. This enables a more fine-grained evaluation of the quality of different generated outputs. Our total reward system consists of three components: the outcome reward, the format reward, and the process reward. The first part is the outcome reward, which is based on a comparison between the final answer generated by the LLM and the ground truth from the dataset. Because rewards based on an exact match are too sparse to effectively compare the accuracy of LLM-generated answers, we follow [54] and use the F1 score as the metric for the outcome reward. Specifically, we define the outcome reward as follows: ğ‘Ÿoutcome(ğ‘, ğ‘ğ‘”ğ‘¡ )=2Â· |ğ‘âˆ©ğ‘ ğ‘”ğ‘¡ | |ğ‘| + |ğ‘ ğ‘”ğ‘¡ | ,(5) where ğ‘ğ‘”ğ‘¡ represents the ground truth, |ğ‘| is the word count of the LLM-generated answer ğ‘, and |ğ‘âˆ©ğ‘ ğ‘”ğ‘¡ |is the number of overlapping words betweenğ‘andğ‘ ğ‘”ğ‘¡. , V ol. 1, No. 1, Article . Publication date: November 2018. 14 Zhang et al. The second part is the format reward, which evaluates whether the structure of the modelâ€™s reasoning path conforms to the structure constructed in Section 4.2. The format reward of reasoning pathP ğ‘˜ and final answerğ‘is defined as follows: ğ‘Ÿformat(Pğ‘˜, ğ‘)= ( 1,if the format is followed 0,otherwise, (6) The third part is the process reward, which assesses the rationality of the LLMâ€™s reasoning process. The process rewards include two components: entity-subquery consistency reward and knowledge matching rewards. The first component is the entity-subquery consistency reward, intended to align the entities identified by the LLM with the anchor of the