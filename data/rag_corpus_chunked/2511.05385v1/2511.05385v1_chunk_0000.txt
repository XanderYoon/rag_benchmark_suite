TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework CHAO ZHANG,University of Science and Technology of China, China and City University of Hong Kong, Hong Kong YUHAO WANG,City University of Hong Kong, Hong Kong DERONG XU,University of Science and Technology of China, China and City University of Hong Kong, Hong Kong HAOXIN ZHANG,Xiaohongshu Inc., China YUANJIE L YU, YUHAO CHEN, SHUOCHEN LIU, and TONG XU*,University of Science and Technology of China, China XIANGYU ZHAO*,City University of Hong Kong, Hong Kong YAN GAO and YAO HU,Xiaohongshu Inc., China ENHONG CHEN,University of Science and Technology of China, China Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models’ (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur sub- stantial token overhead from search and reasoning. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, aToken-efficientagenticRAGframework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at https://github.com/Applied-Machine-Learning-Lab/TeaRAG. *Corresponding authors. Authors’ Contact Information: Chao Zhang, zclfe00@mail.ustc.edu.cn, University