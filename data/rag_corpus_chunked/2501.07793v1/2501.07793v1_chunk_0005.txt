2024) are de- voted to learning the optimal assignment of queries to different LLMs. The basic idea is to leverage the complementarity of various LLMs to achieve su- perior performance compared to any single model across a range of tasks. Notably, these methods typically require substantial amounts of annotated training data, leading to high costs for label collec- tion. In contrast to these approaches, we explore query routing across different search engines and propose an unsupervised method, thereby elimi- nating the need for manual annotation and signifi- cantly reducing annotation costs. Query Routing for Search Engines Early re- search focused on topic-specific search engines (Manber and Bigot, 1997; Sugiura and Etzioni, 2000), which often suffer from limited coverage. Alternatively, other conventional systems (Gravano et al., 1999; Liu, 1999) target on general-purpose search engines, but they require access to the com- plete internal databases associated with each en- gine. To address this issue, (Mu et al., 2024) re- cently utilized annotated (query, answer) data to train neural models that can find the most appropri- ate general-purpose search engine for a given query. However, these supervised methods rely heavily on annotated data. In contrast, our method does not require manual annotation and directly uses real user queries for training, thus offering promising scalability and generalization capabilities. 3 Preliminaries Given a user queryq and M search tools {Tm}M m=1, the core task of query routing is to create annotated training data in the form (q, π), where π represents the search engine index indicating which search engine should be selected to address the query. 3.1 Briefing of Previous Supervised Methods Existing supervised methods (Shnitzer et al., 2023; Mu et al., 2024) rely heavily on annotated (query, answer) paired data. Specifically, using each search tool Tm, they are able to obtain the retrieval- augmented