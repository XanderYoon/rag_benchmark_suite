accuracy of automatically labelled training datasets. The Similarity metric provides more accurate labels compared to the Coherence metric, as confirmed by our experiment (§ 5.4). By integrating both met- rics, our weighted overall metric yields the highest accuracy in labeling. Given the automated nature of our method, we consider an 86% accuracy rate to be satisfactory. Visualization We conduct a further analysis of the constructed training labels. According to the label π, we categorize the queries into three dis- tinct groups: those should be assigned to Quark, Bing, and Google, respectively. Then, we tally the high-frequency words presented in the queries of each group and visualize high-frequency words in each group, as depicted in Figure 4. In the "Bing" group, terms such as "earthquake", "MacBook Pro", and "Hong Kong stock" demonstrate a high frequency, indicating that Bing has good support for news hotspots as well as significant political and economic events. In the "Google" group, high- frequency words include "python, open-source, 5G", etc. This indicates that Google is better able to handle programming, technology, and other queries that require strong professionalism. This is quite in- tuitive, as Google, renowned as the world’s leading Figure 4: The visualization of the high-frequency words. The words are translated from Chinese. We leave the original version in Appendix C. search engine, offers the most extensive internal documentation available, enabling the platform to effectively tackle a diverse array of professional issues. 6 Conclusion In this work, we present an unsupervised query routing approach. Given the insight that multi- sourced retrieval yields superior performance, we ingeniously design an automated process to assess the quality of single-sourced responses, thereby generating training labels without manual annota- tion. Experimental results demonstrate that our method has excellent scalability and generalization ability. We are confident that our approach will inspire new