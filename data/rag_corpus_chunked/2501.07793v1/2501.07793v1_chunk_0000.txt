Unsupervised Query Routing for Retrieval Augmented Generation Feiteng Mu1*, Liwen Zhang2, Yong Jiang2†, Zhen Zhang3, Wenjie Li1, Pengjun Xie2, Fei Huang2, 1The Department of Computing, The Hong Kong Polytechnic University, Hong Kong 2Institute for Intelligent Computing, Alibaba Group 3College of Software, Nankai University {csfmu,cswjli}@comp.polyu.edu.hk,{yongjiang.jy,zlw439616}@alibaba-inc.com Abstract Query routing for retrieval-augmented genera- tion aims to assign an input query to the most suitable search engine. Existing works rely heavily on supervised datasets that require ex- tensive manual annotation, resulting in high costs and limited scalability, as well as poor generalization to out-of-distribution scenarios. To address these challenges, we introduce a novel unsupervised method that constructs the "upper-bound" response to evaluate the quality of retrieval-augmented responses. This evalu- ation enables the decision of the most suitable search engine for a given query. By eliminating manual annotations, our approach can automat- ically process large-scale real user queries and create training data. We conduct extensive ex- periments across five datasets, demonstrating that our method significantly enhances scalabil- ity and generalization capabilities. 1 Introduction Retrieval Augmented Generation (RAG) (Lewis et al., 2020; Gao et al., 2023) typically begins with a retrieval phase where user queries are scoured through search engines like Google and Bing to gather relevant background documents before en- gaging large language models (LLMs) (OpenAI, 2023; Qwen Team, 2023). In today’s digital land- scape, even among major comprehensive search engines, each has its strengths and weaknesses, offering unique features and capabilities. Conse- quently, Query Routing (Sugiura and Etzioni, 2000; Wang et al., 2024; Mu et al., 2024) seeks to direct queries to the most suitable search engines to opti- mize performance and reduce costs. Current query routing methods (Shnitzer et al., 2023; Mu et al., 2024) primarily use open-sourced (query, answer) paired data to create training labels. Specifically, by leveraging these gold-standard *Work done