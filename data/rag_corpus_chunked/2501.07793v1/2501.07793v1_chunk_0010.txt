score are calculated as follows: sBertm = sBert m − µBert σBert , sCohm = sCoh m − µCoh σCoh . (7) The overall score of rm is calculated as: sm = sBertm + sCohm 2 . (8) Converting to Training Labels After obtaining {sm}M m=1, we sort them in ascending order. We use the indices of {sm}M m=1 in the ordered sequence as the label, denoted as π ∈ R M. π actually repre- sents a permutation of {1, 2, · · · , M}, indicating the priority of routing q to T1, · · · , TM, respec- tively. This kind of label enables us to create a listwise ranking loss to effectively leverage the pri- ority relationships between each pair of tools. 4.4 Model Training and Inference Given the labeled (q, π) examples, we train a neu- ral model M to predict the scores of routing q to {Tm}M m=1, respectively: p = M(q) (9) where p = {p1, · · · , pm, · · · , pM }, pm denotes the score of routing q to Tm. Then, we adopt the listwise ranking loss ListMLE (Guiver and Snelson, 4We discard the illegal ranking output by LLMs (like "A > B, B > C, C > A "). Search Strategies Qwen2-max GPT4 WebQA PrivateMH NLPCC-MH CDQA SogouQA WebQA PrivateMH NLPCC-MH CDQA SogouQA No-RAG 4.609 2.77 1.803 2.543 3.31 3.927 1.924 2.647 2.538 3.715 Using one search engine Quark 4.833 3.38 2.258 3.691 4.484 4.321 2.657 2.735 3.73 4.42 Bing 4.79 3.309 2.151 3.661 4.437 4.168 2.461 2.737 3.559 4.33 Google 4.797 3.205 2.104 3.745 4.395 4.225 2.557 2.644 3.79 4.312 Using two search engines Quark+Bing 4.823 3.428 2.274 3.829 4.546 4.323 2.669 2.755 3.877 4.445 Quark+Google 4.822 3.418 2.261 3.917 4.487 4.285 2.682 2.701 3.925 4.412