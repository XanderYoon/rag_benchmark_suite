Microsoft [1]. Majumdar et al. [2, 13] proposed a framework to evaluate comments based on concepts that are relevant for code comprehension. They developed textual and code correlation features using a knowledge graph for semantic interpretation of information contained in comments. These approaches use semantic and structural features to design features to set up a prediction problem for useful and not useful comments that can be subsequently integrated into the process of decluttering codebases. With the advent of large language models [ 14], it is important to compare the quality as- sessment of code comments by the standard models like GPT 3.5 or llama with the human interpretation. The IRSE track at FIRE 2023 extends the approach proposed in [2] to explore var- ious vector space models [15] and features for binary classification and evaluation of comments in the context of their use in understanding the code. This track also compares the performance of the prediction model with the inclusion of the GPT-generated labels for the quality of code and comment snippets extracted from open-source software. 3. IRSE Track Overview and Data Set The following section outlines the task descriptions and the characteristics of the dataset. 3.1. Task Description Comment Classification: A binary classification task to classify source code comments as Useful or Not Useful for a given comment and associated code pair as input. Input: A code comment with surrounding code snippet (written in C) Output: A label (Useful or Not Useful) that characterises whether the comment helps developers comprehend the associated code Therefore in this classification task, the output is based on whether the information contained in the comment is relevant and would help to comprehend the surrounding code, i.e., it isuseful. Useful: Comments have sufficient software development concept â†’ Comment is Relevant, and these concepts are not