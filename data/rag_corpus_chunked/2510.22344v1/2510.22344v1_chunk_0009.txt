and triggers retrievals accordingly, effectively interleaving prediction and lookup steps. Similarly, Corrective RAG (Yan et al., 2024) incorporates a post-retrieval correc- tion phase, using an evaluator to assess and refine retrieved documents based on their relevance and factual consistency. While these methods improve upon standard iterative loops by adding predictive or corrective elements, they often rely on heuristic triggers or post-hoc adjustments, which can still overlook systematic evidence gaps in highly com- plex queries. In contrast, FAIR-RAG’s Structured Evidence Assessment (SEA) module provides a more principled, checklist-driven analysis that ex- plicitly identifies and targets informational defi- ciencies, enabling a targeted and iterative refine- ment without dependence on generation-time pre- dictions. 2.3 Adaptive and Faithfulness-Aware RAG A third stream of research focuses on making RAG systems more adaptive and reliable. Adaptivity is often geared towards computational efficiency. For instance,Adaptive-RAG(Jeong et al., 2024) intro- duces a classifier to pre-assess query complexity and route it to an appropriate strategy: no retrieval for simple questions, single-step retrieval for mod- erate ones, or a multi-step approach for complex queries. This routing is performed once at the be- ginning. In contrast, FAIR-RAG’s adaptivity is dynamic and occurswithinthe iterative process, as it continually adapts its query generation strategy based on the evolving set of retrieved evidence. Enhancing the faithfulness of the generated out- put is another critical concern. Standard RAG mod- els do not explicitly guarantee that the generator will adhere to the retrieved context. (Es et al., 2025) To address this, SELF-RAG (Asai et al., 2023) fine- tunes an LLM to generate special “reflection to- kens”, enabling it to critique its own output for relevance and factual support in an inline fashion during generation. While effective, this approach has two limitations: its reliance on fine-tuning re- stricts applicability to off-the-shelf models, and its evaluation is inherentlytactical,