ensure a rigorous and fair comparison. We evaluate two primary configurations of our framework: – Uniform Model Configuration:To iso- late the architectural benefits of our iter- ative approach, the FAIR-RAG 1-4 vari- ants exclusively use Llama-3-8B-Instruct for all internal tasks and for the final an- swer generation. This ensures a direct and fair comparison against all baseline methods, which are also benchmarked us- ing the same Llama-3-8B-Instruct model. In this configuration, the adaptive LLM selection (SMALL, LARGE, REASON- ING roles) is intentionally disabled, with all roles defaulting to the single model. – Adaptive LLM Configuration:To demonstrate the full potential of our framework, we also report results for FAIR-RAG (Adaptive LLMs). This con- figuration employs a dynamic, multi- agent allocation strategy to optimize the trade-off between performance and cost: * For less complex internal tasks, such as query decomposition and Struc- tured Evidence Assessment (SEA), we utilize Llama-3-8B-Instruct. * For more cognitively demanding tasks, including evidence filter- ing, query refinement, and faith- ful answer generation, we leverage the more powerful Llama-3.1-70B- Instruct. (AI@Meta, 2024) * For tasks requiring deep reasoning, the system routes to a specialized DeepSeek-R1 model. (DeepSeek-AI, 2025) Unless otherwise specified, all other hyperpa- rameters adhere to the default settings of the un- derlying framework to maintain consistency across experiments. 5 Results This section presents a comprehensive evaluation of FAIR-RAG. We first report the main end-to-end results against a suite of strong baseline methods (Section 5.1). We then provide a deeper analysis of the framework’s internal mechanics, including a component-wise ablation study (Section 5.2.1) and an examination of the impact of iterative refinement on answer quality and cost (Section 5.2.2). 5.1 Main Results Table 2 presents the main performance comparison of FAIR-RAG and baseline methods across four di- verse question-answering benchmarks. Our frame- work demonstrates state-of-the-art performance, particularly on