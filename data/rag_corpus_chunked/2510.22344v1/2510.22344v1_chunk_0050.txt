knowledge- intensive multi-step questions. Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2024. Text embeddings by weakly- supervised contrastive pre-training. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits rea- soning in large language models.Advances in Neural Information Processing Systems, 35:24824â€“24837. Shi-Qi Yan, Kang Liu, Jia-Chen Li, Zhao-Xiang Wang, Jie Zhang, and Lin Gui. 2024. Correc- tive retrieval augmented generation.arXiv preprint arXiv:2401.15884. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben- gio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. Hotpotqa: A dataset for diverse, explainable multi-hop question answer- ing.arXiv preprint arXiv:1809.09600. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models.arXiv preprint arXiv:2210.03629. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Brooks, Eric Xing, et al. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.arXiv preprint arXiv:2306.05685. A Implementation Details and Hyperparameters To ensure full reproducibility of our experimen- tal results, this section provides a comprehensive overview of the models, configurations, and hy- perparameters used in our study. All experiments were conducted within theFlashRAGframework, a standardized library for RAG research. This ensures that the underlying implementation de- tails, such as data loading and prompt templat- ing, remain consistent across all compared meth- ods. The source code and default configurations can be found on the official project repository: https://github.com/ruc-nlpir/flashrag. The specific configurations for our experiments are detailed in Table 5 below. Category Parameter & Value General Framework Base Framework: FlashRAG Max Iterations: 3 Retriever Configuration Model: e5-base-v2 Documents Retrieved (top_k): 5 Index Type: Faiss (IndexFlatIP) Pooling Method: mean Query Max Length: 128 Generator Configuration