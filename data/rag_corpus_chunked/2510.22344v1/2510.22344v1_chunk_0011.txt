language models. In summary, while existing works have made substantial advancements, FAIR-RAG provides a novel contribution by synergistically integrating three core principles into a cohesive framework: (1) a structured, gap-aware iterative refinement loop, (2) context-aware, adaptive sub-query generation, and (3) an explicit, modular faithfulness assessment that requires no model fine-tuning. 3 Methodology The FAIR-RAG framework is designed as a multi- stage, iterative process that dynamically adapts its strategy to the complexity of a userâ€™s query. Our architecture transforms the standard, static RAG pipeline into an intelligent, evidence-driven work- flow that progressively builds context to answer complex questions. The entire process, illustrated in Figure 1, can be divided into four main phases: (1) Initial Query Analysis and Adaptive Routing, (2) The Iterative Retrieval and Refinement Cycle, (3) Faithful Answer Generation, and (4) Dynamic Resource Allocation. The entire inference proce- dure is detailed step-by-step in Algorithm 1. The process is initiated by theAdaptive Routingagent (Arouter), which classifies the query and selects the most appropriate generator LLM ( Gselected) from the predefined set of available models (G). 3.1 Overall Architecture The overall architecture of FAIR-RAG, illustrated in Figure 1, employs a dynamic, multi-step pro- cess to handle user queries. An initial routing step assesses query complexity. Simple queries are an- swered directly, while complex ones trigger an it- erative refinement loop. This core loop consists of adaptive query generation, hybrid retrieval, filter- ing, and a Structured Evidence Assessment (SEA). The SEA module determines if the collected evi- dence is sufficient. If not, the loop repeats with refined queries targeting information gaps. Once sufficiency is met, a final, evidence-grounded an- swer is generated. The entire inference procedure is detailed step-by-step in Algorithm 1. All LLM agents in our pipeline are guided by meticulously engineered prompts. The full details and examples for each prompt are