A key trend highlighted by the plots is thestrong positive correlation between the F1 score and the ACCLLM. This suggests that the architectural improvements within FAIR-RAG, which enhance the accuracy of the Large Language Model’s inter- nal processing and decision-making, are directly responsible for the enhanced final answer accu- racy. This relationship is particularly evident in the HotpotQA and 2WikiMultiHopQA results, where a noticeable uplift in the ACC LLM line for FAIR- RAG variants coincides with a significant increase in their corresponding F1 scores compared to the baselines. Thus, the visualizations not only con- firm FAIR-RAG’s state-of-the-art performance but also offer insight into the synergistic relationship between its internal reasoning accuracy and its final output quality. 5.2 Further Analysis Beyond the main end-to-end results, we conduct a series of deeper analyses to deconstruct the sources of FAIR-RAG’s performance. We perform a de- tailed component-wise evaluation to understand the contribution of each module, analyze the spe- cific impact of the iterative refinement process, and present a qualitative case study to illustrate the framework in action. For these fine-grained assess- ments, we employ a sophisticatedLLM-as-Judge methodology, using a powerful LLM to score the output of each internal module against a set of pre- defined criteria (Zheng et al., 2023). This task is guided by a structured prompt (see Appendix C for details). 5.2.1 Component-wise Performance Analysis (Ablation Study) To quantify the contribution of each key module within the FAIR-RAG pipeline, we conducted an ablation study using an LLM-as-Judge method- ology on 1000 samples from each dataset. The results, summarized in Table 3, demonstrate the high functionality of each component, justifying its inclusion in the final architecture. For com- ponents likeQuery DecompositionandQuery Refinement, the judge rated the output quality on a 1-to-5 Likert scale. The rating was based on a holis- tic assessment