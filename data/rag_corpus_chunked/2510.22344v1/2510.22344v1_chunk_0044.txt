HotpotQA and 2WikiMul- tiHopQA. These results empirically validate our central hypothesis: that a procedural, multi-stage workflow with explicit evidence assessment is es- sential for achieving high accuracy and faithfulness in knowledge-intensive tasks. 6.1 Limitations Despite its strong performance, FAIR-RAG presents several inherent trade-offs and limitations that warrant discussion: • Dependency on LLM Reasoning Fidelity and Prompt Engineering:The performance of FAIR-RAG’s modular agents (e.g., query refinement, SEA) is inherently bound by two key factors: the reasoning capabilities of the underlying LLMs and the meticulous design of the prompts that guide them. While our structured prompting methodology—which incorporates clear instructions, illustrative ex- amples, and scaffolding techniques—is de- signed to ensure consistency and robustness, the system’s effectiveness remains sensitive to both the choice of the backbone model and the specific phrasing of the prompts. This dual dependency is an intrinsic limitation of current LLM-based agentic systems, where performance gains are often tightly coupled with advancements in both model architecture and sophisticated prompt engineering. • Comprehensiveness vs. Efficiency Trade- off:The iterative nature of FAIR-RAG, which is key to its high accuracy on complex queries, introduces a natural trade-off with efficiency. As shown in our analysis (Table 4), each re- finement cycle increases overall latency and computational cost, making it more expensive than single-shot RAG methods. • Potential for Error Propagation:As a multi- stage pipeline, errors in early stages can cas- cade. The SEA module, in particular, repre- sents a critical point of failure. An erroneous sufficiency judgment—either a false positive that terminates the loop prematurely or a false negative that extends it unnecessarily—can lead the evidence-gathering process astray. • Fixed Iteration Policy:The maximum of three iterations is an empirically derived heuristic that balances performance and cost. However, a fixed limit lacks the flexibility to adapt to the varying complexity of individual queries. Our results