on simpler retrieval tasks and can effectively streamline its process, largely due to the initialAdaptive Routingmodule. Comparing different variants of our model, we see a consistent performance increase from FAIR- RAG 1 to 4, indicating that the incremental en- hancements contribute positively. The introduction ofAdaptive LLMsfurther boosts performance across the board, confirming the benefits of dynam- ically allocating computational resources based on task complexity. To complement the tabular data, Figure 2 pro- vides a visual comparison, plotting the F1 scores (bars) against the ACC LLM metric (lines) for all methods across the four benchmarks. The figure visually corroborates the superior performance of our FAIR-RAG framework, where its variants (in- Type Method HotpotQA 2WikiMultiHopQA Musique TriviaQA EM F1 ACC ACC LLM EM F1 ACC ACC LLM EM F1 ACC ACC LLM EM F1 ACC ACC LLM Sequential Standard RAG .238 .342 .328 .598 .086 .180 .282 .369 .074 .149 .137 .380 .570 .667 .675 .795 Branching Sure .232 .346 .293 .646 .134 .198 .167 .408 .101 .169 .114 .397 .566 .675 .641 .799 Conditional Adaptive-RAG .144 .239 .368 .628 .041 .133 .340 .429 .038 .095 .160 .366 .480 .583 .670 .789 Reasoning ReAct .000 .028 .096 .503 .000 .062 .295 .467 .000 .016 .018 .376 .000 .046 .129 .667 Iterative Iter-Retgen .265 .370 .353 .621 .104 .209 .310 .401 .115 .190 .178 .391 .581 .676 .689 .804 Self-RAG .174 .299 .321 .626 .123 .251 .333 .466 .073 .162 .132 .392 .385 .540 .639 .774 IRCoT .006 .087 .399 .631 .001 .085.433 .488.001 .056 .210 .416 .016 .169 .674 .800 Iterative FAIR-RAG 1 .300 .398 .337 .628 .186 .288 .286 .414 .133 .216 .169 .418 .622 .706 .682 .821 FAIR-RAG 2 .335 .447 .397 .689 .216 .325 .341 .458 .168 .253 .214 .465 .645 .732 .712 .837 FAIR-RAG 3 .332 .447 .404