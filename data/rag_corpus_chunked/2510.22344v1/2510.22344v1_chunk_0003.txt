and an explicit, modular faithfulness check. Existing iterative methods can propagate noise by using entire generations as queries, while adaptive methods may not sufficiently refine the evidence needed for complex queries after the initial routing. In this paper, we introduceFAIR-RAG, a novel framework forFaithful,Adaptive,Iterative Refinement inRetrieval-AugmentedGeneration. FAIR-RAG is designed to robustly handle complex queries by orchestrating a dynamic, multi-stage workflow. The framework begins with anAdaptive Routingmodule that analyzes query complexity to determine an optimal execution path, either by di- rectly answering simple queries or by allocating the appropriate computational resources for complex ones. For non-trivial queries, FAIR-RAG initiates a cyclical process designed to progressively build and validate a context. At the core of this cycle is anIterative Refinementloop where LLM agents intelligently decompose information needs, retrieve evidence, and filter out noise. Crucially, each cy- cle culminates in aStructured Evidence Assess- ment (SEA)module, which acts as an analytical gating mechanism. This module emulates a cog- nitive workflow by first deconstructing the user’s query into a checklist of required findings. It then systematically synthesizes the retrieved evidence against this checklist, verifying what is confirmed and, most importantly, explicitly identifying any “Remaining Gaps.”These identified gaps provide a precise, actionable signal for theAdaptive Query Refinementmodule, which then generates new, tar- geted queries specifically designed to retrieve the missing information. This evidence-centric loop continues until sufficiency is achieved, ensuring that the finalFaithful Answer Generationstep is strictly grounded in a comprehensive and ver- ified knowledge context, substantially enhancing trustworthiness and reducing hallucination. Our main contributions are as follows: • We introduce a novel agentic RAG architec- ture centered on anIterative Refinement loop. This evidence-centric cycle is governed by an analytical gating mechanism we term Structured Evidence Assessment (SEA). By systematically deconstructing the query and identifying specific information gaps, the SEA module intelligently guides subsequent itera- tions.