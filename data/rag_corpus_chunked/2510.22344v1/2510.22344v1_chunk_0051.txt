The source code and default configurations can be found on the official project repository: https://github.com/ruc-nlpir/flashrag. The specific configurations for our experiments are detailed in Table 5 below. Category Parameter & Value General Framework Base Framework: FlashRAG Max Iterations: 3 Retriever Configuration Model: e5-base-v2 Documents Retrieved (top_k): 5 Index Type: Faiss (IndexFlatIP) Pooling Method: mean Query Max Length: 128 Generator Configuration Baseline: Llama-3-8B-Instruct Self-RAG: selfrag-llama-7b FAIR-RAG: Llama-3-8B-Instruct Max New Tokens: 1024 Max Input Length: 8000 Evaluation Settings Metrics: em, f1, acc Random Sample: True Table 5: Hyperparameter and Model Configuration De- tails. Unless specified otherwise, all hyperparameters such as temperature, top_p, and sequence lengths were kept at the default values provided by the FlashRAG framework to ensure a fair and controlled comparison across all tested methodologies. B Full Prompts for the FAIR-RAG Pipeline This appendix reproduces the exact prompts that guide the behavior of the specialized agents within the FAIR-RAG pipeline. B.1 Query Validation and Dynamic Model Selection The following prompt is used by the initial agent to validate the userâ€™s query for clarity and safety, and to select the most appropriate execution model (e.g., simple RAG vs. full agentic pipeline). PROMPT = """ **Situation:** A user has submitted a question to a Question Answering System that uses different processing strategies based on query complexity. **Intent:** Analyze the user's question to determine the optimal processing strategy required to generate the most accurate answer. The strategies are: Factual Retrieval (SMALL), Information Synthesis (LARGE), or Multi-Step Deduction (REASONER). **Scaffolding:** You are a highly-calibrated query analysis agent. Your task is to classify the user's question into one of the three categories below based on the cognitive process required to answer it. After "Selected Label:", output ONLY the exact label. - **"SMALL" (Factual Retrieval):** - **Process:** Requires finding a single, self-contained fact. The answer is