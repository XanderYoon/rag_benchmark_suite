Queries: """ B.6 Faithful Answer Generation This is the final and most comprehensive prompt, instructing the generation model to synthesize the filtered evidence into a faithful, accurate, and well- structured answer. It strictly constrains the model to use only the provided sources and to avoid any form of hallucination. PROMPT = """Answer the question based on the given documents. ONLY give me the answer and do not output any other words. The following are given documents. The retrieval documents are listed as follows: {combined_evidence} Question: {original_query} Answer: """ C LLM-as-Judge Evaluation Prompts This appendix contains the complete and unabridged prompts used in ourLLM-as-Judge evaluation framework. To ensure full transparency and enable the replication of our evaluation methodology, we provide the exact instructions given to the judge model for each assessment criterion. Each prompt is carefully designed to elicit a consistent and unbiased evaluation of a specific quality aspect of the generated responses. The evaluation is performed by providing the judge model with the original query, the retrieved context, and the generated answer, along with one of the following instructional prompts. C.1 Binary Semantic Correctness (ACC LLM) To ensure the reproducibility of our semantic accu- racy evaluation, this section details the prompt used for theLLM-as-Judge Accuracy (ACC LLM)met- ric, as reported in Table 2. The prompt instructs the LLM to act as an impartial judge, comparing the modelâ€™s generated answer against a set of ground- truth answers. It provides a binary "Yes" or "No" judgment in a structured JSON format, enabling automated and consistent evaluation of semantic correctness. ACC_PROMPT = """You are an impartial judge. Evaluate whether the model's prediction correctly answers the given question. The prediction is correct if it implies ANY of the ground-truth answers provided. - Question: {question} - Ground-truth Answers (The prediction is correct if it matches