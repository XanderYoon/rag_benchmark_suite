prevents the model from introducing external knowledge. This combi- nation ensures the final answer is both verifi- able and trustworthy. We conducted extensive experiments on a suite of four challenging open-domain QA bench- marks to evaluate the FAIR-RAG framework, en- compassing complex multi-hop reasoning tasks (HotpotQA(Yang et al., 2018),2WikiMulti- HopQA,Musique) and a large-scale single-hop factual dataset (TriviaQA). Our best-performing configuration,FAIR-RAG 3 (Adaptive LLMs), was benchmarked against a wide range of strong baselines, including sequential (Standard RAG), conditional (Adaptive-RAG), and other state-of- the-art iterative methods (Iter-Retgen, Self-RAG). The results clearly demonstrate the superiority of our approach. On theHotpotQAbenchmark, our model sets a new state-of-the-art with an F1-score of0.453, surpassing the strongest iterative baseline, Iter-Retgen (0.370), by a significant margin of8.3 points. This pattern of superior performance is consistent across other complex benchmarks: on 2WikiMultiHopQA, FAIR-RAG achieves an F1 of0.320, outperforming the next best method,Self- RAG (0.251), by6.9 points, and onMusique, it scores an F1 of0.264, which is7.4 pointshigher thanIter-Retgen (0.190). Notably, FAIR-RAG’s architecture also excels on simpler factual queries, achieving a state-of-the- art F1 score of0.731onTriviaQA, showcasing its versatility. Our analysis further validates FAIR- RAG’s core principles: performance consistently improves as the number of refinement iterations increases from one to three (e.g., F1 on HotpotQA improves from 0.398 for FAIR-RAG 1 to 0.447 for FAIR-RAG 3), confirming the value of the iterative evidence-gathering loop. Furthermore, the adap- tive LLM allocation strategy provides an additional performance boost across all metrics. Finally, our framework consistently achieves the highest scores on the semantic metricACC LLM (e.g.,0.847on TriviaQA), confirming that its improvements reflect a deeper contextual understanding, not just lexical overlap. This robust performance validates the ef- fectiveness of our iterative, evidence-driven frame- work in enhancing both the accuracy and faithful- ness of LLM-based QA systems. 2 Related Work The paradigm of Retrieval-Augmented Genera- tion