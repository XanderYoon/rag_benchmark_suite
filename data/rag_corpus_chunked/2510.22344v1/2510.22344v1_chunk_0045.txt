erroneous sufficiency judgment—either a false positive that terminates the loop prematurely or a false negative that extends it unnecessarily—can lead the evidence-gathering process astray. • Fixed Iteration Policy:The maximum of three iterations is an empirically derived heuristic that balances performance and cost. However, a fixed limit lacks the flexibility to adapt to the varying complexity of individual queries. Our results show this is a robust aver- age but may not be optimal for every specific case. 6.2 Future Work The limitations of our current work open up several promising directions for future research to create more efficient and adaptive systems: •Distilling Task-Specific Expert Models:To mitigate the reliance on expensive, general- purpose LLMs, a promising direction is to fine-tune or distill smaller, specialized mod- els for each core task (Hinton et al., 2015). Creating dedicated expert models for query refinement or evidence assessment could lead to a system that is faster, cheaper, and more robust. • Learning a Dynamic Control Policy:The iterative process can be framed as a sequential decision-making problem. We propose explor- ing Reinforcement Learning (RL) to train a policy network that learns to dynamically con- trol the workflow (Schick et al., 2023). At each step, this agent could decide whether to retrieve more information, refine the query, or proceed to generation, replacing the fixed- loop structure with a far more efficient and adaptive strategy. • Extension to Multimodal Reasoning:The current FAIR-RAG framework operates exclu- sively on textual data. A natural and impactful extension would be to adapt its core principles of decomposition, iterative refinement, and structured assessment to handle queries over multimodal knowledge bases that include ta- bles, images, and structured data, creating a more versatile and comprehensive question- answering system (Alayrac et al., 2022). References AI@Meta. 2024. The llama 3 herd of models.arXiv preprint arXiv:2407.21783. AI@Meta. 2025.