balance of 2-3 it- erations provides the best balance between answer quality and resource consumption. Conversely, on the simplerTriviaQAdataset, the quality rank degrades with each additional it- eration, confirming that for single-hop queries, the initial retrieval is generally sufficient, and further iterations are unnecessary and even detrimental. This analysis confirms that iteration is crucial for complex reasoning, but an unrestrained number of iterations is suboptimal. Our framework’s default setting of a maximum of 3 iterations is thereby em- pirically justified as an effective balance between performance and efficiency. 5.2.3 A Complex Case Study: Comparative Multi-Hop Reasoning To demonstrate the unique advantages of the FAIR- RAG architecture over other advanced RAG frame- works, we analyze a hybridcomparative, multi- hop query. This type of query is particularly chal- lenging because it requires the system to conduct two parallel lines of multi-hop reasoning simulta- neously and then synthesize the results. The query is: “Compare the architectural styles of the building that houses theMona Lisa and the museum in London that houses the Rosetta Stone.” Standard RAG Failure:A standard RAG sys- tem would treat this complex comparative query as a single, semantically overloaded search vector. This unfocused approach is highly likely to fail for two primary reasons: First, it would struggle to si- multaneously retrieve relevant, detailed documents for both distinct lines of inquiry (the Louvre and Dataset Max Iter. Avg. Answer Rank Improvement Rate Avg. API Calls Avg. Tokens/Query (Lower is better) (vs. Iter 1) (#) HotpotQA 1 2.73 - 4.97 9,787 22.23 58.50%6.64 14,332 3 2.38 57.00% 7.83 17,281 4 2.66 57.00% 9.01 20,299 2WikiMultiHopQA 1 3.08 - 4.99 9,823 2 2.31 69.30% 7.10 15,413 32.18 70.90%8.79 19,812 4 2.43 67.30% 10.14 23,231 Musique 1 2.89 - 4.98 9,613 22.2063.40% 7.25 15,688 3 2.2863.70%9.01 20,162 4 2.63 61.20% 10.56 24,218 TriviaQA 11.83-