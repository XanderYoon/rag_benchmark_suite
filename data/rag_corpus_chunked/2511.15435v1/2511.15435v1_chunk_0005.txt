the multi- modal user query and the augmented knowledge. Our hier- archical method targets at misaligning and disrupting these two inputs, creating knowledge conflicts for the generator while breaking different levels of model capabilities. For retrieval, we employ a hierarchical two-stage strategy to op- timize the applied noise in modality and semantic levels. We first alter the query features to no longer correspond accurately to itself, so that the retrieval query is deviated. Then, the semantic alignment between query and knowl- edge is broken down. By structurally targeting the model’s core competencies across different levels of abstraction, our approach achieves severe and effective degradation regard- ing retrieval and generation performance. In summary, our main contributions are as follows: • We propose a novel Hierarchical Visual Attack method, which misaligns and disrupts the two inputs of generator in MRAG, posting stealth and severe threats for MRAG systems. • Our method is the first to disrupt MRAG systems only us- ing image perturbations, which further reveals the vulner- abilities of MRAG systems towards more imperceptible attacks. • We conduct extensive experiments on two datasets and four versions of retrievers to prove our attack’s effective- ness. 2. Related Work 2.1. Multimodal RAG and Existing Attacks Multimodal Retrieval-Augmented Generation [1, 27] has emerged as an important technique by extending traditional RAG [17] to multimodal data, enabling more real-world applications. Despite its huge success, the security issue has gained much attention. Recent studies have highlighted the vulnerabilities of multimodal RAG systems to knowl- edge poisoning attacks, where malicious information is in- jected into the external knowledge databases to manipulate the RAG’s outputs. MM-Poisoning [11] achieved the attack by constructing query-specific misinformation into injected text and images, or inserting a single irrelevant knowledge instance to fool all queries. Poisoned-MRAG [24] formal- ized the attack as an