retrieval and generation,attack r(·)represents our hierarchical at- tack method of learning retrieval and generation perturba- tions respectively,ϵis the bound of added perturbation to ensure that it is imperceptible to human eye. 3.2. Overall Hierarchical Attack Framework The overall attack framework is illustrated in Figure 3. To produce confusion for the generator in MRAG, we aim to misalign the two inputs of it: the input query and augmented knowledge. Thus, we hierarchically apply two different per- turbations to the image, resulting in misleading effect in two directions. For the augmented knowledge, the added perturbation δr mainly takes effect by disrupting the retrieval process. We further adopt a hierarchical two-stage strategy to learn δr, targeting at modality alignment and semantic alignment within retrieval respectively. The detailed design of this hierarchical strategy is described in subsection 3.3. For the generator input query, the added perturbationδ g breaks down the uni-modal semantic within the image input, so as to disrupt image understanding in generation. 3.3. Hierarchical Visual Attack on Augmented Knowledge The visual attack on the augmented knowledge as inputs to the generator is achieved by disrupting the retrieval process. We employ a hierarchical two-stage strategy to break down modality and semantic alignments respectively, which are key characteristics in success retrieval. Stage 1: Modality Alignment Attack Multimodal dual-encoder retrievers, such as CLIP [29], achieve strong alignment between text and image modal- ities. The corresponding text and image embeddings are close in the embedding space, enabling relevant knowledge to be retrieved through the ranking of embedding similar- ities during cross-modal retrieval. Thus, the first stage of visual attack on augmented knowledge is to break down the multimodal alignment between these modalities. We achieve this by pushing the query image close to the least similar sample. Given a user query image, we search for a reference