embeddings with highest similarity are retrieved as results. The multimodal embedding of a user query is obtained by summing the corresponding image and text embeddings, i.e.,E I (I) +E T (T). The knowledge embedding is de- pended on its modality. For text corpus, each passageK t’s embedding isE T (Kt). For multimodal KB, each image- text pair(Ki, Kt)’s embedding isEI (Ki) +E T (Kt). In this paper, our goal is to attack the MRAG pipeline by solely modifying the input image. We achieve our attack by misaligning and disrupting the two inputs of the generator compomnent in MRAG, which results in confusion within inputs along with misleading information. To be more spe- cific, for the augmented knowledge, we optimize a small perturbationδ r added at the input imageI q to mislead the retriever to return irrelevant knowledge. For the image in- put of the generator, we add another small perturbationδ g that breaks down uni-modal semantic within the image to disrupt image understanding. Consequently, the generator produces incorrect answers based on the misaligned input query and augmented knowledge, with misleading irrele- vant contents. The attack objective can be formulated as follows: Iadvr =attack r(Iq, δr),||I q −I advr ||∞ =||δ r||∞ < ϵ, Iadvg =I q +δ g,||I q −I advg ||∞ =||δ g||∞ < ϵ, T opkadv =R(T, I advr ,KB), Aadv =G(T, I advg , T opkadv), whereδ r andδ g are noises added to the image in retrieval and generation,attack r(·)represents our hierarchical at- tack method of learning retrieval and generation perturba- tions respectively,ϵis the bound of added perturbation to ensure that it is imperceptible to human eye. 3.2. Overall Hierarchical Attack Framework The overall attack framework is illustrated in Figure 3. To produce confusion for the generator in MRAG, we aim to misalign the two inputs