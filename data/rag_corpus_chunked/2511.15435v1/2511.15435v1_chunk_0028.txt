2025. 1 [35] Ziyi Yin, Muchao Ye, Tianrong Zhang, Jiaqi Wang, Han Liu, Jinghui Chen, Ting Wang, and Fenglong Ma. Vqattack: Transferable adversarial attacks on visual question answer- ing via pre-trained models. InProceedings of the AAAI Con- ference on Artificial Intelligence, pages 6755–6763, 2024. 1 [36] Yixiao Zeng, Tianyu Cao, Danqing Wang, Xinran Zhao, Zimeng Qiu, Morteza Ziyadi, Tongshuang Wu, and Lei Li. Rare: Retrieval-aware robustness evaluation for retrieval-augmented generation systems.arXiv preprint arXiv:2506.00789, 2025. 2 [37] Chenyang Zhang, Xiaoyu Zhang, Jian Lou, Kai Wu, Zilong Wang, and Xiaofeng Chen. Poisonedeye: Knowledge poi- soning attack on retrieval-augmented generation based large vision-language models. InForty-second International Con- ference on Machine Learning. 2, 5, 7 [38] Chiyu Zhang, Lu Zhou, Xiaogang Xu, Jiafei Wu, and Zhe Liu. Adversarial attacks of vision tasks in the past 10 years: A survey.ACM Computing Surveys, 58(2):1–42, 2025. 2 [39] Jiaming Zhang, Junhong Ye, Xingjun Ma, Yige Li, Yunfan Yang, Yunhao Chen, Jitao Sang, and Dit-Yan Yeung. Anyat- tack: Towards large-scale self-supervised adversarial attacks on vision-language models. InProceedings of the Computer Vision and Pattern Recognition Conference, pages 19900– 19909, 2025. 2, 6, 7, 8 [40] Wei Zou, Runpeng Geng, Binghui Wang, and Jinyuan Jia.{PoisonedRAG}: Knowledge corruption attacks to {Retrieval-Augmented}generation of large language mod- els. In34th USENIX Security Symposium (USENIX Security 25), pages 3827–3844, 2025. 1