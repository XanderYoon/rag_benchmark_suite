the vulnerabilities of multimodal RAG systems to knowl- edge poisoning attacks, where malicious information is in- jected into the external knowledge databases to manipulate the RAGâ€™s outputs. MM-Poisoning [11] achieved the attack by constructing query-specific misinformation into injected text and images, or inserting a single irrelevant knowledge instance to fool all queries. Poisoned-MRAG [24] formal- ized the attack as an optimization problem and proposed cross-modal attack strategies to disrupt both retrieval and generation. PoisonedEye [37] designed injected textual context or optimized the poison image to reduce retrieval performance to achieve attack goals. Despite these ad- vancements, existing research still follows the line of text RAG attacks, which mainly focus on knowledge poison- ing attacks. Furthermore, the multimodal characteristics re- mains underexplored. Thus, in this paper, we propose a new attack on multimodal RAG by only learning small adversar- ial perturbations added to the image in user query, without modifying the external knowledge base. 2.2. Visual Attack Visual adversarial attacks can be categorized into white- box, gray-box and black-box based on the level of knowl- edge about the attacked model [38]. White-box methods[2, + + +... + + Stage 1: Modality Alignment Attack Frozen Gradient Flow HV-Attack Generation Process When was the cola brand on the signs founded? Query Image + Text DPR fine-tuned Retriever Answer Adversarial Query Image + Text HV-Attack for Retriever Hierarchical Visual (HV)-Attack on MRAG ... ... Reference Sample Selection (RSS) Visual Attack for Query Generator Positive Caption A photo of a dog catching a frisbee in the grass, where a woman is watching. Negative Caption A photo of a small shack with a sign that says stop, where coca cola is sold. A photo of asmall shack with a sign that saysstop, where coca cola is sold. Image + Cpation RSS Modality-level Contrastive Learning MCL Stage