In Figure 9, we look at ùëõ-gram overlap and cosine similarity between retriever embeddings, and visualize them with respect to MIA scores for our attack. We observe that above some certain meaningful threshold (0.2 for 4-gram overlap, 0.9 for embedding cosine similarity), there is a positive correlation between how "similar" the non-member documents are to documents already present in the RAG, and the MIA Score (and by extension, questions answered correctly by the RAG). In summary, the failure cases are primarily due to limitations of the RAG system itself, such as occasional paraphrasing failures and the generator‚Äôs inability to answer questions effectively, rather than drawbacks of our attack. 7.3 Financial Cost Analysis Since our attack requires the adversary to deploy paid APIs to access models, such as GPT-4o, it is essential to analyze the finan- cial cost of this process. These models are utilized in three stages: generating yes/no questions, creating a general description of the target document, and obtaining ground-truth answers. Below, we provide an estimate of the cost for each stage. OpenAI pricing ac- counts for both input and output tokens, so both are considered in our calculations. For all calculations, we calculate the compute the cost to be able to cover 99% of all samples. For all estimations, we use the NFCorpus dataset, which contains the longest texts, as the worst-case scenario. Yes/No Question Generation. For this stage, we use GPT-4o to gener- ate yes/no questions. Based on our analysis, the input to GPT-4o for this task is 902 ¬± 108 tokens on average, and the output is 513 ¬± 64 tokens on average. Based on these numbers, the cost for this stage is $0.01 per document, taking an average of 6.86 s to run. Description Generation. Similarly, for generating the description of each document, we use