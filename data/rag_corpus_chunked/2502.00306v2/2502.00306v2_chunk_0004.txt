â€¢ Stealthy: Comprises only of natural-text queries that are not flagged by detection systems. â€¢ Efficient: Requires as few as 30 queries to the RAG system. IA leverages the intuition that natural queries, when crafted to be highly specific to a target document, can serve as stealthy member- ship probes for RAG systems (Section 5). Inspired by the doc2query task in Information Retrieval (IR) lit- erature [17, 37], we employ established few-shot prompting [ 8] techniques to guide an LLM in creating queries that are both top- ically aligned with and uniquely answerable by the target docu- ment. These queries capture fine-grained and nuanced information specific to the target document, enabling us to subtly exploit the behavior of the RAG system in an undetectable manner. We then issue these queries to the RAG system, with documentğ‘‘âˆ— being the target for membership inference. Since these queries are highly rel- evant to the target document, a well-performing RAG will retrieve and incorporate ğ‘‘âˆ— (if available) to generate accurate answers. We can thus verify the correctness of these answers to probe mem- bership. Aggregating signals from multiple queries enables strong membership inference. Crucially, each query remains benign, avoid- ing direct requests for verbatim content or displaying suspicious â€œjailbreakingâ€ patterns, ensuring the attack remains undetectable by any detection systems. https://platform.lakera.ai We conduct extensive experiments across multiple datasets and RAG configurations by varying retrieval and generation models (Section 6). While existing attacks are either detected easily or lack potency, we achieve successful inference while remaining virtu- ally indistinguishable from natural queries, with detection rates as low as 5%, compared to upwards of 90% for most inference at- tacks against RAG. Finally, we analyze our attackâ€™s failure cases (Section 7) and find that RAG may often be unnecessary: in many instances, the underlying LLM can answer