(1) For the transformed query Ë†ğ‘, the retrieverğ‘… begins by producing an embedding for Ë†ğ‘ and based on some similarity function (typically cosine similarity), fetching the ğ‘˜ most relevant documents ğ·ğ‘˜ = arg top-ğ‘˜ğ‘‘ âˆˆ Dsim( Ë†ğ‘, ğ‘‘), (2) where sim() represents the similarity function, and arg top-ğ‘˜ se- lects the top-ğ‘˜ documents with the highest similarity scores. The generator G then generates an output based on the contextual information from the retrieved documents [23]: ğ‘¦ = G (ins( Ë†ğ‘, ğ·ğ‘˜ )), (3) where ins(ğ‘, ğ·ğ‘˜ ) represents the query and context wrapped in a system instruction for the generative model. An end user only gets to submit query ğ‘ to the RAG system S and observe the response ğ‘¦ directly in the form of generated text. 2.2 Membership Inference in ML Membership inference attacks (MIAs) in machine learning seek to determine whether a specific data point ğ‘¥ âˆ— is part of a dataset involved in the ML pipeline, such as training [4, 36, 44, 46, 52] or fine-tuning data [16, 33]. Formally, given access to a model M, an adversary constructs an inference function A that outputs: A (ğ‘¥ âˆ—, M) âˆˆ { 1, 0}, 2 where 1 indicates that ğ‘¥ âˆ— is a member of the dataset, and0 indicates otherwise. Such attacks have been explored across a broad spectrum of modelsâ€”including traditional ML architectures [ 46], LLMs [13], and diffusion models [12]â€”by exploiting behavioral discrepancies between data seen during training (members) and unseen data (non- members). For instance, many ML models assign higher confidence scores to member data points [46]. MIAs have shown varying degrees of success across different domains, including images and tabular data [4, 46, 47, 55]. However, these successes predominantly rely on parametric outputs (e.g., con- fidence scores, perplexity, or loss values). Such outputs are