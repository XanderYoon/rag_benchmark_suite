relevant and matching text in the prompt. ’}. 0.626 0.070 MBA [29] Example: {sample} Predict the answers of the masks in the given texts:\n\n In a sample of 127 [MASK_1] adolescents, the ability to understand and manage emotions, assessed by a performance measure of [MASK_2]. . .\n\n You should strictly follow the contexts below to answer, and provide your answers in the specified format:\n"[Mask_i]: answer_i\n" for each mask: 0.928 0.974 Baseline (SQuAD) Example: When did the Scholastic Magazine of Notre dame begin publishing? 0.002 0.000 (AI Medical Chatbot) Example: Hi doctor, I am just wondering what is abutting and abutment of the nerve root means in a back issue. Please explain. What treatment is required for annular bulging and tear? 0.000 0.126 Interrogation Attack (Ours) My inquiry concerns Plasma adiponectin concentrations, body composition, and plant- based dietary influences in female twins. Does circulating adiponectin serve as a link between obesity, type 2 diabetes, and cardiovascular disease? Please answer with "Yes, " "No, " or "I don’t know" 0.012 0.050 Table 1: Evaluating the effectiveness of malicious-input detection against prompt-based methods proposed in the literature for privacy leakage (via membership inference or dataset extraction) for RAG-based systems. Most attacks (except MBA) use the target sample directly in the attack query {sample}, as descbribed by the attack templates above. For prompts that require the query, we compute scores based on aggregate statistics over 500 samples from various datasets. Both few-shot GPT-4 and Lakera can easily detect attempts to infer retrieved documents. Our attack achieves near-zero detection rate, unlike prior attacks that are almost always detected. We aim to craft natural queries—those resembling ordinary user inputs—yet highly specific to a target document. The premise here is that such a document contains information that is uniquely specific, often the rationale for employing RAG in