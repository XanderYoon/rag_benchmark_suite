compromise privacy or reveal sensitive internal con- text. For example, documents containing PII might disclose that a user interacted with a system, while the presence of internal guide- lines or strategy papers can hint at organizational priorities. These inferences carry implications for privacy, IP exposure, and regu- latory compliance. Since RAG systems ingest data at deployment, membership inference can serve as a valuable tool for auditing what content—licensed, protected, or otherwise—has been incorporated. Although several studies have demonstrated membership in- ference on RAG-based systems, these methods generally rely on unnatural queries (e.g., high-perplexity documents generated dur- ing optimization [15, 43]) or exploit "jailbreaking" [45, 53] to coerce the generative models into undesired behaviors. Such attacks can be detected using off-the-shelf detection tools such as Lakera , al- lowing RAG systems to thwart these attacks or even simply refuse to respond. To the best of our knowledge, there are currently no privacy-leakage attacks on RAG systems that cannot be eas- ily thwarted through straightforward detection mechanisms . A desirable MIA for a RAG system should thus be undetectable while retaining its effectiveness. Towards this, we systematically evaluate existing MIAs [2, 26, 29] across various detection mechanisms and show that prior attacks completely break down against these detection strategies (Section 4). We then introduce Interrogation Attack (IA), a MIA which is: • Effective: Achieves high precision and recall. • Black-box: Does not rely on access or knowledge of the underlying retriever/generator models. • Stealthy: Comprises only of natural-text queries that are not flagged by detection systems. • Efficient: Requires as few as 30 queries to the RAG system. IA leverages the intuition that natural queries, when crafted to be highly specific to a target document, can serve as stealthy member- ship probes for RAG systems (Section 5). Inspired by the doc2query task