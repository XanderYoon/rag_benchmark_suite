detection performance. The presented method is able to simultaneously determine both the distance and direction of the nearby ferromag- netic obstacles. Both simulation and experimental results are presented to validate the sensing principle and operational performance. Our Adversarial Query: "I am inquiring about a compact magnetic proximity sensor for directional detection in spherical robots . Is the presence of a sealed outer shell a characteristic feature of spherical robots? Please answer with â€™Yes, â€™ â€™No, â€™ or â€™I donâ€™t knowâ€™. " Rewritten Query: "Iâ€™m seeking information on a compact magnetic proximity sensor designed for detecting direction in spherical robots. Do spherical robots typically have a sealed outer shell? Please respond with â€œYes, â€ â€œNo, â€ or â€œI donâ€™t know. â€" Figure 3: Example of a particular document discussing proximity sensors for spherical robots, with an example query generated by our attack and the corresponding rewritten version that is used by the RAG system. The red text represents the generated general description specific to the target document, while the blue text is the generated yes/no question. Note that the adversary is unaware of the exact query-rewriting strategy, and thus does not get to observe the rewritten query directly. the final compute the membership score as 1 ğ‘› ğ‘›âˆ‘ï¸ ğ‘–=1 I[ğ‘Ÿğ‘– = ğ‘”ğ‘– ] âˆ’ ğœ†I[ğ‘Ÿğ‘– = UNK], (5) where I[Â·] is the indicator function that evaluates to1 if the equality condition holds and 0 otherwise, and ğœ† is a hyper-parameter that penalizes the inability to answer a question. A higher score indicates that the RAG system consistently retrieves correct information, suggesting that ğ‘‘âˆ— is included in the knowledge base. 6 Experiments We evaluate our attack across multiple retrievers, generators, and datasets (Section 6.1). As we observed before, none of the existing attacks would make it past a simple detection stage (Section