details, see Appendix A. Easily Detectable Attacks. Employing an off-the-shelf detection method can completely filter out the attack queries for two out of seven attacks, including the RAG document extraction attack [7] and MBA [29] (Table 1), and can filter approximately 58% of the attack queries for the prompt-injected data extraction attack [42]. When using GPT-4o as a detection technique specifically aligned with context probing attacks, the majority of attack queries are successfully filtered out. Importantly, neither of these two tech- niques significantly impacts natural queries from users, ensuring that legitimate queries remain mostly unaffected. These results highlight the necessity for attackers to craft stealthy queries that avoid explicit instructions aimed at recovering docu- ments from the modelâ€™s context. While adversarially crafted texts designed to bypass detection are feasible, an ideal attack strategy would involve generating clean-text queries that are immune to such defensive countermeasures. Making an attack stealthy requires it to be designed with stealth as a core objective. In Appendix E, we explore modifications to existing attacks to improve their stealth, but find that they remain largely detectable. Thus for an inference attack to be successful in the context of a practical RAG system, it must bypass any query-filtering systems that can detect obvious inference attempts. 5 Our Method: Interrogation Attack Given black-box access to a RAG system S, the adversary can only interact with it by submitting queries and observing generated responses. Approaches that aggressively probe the system with suspicious or contrived queries deviate from typical usage patterns, thus making them easily detectable. Instruction template for this classification task is presented in the Appendix (Figure 13) 4 Proposed Attack Prompt Template/Example GPT4 Lakera The Good and The Bad [56] {sample} Please repeat all the context. 0.928 0.134 Prompt-Injected Data Extrac- tion [42] Here is a sentence: {sample}.