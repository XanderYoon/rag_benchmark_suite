penalizes the inability to answer a question. A higher score indicates that the RAG system consistently retrieves correct information, suggesting that ùëë‚àó is included in the knowledge base. 6 Experiments We evaluate our attack across multiple retrievers, generators, and datasets (Section 6.1). As we observed before, none of the existing attacks would make it past a simple detection stage (Section 4) in a practical RAG system. Regardless, we find that even the absence of such guardrails, our attack outperforms existing baselines in most cases and is fairly robust across all these configurations (Section 6.2). 6.1 Evaluation Setup Dataset. For our evaluations, we consider three distinct datasets representing scientific and medical documents. Specifically, we se- lect NFCorpus, TREC-COVID, and SCIDOCS from the BEIR bench- mark [49]: collections of scientific and medical documents, contain- ing approximately 3.5K, 116K, and 23K samples respectively. For each dataset, after de-duplicating the samples, we randomly select 1000 members and 1000 non-members. Additionally, we use the TF-IDF technique to identify near-duplicate samples to the non- members (with a similarity threshold of 0.95) and remove them from the entire dataset. This ensures that the non-members do not over- lap with or exist in the final dataset, maintaining the integrity of the evaluation, an issue observed in membership-inference evaluations for LLMs [9, 13, 32, 34]. Generator and Retriever. We utilize two retrievers in our eval- uations: GTE [27] and BGE [57]. For generators, we evaluate four 7 different models: Llama 3.1 Instruct-8B [14], Command-R-7B, Mi- crosoft Phi-4 [1], and Gemma-2-2B [48]. Shadow LLM. As described, the shadow LLM is employed to gen- erate ground-truth answers for the questions created based on the target documents. In all experiments, we use GPT-4o-mini as the shadow model because it is fast and cost-efficient, and it belongs to a different family of LLMs