their queries are in bypassing current detection filtersâ€”an area currently underexplored in the literature. To evaluate the ability of current attacks to bypass detection methods, we adopt two different approaches. First we utilize Lak- eraGuard, a commercial off-the-shelf guard model designed for detecting prompt-injection and jailbreak attempts [24], to evaluate queries from different attacks. While this tool can detect queries from some existing attacks, it tends to fall short in identifying queries from attacks whose prompts appear more natural. These tools are designed to detect a wide range of prompt injection queries, so it is unsurprising that they may not perform perfectly in spe- cialized settings like context probing attacks. To develop a more tailored detection tool, we leverage the capabilities of GPT-4o as a classifier with few-shot prompting to classify input queries as either "natural" or "context probing. " GPT-4o has recently shown great performance in prompt injection detection, further support- ing its use for this task [ 24]. Both approaches have shown good performance in prompt injection detection [30]. Setup. We consider attack prompts from three document extraction attacks and four MIAs, including ours. Apart from the MBA attack [29], all prior inference attacks use a fixed, specific template for their attack queries. The templates for these queries are presented in Table 1. To evaluate baseline behavior of these detection methods on natural user queries, we include baselines on SQuAD and AI Medical Chatbot question-answer datasets. For more details, see Appendix A. Easily Detectable Attacks. Employing an off-the-shelf detection method can completely filter out the attack queries for two out of seven attacks, including the RAG document extraction attack [7] and MBA [29] (Table 1), and can filter approximately 58% of the attack queries for the prompt-injected data extraction attack [42]. When using GPT-4o as a detection technique