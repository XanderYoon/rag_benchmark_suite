necessary content to generate 30 distinct and effective questions. This limitation is less critical in domain-specific RAG applications, where documents are typically longer and rich enough in content to justify the use of a RAG system. Generic Documents. In addition to length, the targeted docu- ments must contain information that the base LLM is unaware of or not very good at. The attack may perform poorly on highly generic documents, as they do not contain enough specific details to craft unique and distinguishable questions, and correspond to content that the base LLM may be familiar with. However, it is worth noting that in such cases, the utility of RAG might be limited, as generic documents provide less value for retrieval-based systems and the RAG owner might benefit in efficiency from discarding such documents from their datastore. 7.2 Analyzing Failure Cases Although our attack achieves a higher AUC in all settings compared to the baselines, its TPR@low FPR leaves room for improvement in some cases. Examining the failed examples can shed light on why this happens. We begin by visualizing the distribution of MIA scores for member and non-members documents with our attack. In Figure 8, we observe the distribution of the member and non- member scores to be mostly separable but do note some overlap between them. This overlap between distributions can be attributed to two reasons: (1) members with low MIA scores, and (2) non- members with high MIA scores. False Negatives. The fact that we observe high retrieval recall for our attack rules out the possibility of the target document being absent from the context provided to the RAG generator. The RAG’s inability to answer the question properly can thus have two po- tential reasons. On rare occasions, GPT-4o fails to paraphrase the user’s query accurately (see Appendix