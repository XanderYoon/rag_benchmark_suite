is important to note that, in a realistic scenario, the MBA attack’s queries are unlikely to pass detection filters, limiting its practical applicability. E Making Prior Works Stealthy Existing membership inference attacks against RAG models were de- veloped assuming a plain, minimal RAG setup, without accounting for the additional components often present in real-world systems, such as detection mechanisms. This makes retrofitting stealth into these attacks difficult, as meaningful changes can start to resemble entirely new attacks. In this appendix, we attempt to modify stan- dard attacks for improved stealth, but find that they still remain easily detectable. E.1 Reducing Prompt Length via Document Summaries Prior work uses the target document with minimal transformation [2, 26]. In contrast, our attack relies on a combination of document summaries and questions based on distinct pieces of information from the document (as described in Section 5.1). As a result, the reduced prompt size may make our queries less conspicuous. To test whether it this reduced query length that leads to low detection rates, we modify existing attacks to use a summarized version of the document instead of the full document. Detection rates remain high even with the paraphrased document, as shown in Table 6. This outcome is expected, since the detection methods focus on identifying malicious intent in the query’s structure, not on the specific document content used. Attack GPT4 Lakera RAG-MIA [2] 1.000 0.000 S2-MIA [26] 0.656 1.000 MBA [29] 1.000 0.944 Table 6: Evaluating the effectiveness of malicious-input de- tection against baseline attacks for membership inference. E.2 Adapting Queries to Elicit Binary Responses While RAG-MIA already constructs queries that correspond to a ‘yes’ or ‘no’ response, other baselines like S2-MIA rely on the RAG system ‘autocompleting’ some given text. We therefore experiment with a variant of the S 2-MIA attack by