graph are close in content, their similarity is high, and thus their confidence is also high; conversely, if they are not, their confidence is low. Let G be a homologous line graph, and N (G) be the set of nodes in the graph. For any two nodes vi, vj ∈ N (G) with the same attributes, the similarity S(vi, vj) between them is defined based on the calculation method of mutual information entropy. The mutual information entropy I(vi, vj) measures the interdependence of the attribute content of the two nodes, and its calculation formula is: I(vi, vj) = X x∈Vi X y∈Vj p(x, y) log( p(x, y) p(x)p(y) ) (4) where Vi and Vj are the sets of attribute values for nodes vi and vj, respectively, p(x, y) is the joint probability distribution of vi taking attribute value x and vj taking attribute value y, and p(x) and p(y) are the marginal probability distributions of x and y, respectively. The similarity S(vi, vj) can be defined as the normalized form of mutual information entropy to ensure that its value lies within the interval [0, 1]: S(vi, vj) = I(vi, vj) H(Vi) + H(Vj) (5) where H(Vi) and H(Vj) are the entropies of the attribute value sets of nodes vi and vj, respectively, calculated as: H(V ) = − X x∈V p(x) log p(x) (6) Subsequently, the confidence C(G) of the homologous line graph G can be determined by calculating the average simi- larity S(vi, vj) of all node pairs in the graph: C(G) = 1 |N (G)|2 − |N (G)| X vi∈N (G) X vj ∈N (G) j̸=i S(vi, vj) (7) where |N (G)| denotes the number of nodes in the graph. Notably, a homologous line graph exhibiting high confi- dence demonstrates that its constituent nodes maintain strong attribute-level consistency