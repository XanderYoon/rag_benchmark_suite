[51] contains nearly 18,000 RAG-generated responses with detailed manual annota- tions including word-level hallucination intensities. However, diverse and complex data sources continue to challenge exist- ing evaluation frameworks. VI. CONCLUSION In this work, we introduce MultiRAG, a framework de- signed to mitigate hallucination in multi-source knowledge- augmented generation. To address hallucinations arising from data sparsity and inconsistency, we propose two key inno- vations: multi-source knowledge aggregation and multi-level confidence calculation. The introduction of multi-source line graphs enables efficient cross-domain data aggregation, en- hancing knowledge connectivity and retrieval performance. Meanwhile, our multi-level confidence computing module adaptively filter out low-quality subgraphs and unreliable nodes. Future work will explore more challenging aspects of hallucination mitigation, particularly in multimodal retrieval and ultra-long text reasoning, to better adapt generative re- trieval systems to real-world, open multi-source environments. VII. ACKNOWLEDGEMENT This work is supported by the National Natural Science Foundation of China (62176185, U23B2057), and the “14th Five-Year Plan” Civil Aerospace Pre-research Project of China (D020101). REFERENCES [1] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray et al. , “Training language models to follow instructions with human feedback,” Advances in neural information processing systems , vol. 35, pp. 27 730–27 744, 2022. [2] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal, H. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval- augmented generation for knowledge-intensive nlp tasks,” Advances in Neural Information Processing Systems , vol. 33, pp. 9459–9474, 2020. [3] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, “Retrieval augmented language model pre-training,” in International conference on machine learning . PMLR, 2020, pp. 3929–3938. [4] Y . Gao, Y . Xiong, X. Gao, K. Jia, J. Pan, Y . Bi, Y .