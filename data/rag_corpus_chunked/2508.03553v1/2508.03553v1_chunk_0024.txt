varying data sparsity and inconsistency. To validate it, we conducted experiments from the following two perspectives. 1) Sparsity of multi-source data: We applied 30%, 50%, and 70% random relationship masking to four pre-processed datasets, TABLE III: Ablation experiments of multi-source knowledge aggregation(MKA) and multi-level confidence computing(MCC) Datasets Source MultiRAG w/o MKA w/o Graph Level w/o Node Level w/o MCC F1/% QT/s PT/s F1/% QT/s PT/s F1/% QT/s PT/s F1/% QT/s PT/s F1/% QT/s PT/s Movies J/K 52.6 25.7 62.64 48.2 2783 62.64 45.3 50.1 58.2 38.7 21.3 0.31 31.6 25.7 0.28 J/C 54.3 12.7 61.36 49.1 1882 61.36 46.8 28.9 57.4 40.2 10.5 0.29 30.5 12.7 0.29 K/C 49.1 31.6 64.40 45.5 4233 64.40 42.7 65.3 61.8 35.9 28.4 -0.27 33.1 31.6 -0.29 J/K/C 54.8 39.2 60.8 47.5 4437 60.8 48.1 75.6 56.2 41.5 35.8 0.30 34.7 39.2 0.32 Books J/C 63.5 1.19 2.47 57.1 11.9 2.47 55.2 4.7 2.12 49.8 0.92 0.18 43.4 1.19 0.22 J/X 63.1 1.22 2.56 59.3 11.7 2.62 54.7 5.1 2.24 48.3 0.89 0.19 42.6 1.22 0.22 C/X 64.2 1.16 2.38 55.3 8.39 2.38 53.9 3.9 2.05 47.1 0.85 0.16 41.0 1.16 0.17 J/C/X 66.8 1.31 3.07 57.2 15.8 3.08 59.4 6.3 2.89 52.7 1.12 0.21 36.4 1.31 0.20 Flights C/J 74.9 29.8 109.9 72.2 NAN 109.9 68.3 142.7 98.5 61.4 25.3 0.85 52.1 29.8 1.07 Stocks C/J 78.6 2.72 5.36 69.6 450.8 5.36 72.1 8.9 4.12 65.3 1.98 0.15 45.4 2.72 0.17 TABLE IV: Performance comparison on HotpotQA and 2WikiMultiHopQA datasets Method HotpotQA 2WikiMultiHopQA Precision Recall@5 Precision Recall@5 Standard RAG 34.1 33.5 25.6 26.2 GPT-3.5-Turbo+CoT 33.9 47.2 35.0 45.1 IRCoT 41.6 41.2 42.3 40.9 ChatKBQA 47.8 42.1 46.5 43.7 MDQA 48.6 52.5 44.1 45.8 RQ-RAG 51.6 49.3 45.3 44.6 MetaRAG 51.1 49.9 50.7 52.2 MultiRAG 59.3 62.7 55.7 61.2 making the connections between data