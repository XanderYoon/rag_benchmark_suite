the similarity between these two outputs can assess the self-consistency score and the degree of hallucination. We designed an LLM-based evaluator S to convert scores, e.g., similarity or relevance, into the probability of generating indicative tokens (e.g., ’yes’ or ’no’). We calculate the similarity scoresssc through LLM-based evaluator Ssc as the following formulation: Figure 3: Overview of our RetroRAG structure. x = LLM ([a, asc, q], Msc) Ssc = P (x =′ yes′|([a, asc, q], Msc))P i∈[′yes′,′no′] P (x = i|([a, ac, q], Msc)) ssc = Ssc(([a, asc, q], Msc)) (1) Where Msc is a customized prompt, and a threshold t is utilized to govern the model‘s output, only when ssc > t , the iteration process is stop, and output the answer as the final answer. A higher value of t implies that a more strin- gent requirement of knowledge context. And follow the re- search from (Zhou et al. 2024), a declarative assessor is im- plemented to ensure the standardization of the answer. Evidence Collation and Discovery In each round of iteration, the initial queryq and its key enti- ties k will be fixed as constant input for ELLERY structure. The ELLERY structure obtains and updates source evidence through Evidence Collation, while based on which gener- ating inferential evidence and proposing re-querie to obtain the required knowledge through Evidence Discovery. Evidence Collation In the L-th iteration, we use the search query generated from end of the last round q(L−1) s ,which is designed to specifically target missing information, to re- trieve relevant passages D(L) C . And concatenate q(L−1) s with q to obtain the matching query q(L) m = [ q, q(L−1) s ], which is designed to match the most relevant evidence within the current knowledge context, while avoiding the issue of devi- ating from the