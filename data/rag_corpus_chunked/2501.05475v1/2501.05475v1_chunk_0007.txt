of holistic thinking, continuously increas- ing the amount of knowledge retrieved based on unsolved questions, until effective reasoning can be achieved(Trivedi et al. 2023; Zhou et al. 2024), and more recent studies have explored fine-tuning certain components to enhance the reli- ability of retrieval process(Yan et al. 2024; Liu et al. 2024). All these approaches are proven to be effective. However, due to factually related irrelevant documents from the inher- ent flaws of the current retrieval system, they address issues of insufficient reasoning and over-reasoning, respectively. This paper addresses the aforementioned issues by exploring the application of evidence, to construct a retroactive reason- ing process. Through continuously generating and updating credible evidence, our work builds an effective RAG frame- work to address the hallucination in question answering task without fine-tuning or pre-training of LLMs. Methodology Existing retrieval augmented methods, due to their unidirec- tional forward reasoning paradigm, are prone to the risk of external hallucination from factually related irrelevant doc- uments. Since the process of answering decomposed sub- questions can be equivalently regarded as the process of ob- taining sub-evidence to answer the initial question, as illus- trated in Figure 2, previous approaches have employed a lin- ear paradigm of progressive sub-evidence generation, where the generation of each node is highly depends on the previ- ous nodes. Although the verification of knowledge can pre- vent the emergence of subsequent unreliable node B⃝, it is incapable of correcting erroneous validation node C⃝ caused from the inherent flaws of current retrieval systems, like Eric Harrison in Figure 1 when it has reached node D⃝. The LLMs will propagate the erroneous information as definitive knowledge, leading to inaccuracies in the following output. By generating and updating of evidence, RetroRAG en- ables LLMs to refine their knowledge by integrating newly evidence D⃝, J⃝, K⃝,