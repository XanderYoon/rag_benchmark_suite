41.0 25.6 30.9 31.0 32.1 SearChain(Xu et al. 2024) 29.6 41.2 41.5 43.4 33.4 42.6 42.5 44.8 MetaRAG(Zhou et al. 2024) 32.4 44.3 45.5 45.6 28.8 36.0 35.7 38.4 RetroRAG 41.2 * 54.9* 56.2* 58.3* 38.6* 46.6* 46.9* 49.5* present a clearer progressive structure, such as samples in 2WikiMQA dataset, the approaches of decomposing sub- problems will perform better, so Self-Ask and SearChain demonstrate superior performance compared to IR-COT and MetaRAG in 2WikiMQA dataset since the latter may intro- duce excessive noise; On the contrary, the idea of collecting enough knowledge would help more in answering since the decomposing-answering mode could mislead the reasoning process, causes IR-COT and MetaRAG perform better on HotpotQA dataset. Due to our workâ€™s design of generation of inferential evidence and updating of evidence, which sup- presses the introduction of noisy information and achieves a retroactive-progressive reasoning structure, achieving the best performance above all baselines on both datasets. Table 2: Ablation Studies on RetroRAG. HotpotQA 2WikiMQA EM F1 EM F1 RetroRAG 41.2 54.9 38.6 46.6 Ablation of structure -w/o AE 38.6 51.7 32.6 40.1 -w/o ELLERY 19.0 25.5 26.0 30.7 Ablation of evidence utilization -w/o SE 34.8 46.1 29.2 35.6 -w/o IE 38.4 51.9 36.6 44.5 -w/o UoE 39.4 53.0 38.2 45.9 -w/o EoE 40.5 54.8 38.0 45.8 Ablation Study To verify the effectiveness of different components in RetroRAG, we conduct a comparative analysis respectively focus on frameworks, including Answerer (solely on the An- swer Evaluation (AE) mechanism since Answerer needs to generate answer output) and ELLERY; Besides, we also fo- cus on the designs of evidence utilization, including Source Evidence (SE), Inferential Evidence (IE), Updating of Evi- dence (UoE) and Evaluation of Evidence (EoE). The results are shown in Table 2. Ablation of structure As shown in Table 2, it is evident that removing either