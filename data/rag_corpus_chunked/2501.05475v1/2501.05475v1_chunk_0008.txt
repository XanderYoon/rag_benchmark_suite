C⃝ caused from the inherent flaws of current retrieval systems, like Eric Harrison in Figure 1 when it has reached node D⃝. The LLMs will propagate the erroneous information as definitive knowledge, leading to inaccuracies in the following output. By generating and updating of evidence, RetroRAG en- ables LLMs to refine their knowledge by integrating newly evidence D⃝, J⃝, K⃝, with the previous evidence A⃝, B⃝, C⃝ based on the relevance to the question, retaining only the most pertinent evidence. This process allows for a more comprehensive understanding as new evidence is in- tegrated(for instance, Eric Harrison is the youth coach of Alex Ferguson), while erroneous nodes at any stage are dis- carded (for instance, Harrison recruited Beckham as man- ager will be correct). The correct nodes A⃝, J⃝, K⃝ will be preserved to the next stage. Essentially, it can be considered that RetroRAG constructs a graph-based thinking structure. Overview We propose Retroactive Retrieval-Augmented Generation (RetroRAG) framework to tackle the issue of insufficient reasoning and over-reasoning, which applies Answerer to Figure 2: Comparison between previous methods and RetroRAG in mechanism. generate and evaluate credible answers, and Evidence- coLLation-and-discovERY (ELLERY) framework retrieves, generates, and updates the evidence. In the QA scenario, the target of RetroRAG is to gener- ate an answer a to the given question q with key entities k. As illustrated in Figure 3, RetroRAG utilizes the itera- tion application of two processes: (1)Answerer generates an answer based on the current knowledge context, and deter- mines if a consistent response can be generated within the current knowledge context. (2) ELLERY obtains documents DQ from the retrieval corpus D = {di}|D| i=1(with Wikipedia dumps served as the primary data source in this study) re- lated to the question, as the source evidence, and by which generates credible evidence E, and