on the quality of responses. Besides, the updating and evalu- ating of evidence can alleviate the introduction of irrelevant information, ensuring the progression of the current answer- ing process while aligning with the initial question, thereby enhancing performance. Qualitative Analysis To better delve into the impact of the numbers of iterations and evidence, as well as similarity thresholds, we have em- barked on a series of qualitative experiments. The results are shown in Figure 4. It can be observed that: Different maximum numbers of iterations Although the Answer Evaluation mechanism plays a significant role in the performance of RetroRAG, the maximum number of itera- tions also has a substantial impact on the final results. As depicted in Figure 4, we can find that on both datasets, the accuracy of RetroRAG improves progressively before the it- erations reach 3, and then grows relatively stable, peaking when the iterations reach 5 or 6. After the peak, we observed a risk of decline in the performance with the increase of iter- ations. We think these results suggest that, by increasing the number of iterations, RetroRAG can extract more effective evidence, thereby improving performance. However, exces- sively increasing may cause over-reasoning and introduce noise information, which in turn to a decline in performance. Different numbers of evidence For the convenience of the experiment, we set the numbers of both source evidence and inferential evidence to the same. Based on this setting, we design a series of experiments to investigate the impact of the number of evidence. As depicted in Figure 4, we find that on both datasets, increasing the numbers of evidence from 1 to 3 can significantly improve the performance of RetroRAG, which reflects that under the condition of insuf- ficient information, it is difficult for LLMs to perform effec- tive reasoning. The