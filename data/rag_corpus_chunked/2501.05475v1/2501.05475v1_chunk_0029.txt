arXiv:2404.10198. Wu, S.; Xie, J.; Chen, J.; Zhu, T.; Zhang, K.; and Xiao, Y . 2024. How Easily do Irrelevant Inputs Skew the Responses of Large Language Models? arXiv preprint arXiv:2404.03302. Xu, S.; Pang, L.; Shen, H.; Cheng, X.; and Chua, T.-S. 2024. Search-in-the-Chain: Interactively Enhancing Large Lan- guage Models with Search for Knowledge-intensive Tasks. In Proceedings of the ACM on Web Conference 2024, WWW ’24, 1362–1373. New York, NY , USA: Association for Com- puting Machinery. Yan, S.-Q.; Gu, J.-C.; Zhu, Y .; and Ling, Z.-H. 2024. Corrective retrieval augmented generation. arXiv preprint arXiv:2401.15884. Yang, Z.; Qi, P.; Zhang, S.; Bengio, Y .; Cohen, W.; Salakhut- dinov, R.; and Manning, C. D. 2018. HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering. In Riloff, E.; Chiang, D.; Hockenmaier, J.; and Tsujii, J., eds., Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2369–2380. Brussels, Bel- gium: Association for Computational Linguistics. Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K. R.; and Cao, Y . 2023. ReAct: Synergizing Reasoning and Acting in Language Models. In The Eleventh International Conference on Learning Representations. Ye, H.; Liu, T.; Zhang, A.; Hua, W.; and Jia, W. 2023. Cog- nitive mirage: A review of hallucinations in large language models. arXiv preprint arXiv:2309.06794. Yu, W.; Zhang, H.; Pan, X.; Ma, K.; Wang, H.; and Yu, D. 2023. Chain-of-Note: Enhancing Robustness in Retrieval- Augmented Language Models. arXiv:2311.09210. Zhou, Y .; Liu, Z.; Jin, J.; Nie, J.-Y .; and Dou, Z. 2024. Metacognitive Retrieval-Augmented Large Language Mod- els. In Proceedings of the ACM on Web Conference 2024 , 1453–1463. New York, NY , USA: Association for Comput- ing Machinery. A. Prompt Detail We show the prompt used in experiment on both datasets in Figure 7 to Figure 13. In this work,