Introduction Dense retrieval has become the new paradigm in passage retrieval. It has demon- strated higher eﬀectiveness than traditional lexical-based metho ds due to its abil- ity to tackle the vocabulary mismatch problem [5]. Even though dens e retrievers are highly eﬀective on typo-free queries, they can witness a drama tic perfor- mance decrease when dealing with queries that contain typos [11,12,1 4]. Recent works on robustifying dense retrievers against typos utilize data a ugmentation to obtain typoed versions of the original queries at training time. Mo reover, they introduce additional robustifying subtasks to minimize the rep resentation discrepancy between the original query and its typoed variants. Sidiropoulos and Kanoulas [11] applied an additional contrastive loss t o en- force the latent representations of the original, typo-free quer ies to be closer to their typoed variants. Zhuang and Zuccon [14] utilized a self-teach ing training 2 Georgios Sidiropoulos and Evangelos Kanoulas strategy to minimize the diﬀerence between the score distribution o f the origi- nal query and its typoed variants. Alternatively, Tasawong et al. [13] employed dual learning in combination with self-teaching [14] and contrastively trained the dense retriever on the prime task of passage retrieval and th e dual task of query retrieval (learns the query likelihood to retrieve queries for passages). Despite the improvements in robustness, the existing typo-robus t methods do not always make optimal use of the available typoed queries. In de tail, they address the robustifying subtasks with contrastive learning, ass uming a single positive sample (query) and a set of negative ones per anchor (dep ending on the approach, the anchor can be either a query or a passage). Howev er, alongside the original query, its multiple typoed variants are available. Hence, there is more than one positive sample per anchor. As a result,