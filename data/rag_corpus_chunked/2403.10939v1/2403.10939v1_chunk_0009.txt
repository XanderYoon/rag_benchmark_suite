use the same underlying corpus of 8 .8 million passages and ∼ 400K training queries but diﬀer in evaluation queries. DL-Typo provides 60 real-world queries with typos alongside their manually corrected typo-free ve rsion. The development set of MS MARCO consists of 6 , 980 queries (the test set is not publicly available). Following previous works [13,14], we obtain typo var iations for each typo-free query via a synthetic typo generation model a nd repeat the typo generation process 10 times. To measure the retrieval perf ormance, we re- port the oﬃcial metrics of each dataset. For the evaluation on the typo version of MS MARCO, we report the metrics averaged for each repeated e xperiment since typoed queries are generated 10 times for each original quer y. Implementation details. We follow an in-batch negative training setting with 7 hard negative passages per query and a batch size of 16 to train t he dense re- trievers. 2 We use AdamW optimizer with a 10 − 5 learning rate, linear scheduling with 10 K warm-up steps, and decay over the rest of the training steps. We train up to 150 K steps. We implement the query and passage encoders with BERT [2]. When applicable, we set the query augmentation size to 40. For the r emaining hyperparameters speciﬁc to each method (e.g., weight w in DR+CL), we use the values initially proposed by the creators of each method. We use the Tevatron toolkit [3] to train the models and the Ranx library [1] to evaluate the r etrieval performance. Finally, we use the typo generators from the TextA ttack toolkit [9] for all the methods we experiment with to augment the training qu eries. 2 The original methods and our proposed counterparts employ t he same number of original, typo-free