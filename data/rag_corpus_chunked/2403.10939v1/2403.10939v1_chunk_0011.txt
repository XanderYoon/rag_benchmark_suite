(ty- poed queries) at once and using multi-positive contrastive loss outp erforms sam- pling a diﬀerent positive at each update and using a single positive cont rastive loss (see Section 2.1). The improvements are held even when compar ing our DR+DL+STM against DR+DL+ST, a model that already uses multiple posi- tives. As seen in Section 2.3, DR+DL+ST uses a contrastive loss with a single positive for the query retrieval dual task (i.e., Lq CE ) while considering multiple positives simultaneously to compute the KL-divergence losses (i.e., Lp KL , Lq KL ). Table 1. Retrieval results for the settings of (i) clean queries (Cle an), and (ii) queries with typos (Typo). Statistical signiﬁcant gains (two-tail ed paired t-test with Bonferroni correction, p < 0.05) obtained from models with multi-positive contrastive l oss (ours) over their original version with standard contrastive loss are indicated by †. Model Multi-positive contrastive loss MS MARCO DL-Typo Clean Typo Clean Typo MRR@10 R@1000 MRR@10 R@1000 nDCG@10 MRR MAP nDCG@10 MRR MAP DR ✗ .331 .953 .140 .698 .677 .850 .555 .264 .395 .180 DR+DL ✗ .332 .953 .140 .698 .679 .826 .557 .269 .411 .186 DR+DLM ✓ .335 .958 .213 † .866† .699 .864 .585 .347 † .452 .259 † DR+CL ✗ .321 .957 .170 .787 .659 .797 .535 .284 .411 .207 DR+CLM ✓ .322 .956 .178 † .811† .652 .847 .539 .290 .447 .215 DR+ST+DL ✗ .334 .951 .259 .893 .681 .868 .567 .412 .543 .315 DR+ST+DLM ✓ .335 .955 .261 .902 † .687 .870 .579 .426 † .583 .342 † At this point, we want to explore how the diﬀerent numbers of positiv es aﬀect our multi-positive approach ( RQ2). To do so, we compare our DR+DL+ST M against DR+DL+ST. In its training, the latter already employs multiple posi- tives simultaneously to compute