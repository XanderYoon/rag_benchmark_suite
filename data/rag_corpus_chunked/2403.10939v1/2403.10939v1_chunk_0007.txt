Q, Q− ). The ﬁnal loss is computed as L = Lp CE +wLq M CE. 2.3 Dense Retriever with Dual Learning and Self-T eaching DR+ST+DL trains a dense retriever with dual learning and self-teaching [13]. Similar to DR+DL, it minimizes the Lp CE and Lq CE for the main task of pas- sage retrieval and the subtask of query retrieval, respectively. The additional self-teaching mechanism distills knowledge from a typo-free query q into its ty- poed variants Q′ = {q′ i}K i=1 by forcing the model to match score distributions of misspelled queries to the score distribution of the typo-free query for both the passage retrieval and query retrieval task. This is achieved by min imizing the KL- divergence losses: (i) Lp KL = 1 K ∑K k=1 LKL (s′k p , sp), where {s′1 p , s′2 p , . . . , s′K p } and sp is the score distribution in a passage-to-queries direction (passag e retrieval) for the typoed queries and the typo-free query, respectively an d (ii) Lq KL = 1 K ∑K k=1 LKL (s′k q , sq), where {s′1 q , s′2 q , . . . , s′K q } and sq is the score distribution in a query-to-passages direction (query retrieval) for the typoe d queries and the typo-free query, respectively. The ﬁnal loss is computed as the w eighted summa- tion of the four losses, L = (1 −β)((1−γ)Lp CE +γLq CE )+ β((1−σ)Lp KL +σLq KL ). DR+ST+DLM is our multi-positive variant of DR+ST+DL. Even though DR+ST+DL simultaneously uses all the available typo variations of a qu ery in order to calculate the KL divergence losses for the prime passage retrieval Typo-Robust Dense Retrieval via Multi-positive Contrasti ve Learning 5 task and the dual query retrieval, it uses