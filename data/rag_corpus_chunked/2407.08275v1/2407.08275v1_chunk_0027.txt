context. Our analysis demonstrates that although models tend to be most similar to models from their own family, inter-family clusters exist. The most prominent of these clusters is formed by the models bge- large-en-v1.5, UAE-Large-V1 and mxbai-embed-large-v1, which demonstrate high similarity even for retrieval at low ğ‘˜. Never- theless, the high variance of retrieval similarity of the remaining clusters for small ğ‘˜ means that while the identified clusters might provide some measure of orientation when choosing an embedding model, the choice still remains a non-trivial task. Identifying suit- able alternatives to proprietary models is likewise not as simple. While we were able to determine SFR-Embedding-Mistral as the model being most similar to OpenAIâ€™s embedding models, Jaccard similarity at top-10 for larger datasets shows a low overlap in re- trieved text chunks. Furthermore, for Cohereâ€™s embedding model, we were unable to find a single most similar model, as this model varied across datasets for small ğ‘˜ values. 7 CONCLUSION In this paper we evaluated the similarity of embedding models on different datasets. Given the large number of available models, iden- tifying clusters or families of models with similar embeddings can simplify the model selection process. While previous work on LLM similarity exists, to the best of the authorsâ€™ knowledge, it so far lacks a clear focus on embedding models specifically in the context of RAG. We therefore analyzed the similarity of embeddings gener- ated by 19 different models using CKA for pairwise comparison as well as Jaccard and rank similarity to compare retrieval behavior at top-ğ‘˜ across five datasets. Comparing embeddings with CKA generally showed intra- and inter-family clusters across datasets. These clusters also appeared when evaluating top-ğ‘˜ retrieval simi- larity with large ğ‘˜ values. However, scores for low ğ‘˜ values, which would commonly be chosen in RAG systems, show high