0.48 0.44 0.46 0.47 0.47 0.44 1.00 0.61 0.54 0.51 0.49 0.39 0.51 0.39 0.43 0.43 0.47 0.45 0.37 0.43 0.45 0.40 0.49 0.51 0.42 0.61 1.00 0.55 0.53 0.61 0.50 0.56 0.47 0.46 0.54 0.53 0.54 0.48 0.53 0.48 0.44 0.51 0.53 0.50 0.54 0.55 1.00 0.66 0.55 0.46 0.53 0.44 0.45 0.53 0.54 0.52 0.49 0.50 0.47 0.44 0.50 0.53 0.47 0.51 0.53 0.66 1.00 0.4 0.5 0.6 0.7 0.8 0.9 1.0 (b) Figure 5: Jaccard similarity for the top-10 retrieved text chunks averaged over 25 queries on SciFact (a) and ArguAna (b). The UAE and mxbai models show high levels of similarity along with bge-large. The remaining models tend to show the highest similarity within their own family with the exception of the bge/gte inter-family cluster. low. As RAG systems usually operate on millions of embeddings, our datasets are comparatively small. Therefore, should a general trend of larger datasets leading to lower retrieval similarity exist, text chunks retrieved by different models in a regular use case might be nearly distinct for small ğ‘˜. Overall, our results suggest that even though embeddings seem rather similar when compared directly, retrieval performance can still vary substantially, is most unsta- ble for ğ‘˜ values that are commonly used in RAG systems and also dataset-dependent. Retrieved text chunks at small ğ‘˜ show the least overlap, often leading to high differences in the data that would be presented to an LLM as additional context. Our analysis demonstrates that although models tend to be most similar to models from their own family, inter-family clusters exist. The most prominent of these clusters is formed by the models bge- large-en-v1.5, UAE-Large-V1 and mxbai-embed-large-v1, which demonstrate high similarity even for retrieval at low ğ‘˜. Never- theless, the high variance of retrieval similarity of the remaining clusters for