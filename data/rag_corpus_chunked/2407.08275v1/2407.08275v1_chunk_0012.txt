dimensions, model size and memory usage. Finally, we include SFR-Embedding-Mistral (Mistral) [24] as the best-performing model on the leaderboard at the time of our experiments. A detailed overview of all selected models can be seen in Table 2. To compare embedding similarity across models and datasets, we employ different strategies depending on the similarity measure. We apply CKA by retrieving all embeddings created by a model, matching embeddings using their document and text chunk ids and then computing their similarity for each of the five datasets. For Jaccard and rank similarity, we use sklearnâ€™s NearestNeighbor class [32] to determine the the top-ğ‘˜ retrieval results. We compute Jaccard and rank scores per dataset, averaging over 25 queries. For the NFCorpus dataset, we calculate retrieval similarity for all possible ğ‘˜, i.e. using all embeddings generated for the dataset. As calculating similarity for each possible ğ‘˜ is computationally expensive, we did not repeat this for the remaining datasets and chose a smaller ğ‘˜ value instead. Furthermore, as only a limited number of results are to be provided as context to the generative model, analyzing retrieval similarity at low ğ‘˜ values for e.g. top-10 is of most interest. As we are interested in identifying clusters of similar models, we also perform a hierarchical clustering on heatmap values using Seaborn [38]. The following section describes the results of our evaluation for the different measures. 0 1000 2000 3000 4000 5000 6000 0.1 0.2 0.3 0.4 0.5 0.6 0 10 20 30 40 500.0 0.2 0.4 0.6 gte-large_vs_SFR-Embedding-Mistral gte-large_vs_UAE-Large-V1 gte-large_vs_bge-base-en-v1.5 gte-large_vs_bge-large-en-v1.5 gte-large_vs_bge-small-en-v1.5 gte-large_vs_e5-base-v2 gte-large_vs_e5-large-v2 gte-large_vs_e5-small-v2 gte-large_vs_embed-english-v3.0 gte-large_vs_gte-base gte-large_vs_gte-small gte-large_vs_gtr-t5-base gte-large_vs_gtr-t5-large gte-large_vs_mxbai-embed-large-v1 gte-large_vs_sentence-t5-base gte-large_vs_sentence-t5-large gte-large_vs_text-embedding-3-large gte-large_vs_text-embedding-3-small Figure 2: Rank similarity over all ğ‘˜ on NFCorpus, comparing gte-large to all other models. Scores are highest and vary most for small ğ‘˜, but then drop quickly before stabilizing for