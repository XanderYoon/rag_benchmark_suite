ilar the retrieved results are. Our evaluation focuses on several prominent model families, to analyze similarities both within and across them. We also compare proprietary models (such as those by arXiv:2407.08275v1 [cs.IR] 11 Jul 2024 Caspari et al. OpenAI or Cohere) to open-sourced ones in order to identify the most similar alternatives. Our experiments are carried out on five popular benchmark datasets to determine if similarities between models are influenced by the choice of data. Our code is available at https://github.com/casparil/embedding-model-similarity. 2 RELATED WORK Studies evaluating similarities of neural networks fall into two main categories: the first involves comparing activations of dif- ferent models generated at any pair of layers for a specific input (representational similarity), while the second compares the model outputs (functional similarity). Raghu et al. [33] and Morcos et al. [26] propose measures building on Canonical Correlation Analysis (CCA) [11], a statistical technique used to find the linear relation- ship between two sets of variables by maximizing their correlation. Such comparisons using CCA or variants thereof can be found in several works [6], [42], [4]. Beyond CCA-based measures, other works have also explored computing correlations [21] and the mu- tual information [20] between neurons across networks. Kornblith et al. [16] propose Centered Kernel Alignment (CKA), which they show improves over several similarity measures in identifying corre- sponding layers of identical networks with different initializations. A diverse range of functional similarity evaluations have also been explored in the literature. A few examples include model-stitching [2], [18], [1], disagreement measures between output classes [25], [41], and quantifying the similarity between the class-wise out- put probabilities [22]. We would point the reader to the survey by Klabunde et al. [15] for a detailed overview of representational and functional similarity measures. Recently, a few works have also focused on specifically evaluat-