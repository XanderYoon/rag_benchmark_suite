important to note that this field is rapidly evolving, and ongoing research is necessary to continuously improve these systems and address emerging challenges. 9 4 Methods for trustworthy use of LLMs to health documents 4.1 Strategies for improving the accuracy of the LLM -generated answer Finetuning, prompt engineering and RAG, are three distinct approaches that can be employed to improv e the performance of language models in terms of accuracy, each with its own characteristics and use cases. Finetuning is the process of further training a pre-trained model on a specific dataset or task. This approach adapts the model's weights to perform better on the target task and can significantly improve performance for specialized applications, such as the ones in the health domain, where a general L LM might not have already encountered the relevant vocabulary before. This is however a computationally intensive operation , especially for LMs of large size. Prompt engineering is a technique that focuses on crafting effective prompts to guide model behavior. Unlike finetuning, prompt engineering does not modify the model itself but instead optimizes the input to achieve desired outputs. This method can be used to improve performance without additional training and relies on understanding model behavior and crafting precise instructions. In LLMs, prompt engineering allows the use of In Context Learning (ICL) which, as discussed in Section 3.1, is an emerging property of models with a large number of parameters that enables them to generalize and apply learned knowledge to new tasks without the need for explicit retraining or fine -tuning. By designing prompts in specific ways, users can guide the model to perform tasks in a zero-shot or few-shot manner, leveraging the model's ability to infer the desired output based on the context provided within the prompt itself. [27]. Retrieval Augmented Generatio n