an embedding model and stored in a vector database. This step is crucial for enabling efficient similarity searches in the subsequent retrieval phase. 4.2.1 Indexing The most common chunking strategy is to split the document into chunks on a fixed number of tokens (e.g., 100, 256, 512) [34]. Larger chunks can capture more context, but they also generate more noise, requiring longer processing time and higher costs. While smaller chunks 11 may not fully convey the necessary context, they introduce less noise. However, chunk ing might lead to truncation within sentences, and uncertainty on the best granularity of the embedding. Some strategie s seek to optimize that with recursive splits and sliding window methods, enabling layered retrieval and merging globally related information across multiple retrieval processes [35]. Nevertheless, these approaches still cannot strike a balance between semantic completeness and context len gth. Therefore, methods like Small2Big have been proposed, where sentences (small) are used as the retrieval unit, and the preceding and following sentences are provided as (big) context to LLMs. Additional methods are establishing a hierarchical index or using knowledge graphs [36]. 4.2.2 Embeddings Text embeddings are dense vector representations of text data. In this context, words and documents with similar meanings are represented by similar vectors in a high -dimensional vector space [37] [38]. Th us, embeddings encode semantic information and serve as a foundation for various downstream applications, including retrieval, reranking, classification, clustering, and semantic textual similarity tasks. Additionally, the embedding-based retriever plays a crucial role in retrieval -augmented generation [24], which allows LLMs to access the most up-to-date external or proprietary knowledge without modifying the model parameters [39], [40], [41], [42]. Word2Vec [43] was the first neural network -based approach to predict surrounding words for a target word in each context. It learns to encode word