with respect to the results presented in this report. 2 1.2 Acknowledgements We would like to thank Mr. Riccardo Medinas and Prof. Diego Reforgiato Recupero from the University of Cagliari for providing the implementation and results of the analysis of the ColBERT pipeline. We are also grateful to colleagues from the GPT@JRC team for providing an infrastructure to run Large Language Models experiments at scale in a safe environm ent. We would also like to thank colleagues from SANTE.R .4 and RTD.G.6 for the fruitful discussions and all colleagues from JRC.F who tested the system and provided useful feedback. 3 2 Introduction and related work Over recent years, there has been an un precedented surge in the volume of scientific publications and policy reports across various fields. Just between 2014 and 2024, 10,036,232 documents and 2,027,823 preprints have been published in S copus database in the health domain.1 This exponential growth [1], while bringing an enormous richness of accessible knowledge, also poses challenges for researchers, policymakers, and practitioners in view of keeping updated on contemporary research outcomes. The sheer volume of information makes it increasingly difficult to stay at the forefront of the latest developments, identify emerging trends, and pinpoint gaps in existing research. Traditional methods of literature review, reliant on manual curation and analysis, are no longer suffici ent to manage the overflow of information. Large language models (LLMs) have emerged as a powerful tool in natural language processing, with potential applications across numerous domains [2]. In the healthcare sector, these models offer promising opportunities to process, analyze, and generate insights from vast amounts of documentation [3]. LLMs, with their ability to understand context, extract relevant information, and generate human -like text, present a novel approach to addressing these challenges of information overload, but come with their own set