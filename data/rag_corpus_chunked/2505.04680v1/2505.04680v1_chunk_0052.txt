infection by Staphylococcus pseudintermedius in dogs in Finland. Comments: The system does not see the figure and is trying to reply from the text but the information is not in the text. Besides, very surprisingly, it mentions an INTERRUPT and asks from itself a question from a USER, who is not me, and gives a reply form the system, obviously inspired form the above question on E. Coli (hallucination). Score: 0 A similar analysis to the VHT holds for the bacteriophages. The system provides a good answer for concept questions. One should not expect an exhaustive answer from all pipelines, especially in case of listing items. It can give a good overview of a topic with structured and well formulated answer. It looks in the several documents of the collection to find related information (as shown by the paragraphs/chunks). Obviously, prompting is crucial to frame the answer, using simple sentences and precise wording. Description of the issues identified during usability testing:  Sometimes the complete answer requires a few minutes.  It does not always find numerical values, the circumstances that make the system miss numerical values are not clear.  It might confuse notions such as ‘Europe’ and ‘EU’ which requires some ‘human knowledge’ or interpretation.  Long answers might end in the middle of a sentence as if the number of characters was too long.  It provides too many references that should not be provided. 5.3 Quantitative analysis We show in Figure 8 the average scores (± standard error) assigned by human annotators to the system’s reply. As shown, the pipeline obtained its best results (judged on a scale [0,5]) on the Horizon Research collection (HR - 4.4), where it showed the lowest variability (± 0.24). The Bacteriophages (AMR - 3.4) and Virtual Human Twin (VHT -