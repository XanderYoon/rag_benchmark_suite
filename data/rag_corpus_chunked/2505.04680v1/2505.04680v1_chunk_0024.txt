match a query using scalable vector-similarity operators. ColBERTv2 [53] is a follow-up to ColBERT achieving 6-10x storage reduction while maintaining performance. It uses compression techniques and denoised supervision. 4.3.2 System architecture The system is structured as in Figure 3, in a hybrid cloud architecture, with part of the system running on premises in the JRC datacentre, and part in Azure cloud. The former include the landing page of the DigLife project, along with the frontend of our RAG-Ev reference pipeline. The latter is the backend system exposing the APIs used to manage the knowledge bases and interact with them, leveraging large language model and dedicated pipelines. 15 The frontend has been developed in NextJS16 and is deployed on internal JRC Openshift, under EULogin17, and takes care of user authentication and communication with the backend. The backend system is deployed on Azure Managed Kubernetes instances 18. This system allows CRUD (Create, Read, Update, and Delete) operations on collections of documents, their embeddings in vector DBs such as Milvus19 and to control the various retrieval pipelines. A set of APIs is provided to control all functionalities via python scripts. The backend system also manages communications with the JRCâ€™s Big Data Platform (BDAP)20 for model training and finetuning, and with GPT@JRC for using large language models in a safe environment. Figure 3 - Main architecture of the system. We use a hybrid cloud approach, where the model training is done on premises on BDAP servers. Most of the experiments use the LLMs served by the GPT@JRC infrastructure. 4.4 Datasets for benchmarking and usability checks (RAGEv - Bench) To systematically evaluate our sys tem and its configurations, we used a two -fold approach. First, we ran an automatic evaluation based on public datasets and on classical automatic metrics. This part of the evaluation, called