classical models locally interpretable machine learning techniques such as LIME11 and SHAP12 can be utilized to provide insights into model decision- making processes [21], [22], [23] , these techniques do not work well for LLMs. Developing domain-specific explanation methods such as [12], using in -domain knowledge augmentation, and combining LLMs with rule -based sy stems can further enhance transparency. Additionally, providing confidence scores and uncertainty estimates can support healthcare professionals to better understand and trust the model outputs. Forgetfulness and limited factuality are significant concerns when using LLMs for healthcare document processing. Implementing retrieval -augmented generation techniques can help addressing these issues by allowing the models to access and incorporate up -to-date 11 https://github.com/marcotcr/lime 12 https://shap.readthedocs.io/en/latest/ 8 information [24]. Regularly updating model knowledge bases and using fact -checking mechanisms are also crucial. Furthermore, c ombining LLMs with structured knowledge graphs can enhance their ability to provide accurate and current information. Toxicity in LLM outputs can be particularly problematic in healthcare contexts. To mitigate this issue, models should be fine-tuned on curated, non-toxic datasets specific to healthcare, or undergo unlearning [25] of the unwanted content. Additional strategies could be implementing content filtering and moderation systems, along with toxicity detection algorithms, which can help preventing the generation of harmful or inappropriate content [26]. We believe that - by addressing the abovementioned critical aspects the use of LLMs in healthcare document processing can be made safer, more reliable and effective. However, it is important to note that this field is rapidly evolving, and ongoing research is necessary to continuously improve these systems and address emerging challenges. 9 4 Methods for trustworthy use of LLMs to health documents 4.1 Strategies for improving the accuracy of the LLM -generated answer Finetuning, prompt engineering and RAG, are three distinct approaches that can be employed to improv