th e 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), A. Moschitti, B. Pang, and W. Daelemans, Eds., Doha, Qatar: Association for Computational Linguistics, Oct. 2014, pp. 1532 –1543. doi: 10.3115/v1/D14-1162. [45] N. Reimers and I. Gurevych, “Sentence -BERT: Sentence Embeddings using Siamese BERT -Networks,” Aug. 2019, [Online]. Available: http://arxiv.org/abs/1908.10084 [46] “[2401.00368] Improving Text Embeddings with Large Language Models.” Accessed: Jul. 09, 2024. [Online]. Available: https://arxiv.org/abs/2401.00368 [47] A. Q. Jiang et al., “Mistral 7B,” Oct. 10, 2023, arXiv: arXiv:2310.06825. Accessed: Oct. 25, 2023. [Online]. Available: http://arxiv.org/abs/2310.06825 [48] N. Muennighoff, N. Tazi, L. Magne, and N. Reimers, “MTEB: Massive Text Embedding Benchmark,” Mar. 19, 2023, arXiv: arXiv:2210.07316. doi: 10.48550/arXiv.2210.07316. [49] P. BehnamGhader, V. Adlakha, M. Mosbach, D. Bahdanau, N. Chapados, and S. Reddy, “LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders,” Apr. 08, 2024, arXiv: arXiv:2404.05961. doi: 10.48550/arXiv.2404.05961. [50] “SFR-Embedding-Mistral: Enhance Text Retrieval with Transfer Learning,” Salesforce AI. Accessed: Jul. 09, 2024. [Online]. Available: https://blog.salesforceairesearch.com/sfr-embedded-mistral/ [51] C. Lee et al., “NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models,” May 27, 2024, arXiv: arXiv:2405.17428. doi: 10.48550/arXiv.2405.17428. [52] O. Khattab and M. Zaharia, “ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT,” Jun. 04, 2020, arXiv: arXiv:2004.12832. doi: 10.48550/arXiv.2004.12832. [53] K. Santhanam, O. Khattab, J. Saad-Falcon, C. Potts, and M. Zaharia, “ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction,” Jul. 10, 2022, arXiv: arXiv:2112.01488. doi: 10.48550/arXiv.2112.01488. 39 [54] T. Zhang, V. Kishore, F. Wu, K. Q. Weinberger, and Y. Artzi, “BERTScore: Evaluating Text Generation with BERT,” Feb. 24, 2020, arXiv: arXiv:1904.09675. doi: 10.48550/arXiv.1904.09675. [55] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking Large Language Models in Retrieval-Augmented Generation,” Dec. 20, 2023, arXiv: arXiv:2309.01431. Accessed: May 21, 2024. [Online]. Available: http://arxiv.org/abs/2309.01431 [56] P. Bajaj et al., “MS MARCO: A Human Generated MAchine Reading