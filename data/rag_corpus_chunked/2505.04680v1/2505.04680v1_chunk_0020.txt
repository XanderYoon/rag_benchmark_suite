struggles with precision and recall, leading to the selection of misaligned or irrelevant chunks, and the missing of crucial information. 4.2.4 Generation The posed query and selected documents are synthesized into a coherent prompt to which a large language model is tasked with formulating a response. The modelâ€™s approach to answering may vary depending on task -specific criteria, allowing it to either draw upon its inherent parametric knowledge, or restrict its responses to the information contained within the provided documents. In cases of ongoing dialogues, any existing conversational history can be integrated into the prompt, enabling the model to engage in multi -turn dialogue interactions effectively. 13 In generating responses, the model may face the issue of hallucination, where it produces content not supported by the retrieved context. This phase can also suffer from irrelevance, toxicity, or bias in the outputs, detracting from the quality and reliability of the responses. The process may also encounter redundancy when similar information is retrieved from multiple sources, leading to repetitive responses. Determining the significance and relevance of various passages and ensuring stylisti c and tonal consistency add further complexity , as it will become clear from the next section. 4.3 Reference implementation (RAGEv) As we discussed in the previous section, traditional RAG faces two important challenges. The first one is in the retrieval phase, where it often struggles with precision and recall, leading to the selection of misaligned or irrelevant chunks, and the missing of crucial information. The second one is the generation phase, where it might produce content which is not supported by the retrieved contexts, or that also be irrelevant, toxic or redundant. A reference implementation of several pipelines that use LLMs to analyse scientific publications and policy documents within the health domain was preparedperformed, as illustrated in the following. Such