memory management can result in memory leaks, gradually consuming system resources. Monitor memory usage and free up resources after each loop to avoid system slowdowns. Model re-initialization Reloading or re-initializing models unnec- essarily can slow down your system. Reuse initialized models when- ever possible to improve system efficiency and reduce overhead. OLlama (Llama 3.1) is a local language model that runs entirely on the user’s machine, ensuring data privacy and faster response times depending on the system’s hardware. The accuracy of its outputs depends on the qual- 29 ity of its training data, and it can be further improved by fine-tuning with domain-specific knowledge. Fine-tuning involves retraining the model with specialized datasets, allowing it to internalize specific organizational knowl- edge for more precise and relevant responses. This process keeps the model updated and tailored to the user’s needs while maintaining privacy. 5 Preliminary Evaluation of the Guide 5.1 Feedback Process Overview This experience report underwent an informal evaluation process aimed at gath- ering feedback for the section: Using OpenAI’s Assistant API : GPT Se- ries.[4.2.1] Although the feedback session was not formally structured, it still provided valuable insights that helped validate the ideas presented in this sec- tion and refine the guide based on it. The feedback gathered from participants demonstrates that the workshop was successful. A majority of attendees were able to follow the provided guide and successfully implemented their RAG mod- els by the end of the session. 5.2 Participants (a) Job Titles of Participants (b) Primary Area of Expertise Fig. 3: Demographic Information from Participants We collected feedback from a small but diverse group of participants during a workshop. A total of 8 individuals completed a demographics form, which pro- vided us with an understanding of the participants’ backgrounds and technical expertise. The group consisted of individuals