better understand the 31 Fig. 6: Most Valuable Aspects of the Workshop. implementation of RAG systems. Additionally, several participants mentioned the discussions with peers and instructors as a key takeaway. 5.4 Incorporating Feedback to Improve the Guide The evaluation also revealed opportunities for improvement of guide, particularly in enhancing the clarity of instructions and streamlining the implementation process. The most common issues raised were technical, most of them related to copying from PDF file generating errors as number of lines. In addition to that, we implemented error handling to throw meaningful errors to the user in the code snippets provided to seamlessly run the code. Fig. 7: Feedback on challenges faced during the implementation of the guide Several participants also provided suggestions for future improvement. One notable suggestion was to include a warning regarding sensitive data in OpenAI vector store. The detailed comment are shown in Fig[8]. In conclusion, the evaluation process proved valuable in validating the ap- proach outlined in the guide. By testing it in a hands on workshop environment, and in an open discussion sessions of how the developed RAG models improved 32 Fig. 8: Comments and suggestions for improving the guide trustworthiness in specific scenarios, we were able to collect meaningful feed- back and directly address areas of difficulty faced by practitioners. The feedback driven improvements have not only made the guide more user friendly but also demonstrated the importance of continuous iteration based on real world use. 6 Discussion Practitioners in fields like healthcare, legal analysis, and customer support, often struggle with static models that rely on outdated or limited knowledge. RAG models provide practical solutions with pulling in real time data from provided sources. The ability to explain and trace how RAG models reach their answers also builds trust where accountability and decision making