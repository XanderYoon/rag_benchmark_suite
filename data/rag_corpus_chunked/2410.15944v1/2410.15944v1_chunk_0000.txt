Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report Ayman Asad Khan Tampere University ayman.khan@tuni.fi Md Toufique Hasan Tampere University mdtoufique.hasan@tuni.fi Kai Kristian Kemell Tampere University kai-kristian.kemell@tuni.fi Jussi Rasku Tampere University jussi.rasku@tuni.fi Pekka Abrahamsson Tampere University pekka.abrahamsson@tuni.fi Abstract. This paper presents an experience report on the develop- ment of Retrieval Augmented Generation (RAG) systems using PDF documents as the primary data source. The RAG architecture combines generative capabilities of Large Language Models (LLMs) with the preci- sion of information retrieval. This approach has the potential to redefine how we interact with and augment both structured and unstructured knowledge in generative models to enhance transparency, accuracy and contextuality of responses. The paper details the end-to-end pipeline, from data collection, preprocessing, to retrieval indexing and response generation, highlighting technical challenges and practical solutions. We aim to offer insights to researchers and practitioners developing similar systems using two distinct approaches: OpenAI’s Assistant API with GPT Series and Llama’s open-source models. The practical implications of this research lie in enhancing the reliability of generative AI systems in various sectors where domain specific knowledge and real time infor- mation retrieval is important. The Python code used in this work is also available at: GitHub. Keywords: Retrieval Augmented Generation (RAG), Large Language Models (LLMs), Generative AI in Software Development, Transparent AI. 1 Introduction Large language models (LLMs) excel at generating human like responses, but base AI models can’t keep up with the constantly evolving information within dynamic sectors. They rely on static training data, leading to outdated or incom- plete answers. Thus they often lack transparency and accuracy in high stakes arXiv:2410.15944v1 [cs.SE] 21 Oct 2024 decision making. Retrieval Augmented Generation (RAG) presents a powerful solution to this problem. RAG systems pull in information from external data sources, like PDFs, databases, or