In this section, we show the overall experimental results and offer in-depth analyses of our method. 5.1 Main Results Table 2 summarizes the primary findings for PersonaRAG across various single-hop question answering datasets. The approach was evaluated against multiple baseline models, including large language models (LLMs) without retrieval-augmented generation (RAG), the conventional RAG model, and self-refined variants, such as utilizing raw retrieved passages (CoT with Passage) or refining passages into notes (CoT with Note). PersonaRAG demonstrated superior performance compared to most of the baseline models, achieving significant improvements over the conventional RAG (i.e., vanillaRAG) of over 10%, particu- larly on the WebQ dataset. It also consistently outperformed the ChatGPT-3.5 model, except on TriviaQA, which we suspect is part of the model’s training dataset. These results suggest PersonaRAG’s capability to guide LLMs in extracting relevant information through active learning techniques. Specifically, the performance of RAG models was assessed using the top 3 and 5 ranked passages. While other RAG models generally benefited from more passages, PersonaRAG maintained consistent performance with either 3 or 5 passages, suggesting that 3 pas- sages were adequate for generating accurate answers. PersonaRAG agents played a crucial role in efficiently extracting the necessary information regarding the user’s information need to achieve these improvements. Furthermore, on the WebQ dataset, PersonaRAG achieved accu- racy scores of 63.46% and 67.50% using Top-3 and Top-5 passages, respectively, surpassing the vanillaRAG model by 25% and 17.36%, and nearly all other baseline models (except for Chain-of-Thought using Top-5, which performed equally). On the NQ dataset, Per- sonaRAG maintained similarly robust performance with scores of 49.02% and 48.78%, outperforming all baselines (except for Chain- of-Thought and Self-Rerank (SR) using Top-5). This pattern was further validated by experiments on other datasets, with results showing that PersonaRAG consistently outperforms conventional RAG models with the capability of