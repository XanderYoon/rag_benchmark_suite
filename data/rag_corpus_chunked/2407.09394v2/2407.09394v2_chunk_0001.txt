advancements, the deployment of RAG systems within broader AI frameworks continues to face significant challenges, particularly in handling noise and irrelevance in retrieved data [8]. A key limitation of existing RAG systems is their inability to adapt outputs to users’ specific informational and contextual needs. Personalized techniques in information retrieval, such as adaptive retrieval based on user interaction data and context-aware strate- gies, are increasingly recognized as essential for enhancing user interaction and satisfaction [30, 31]. These methods aim to refine the retrieval process dynamically, tailoring it more closely to indi- vidual user profiles and situational contexts [1]. Figure 1: Illustrations of Various RAG Models. Vanilla RAG and Chain-of-Thought [39] use passive learning, while Per- sonaRAG involves user-centric knowledge acquisition. arXiv:2407.09394v2 [cs.IR] 15 Jan 2026 , Zerhoudi et al. The integration of agent-based systems with personalized RAG architectures presents a compelling avenue for research. Such sys- tems utilize a multi-agent framework to simulate complex, adaptive interactions tailored to user-specific requirements [35]. By embed- ding intelligent, user-oriented agents within the RAG framework, these systems can evolve into more sophisticated tools that not only retrieve relevant information but also align it closely with the user’s specific preferences and contexts in real-time. Importantly, the personalization strategy employed in these systems is fully transparent to the user, ensuring that the user is aware of how their information is being used to tailor the results. In this study, we present PersonaRAG, an innovative method- ology that extends traditional RAG frameworks by incorporating user-centric agents into the retrieval process. This approach ad- dresses the previously mentioned limitations by promoting active engagement with retrieved content and utilizing dynamic, real- time user data to continuously refine and personalize interactions. PersonaRAG aims to enhance the precision and relevance of LLM outputs, adapting dynamically to user-specific needs while main- taining