Generation, Neurosym- bolic Retrieval, Knowledge Graphs, Interpretable Retrieval, Graph-based Ranking, Procedural Reasoning, Mental Health Assessment. INTRODUCTION As machines learn, they may develop unforeseen strategies at rates that baffle their programmers— Norbert Wiener (1960) This observation captures a central challenge in contempo- rary AI: the need for symbolic grounding, especially along the procedural grounding dimension, to ensure that machine outputs remain aligned with explicit, auditable reasoning pro- cesses [1]. Although generative AI systems based on large language models (LLMs) now underpin applications in scien- tific discovery, healthcare, cybersecurity, and law, their fluency This work is supported by a UMBC Faculty Startup Award and a gift from NeuralNest LLC. The opinions expressed are those of the authors and do not necessarily reflect the views of UMBC or NeuralNest. masks persistent shortcomings. LLMs routinely hallucinate facts , struggle to access current or specialized knowledge, lack transparent attribution, and operate without structured mecha- nisms for uncertainty detection or domain-specific procedural reasoning. These limitations constrain their reliability in high- stakes decision-making contexts. Retrieval-Augmented Generation (RAG) has emerged as a promising remedy by conditioning generation on retrieved evi- dence. Its canonical retriever–re-ranker–generator pipeline en- ables temporal updates, factual grounding, personalization, and explicit citation, supporting use cases ranging from enterprise knowledge management to clinical support. Yet despite these strengths, RAG systems inherit a profound interpretability (ante-hoc and post-hoc) deficit: each component operates as a neural closed box. Developers cannot determine why particular documents were retrieved or ranked; users cannot verify which passages shaped the model’s answer; and domain specialists cannot confirm adherence to established workflows. Conse- quently, RAG’s nominal transparency by providing sources fails to guarantee trustworthy reasoning. In a clinical-decision-support context, a system might re- trieve and present appropriate clinical guidelines, yet still fail by violating the correct sequence of care. For instance, first, a screening