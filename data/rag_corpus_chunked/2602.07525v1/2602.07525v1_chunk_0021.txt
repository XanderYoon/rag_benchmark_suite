declines. Although the fixed-iteration variant consumes a comparable number of tokens, it consistently lags behind IGMiRAG. The peak coincides with Figure 5, where IGMi- RAG allocates the largest proportion of depth 3 (54.0%) on MuSiQue. This confirms that a fixed iteration budget cannot adapt to the true distribution of reasoning depths. Figure 6 (b) presents that while performance initially im- proves with an expanding context window, the trend flattens. Even at the maximum token budget of 9.6 k+, the ceiling remains below that of IGMiRAG. These results confirm that marginal gains from naively stacking context degrade rapidly. In contrast, IGMiRAG’s complexity-driven window allocation achieves superior accuracy at a lower cost. 6. Conclusion We propose IGMiRAG, a novel RAG framework designed to optimize reasoning depth and retrieval efficiency. By constructing a Hierarchical Heterogeneous Hypergraph to model human-like memory structures and employing an intuition-inspired strategy to guide associative diffusion, IG- MiRAG introduces a “Strategy-Diffusion” paradigm. This paradigm enables in-depth memory mining with adaptive context scaling, achieving superior performance with fewer dynamic tokens. Such a cognitively inspired approach not only enhances retrieval efficiency and effectiveness but also bridges artificial mechanisms with human-like memory pro- 8 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory cessing. Despite the approximate nature of current intuition signals, refining intuition-retrieval alignment holds promise for advancing LLM memory recall and complex reasoning. Impact Statement This paper presents work on Retrieval-Augmented Gen- eration (RAG), aiming to advance the field by improving retrieval efficiency and effectiveness to enhance memory precision and reasoning depth in Large Language Models. While our work may have various potential societal impli- cations, we do not foresee specific concerns that warrant emphasis beyond the general risks associated with large language models and information retrieval systems. References Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I.,