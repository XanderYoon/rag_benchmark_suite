Description of Vertices Name of Vertices KE: Key Entities QI: Query Intentions l: Target Layer m: Matching Score NQ: Rewriten Query Intuitive Anchors Retrieval ... Memory Anchors Retrieval Strategy Paser Preference-Aware Bidirectional DiffusionMemory Context Window In-Depth Memories ... Relevant Chunks ... d: Semantic Depth A B C LLM Intuition Response D E Adaptive Deep MiningHHHG Index Knowledge Memory Extraction Retrieval: Intuition Inspired Two-Stage Retrieval Figure 2.The framework of IGMiRAG. Indexing:A. An LLM-based analyzer extracts multi-granular knowledge memories from each chunk.BOrganizing all knowledge into a hierarchical heterogeneous hypergraph (HHHG) persisted in HyperGraph-DB. The semantic descriptions of all units are embedded and indexed as a global–local dual-focus HNSW index (DF-Index), and a separate BM25 corpus is built from name fields.Retrieval:C. An LLM-based Retrieval-Strategy Parser (RSP) distills strategies from user queries by simulating human intuition response.D. Multi-channel recall, combining BM25 string matching with dual-focus vector retrieval, identifies high-quality seed vertices as intuitive memory anchors.E. Preference-aware bidirectional diffusion traverses the HHHG to mine latent, in-depth memories. These units are then aggregated into a context window, the size of which is dynamically scaled according to query complexity, before being fed to the LLM. Two examples of the indexing and Retrieval process are provided in Appendix B. IL = HNSW(X),X ∈ {De N ,De L,De H}.(5) Global Indexinginserts thesemantic-descriptionvectors of all knowledge into a single HNSW graph IG. This establishes a cross-type global navigation structure, en- abling rapid localization of candidate regions across the entire knowledge space.Local Indexingconstructs separate HNSW subgraphs IL for vectors of each type in {N,L,H} . Searching within these type-homogeneous neighborhoods could provide targeted supplements to the global candidates. 3.3. Query Parsing User queries imply high-level strategic cues that integrate surface semantics with task-specific features (e.g., evalua- tive focus and response difficulty). To exploit these cues, IGMiRAG employs an LLM-based RSP that