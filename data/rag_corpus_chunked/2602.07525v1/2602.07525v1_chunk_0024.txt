of retrieval-augmented generation (rag): Evolution, current landscape and future directions.arXiv preprint arXiv:2410.12837, 2024. Guti´errez, B. J., Shu, Y ., Qi, W., Zhou, S., and Su, Y . From rag to memory: Non-parametric continual learning for large language models.arXiv preprint arXiv:2502.14802, 2025. Haveliwala, T. H. Topic-sensitive pagerank. InProceedings of the 11th international conference on World Wide Web, pp. 517–526, 2002. Ho, X., Nguyen, A.-K. D., Sugawara, S., and Aizawa, A. Constructing a multi-hop qa dataset for compre- hensive evaluation of reasoning steps.arXiv preprint arXiv:2011.01060, 2020. Hu, H., Feng, Y ., Li, R., Xue, R., Hou, X., Tian, Z., Gao, Y ., and Du, S. Cog-rag: Cognitive-inspired dual-hypergraph with theme alignment retrieval-augmented generation. arXiv preprint arXiv:2511.13201, 2025. Huang, H., Huang, Y ., Yang, J., Pan, Z., Chen, Y ., Ma, K., Chen, H., and Cheng, J. Retrieval-augmented gen- eration with hierarchical knowledge.arXiv preprint arXiv:2503.10150, 2025a. 9 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., et al. A survey on hallucination in large language models: Principles, taxon- omy, challenges, and open questions.ACM Transactions on Information Systems, 43(2):1–55, 2025b. Jimenez Gutierrez, B., Shu, Y ., Gu, Y ., Yasunaga, M., and Su, Y . Hipporag: Neurobiologically inspired long-term memory for large language models.Advances in Neural Information Processing Systems, 37:59532–59569, 2024. Jones, N. Ai hallucinations can’t be stopped—but these techniques can limit their damage.Nature, 637(8047): 778–780, 2025. Labatut, V . and Bost, X. Extraction and analysis of fictional character networks: A survey.ACM Computing Surveys (CSUR), 52(5):1–40, 2019. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., K¨uttler, H., Lewis, M., Yih, W.-t., Rockt¨aschel, T., et al. Retrieval-augmented generation for knowledge- intensive nlp tasks.Advances in neural information pro- cessing systems,