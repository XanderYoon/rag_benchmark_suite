effectively balances retri eval efﬁciency with task performance. The Degree Matrix (Jaccard) method also showed promising results, particularly in redu cing re- trieval costs while maintaining reasonable performance. C onversely, methods such as Semantic Sets and FLARE-Instruct underperformed, highlighting the need for more reliable un certainty es- timators. Although some black-box uncertainty detection methods req uire multiple runs of generation, which can be costly, always retrieving may be preferable in RAG app lications where lightweight retrieval methods like BM25 sufﬁce. This is also evident from the resul ts on the larger set. Besides, we feel that uncertainty detection might become mo re mainstream as the propensity for hallucination in LLMs increases, and as end applications de mand more conﬁdence and interpretabil- ity Dhole et al. (2024) in their outputs making uncertainty d etection a necessity. Our work focuses on exploiting uncertainty detection for RAG, especially wh ere retrieval can be expensive like the us- age of heavy and composite retrieval systems employing nume rous components like reformulation, dense retrieval Santhanam et al. (2021), reranking, etc. 8 E THICAL CONSIDERATIONS When evaluating large language models (LLMs), it is essenti al to adopt a sociotechnical perspec- tive Dhole (2023), acknowledging that their outputs are inﬂ uenced by both social contexts and technical design choices. Proper safeguards should be in pl ace to mitigate biases and prevent the 5 1st workshop of “Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI” at ICLR’25 generation of harmful or toxic content. Furthermore, the un certainty detection approaches we em- ployed rely on estimations derived from various neural netw ork computations, which are inherently shaped by the data on which the models are trained. Consequen tly, it is critical to thoroughly test uncertainty detection methods to ensure they meet the requi rements