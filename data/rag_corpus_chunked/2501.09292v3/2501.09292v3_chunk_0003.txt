with dynamic retrieval through uncertainty detection • We perform an exhaustive analysis of various conditions fr om the “uncertainty quantiﬁca- tion” literature to gauge the best strategy to dynamically r etrieve during generation • Based on the results, we present insights for future resear ch Our insights are useful to gauge whether uncertainty detect ion methods can help improve the efﬁ- ciency of RAG. 2 R ELATED WORK Here, we summarise some of the related work on uncertainty qu antiﬁcation and some active RAG efforts. There has been a lot of recent work on uncertainty quantiﬁcat ion of white box and black box NLG models. Lin et al. (2023) showed that along with their genera tions, GPT-3 can output a verbal- ized form of the uncertainty, viz. “high conﬁdence” or “85% c onﬁdence”. Kadavath et al. (2022) show that models can be made to sample answers and then made to self-evaluate the probability of P(True). Kuhn et al. (2023) recently proposed to compute the semantic entropy by considering the equivalence relationships amongst generated responses. Wang et al. (2024) proposed Self-DC that tackled compositio nal questions via iterative divide-and- conquer based on LLM certainty. Y ao et al. (2024) propose uti lising the model’s internal states to estimate uncertainty and deciding whether to retrieve or no t. We now describe the tasks and datasets used in our analysis along with the UD approaches employed. 3 T ASKS AND DATASETS We conduct experiments on the 2WikiMultihopQA dataset Ho et al. (2020), a multi-hop open do- main question answering (QA) dataset that tests the reasoni ng and inference skills of question- answering models. Questions in this dataset generally requ ire two steps of reasoning to deduce the ﬁnal answer, and the information for each step of reasoni ng can be obtained through referencing