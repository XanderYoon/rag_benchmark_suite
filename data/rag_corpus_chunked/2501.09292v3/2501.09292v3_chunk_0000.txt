arXiv:2501.09292v3 [cs.CL] 18 Mar 2025 1st workshop of “Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI” at ICLR’25 TO RETRIEVE OR NOT TO RETRIEVE ? U NCERTAINTY DETECTION FOR DYNAMIC RETRIEVAL AUGMENTED GENERATION Kaustubh D. Dhole Department of Computer Science Emory University Atlanta, GA 30307, USA kdhole@emory.edu ABSTRACT Retrieval-Augmented Generation equips large language mod els with the capabil- ity to retrieve external knowledge, thereby mitigating hallucinations by incorporat- ing information beyond the model’s intrinsic abilities. Ho wever, most prior works have focused on invoking retrieval deterministically, whi ch makes it unsuitable for tasks such as long-form question answering. Instead, dy namically performing retrieval by invoking it only when the underlying LLM lacks t he required knowl- edge can be more efﬁcient. In this context, we delve deeper in to the question, “To Retrieve or Not to Retrieve?” by exploring multiple uncerta inty detection meth- ods. We evaluate these methods for the task of long-form ques tion answering, employing dynamic retrieval, and present our comparisons. Our ﬁndings suggest that uncertainty detection metrics, such as Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval calls by almost half, with only a slight reduction in question-answering accuracy. 1 I NTRODUCTION Recently, Large Language Models (LLMs) like ChatGPT OpenAI (2023), Gemini Team et al. (2023), and others are showing impressive strides in tasks a cross numerous bench- marks Srivastava et al. (2023). This success has been largel y owed to their exposure to massive training data and successive ﬁne-tuning of instruction dat asets. To increase the helpfulness and decrease the harmfulness of the models, they are being furth er ﬁne-tuned over preference collec- tions Bai et al. (2022); Ouyang et al. (2022); Rafailov et al. (2024). Further, Retrieval Augmented Generation (RAG) Lewis et al. (2020); Dhole (2024a);