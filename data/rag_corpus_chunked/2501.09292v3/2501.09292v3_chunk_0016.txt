language models. Transactions on Machine Learning Research , 2023. Gemini Team, Rohan Anil, Sebastian Borgeaud, Y onghui Wu, Je an-Baptiste Alayrac, Jiahui Y u, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et a l. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805 , 2023. Hongru Wang, Boyang Xue, Baohang Zhou, Tianhua Zhang, Cunxi ang Wang, Huimin Wang, Guan- hua Chen, and Kam-fai Wong. Self-dc: When to reason and when t o act? self divide-and-conquer for compositional unknown questions. arXiv preprint arXiv:2402.13514 , 2024. Yile Wang, Peng Li, Maosong Sun, and Y ang Liu. Self-knowledg e guided retrieval augmentation for large language models. In Houda Bouamor, Juan Pino, and K alika Bali (eds.), Findings of the Association for Computational Linguistics: EMNLP 2023 , pp. 10303–10315, Singapore, Decem- ber 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.ﬁndings-emnlp.691. URL https://aclanthology.org/2023.findings-emnlp.691. 7 1st workshop of “Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI” at ICLR’25 Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824–24837, 2022. Zijun Y ao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. Seakr: Self-aware knowledge retrieval for adaptive ret rieval augmented generation. arXiv preprint arXiv:2406.19215, 2024. 8