Pass Rate of ToolLlama Pass Rate of ToolLlama Pass Rate of ToolLlama ToolBench-G1 ToolBench-G2 ToolBench-G3 oracle (62.00) oracle (64.20) oracle (67.50) oracle (53.60) oracle (50.80) oracle (49.10) oracle performance NDCG@10 NDCG@10 NDCG@10 Figure 6: The horizontal axis indicates the retrieval performance of IR models, both before and after training. The vertical axis corresponds to the end-to-end pass rate of tool-use LLMs using the tools retrieved by these IR models. improve their task-solving performance. 7.2 Towards better retrieval The analysis in § 6.2 highlights the advantage of instruction-tuning in improving tool retrieval. How- ever, to the best of our knowledge, there is no large- scale instructional IR dataset for tool retrieval tasks. We propose the TOOL RET-train to fill this gap. Large-scale training data We extend the data collection process from TOOL RET to include the training sets of three mainstream tool-use datasets: ToolACE (Liu et al., 2024a), ToolBench (Qin et al., 2023) and APIGen (Liu et al., 2024b). Ultimately, we collect over 200k training instances, each com- prising a query q and a set of target tools T . We also pair each query q with an instruction I using our target-aware strategy (See Appendix D). Learning objective To train a IR model (denoted as θ), we first use it to retrieved top- K negative tools, denoted as bT = {ˆtj | j ∈ [K] , ˆtj /∈ T } . The model θ is then optimized by maximizing the log-likelihood of the target tools. The loss function L is formulated as: − 1 |T | X ti∈T log esim(I⊕q,ti) esim(I⊕q,ti) + P ˆtj ∈ bT esim(I⊕q,ˆtj ) . The I ⊕ q indicates concatenation of instruction and query with a special token. During the training, we set the K to 10 and the learning rate to 5e-5. Improvement from