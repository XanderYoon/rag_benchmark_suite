significantly in tool retrieval tasks. A key factor contributing to this performance degradation is the lack of a large-scale training dataset specifically tailored for tool retrieval. To address this gap, we introduce TOOL RET-train, a diverse training dataset comprising more than 200k tool retrieval tasks. Each example in TOOL RET-train consists of an input query, an instruction generated using our target-aware strategy, the corresponding target tools, and a set of Model TOOLRET-Web T OOLRET-Code T OOLRET-Customized Average N@10 P@10 R@10 C@10 N@10 P@10 R@10 C@10 N@10 P@10 R@10 C@10 N@10 C@10 Sparse and dense models bm25 49.01 7.17 64.96 63.68 28.92 6.78 37.09 24.44 51.28 10.66 60.70 48.4043.07 45.51 COLT 36.58 5.74 50.84 49.04 21.98 5.12 29.68 20.03 46.02 9.12 58.02 45.27 34.86 38.12 Colbert 43.80 6.40 58.02 56.28 16.60 3.05 20.85 14.95 31.18 5.86 39.40 32.10 30.53 34.44 contriever-msmarco35.78 5.31 47.17 46.07 25.19 5.67 31.95 20.56 44.37 9.35 57.53 46.80 35.11 37.81 gtr-t5-base 37.45 5.50 48.78 47.44 22.54 4.93 29.64 20.60 51.02 10.28 61.08 49.06 37.00 39.03 gtr-t5-large 42.14 5.98 53.59 52.19 26.60 5.71 33.68 22.38 53.9511.1766.08 52.21 40.90 42.26 Embedding models all-MiniLM-L6-v2 36.93 5.65 49.54 47.92 15.89 3.89 22.68 15.24 43.09 9.29 56.84 43.96 31.97 35.71 e5-small-v2 38.22 5.55 49.34 48.07 28.97 6.81 36.96 23.45 47.59 9.78 58.19 45.31 38.26 38.94 e5-base-v2 40.69 6.51 55.38 54.01 28.43 6.59 37.14 23.67 47.89 9.48 59.01 46.91 39.00 41.53 e5-large-v2 40.14 5.87 52.23 50.80 26.88 6.16 35.65 24.31 51.40 10.65 61.45 48.28 39.47 41.13 gte-base-en-v1.5 48.25 7.16 61.96 59.17 33.28 7.57 41.99 27.20 50.33 9.70 62.05 50.09 43.95 45.49 gte-large-en-v1.5♠ 40.48 6.46 56.34 54.52 30.58 7.00 38.79 24.78 49.24 9.98 59.13 47.20 40.10 42.17 bge-base-en-v1.5 43.74 6.43 57.33 55.85 29.83 6.96 38.86 25.67 52.4110.7563.84 51.19 41.99 44.24 bge-large-en-v1.544.07 6.44 56.78 55.22 33.88 7.90 43.11 28.62 53.4810.53 63.6652.00 43.81 45.28 gte-Qwen2-1.5B-inst.♠ 47.29