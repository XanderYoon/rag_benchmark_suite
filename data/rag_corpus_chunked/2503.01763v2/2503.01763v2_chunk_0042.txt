40- TaskBench-DLsubset https://github.com/microsoft/JARVIS/taskbench/huggingface 23 23ToolAlpaca (Tang et al., 2023)https://github.com/tangqiaoyu/ToolAlpaca 94 1,937Toolbench-sam (Xu et al., 2023)https://github.com/sambanova/toolbench 197 197ToolEmu (Ruan et al., 2023)https://github.com/ryoungj/ToolEmu 38 38TooLink (Qian et al., 2023)https://github.com/qiancheng0/Toolink 497 1,804UltraTool (Huang et al., 2024)https://github.com/JoeYing1019/UltraTool 500 1,171Tool-be-honest (Zhang et al., 2024)https://github.com/ToolBeHonest/ToolBeHonest 350 892 Table 6: The detailed statistics about the each collected dataset in TOOL RET. We highlight that the subsets of ToolBench share a same toolsets containing 13,000+ tools. Besides, the TOOL RET combine and deduplicate the toolsets from the above datasets to build the final tool retrieval corpus. • Gorilla-Tensor (Patil et al., 2023): Includes TensorFlow functions as tools, collected from Tensor- Flow Hub, to assess LLMs’ tool selection capabilities in deep learning scenarios. • Gorilla-HuggingFace (Patil et al., 2023): Treats specific downstream models from the Hugging Face platform as tools. This dataset evaluates LLMs’ performance in correctly calling Hugging Face models based on user queries. • CRAFT-TabMWP(Yuan et al., 2023): Evaluates LLMs’ ability to usefunctions for table process- ing. The functions in this dataset are first generated by GPT-4 and subsequently verified. • CRAFT-VQA (Yuan et al., 2023): Provides evaluation cases for visual question answering (VQA), where LLMs must call image processing functions such as image capture and object detection. • CRAFT-Math-Algebra (Yuan et al., 2023): Assesses LLMs’ ability to invokealgebra functions for solving complex mathematical problems. B.4 T OOL RET-Customized Besides Web APIs and code functions, we also collect datasets that contain customized apps. Unlike Web APIs and code functions, customized apps are described using free-form natural language documentation Algorithm 1: The pseudo algorithm for our target-aware strategy in automatically constructing instructions for evaluation tasks. Input: A set of N seed instructions S = {si | i ∈ [N ]} manually crafted by human experts; A powerful LLM M (e.g., GPT-4o); Collected tasks T = {ti|i ∈ [|T