. These models re- rank the initially retrieved documents based on the query-passage relevance. We evaluate: MonoT5 (Nogueira et al., 2020), mxbai-rerank- large, jina-reranker-v2-base, and bge-reranker. LLM agents. These methods leverage general- purpose LLM agents for re-ranking tasks in a zero- shot setting, simulating the tool selection process of tool-use agents. We evaluate the widely used LLM re-ranking framework, i.e., RankGPT (Sun et al., 2023), with various LLMs as backbone. Initial tools for LLM agent and Re-ranking base- lines are retrieved by Nv-embedd-v1 model. De- tails of these baselines are provided in Appendix D. 6 Experiment result 6.1 Tool retrieval performance Existing retrievers struggle. As shown in Ta- ble 9, the tool retrieval tasks in TOOL RET raise significant challenges for existing retriever mod- els. Specifically, all retrievers in our experiments achieve less than 35% in Completeness@10 and under 52% in recall@10. Notably, retrieval meth- ods that demonstrate strong performance in con- 16 18 20 22 24 26 28 30 32 Evaluation score on our benchmark 40 45 50 55 60Evaluation score on MTEB benchmarkbm25 e5-small-v2 contriever-msmarco gtr-t5-base gtr-t5-large all-MiniLM-L6-v2 e5-base-v2 e5-large-v2 gte-base-en-v1.5 bge-base-en-v1.5 bge-large-en-v1.5 e5-mistral-7b-inst.gte-large-en-v1.5 gte-base-en-v1.5 NV-Embed-v1 Pearson coefficient = 0.790 Spearman coefficient = 0.441 bm25 e5-small-v2 contriever-msmarco gtr-t5-base gtr-t5-large all-MiniLM-L6-v2 e5-base-v2 e5-large-v2 gte-base-en-v1.5 bge-base-en-v1.5 bge-large-en-v1.5 e5-mistral-7b-inst. gte-large-en-v1.5 gte-base-en-v1.5 NV-Embed-v1 Figure 5: Correlation between the score on our bench- mark and MTEB (retrieval subset). ventional information retrieval (IR) tasks, such as ColBERT, even underperform compared to sim- ple lexical-based matching approaches like BM25. Similarly, other embedding-based models, even the NV-Embed-v1 with 7B parameter, achieve less than 45% in completeness@10, exhibiting limitations. We identify two potential reasons for the above performance degradation: (i) Tool retrieval tasks require intensive reasoning over the input query to align user intentions with candidate tools, as the lexical overlap between the query and targets is