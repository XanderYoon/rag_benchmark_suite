matching approaches like BM25. Similarly, other embedding-based models, even the NV-Embed-v1 with 7B parameter, achieve less than 45% in completeness@10, exhibiting limitations. We identify two potential reasons for the above performance degradation: (i) Tool retrieval tasks require intensive reasoning over the input query to align user intentions with candidate tools, as the lexical overlap between the query and targets is low. (ii) There exists a domain shift between the conventional training corpora used for retrieval models and the specific tool retrieval tasks, which current models are not explicitly optimized for. Re-ranking technique has limited improvement. As shown in Table 9, commonly used re-ranking Model TOOLRET-Web T OOLRET-Code T OOLRET-Customized Average N@10 P@10 R@10 C@10 N@10 P@10 R@10 C@10 N@10 P@10 R@10 C@10 N@10 C@10 BM25s 26.33 6.10 34.22 22.79 41.90 6.20 56.49 55.39 41.16 8.39 48.60 38.90 36.46 39.03COLT 28.91 4.61 40.64 38.83 20.06 4.71 27.78 18.84 31.29 6.05 42.19 34.01 26.75 30.56Colbert 16.67 3.12 21.14 14.94 30.35 4.37 41.38 40.28 24.35 4.56 30.97 24.87 23.79 26.70contriever-msmarco23.48 5.29 30.21 19.69 31.61 4.84 43.01 41.74 21.93 3.85 27.28 23.04 25.67 28.16gtr-t5-base 20.38 4.49 27.53 19.24 33.59 4.90 43.18 41.88 41.84 7.66 48.35 39.28 31.94 33.46gtr-t5-large 24.37 5.27 31.6421.2636.76 5.33 47.4245.9242.04 8.48 50.8440.0034.3935.73 all-MiniLM-L6-v212.77 3.26 19.38 13.33 31.59 5.06 43.86 42.25 32.24 7.14 43.55 32.34 25.53 29.31e5-small-v2 26.42 6.20 34.44 21.39 32.36 4.84 42.38 41.11 34.62 6.90 42.29 32.58 31.14 31.69e5-base-v2 24.71 5.78 33.45 21.94 31.40 5.01 42.83 41.38 38.06 7.54 46.84 36.43 31.39 33.25e5-large-v2 23.62 5.52 32.19 21.80 34.27 5.05 44.42 43.19 43.32 8.51 52.30 41.42 33.73 35.47gte-base-en-v1.530.75 7.00 39.4425.8841.68 6.20 53.9651.6437.95 6.96 46.57 38.10 36.79 38.54gte-large-en-v1.528.06 6.55 36.32 22.57 35.77 5.75 49.56 47.71 37.27 7.88 47.98 35.84 33.70 35.37bge-base-en-v1.525.95 6.16 35.12 23.40 35.15 5.22 45.74 44.32 43.208.82 53.5442.2934.77 36.67bge-large-en-v1.530.03 7.01 39.28 25.63 41.53 6.00 52.76 51.1843.90 8.31 51.79 42.2438.4939.68e5-mistral-7bâ™  31.07