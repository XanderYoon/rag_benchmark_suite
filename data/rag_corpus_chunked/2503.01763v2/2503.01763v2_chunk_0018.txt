36.43 31.39 33.25e5-large-v2 23.62 5.52 32.19 21.80 34.27 5.05 44.42 43.19 43.32 8.51 52.30 41.42 33.73 35.47gte-base-en-v1.530.75 7.00 39.4425.8841.68 6.20 53.9651.6437.95 6.96 46.57 38.10 36.79 38.54gte-large-en-v1.528.06 6.55 36.32 22.57 35.77 5.75 49.56 47.71 37.27 7.88 47.98 35.84 33.70 35.37bge-base-en-v1.525.95 6.16 35.12 23.40 35.15 5.22 45.74 44.32 43.208.82 53.5442.2934.77 36.67bge-large-en-v1.530.03 7.01 39.28 25.63 41.53 6.00 52.76 51.1843.90 8.31 51.79 42.2438.4939.68e5-mistral-7b♠ 31.07 7.65 41.30 27.04 44.97 6.66 58.95 56.79 40.88 7.91 49.35 38.35 38.97 40.73NV-Embed-v1♠ 31.51 7.74 40.52 26.7447.92 7.10 62.0759.60 48.70 10.07 57.69 43.88 42.71 43.41gte-Qwen2-1.5B-inst.♠ 37.53 9.31 48.3130.9547.38 7.29 61.12 59.5552.9810.6359.4745.6845.9645.39GritLM-7B♠ 36.58 9.34 46.01 27.65 41.26 6.17 53.81 52.07 45.55 9.74 54.01 41.40 41.13 40.37 mxbai-rerank-large-v117.53 4.05 25.82 17.95 33.86 5.05 47.84 46.47 26.83 6.71 37.61 28.60 26.08 31.01monoT5-base-msmarco23.33 5.88 30.70 18.13 31.39 5.27 45.18 42.51 37.77 6.76 46.63 39.70 30.83 33.45bge-reranker-v2-m334.83 8.54 45.23 31.73 50.86 7.64 67.26 64.78 42.35 9.52 53.75 39.90 42.68 45.47jina-reranker-v2-base42.3510.1151.2134.2353.21 7.66 66.03 63.94 45.94 10.36 57.96 45.41 47.17 47.86bge-reranker-v2-gemma34.73 8.09 45.08 32.2955.85 8.22 70.5368.7651.9711.0461.20 45.6547.5248.90 Mixtral-8x22B 35.31 7.56 38.63 34.60 33.27 5.77 39.60 38.53 34.40 6.44 39.72 38.20 34.33 37.11gpt-3.5-turbo-012537.22 8.97 40.82 35.22 35.42 6.22 41.16 42.64 37.298.24 41.34 39.7029.60 29.52gpt-3.5-turbo-110638.31 9.02 41.2935.7638.69 7.27 42.5742.8139.30 7.89 43.3137.3138.77 38.63 Table 5: Experiment results in w/ inst. setting (§ 5), where the model takes the query and instruction as input to retrieval. ♠ indicates the model is pre-trained on instructional datasets. We highlight the best performance. methods provide limited and even negative im- provements for the tool retrieval task. When us- ing MonoT5 to re-rank the tools retrieved by NV- Embed-v1, the average NDCG@10 decreases from 33.83 to 28.92. A similar trend is observed with the mxbai-rerank. Other advanced models such as bge- ranker-v2-gemma only have 4.7% improvement in the Completeness@10 metric. These results further indicate the challenging nature of tool retrieval. 6.2 Substantial gains from instruction