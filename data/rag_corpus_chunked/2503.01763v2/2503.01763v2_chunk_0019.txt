retrieval task. When us- ing MonoT5 to re-rank the tools retrieved by NV- Embed-v1, the average NDCG@10 decreases from 33.83 to 28.92. A similar trend is observed with the mxbai-rerank. Other advanced models such as bge- ranker-v2-gemma only have 4.7% improvement in the Completeness@10 metric. These results further indicate the challenging nature of tool retrieval. 6.2 Substantial gains from instruction Besides the evaluation results underw/o inst setting in Table 4, we also present the results under w/ inst setting in Table 5. We observe that all the IR model achieves better performance when an additional instruction is paired with the query as input. No- tably, the instruction-tuned embedding model like NV-embed-v1 or e5-mistral has the most obvious improvement, which potentially benefits from its powerful instruction-following capability. These results illustrate the advantages of the instruction and instruction tuning in tool retrieval tasks. 6.3 Compare with conventional IR tasks To further explore the complexity of tool retrieval tasks, we compare the models’ performance on TOOL RET and conventional IR task benchmark, i.e., MTEB, showing their relationship in Figure 5. First, we can see that the two benchmarks share a similar trend (Pearson’s coefficientβ = 0.790), but the score in TOOL RET is lower. This indicates that the task in TOOL RET has a correlation with conven- tional IR tasks but is more challenging. Second, we also observe that conventional IR models trained with relevance-oriented criteria such as contriever perform poorly on TOOL RET, which indicates that TOOL RET requires more target-aware reasoning ability. This is also illustrated in § 4.1. 7 Retrieval affect downstream task In this section, we qualitatively analyze the impact of retrieval performance on downstream tool-use agents. We conduct end-to-end evaluations on Tool- Bench (Qin et al., 2023) dataset using the official Pass Rate metric that evaluates whether the