(Grant No. 62472261), the Shandong Province Key Research and Develop- ment Program (2024CXGC010108), and the Shan- dong Province Technology Innovation Guidance Program (YDZX2024088). Limitation The limitations of this work include the lack of exploration in multilingual retrieval settings. Cur- rently, our benchmark is confined to the English language and focuses exclusively on text retrieval. To address this limitation, we plan to expand our research to encompass multilingual information retrieval (IR) scenarios in the future. Addition- ally, another limitation lies in the insufficient in- vestigation of prompt sensitivity. Given that large language models (LLMs) are highly sensitive to prompt wording, we aim to annotate a broader range of instructions in the future to examine how variations in prompt phrasing influence LLM per- formance. Building upon TOOL RET, we suggest the fol- lowing directions for future work. (i) Investigating sensitivity to instructions: Con- duct a comprehensive study on how LLM per- formance varies with different prompt formu- lations and instruction styles. (ii) In this work, we focus on the retrieval-then- calling method, where the tool retrieval step is triggered only once initially, and the top-k retrieved tools are then passed to the tool-use LLMs. In the future, we aim to benchmark IR models in interleaved retrieval-and-calling scenarios. Specifically, the LLM can generate long-form reasoning for task planning, and the IR model can receive this reasoning output, exploring step-by-step integration between the LLM and IR models. (iii) Enhancing IR models for improved retrieval accuracy: Further optimize IR models to achieve higher retrieval precision, leverag- ing these improvements to augment tool-use LLMs and, consequently, enhance end-to-end task performance. Ethics Statement We acknowledge the importance of the ACM Code of Ethics and fully agree with it. We ensure that this work is compatible with the provided code in terms of publicly accessible datasets and models.