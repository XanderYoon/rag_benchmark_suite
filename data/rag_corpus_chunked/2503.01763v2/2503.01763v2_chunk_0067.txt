the impact of improved IR models on the end-to-end performance of tool-use LLMs. Specifically, we evaluate tool-use LLMs on the ToolBench (Qin et al., 2023) dataset using the official Pass Rate metric, which measures whether the model successfully invokes the correct tools to complete a given task. For each task in ToolBench, we replace the pre-annotated toolset (oracle) with tools retrieved by IR models from TOOL RETâ€™ tool corpus, which contains 43,000 tools. Since TOOL RET integrates the ToolBench dataset, we can compute NDCG@10 for this retrieval step. For a comprehensive evaluation, we assess two widely used tool-use LLMs, including GPT-3.5 and ToolLLaMA (Qin et al., 2023). Table 15 presents the retrieval NDCG@10 scores alongside the corresponding pass rates on ToolBench.9 Our results demonstrate that LLM agents equipped with improved IR models achieve substantial gains in pass rate, highlighting the critical role of accurate tool retrieval in downstream task performance. Furthermore, Figure 6 visually illustrates a positive correlation between improved IR performance and higher task pass rate, suggesting that better retrieval directly leads to improved downstream outcomes. Based on this analysis, we propose that future work could explore the following two directions: (i) Further optimize IR models to enhance tool retrieval performance; or (ii) Adapt IR models by incorporating feedback from end-to-end task performance, allowing them to better support tool-use LLMs. These approaches provide a more efficient plug-and-play solution compared to fine-tuning LLMs, enabling flexible integration into diverse tool-use systems. 9ToolBench consists of three subsets: ToolBench-G1, ToolBench-G2, and ToolBench-G3. Model TOOLRET-Web T OOLRET-Code T OOLRET-Customized Average N@10 P@10 R@10 C@10 N@10 P@10 R@10 C@10 N@10 P@10 R@10 C@10 N@10 C@10 Sparse and dense models bm25 26.47 4.04 34.51 33.22 20.61 5.06 26.35 15.87 38.48 8.51 48.24 37.09 28.52 28.73 COLT 22.23 3.75 31.66 30.15 21.65 5.36 29.15 19.12 36.12 7.99