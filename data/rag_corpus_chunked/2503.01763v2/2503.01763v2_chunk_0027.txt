accuracy: Further optimize IR models to achieve higher retrieval precision, leverag- ing these improvements to augment tool-use LLMs and, consequently, enhance end-to-end task performance. Ethics Statement We acknowledge the importance of the ACM Code of Ethics and fully agree with it. We ensure that this work is compatible with the provided code in terms of publicly accessible datasets and models. Risks and harms associated with large language models include the generation of harmful, offensive, or biased content. The new benchmark is composed of various previous datasets and is therefore licensed under their respective data licenses. In this research, we prioritize reproducibility by not only utilizing state-of-the-art commercial LLMs but also experimenting extensively with open-source LLMs. Throughout the study, we have strictly followed ethical standards to main- tain the integrity and validity of our work. All tools and resources used in this research were ob- tained from publicly available platforms, ensuring transparency and reproducibility in our experimen- tal procedures. Furthermore, we have made every effort to ensure that our research does not harm individuals or groups, nor does it involve any form of deception or potential misuse of information. References Anirudh Ajith, Mengzhou Xia, Alexis Chevalier, Tanya Goyal, Danqi Chen, and Tianyu Gao. 2024. Lit- search: A retrieval benchmark for scientific literature search. arXiv preprint arXiv:2407.18940. Akari Asai, Timo Schick, Patrick Lewis, Xilun Chen, Gautier Izacard, Sebastian Riedel, Hannaneh Ha- jishirzi, and Wen-tau Yih. 2022. Task-aware retrieval with instructions. arXiv preprint arXiv:2211.09260. Emily M Bender and Batya Friedman. 2018. Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, 6:587â€“604. Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. A sur- vey on evaluation of large