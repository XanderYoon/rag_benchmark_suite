guage processing (NLP) tasks, such as text sum- marization (Chang et al., 2023). However, they suffer from inherent inabilities to interact with the physical world and access vast, up-to-date knowl- edge (Qin et al., 2024). To alleviate these draw- backs, tool learning is proposed to equip LLMs with external tools, augmenting them as agents to manipulate tools for practical task-solving (Qu et al., 2025b; Wang et al., 2024e). In practical applications, retrieving useful tools from toolsets for LLM agents typically serves as *Corresponding author. 1Resource is available on Huggingface and /gtbWebsite. 49 51 53 55 22 25 28 31 34 Recall@10of IR models Pass Rate of GPT-3.5-turbo â€¦ 64.2 Pass rate with pre-annotated toolset (oracle) e5-base-v2 e5-large-v2 ColBET-v2 bge-base-v1.5 bge-large-v1.5 decrease 10.1 only 27.3 recall@10 Figure 1: Correlation between the tool retrieval perfor- mance (e.g., Recall@10) of IR models and the end-to- end task pass rate of tool-use agents. the initial step (Wang et al., 2024c; Xu et al., 2024; Song et al., 2023). This step becomes particularly critical in real-world scenarios where the candidate tools are usually large-scale and many of them are similar in functionality (Qu et al., 2024a). How- ever, most existing work (Guo et al., 2024; Qian et al., 2023) simplifies this retrieval process by man- ually pre-selecting a small set of 10-20 relevant tools for each evaluation task. For example, the ToolACE (Liu et al., 2024a) and ToolBench (Qin et al., 2023) annotate about 10 tools per task. While recent information retrieval (IR) techniques such as semantic matching (Qu et al., 2024a; Xu et al., 2024), can assist with tool retrieval, they are of- ten trained on ad-hoc tool-use datasets, lacking comprehensive evaluation on diverse scenarios, es- pecially for unseen tasks. To further explore the importance of tool retrieval, we conduct a pilot experiment on