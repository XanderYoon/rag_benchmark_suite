RET, which indicates that TOOL RET requires more target-aware reasoning ability. This is also illustrated in ยง 4.1. 7 Retrieval affect downstream task In this section, we qualitatively analyze the impact of retrieval performance on downstream tool-use agents. We conduct end-to-end evaluations on Tool- Bench (Qin et al., 2023) dataset using the official Pass Rate metric that evaluates whether the model successfully calls target tools to complete a task. 7.1 Poor retrieval leads to poor tool-use agents For each task in ToolBench, we replace the offi- cially pre-annotated toolset (oracle) with tools re- trieved by IR models. As shown in Figure 6, the tool-use LLMs, when equipped with the retrieved tools, exhibit substantially lower performance com- pared to their oracle counterparts. For example, in ToolBench-G1, GPT-3.5 achieves a pass rate of 50.60 using tools retrieved by bge-large, decreas- ing by 11.40. This indicates that tool retrieval is a crucial step to build better tool-use LLMs and 45 50 55 60 65 32 42 52 62 72 48 53 58 63 68 6 10 14 18 22 53 57 61 65 69 27 38 49 60 71 NDCG@10 NDCG@10 NDCG@10 bge-large-en-v1.5 bge-base-en-v1.5 e5-large-v2 e5-base-v2 training improvement Pass Rate of GPT-3.5 Pass Rate of GPT-3.5 Pass Rate of GPT-3.5 35 40 45 50 55 32 42 52 62 72 40 43 46 49 52 6 10 14 18 22 30 35 40 45 50 27 38 49 60 71 ToolBench-G1 ToolBench-G2 ToolBench-G3 Pass Rate of ToolLlama Pass Rate of ToolLlama Pass Rate of ToolLlama ToolBench-G1 ToolBench-G2 ToolBench-G3 oracle (62.00) oracle (64.20) oracle (67.50) oracle (53.60) oracle (50.80) oracle (49.10) oracle performance NDCG@10 NDCG@10 NDCG@10 Figure 6: The horizontal axis indicates the retrieval performance of IR models, both before and after training. The vertical axis corresponds to the end-to-end pass rate of tool-use