lations over the graph and hop from indirectly rele- vant vertices to relevant ones, we introduce breadth- first local search which utilizes the LLM to choose the most appropriate neighbor for eachvj in Cqueue to append to the tail of the queue. Specifically, for each vj in Cqueue in each round of hop, we lever- age LLM to reason over all the questions from its out edges to choose one ej,k with the question which the LLM regards as the most helpful for an- swering q and append vertex vk to Cqueue. After hopping from each vertex in the current Cqueue we can expand the context with at most topk new ver- tices. From these new vertices we continue the next round of hop. Since different vertices may hop to the same vertex, we believe the vertices with more visits are more important for answering q, and use a counter Ccount to track the number of visits for each vertex and measure its importance. By con- ducting nhop rounds of hop, we realize reasoning- augmented graph traversal and expand the context length to at most (nhop + 1) × topk. Pruning Phase To avoid including too many in- termediate vertices during the traversal, we intro- duce a novel metric Helpfulness H(·) that inte- grates similarity and logic to re-rank and then prune the traversal counter Ccount. We calculate Hi fol- lowing Equation 2 for each vi in Ccount and keep the topk vertices with the highest Hi, where hybrid textual similarity SIM(vi, q) calculates the aver- age lexical and semantic similarity between the passage in vi and query q following Equation 1; and IMP(vi, Ccount) is defined as the normalized number of visits of vi in Ccount during traversal fol- lowing Equation 3. We prune Ccount by retaining topk vertices