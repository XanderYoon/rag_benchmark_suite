only can it effectively address the inherent knowledge limitations and hal- lucination issues (Zhang et al., 2023), but it can also enable easy interpretability and provenance tracking (Akyurek et al., 2022). Especially, the â€  Equal contribution; * Corresponding author. efficacy of RAG hinges on its retrieval module for identifying relevant documents from a vast corpus. Currently, there are two mainstream types of re- trievers: sparse retrievers (Jones, 1973; Robertson and Zaragoza, 2009b) and dense retrievers (Xiao et al., 2024; Wang et al., 2024b; Sturua et al., 2024; Wang et al., 2024c), which focus on lexical simi- larity and semantic similarity respectively, and are often combined for better retrieval performance (Sawarkar et al., 2024). Despite advancements, the ultimate goal of information retrieval extends beyond lexical and semantic similarity, striving in- stead for logical relevance. Due to the lack of logic-aware mechanism, the imperfect retrieval re- mains prominent (Wang et al., 2024a; Shao et al., 2024; Dai et al., 2024; Su et al., 2024a,b). For precision, the retrieval system may return lexically and semantically similar but indirectly relevant pas- sages; regarding recall, it may fail to retrieve all the necessary passages for the user query. Both cases eventually lead to inaccurate or in- complete LLM responses (Chen et al., 2024; Xiang et al., 2024; Zou et al., 2024), especially for multi- hop or multi-document QA tasks requiring multiple relevant passages for the final answer. In contrast, the reasoning capability of generative models is rapidly advancing, with notable examples such as OpenAI-o1 (Jaech et al., 2024) and DeepSeek-R1 (Guo et al., 2025). Therefore, a natural research question arises: "Is it possible to introduce reason- ing capability into the retrieval module for more advanced RAG systems?" From a logical structure perspective, existing RAG systems can be mainly categorized into three types: Non-structured RAG simply