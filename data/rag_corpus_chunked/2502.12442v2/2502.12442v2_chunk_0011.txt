the topk vertices with the highest Hi, where hybrid textual similarity SIM(vi, q) calculates the aver- age lexical and semantic similarity between the passage in vi and query q following Equation 1; and IMP(vi, Ccount) is defined as the normalized number of visits of vi in Ccount during traversal fol- lowing Equation 3. We prune Ccount by retaining topk vertices with the highest H value, resulting in the final context C. Hi = SIM(vi, q) + IMP(vi, Ccount) 2 (2) IMP(vi, Ccount) = Ccount[vi]P vj ∈Ccount Ccount[vj] (3) Algorithm 1: Reasoning-Augmented Graph Traversal Input: q, topk, nhop, G Output: C 1 vq ← EMB(q); 2 kq ← NER(q); 3 Cqueue ← Retrieve(vq, kq, G); 4 Ccount ←Counter(Cqueue); 5 for i ← 1, 2, ..., nhop do 6 for j ← 1, 2, ..., | Cqueue | do 7 vj ← Cqueue.dequeue(); 8 vk ← Reason({⟨vj, ej,k, vk⟩}); 9 if vk not in Ccount then 10 Cqueue.enqueue(vk); 11 Ccount[vk] ← 1 ; 12 else 13 Ccount[vk] + + ; 14 end 15 end 16 end 17 C ←Prune(Ccount, vq, kq, topk); 18 return C 4 Experiments 4.1 Experimental Setups Datasets We collect several multi-hop QA datasets to evaluate the performance of HopRAG. We use HotpotQA dataset (Yang et al., 2018), 2WikiMultiHopQA dataset (Ho et al., 2020) and MuSiQue dataset (Trivedi et al., 2022). Follow- ing the same procedure as (Zhang et al., 2024), we obtain 1000 questions from each validation set of these three datasets. See Appendix A.2 for details. Baselines We compare HopRAG with a variety of baselines: (1) unstructured RAG - sparse re- triever BM25 (Robertson and Zaragoza, 2009a) (2) unstructured RAG - dense retriever BGE (Xiao et al., 2024; Karpukhin et al., 2020) (3) unstruc- tured RAG - dense retriever BGE with query decomposition (Min et al., 2019)