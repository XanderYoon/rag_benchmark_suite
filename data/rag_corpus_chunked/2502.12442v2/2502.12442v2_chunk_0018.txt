is in bold and the second best is underlined. the inclusion of excessive redundant information. Conversely, the answer quality generally improves, attributed to GPT-3.5-turboâ€™s strong capability in processing and reasoning over extended contexts, with only one exception in the MuSiQue dataset. Effects of nhop To assess the effects of the hy- perparameter nhop on reasoning-augmented graph traversal, we vary nhop from 1 to 4 and evaluate the corresponding retrieval performance and cost, which is measured by the total number of LLM calls during graph traversal. The results shown in Table 4 indicate that as nhop increases, retrieval performance tends to improve, as more vertices are visited during traversal for reasoning and prun- ing. However, the expense and latency from calling LLM also increase with nhop, creating a trade-off between performance and cost. We notice that as nhop increases, the number of new vertices in Cqueue requiring LLM reasoning decays rapidly. Since different vertices may hop to the same impor- tant vertex, the actual queue length in each round of hop is less than topk. Specifically, the aver- age queue length is 2.60 in the fourth round and 1.23 in the fifth round, suggesting that for the three datasets, the local area in the graph structure can be largely explored within four rounds of hop, elimi- nating the need for an additional hop. We set nhop as 4 in Table 1 and 2. We also evaluate the answer performances as nhop varies and show the overall results in Appendix A.8. Ablation on Traversal Model In order to gener- alize HopRAG to scenarios with less computational overhead during retrieval, we supplement results from (1) HopRAG with traversal model Qwen2.5- 1.5B-Instruct (2) HopRAG with non-LLM graph traversal that replaces the reasoning phase in Algo- rithm 1 with similarity matching. Table 5 shows that