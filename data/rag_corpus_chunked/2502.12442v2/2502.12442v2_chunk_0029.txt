shows the basic statistics of our datasets with their corresponding passage pool. Compared with knowledge graph, our graph-structured index is less dense and more efficient to construct. Since we put each passage text in the vertex, we can use fewer vertices to cover all the passages, which lowers the space complexity of the database. The average number of directed edges for each vertex is only 5.87, which lowers the time complexity for graph traversal. A.3 Metrics In our experiment, we mainly report the answer exact match (EM) and F1 score to compare all the methods. Exact Match (EM) The Exact Match (EM) met- ric measures the percentage of predictions that match any one of the ground truth answers exactly. It is defined as: EM = |{p | p = g}| |P | where p denotes a predicted answer, g denotes the corresponding ground truth answer, and P is the set of all the predictions. F1 Score The F1 score is the harmonic mean of precision and recall, which measures the average overlap between the prediction and ground truth answer. Precision P and recall R are defined as: P = |A ∩ ˆA| | ˆA| , R = |A ∩ ˆA| |A| where |A ∩ ˆA| refers to the number of matching to- kens between the prediction ˆA and the ground truth A, and | ˆA|, |A| denote the number of tokens in the predicted and ground truth answers, respectively. The F1 score is then computed as: F 1 = 2 · P · R P + R In our ablation study, we also report the retrieval F1 score to test the sensitivity of HopRAG, which is calculated as follows. The Precision (P) and Recall (R) for retrieval are computed as: P = |Ret ∩ Rel| |Ret| , R = |Ret