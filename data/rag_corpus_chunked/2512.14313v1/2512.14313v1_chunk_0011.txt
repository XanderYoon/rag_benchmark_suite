70% training, 15% validation, and 15%testsetsusingstratifiedsamplingtomaintainclassproportionsacrosssplits. Training was conducted with a batch size of 16, and the best model was selected based on validation accuracy. 5.4 LLM Reranker For the document selection component, we employed Mistral Nemo Instruct (12.2Bparameters)withzero-shotprompting.Thepromptingstrategyinstructed the model to: (1) Analyze the given query and retrieved passages, (2) select ex- actlykpassages (predicted by the classifier) based on relevance to the query, and (3) return relevant passages. The prompt is as follows: "Given the following query and passages, rank the passages (by their ID numbers) that are most rel- evant to answering the query. Return the predicted-k most relevant passage IDs in a Python list." 5.5 Generator The final generation stage utilized Flan-T5-XL as the text generation model, which processes the selected passages alongside the original query to produce the final response. 6 Results and Discussion 6.1 Baseline vs Classifier-k Pipeline ThissectioncomparestheperformancesoftheBaselineandtheClassifierpipelines. The fixed-k value for the Baseline Pipeline was selected to be a standard value of five (k=5). Table 3 shows the generation results for each configuration. The evaluation shows that the Baseline outperformed the Classifier pipeline (Baseline vs. Calssifier rows) in both the MuSiQue and 2WikiMultiHopQA datasets, with all retrieval configurations. Before considering alternative explanations, we must ask whether the issue stems from the classifier, or not.If it always returned the correctkvalue, would the results outperform the baseline?As is depicted in Table 3, the fixed k (Baseline) approach outperforms the classifier- k approach, even when the classifier is ideal. The result is shown in the Ideal Classifier row, using the dense retrieval method, compared the the Baseline. The retrieval results (not listed in the paper) show that while precision scores were 10 M. Iratni et al. Table 3: Evaluation Results Retrieval Pipeline MuSiQue MultihopRAG 2WikiQA EM F1 EM F1 EM F1 BM25 Baseline 0.060 0.105 0.499