performance degradation as distractor ratios increase, and identifies the conditions under which distractors most significantly impair model output. –We examine the “lost in the middle” phenomenon by placing relevant pas- sages at the beginning, middle, and end of the model’s input window, to evaluate how positional placement influences the effectiveness of retrieved context for generation within a RAG pipeline. 2. RELATED WORKS 3 –We introduce a classifier that predicts the optimal number of contexts to retrieve (k), to dynamically adapt the context length to the specific infor- mational requirements of each query. –We integrate the classifier into a full RAG system and compare its perfor- mance against a fixed-k baseline, demonstrating consistent improvements in generation. 2 Related works Recent work has explored adaptive retrieval strategies to overcome the limita- tions of fixed-k retrieval in RAG systems. Jeong et al. (2024) introduce Adaptive- RAG [5], a framework that dynamically selects among non-retrieval, single-step, and multi-step retrieval strategies based on query complexity. Their approach employs a classifier trained to predict query complexity, which guides the se- lection of an appropriate retrieval depth. Sun et al. (2025) introduces Dynami- cRAG [10], which adaptively determines both the ranking and the number (k) of retrieved documents for each query. The core component is a dynamic reranker trained using reinforcement learning, where the quality of LLM-generated re- sponses serves as the reward signal. Taguchi et al. propose Adaptive-k [11], a retrieval method that dynamically selects the number of passages to retrieve based on similarity score distribution. Ìn addition to retrieval size, the positional placement of retrieved content has also been shown to influence generation per- formance. Liu et al. [8] demonstrated that large language models often exhibit a position bias, prioritizing information at the beginning and end of the context, and neglecting passages located in the