Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias Maya Iratni[0000-0002-3567-7885], Mohand Boughanem[0000-0001-7004-0807], and Taoufiq Dkaki[0000-0003-3962-7663] Institut de Recherche en Informatique de Toulouse (IRIT), Toulouse, France {Malika.Iratni, Mohand.Boughanem, Taoufiq.Dkaki}@irit.fr Abstract.Retrieval-Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open- domain question answering. Standard RAG systems typically rely on a fixed top-k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved pas- sages within the input context can influence the model’s attention and generation outcomes. Context placed in the middle tends to be over- looked, which is an issue known as the "lost in the middle" phenomenon. In this work, we systematically analyze the impact of distractors on gen- eration quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demon- strate improved performance over fixed-k baselines. Keywords:Retrieval Augmented Generation (RAG)·Information Re- trieval·Reranking·Multi-hop QA·Large language models (LLM) 1 Introduction Retrieval-Augmented Generation (RAG) is an approach that enhances large lan- guage models with external knowledge by retrieving relevant passages during in- ference. In a standard RAG system, the user’s query is first encoded, and used to retrieve a ranked list of documents from a large collection [2] [7]. The top-K pas- sages,wherekisafixed,predeterminedvalue,arethenprovidedtothegenerative model as additional context, allowing the model to generate a response based on both the query and the retrieved information [7] [3]. This top-K approach has become