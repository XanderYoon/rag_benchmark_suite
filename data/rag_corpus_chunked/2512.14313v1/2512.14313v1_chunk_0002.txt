degrading generation quality [6]. An additional challenge in retrieval-augmented generation lies in the positional effect of the retrieved passages within the input sequence. Prior studies have shown that Large Language Models (LLM) tend to prioritize information that appears at the beginning or end of the input se- quence, attributing less attention to information placed in the middle. This leads to the "lost in the middle" effect [8], wherein the impact of a relevant document on generation may be diminished, or amplified, depending on its location in the context provided to the generator. This positional sensitivity poses a challenge for retrieval strategies that return many documents, as relevant passages can become buried among distractors and receive less attention. This highlights the importance of the structure of the input, in this case the order in which rele- vant documents are provided to the generator. The above points emphasize the fundamental questions of: – RQ1:How much context does a given query need to be effectively answered? – RQ2:Can the impact of distractors be reduced by leveraging the position of relevant context within retrieved documents? Queries differ in complexity, scope, and information requirements. Some may be answerable with a single passage, while others require broader contextual evidence. This is particularly true in the case of multi-hop question answering. To address this challenges, this work makes the following contributions: –We conduct an empirical study of how distractor passages affect generation quality. Our evaluation quantifies the performance degradation as distractor ratios increase, and identifies the conditions under which distractors most significantly impair model output. –We examine the “lost in the middle” phenomenon by placing relevant pas- sages at the beginning, middle, and end of the model’s input window, to evaluate how positional placement influences the effectiveness of retrieved context for generation within a RAG pipeline. 2.