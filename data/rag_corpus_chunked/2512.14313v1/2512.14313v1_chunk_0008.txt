This architecture provides strong end-to-end performance, but uses a fixedk for all queries, which can lead to over or under retrieval depending on query complexity. 4.2 Classifier-k Pipeline The first major modification to this pipeline is the integration of a query-specific kpredictor. We introduce a classifier to estimate the optimal number of context (k) that should be retrieved for each query. The classifier takes as input a given query and outputs an integer value corresponding to the number of contexts 5. EXPERIMENTAL SETUP 7 to retrieve. This value is used to dynamically adjust the number of documents retrieved for each query. The pipeline is thus modified as follows: 1. The classifier processes queryqto predict retrieval count: kpred =Classifier(q) 2. The retriever fetcheskpred passages. 3. The generator produces output: y=Generator(q, P kpred) 4.3 Classifier-LLM Pipeline The second major modification to the pipeline augments the system an LLM module for reranking. In this pipeline, we first retrieve a fixed-k number of candidate contexts, as was done in the basic retrieval pipeline. The classifier- predictedkvalue, the original query, and the topk fixed retrieved contexts are passed as input to an LLM, which will act as an additional reranker. The LLM is prompted to select the top classifier-k passages from the candidate set based on their relevance to the query. These selected passages are then used as the context for the final generation step. The pipeline is thus modified as follows: 1. The classifier processes queryqto predict retrieval count: kpred =Classifier(q) 2. The retriever fetcheskfixed passages (basic retrieval). 3. The LLM reranker filters passages: Pfiltered =LLM_Reranker(q, k pred, Pfixed) |Pfiltered|=k pred 4. The generator produces output:y=Generator(q, P filtered) 5 Experimental setup To evaluate our proposed approach, we conducted experiments using a variety of retrievers on three datasets, using the three pipelines. We describe the