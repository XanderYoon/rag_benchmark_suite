one would be missing. This experiment was conducted four times with the baseline pipeline with varying fixed-k values. The experiment was also conducted with the classifier-k, and with the ideal k value. Table 4 shows the results of this experiment. The best performing setup is with the ideal k, followed by the classifier-k. This shows that with an ideal retriever, the classifier outperforms the fixed-k baseline. Table 4: Generation performance with fixed-k, classifier-k, and ideal-k using ideal retrieval Setting EM F1 k= 20.475 0.621 k= 30.520 0.667 k= 40.523 0.673 k= 50.481 0.638 Classifier-k 0.535 0.682 Ideal-k 0.564 0.705 IdealRerankerInthispart,theretrievalisperformedforbothpipelines(Base- line and Classifier) using a fixed k=5. We then introduce an ‘ideal’ reranking module that reorders the contexts such that relevant contexts appear at the top of the list, followed by any distractors that were retrieved. For example, if the classifier predicts a question to be 3-hop (k=3), the model selects the first three contexts after ideal reranking, ensuring that if relevant contexts exist in the top five, they are prioritized. Table 3 shows the results of this simulation, in the Ideal Reranker row. The results show that an ideal reranking module with the clas- sifier produces better results than the fixed-k pipeline. Although both pipelines end up with the same number of relevant contexts, the increased presence of distractors in the fixed-k approach decreases the generation performance. 6.3 Classifier-LLM Pipeline This model replicates the ideal reranker experiment using an LLM to perform additional reranking. Retrieval is first performed with a fixedk= 5and gen- 12 M. Iratni et al. eration follows as in standard fixed-kpipeline. In the classifier+LLM pipeline, the LLM receives the classifer-k value, the five retrieved contexts, and the query. The LLM is prompted to rank the contexts by relevance, and select the top classifier-kcontexts. The selected contexts,