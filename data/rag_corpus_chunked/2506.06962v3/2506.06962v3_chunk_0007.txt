We utilize each patch vectorVij as the value of a database entry and the representation of its h-hop surrounding patches as the key. Here, the h-hop surrounding patch representation is formed by concatenating the vectors of adjacent patches centering around (i, j) in a top-to-bottom, left-to-right order. For example, for a patch at position (i, j), the 1-hop surrounding representation spans 8 surrounding patches [V(i−1)(j−1) : V(i−1)(j) : V(i−1)(j+1) : V(i)(j−1) : V(i)(j+1) : V(i+1)(j−1) : V(i+1)(j) : V(i+1)(j+1)] where : denotes the concatenation operation of image patch features. If a patch is located at the edge of the image and lacks certain surrounding patches, we substitute each missing surrounding patch with a zero vector 0. 3.2 Distribution-Augmentation in Decoding (DAiD) Given a text prompt T , Janus-Pro autoregressively predicts a sequence of image tokens [v1, v2, ...vN] where per-token probability is defined in Equation 1. As shown in Figure 2, DAiD augments this process by incorporating probability distributions from retrieved image patches. Specifically, when Janus-Pro predicts the next image token vij, we first utilize the codebook Z to convert vij’s h- hop already generated surrounding patches into patch representations. If no surrounding image tokens are available at a given position (e.g., when i = 0 or j = 0), we use the zero vector 0 as a placeholder. Once we compute the representation of vij’sh-hop surrounding patches, we leverage it as the retrieval query and retrieve the top-K most similar patch representations from the database constructed in Section 3.1 using l2 distance. We denote the representations of the top-K retrieved patches as [ˆv1, ˆv2, ..., ˆvK] and their corresponding l2 distances as [s1, s2, ..., sK]. These retrieved representations are then mapped back to discrete token indices using the codebook: ˆvk = Z(ˆvk). To augment the generation process with