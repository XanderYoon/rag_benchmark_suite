between ground-truth tokens and top-10 retrieved tokens (blue line) compared to randomly sampled tokens (red dashed line). The curved arrow indicates a broken y-axis that accom- modates the large gap between the retrieved token and the random token baseline. To assess the effectiveness of our patch-level autoregressive retrieval mechanism, we conduct a comparative analysis between the top- K re- trieved image tokens and the ground-truth to- kens to be generated. Specifically, we randomly sampled 1, 000 instances from our training set, each comprising 576 image tokens and 576 × k retrieved tokens. To demonstrate the accuracy of the retrieved image tokens, for each ground- truth image token, we also randomly sample a vocabulary code as non-relevant tokens. Us- ing the shared codebook, we transform all im- age tokens into vector representations and com- pute the l2 distances between each ground-truth image token and its top- K retrieved counter- parts. Similarly, we also compute the mean of the l2 distance between each ground-truth token and the randomly sampled tokens. As shown in Figure 6, the l2 distance between retrieved tokens and ground-truth image tokens is signif- icantly smaller than the distance between ran- domly sampled tokens and ground-truth tokens. As k increases, the distance between the k-th retrieved token and the ground-truth token also increases, demonstrating the effectiveness of the retrieval approach and our assumption that image patches with similar neighbors usually exhibit inherent similarities. C.2 Hyperparameter Optimization Figure 7: Hyperparameter optimization results for DAiD and FAiD on FID scores. Left: FID scores for DAiD across different combinations of retrieval temperature τ and merging weight λ. Right: FID scores for FAiD across varying levels of hop h and numbers of blender modules b. All experiments conducted on the Midjourney-10K benchmark, with optimal configurations highlighted by red borders. Both DAiD and FAiD