aug- mentation improves the vanilla image generation models. The vanilla model struggles with object interactions (e.g., col- umn 3, where shoes merge with a coffee machine in the background), complex structures (e.g., columns 2 and 5, where camels and sheep have anatom- ically incorrect numbers of or- gans), and implausible configu- rations (e.g., column 4, where a chair exhibits an impossible design). Both DAiD and FAiD substantially reduce such local distortions, with FAiD yielding the highest visual quality. These results confirm that autoregressive retrieval effectively maintains object consistency and structural integrity throughout the generation process, particularly for complex objects and multi-object scenes. (d) A photo of a green couch and an orange umbrella. (c) A photo of a green cup and a yellow bowl. Retrieved Image AR-RAG ImageRAG Retrieved Image AR-RAG ImageRAG (a) A photo of an apple. Retrieved Image AR-RAG ImageRAG Retrieved Image AR-RAG (b) A photo of a white dog and a blue potted plant. ImageRAG Figure 5: Images generated by ImageRAG [33] and our AR-RAG . ImageRAG excessively copies retrieved images and does not follow user prompts. Figure 5 presents a comparative analysis of conventional image-level and our autoregressive patch- level retrieval augmentation methods. By comprehensively examining images produced by Im- ageRAG alongside their corresponding retrieved reference images, we identify two critical challenges inherent in image-level retrieval augmentation approaches. First, these methods tend to overcopy irrelevant visual elements from retrieved reference images into the generation outputs. As illustrated in Figure 5 (a), when generating an image of an apple, image-level retrieval approaches retrieve a reference image showing an apple on a tree branch and subsequently incorporate both the apple and the surrounding branches, despite the prompt making no mention of them. Similarly, for the prompt “a green cup and a yellow bowl ” in Figure 5 (b),