← Conv1 q×q(Hl loc); 9 ˆhq += Conv2 q×q(M); 10 ˆhi ← ˆhq Q−1 ; Algorithm A illustrates the multi-scale fea- ture smoothing, which is the core computa- tional procedure for refining retrieved patch representations within their generation con- text. This algorithm ensures that retrieved visual elements are spatially and stylisti- cally coherent with the surrounding image content through systematic multi-scale con- volution operations. The algorithm processes each retrieved patch representation ˆhi independently, ap- plying convolution operations at multiple scales ranging from 2 ×2 to Q × Q kernels. For each scale q, the algorithm initializes a temporary feature tensor M ∈ RQ×Q×D and an accumulation vector ˆhq ∈ RD. The nested loops over indices m and n system- atically extract local patch features from different spatial windows around the target position (i, j). Each extraction operation Hl loc ← Hl[i − m : i + q − m, j − n : j + q − n] captures a local neighborhood of size q × q centered at varying offsets from the target position. The extracted local features undergo two-stage convolution processing. The first convolution operation Conv1 q×q transforms the local patch features into an intermediate representation stored in Mmn, effectively capturing contextual relationships within each local window. The second convolution operation Conv2 q×q processes the accumulated intermediate features to produce scale-specific refined representations. This two-stage design enables the algorithm to first capture local contextual patterns and then integrate them into a coherent scale-specific feature representation. After processing all scales for a given retrieved patch, the algorithm computes the final refined representation by averaging the scale-specific features. The normalization factor (Q − 1) accounts for the number of scales processed, ensuring consistent feature magnitudes across different retrieved patches. This averaging operation effectively combines multi-scale contextual information into a single