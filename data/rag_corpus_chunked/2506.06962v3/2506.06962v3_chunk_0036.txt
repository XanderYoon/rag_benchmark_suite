image tokens with the same image tokenizer [37] employed in the Janus-Pro model. For each image patch, we further retrieve the top-K image tokens from our retrieval database that exhibit similar neighborhood relationships. Conse- quently, each training instance comprises: (1) a textual image caption that serves as the conditioning input, (2) a sequence of 576 image tokens representing the ground-truth image, where each token is paired with K relevant image tokens retrieved from the database based on similar contextual features. Training Details For the implementation of our FAiD approach, we fine-tune two pre-trained text- to-image generation models using the training dataset of 50K text-image pairs that we constructed. We select Janus-Pro-1B [9] and Show-o [44] as our base models. The fine-tuning process is conducted on 4 NVIDIA A100 (80GB) GPUs with a global batch size of 256 for a single epoch. We utilize the AdamW optimizer without weight decay, incorporating a 10% linear warm-up schedule followed by a constant learning rate of 2e-4. B.4 Evaluation Benchmarks and Metrics To comprehensively evaluate our proposed methods, we adopt multiple widely used benchmarks that assess different aspects of image generation quality: • GenEval [14] is a benchmark designed to evaluate models’ ability to understand and generate images based on specific attributes and relationships described in text prompts. It comprises multiple categories such as single object generation, two-object composition, counting, colors, positioning, color attribution and so on. Performance is measured as the percentage of generated images that correctly align with the text descriptions. • DPG-Bench [18] (Detailed Prompt Generation Benchmark) evaluates how well image generation models handle detailed prompts with complex requirements, covering categories such as global image quality, entity generation, attribute accuracy, relationship modeling, and other complex generation tasks. Scores are reported as percentages. • For the Midjourney-30k benchmark [40], we employ three