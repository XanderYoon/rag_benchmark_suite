nugget. Using the prompt in Fig. 2 8 we (1) locate a supporting passage, (2) extract a concise self-contained sentence, and (3) record the LLM’s token-likelihood as the extraction confidence. 7 Segmented into 1000 character chunks, split at sentence boundary. 8 The system message was omitted due to a bug. Updated results in online appendix. 4 Dietz et al. Given the following question and answer, please find the sections in the provided source document that support and validate the answer to the question. If the source document does not support the given answer, then set confidence to 0.0 and all fields to None. Provide the section from the document that supports the answer, with complete sentences directly from the document. Please include context around each supporting segment, making sure that there is enough context to support why the answer is a correct response to the question. Your response should include just the extracted text segment, and nothing else. Then condense the extracted text into one concise sentence that clearly demonstrates how the question is answered, without referring to the source document. - Emit **each field exactly once**, in the order shown. - Do NOT repeat headers. Do NOT include any field more than once. - If a field is unknown, omit it entirely - do NOT write ‘None‘ or ‘null‘. Field name Description In:nugget textInput question In:answerValid answer or list of answers In:source documentInput document chunk In:titleTitle query In:backgroundUser background In:problem statementUser’s problem statement Out:extracted text segmentPassage returned by the model Out:summarySingle concise sentence drawn from the passage Out:reasoningInternal chain of thought (ignored downstream) Out:confidenceModel reported confidence value (float) Fig. 2.Prompt for scanning, extraction, and sentence candidate generation. Verification (optional).Extractions may be double-checked for nugget cover- age and citation support. This step invokes prompts used by theAutoArgue system [26] albeit