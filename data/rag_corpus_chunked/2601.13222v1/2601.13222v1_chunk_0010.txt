nugget. The gen- erated report will contain the best sentence for each nugget, each sentence is supported with exactly one citation. Obtaining near-perfect citation support score of 0.9 (Crucible-Base) and 0.96 (Crucible-Verified) supports that either this solves the citation-support problem, or that we need more precise evaluation methods for citation support. We hope that future work will explore a greater variety of RAGE systems across the gamut of RAG and LLM-as-a-Judge paradigms. Disclosure of Interests.Authors have no competing interests. Bibliography [1] Asai, A., Wu, Z., Wang, Y., Sil, A., Hajishirzi, H.: Self-rag: Learning to retrieve, generate, and critique through self-reflection. In: Proceedings of the International Conference on Learning Representations (ICLR) (2024) [2] Bansal, S.: textstat (Jul 2025), URLhttps://github.com/textstat/ textstat [3] Cheng, X., Wang, X., Zhang, X., Ge, T., Chen, S.Q., Wei, F., Zhang, H., Zhao, D.: xrag: Extreme context compression for retrieval-augmented gen- eration with one token. In: Advances in Neural Information Processing Sys- tems (NeurIPS) (2024) [4] Dietz, L.: A workbench for autograding retrieve/generate systems. In: Pro- ceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 1963â€“1972 (2024) [5] Dietz, L., Li, B., Mayfield, J., Lawrie, D., Yang, E., Walden, W.: [hltcoe] hltcoe evaluation team at trec 2025: Rag, ragtime, and dragun. In: The Thirty-Fourth Text REtrieval Conference Proceedings (TREC2025) (2025) [6] Dietz, L., Li, B., Yang, E., Lawrie, D., Walden, W., Mayfield, J.: Insider knowledge: How much can rag systems gain from evaluation secrets? In: Pro- ceedings of the 48th European Conference on Information Retrieval (ECIR 2026) (2026) [7] Duh, K., Yang, E., Weller, O., Yates, A., Lawrie, D.: HLTCOE at LiveRAG: GPT-Researcher using ColBERT retrieval. arXiv preprint arXiv:2506.22356 (2025) [8] Elovic, A.: gpt-researcher (Jul 2023), URLhttps://github.com/ assafelovic/gpt-researcher [9] Farzi, N., Dietz, L.: Exam++: Llm-based answerability metrics for ir evalua- tion.