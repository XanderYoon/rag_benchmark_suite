Svitlana Vakulenko, Shayne Longpre, Zhucheng Tu, and Raviteja Anantha. 2020. Question rewriting for conversational question answering. arXiv preprint arXiv:2004.14652. Xiao Wang, Craig Macdonald, and Iadh Ounis. 2020. Deep reinforced query reformulation for informa- tion retrieval. arXiv preprint arXiv:2007.07987. Peilin Yang, Hui Fang, and Jimmy Lin. 2017. Anserini: Enabling the use of lucene for information retrieval research. In Proceedings of the 40th International ACM SIGIR Conference on Research and Develop- ment in Information Retrieval, pages 1253–1256. Shi Yu, Jiahua Liu, Jingqin Yang, Chenyan Xiong, Paul Bennett, Jianfeng Gao, and Zhiyuan Liu. 2020. Few-shot generative conversational query rewriting. arXiv preprint arXiv:2006.05009. Salah Zaiem and Fatiha Sadat. 2019. Sequence to se- quence learning for query expansion. In Proceed- ings of the AAAI Conference on Artiﬁcial Intelli- gence, Student Abstract Track , volume 33, pages 10075–10076. A More Analysis of Retrieval Performance We show the detailed results of top-k retrieval accu- racy of the compared methods in Figs. 2 and 3. GAR performs comparably or better than DPR when k≥ 100 on NQ and k≥ 5 on Trivia. 1 5 10 20 50 100 200 300 500 1000 k: # of retrieved passages 20 30 40 50 60 70 80 90Top-k Accuracy (%) GAR +DPR DPR GAR BM25 +RM3 BM25 Figure 2: Top-k retrieval accuracy of sparse and dense methods on the test set of NQ. GAR improves BM25 and achieves comparable or better performance than DPR when k≥ 100. 1 5 10 20 50 100 k: # of retrieved passages 50 55 60 65 70 75 80 85Top-k Accuracy (%) GAR +DPR DPR GAR BM25 +RM3 BM25 Figure 3: Top-k retrieval accuracy on the Trivia test set. GAR achieves better results than DPR whenk≥ 5. We show in Table 9 the retrieval accuracy break- down using the question-answer overlap categories. The most signiﬁcant