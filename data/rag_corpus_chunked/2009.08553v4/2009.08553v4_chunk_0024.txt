can be trained in parallel. augmented (thus longer) queries, whose computa- tional complexity is signiﬁcantly lower than other methods with comparable retrieval accuracy. We use Nvidia V100 GPUs and Intel Xeon Plat- inum 8168 CPUs in our experiments. As listed in Table 8, the training time of GAR is 3 to 6 hours on 1 GPU depending on the generation target. As a comparison, REALM (Guu et al., 2020) uses 64 TPUs to train for 200k steps during pre-training alone and DPR (Karpukhin et al., 2020) takes about 24 hours to train with 8 GPUs. To build the indices of Wikipedia passages, GAR only takes around 30 min with 35 CPUs, while DPR takes 8.8 hours on 8 GPUs to generate dense representations and another 8.5 hours to build the FAISS index (John- son et al., 2017). For retrieval, GAR takes about 1 min to generate one query context with 1 GPU, 1 min to retrieve 1,000 passages for the NQ test set with answer/title-augmented queries and 2 min with sentence-augmented queries using 35 CPUs. In contrast, DPR takes about 30 min on 1 GPU. 7 Conclusion In this work, we propose Generation-Augmented Retrieval and demonstrate that the relevant contexts generated by PLMs without external supervision can signiﬁcantly enrich query semantics and im- prove retrieval accuracy. Remarkably, GAR with sparse representations performs similarly or better than state-of-the-art methods based on the dense representations of the original queries. GAR can also be easily combined with dense representa- tions to produce even better results. Furthermore, GAR achieves state-of-the-art end-to-end perfor- mance on extractive OpenQA and competitive per- formance under the generative setup. 8 Future Extensions Potential improvements . There is still much space to explore and improve for GAR in future work. For query context generation, one can ex- plore multi-task learning