be easily combined with dense representa- tions to produce even better results. Furthermore, GAR achieves state-of-the-art end-to-end perfor- mance on extractive OpenQA and competitive per- formance under the generative setup. 8 Future Extensions Potential improvements . There is still much space to explore and improve for GAR in future work. For query context generation, one can ex- plore multi-task learning to further reduce computa- tional cost and examine whether different contexts can mutually enhance each other when generated by the same generator. One may also sample multi- ple contexts instead of greedy decoding to enrich a query. For retrieval, one can adopt more advanced fusion techniques based on both the ranking and score of the passages. As the generator and re- triever are largely independent now, it is also inter- esting to study how to jointly or iteratively optimize generation and retrieval such that the generator is aware of the retriever and generates query contexts more beneﬁcial for the retrieval stage. Last but not least, it is very likely that better results can be ob- tained by more extensive hyper-parameter tuning. Applicability to other tasks . Beyond OpenQA, GAR also has great potentials for other tasks that involve text matching such as conversation utter- ance selection (Lowe et al., 2015; Dinan et al., 2020) or information retrieval (Nguyen et al., 2016; Craswell et al., 2020). The default generation tar- get is always available for supervised tasks. For example, for conversation utterance selection one can use the reference utterance as the default target and then match the concatenation of the conversa- tion history and the generated utterance with the provided utterance candidates. For article search, the default target could be (part of) the ground-truth article itself. Other generation targets are more task- speciﬁc and can be designed as long as they