repre- sentations with respect to the original dataset. Only the queries vary in the oracle setting, as the docu- ments inserted are identical across all runs. These results show that the perturbations in queries scatter the internal representations despite the existence of golden documents. 6 Recommendations As a results of our broad experiments across differ- ent retrievers, generator models (i.e. LLMs) and data perturbation types, we provide evidence based practical recommendations to for the improvement of retrieval augmented generation pipelines. These insights are designed to help developers assess the robustness of their RAG pipelines against differ- ent input transformations, essentially helping de- velopers make robustness-aware decisions while increasing the stability of their system. First, we highlight how different perturbation types have different effects on the modules forming the RAG system and its end-to-end performance. Our experiments showed that certain perturbations and dataset combinations lead to more sensitivity on a specific RAG component. Therefore, we rec- ommend that practitioners use our analysis frame- work on their we recommend that practitioners use our analysis framework on their own data for a better diagnosis of sensitivity in their pipeline. We acknowledge that the robustness of the gen- erators is generally assessed in the closed-book set- ting without their use in a RAG pipeline. However, as our results show, certain query perturbations affect the response generation differently when documents are presented in the context window of the generator. Therefore, we recommend that practitioners assess the robustness of the response generation in their systems, especially in an oracle setting, as this setting estimates an upper bound for the system. Furthermore, there is an active field of study in- vestigating the training of retrieval augmented gen- eration systems where the retriever and the LLM are jointly trained (Lin et al., 2024). These sys- tems benefit from