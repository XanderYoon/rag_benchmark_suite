al., 2018), NQ(Kwiatkowski et al., 2019a) and BioASQ(Tsatsaronis et al., 2015).(PERT: Number of perturbed samples for each perturbation type) et al., 2024a,b). These studies primarily aim to ensure that the modelâ€™s outputs remain accurate and consistent despite possible noise or adversarial modifications in the prompt. Pipeline-Level Robustness A further line of re- search adopts a holistic view of RAG, focusing on how noise in retrieved documents-such as irrel- evant passages or misinformation-affects overall performance, proposing methods to mitigate these issues (Chen et al., 2023; Fang et al., 2024; Hu et al., 2024; Yoran et al., 2024; Xiang et al., 2024; Shen et al., 2024; Han et al., 2023). For example, Chen et al. (2023) tests whether the model can ig- nore non-relevant content or misinformation and, if necessary, refuse to answer when the retrieved context is unreliable. Approaches such as Fang et al. (2024) and Yoran et al. (2024) investigate var- ious types of erroneous or irrelevant information in RAG and introduce new training techniques to counteract performance degradation. In addition, Xiang et al. (2024) considers scenarios in which some retrieved documents may have been mali- ciously altered, presenting a defense mechanism. Despite these efforts, many studies focus on ei- ther the retriever or the overall RAG workflow with- out systematically analyzing how each component behaves under diverse query perturbations. By con- trast, we conduct a more comprehensive analysis spanning the entire RAG pipeline and propose a new framework that offers a clearer, more intuitive assessment of system robustness. 3 Data Perturbations We investigate strategies to systematically evaluate the robustness of the RAG pipeline under different input perturbations that commonly appear in real- world applications. For each type of perturbation, we also quantify how the performance of different modules in the RAG pipeline changes. We focus on perturbations that do