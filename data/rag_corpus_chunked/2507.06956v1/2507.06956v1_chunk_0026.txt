Processing , pages 8988– 9003. Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, and Denny Zhou. 2023. Large language models can be easily distracted by irrelevant context. Preprint, arXiv:2302.00093. Georgios Sidiropoulos and Evangelos Kanoulas. 2022. Analysing the robustness of dual encoders for dense retrieval against misspellings. In Proceedings of the 45th International ACM SIGIR Conference on Re- search and Development in Information Retrieval , pages 2132–2136. Jiuding Sun, Chantal Shaib, and Byron C. Wallace. 2023. Evaluating the zero-shot robustness of instruction- tuned language models. Preprint, arXiv:2306.11270. Qwen Team. 2024. Qwen2.5: A party of foundation models. Nandan Thakur, Nils Reimers, Andreas Rücklé, Ab- hishek Srivastava, and Iryna Gurevych. 2021. Beir: A heterogenous benchmark for zero-shot evalua- tion of information retrieval models. Preprint, arXiv:2104.08663. George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Michael Alvers, Dirk Weißenborn, Anastasia Krithara, Sergios Petridis, Dimitris Polychronopou- los, Yannis Almirantis, John Pavlopoulos, Nico- las Baskiotis, Patrick Gallinari, Thierry Artieres, Axel-Cyrille Ngonga Ngomo, Norman Heino, Eric Gaussier, Liliana Barrio-Alvers, and Georgios Paliouras. 2015. An overview of the bioasq large- scale biomedical semantic indexing and question an- swering competition. BMC Bioinformatics, 16:138. Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and Furu Wei. 2024. Multilin- gual e5 text embeddings: A technical report. arXiv preprint arXiv:2402.05672. Chong Xiang, Tong Wu, Zexuan Zhong, David Wag- ner, Danqi Chen, and Prateek Mittal. 2024. Certifi- ably robust rag against retrieval corruption. Preprint, arXiv:2405.15556. Shitao Xiao, Zheng Liu, Peitian Zhang, Niklas Muen- nighoff, Defu Lian, and Jian-Yun Nie. 2024. C-pack: Packed resources for general chinese embeddings. Preprint, arXiv:2309.07597. Guicai Xie, Ke Zhang, Lei Duan, Wei Zhang, and Ze- qian Huang. 2024. Typos correction training against misspellings from text-to-text transformers. In Pro- ceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and