Pearson correla- tion scores between the retriever, generator, and end-to-end performances. First, the performance discrepancy between each perturbed sample and its original non-perturbed counterpart was deter- mined using the metrics "Recall@5" for retrievers and "Match" for generator and end-to-end perfor- mances. The Pearson correlation coefficients cal- culated for retrieval-RAG and generator-RAG set- tings can be found in Table 2 for the BGE-Base re- triever in combination with Llama 3.1-8B-Instruct for the BioASQ and NQ datasets. The results ob- tained with different modules are reported in Table 5 and 6. The correlation scores indicate that different dominant factors exist within the pipeline for dif- ferent perturbation types. For example, in the case of BioASQ dataset for instances involving typo perturbations, the end-to-end results demonstrate a stronger correlation with retriever performance. Conversely, in cases of ambiguity, formal tone change, and redundancy insertion, generator-only settings exhibit higher scores. When these find- ings are compared to the coefficients calculated on the NQ using the same pipeline, we see that the results on NQ correlate more with the retriever performance differences. This also validates our observations that the results for the NQ dataset are mainly defined by the retriever trends. The find- ings of this study demonstrate the potential of such an analysis to assist practitioners in identifying the module within their pipeline that exhibits particular sensitivity to a specific perturbation types. Internal LLM Representations: Lastly, we in- spected the internal representations of the LLMs and analyzed how they differ when faced with var- ious perturbations. For this analysis, we focused on the BioASQ dataset in oracle and RAG settings with BGE-Base as the retriever. We gathered the inputs given to the LLM and obtained an internal representation for these inputs by averaging over all attention heads of Llama-3.1-8B-Instruct for the last hidden state layer