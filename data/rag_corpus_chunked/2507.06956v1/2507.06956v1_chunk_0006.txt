offers a clearer, more intuitive assessment of system robustness. 3 Data Perturbations We investigate strategies to systematically evaluate the robustness of the RAG pipeline under different input perturbations that commonly appear in real- world applications. For each type of perturbation, we also quantify how the performance of different modules in the RAG pipeline changes. We focus on perturbations that do not significantly alter the semantic meaning of the query in practical RAG use cases while having a high chance of occurrence. Specifically, given an original queryq, we apply a perturbation Perturb(q) such that Perturb(q) re- tains the same or very similar semantics as q. In this work, we generate the perturbed samples in two ways: either via prompting an LLM or by in- serting random typos. 3.1 Perturbations Via Prompting To enable large-scale evaluation of the perturba- tions, this first category uses the LLM GPT-4o as a data generator to produce synthetically perturbed samples. This approach is motivated by the obser- vation that LLMs are very successful at processing textual input and are widely used for the genera- tion of synthetic data as well as adversarial exam- ples. Additional details on the evaluation of the generated samples, along with the prompts used to generate them, can be found in Appendix A.2. We investigate three under-explored query per- turbations in the context of RAG. For a query taken from the HotpotQA dataset, we provide examples corresponding to each perturbation. The original non-perturbed sample is shown below. "when does the cannes film festival take place" Redundancy Insertion This perturbation type reflects the cases where a user inserts elements into their queries which do not add additional value or information that will help the system in response generation. "Iâ€™m curious to know the specific dates or time frame for the Cannes Film Festival,