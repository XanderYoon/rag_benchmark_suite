and twelve RAG pipelines which span four retrievers and three LLM generators. Our experi- ments probing these pipelines with five perturba- tion types show that slight variations in the input queries can result in significant performance dis- crepancies. Our analysis framework enables the investiga- tion of RAG module sensitivity to query perturba- Figure 5: Representation of samples taken from Llama-3.1-8B-Instruct for the BioASQ dataset for the oracle (upper) and RAG with BGE Base (lower) settings. The Match performance of the original non-perturbed performances for oracle and RAG (with BGE Base) are 0.71 and 0.61 respectively. tions jointly and in isolation. Using this framework, we provide practical insights and recommendations for the development of RAG systems. We hope that our work brings greater attention to the im- portance of robustness research at the query level while contributing to the development of future robustness-aware retrieval augmented generation pipelines. Limitations Due to computational and time limitations, our ex- periments are constrained to have a limited context window length, number of output tokens generated, and maximum length defined for each text pas- sage inserted into the inference of the LLMs. We acknowledge the limitations of our system and pro- vide a comparative analysis between the pipeline combinations. Hence, the exploration of the hy- perparameter space to formulate optimal pipeline configurations remains a potential avenue for fu- ture research. This search also includes the prompt tuning for sample generation and question answer- ing. In future work, prompts will be further tuned to meet the characteristics of datasets better. Furthermore, we kept our pipeline simple to pro- vide researchers with a framework to evaluate their own system. With the same aim and to reflect the scenario where there is limited computational power and high-quality annotated data, we chose to use retrievers and LLMs directly without applying