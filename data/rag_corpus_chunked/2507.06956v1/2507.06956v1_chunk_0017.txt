and analyzed how they differ when faced with var- ious perturbations. For this analysis, we focused on the BioASQ dataset in oracle and RAG settings with BGE-Base as the retriever. We gathered the inputs given to the LLM and obtained an internal representation for these inputs by averaging over all attention heads of Llama-3.1-8B-Instruct for the last hidden state layer calculated for the last non- padding token. As the vLLM framework utilized in the experimental setup does not permit straightfor- ward access to the internal representations of the LLMs, we obtained them by employing the Hug- gingface deployment of these models and evaluated the results again using BERGEN (Rau et al., 2024) framework. Type R F A T10 T25 BioASQ RET 0.05 0.04 0.15 0.21↑ 0.23↑ CB 0.21 0.08 0.23 0.05 0.10 OR 0.35↑ 0.15↑ 0.33↑ 0.04 0.12 NQ RET 0.31↑ 0.27↑ 0.30↑ 0.35↑ 0.40↑ CB 0.03 0.04 0.11 0.08 0.16 OR 0.11 0.14 0.15 0.06 0.03 Table 2: Pearson correlation coefficients for BioASQ and NQ dataset and BGE Base as retriever. (R: Re- dundancy, F: Formal Tone, A: Ambiguity, TX: Typo %X; Correlations: RET: Retriever-RAG, CB: Closed Book-RAG, OR: Oracle-RAG) We visualize these representations by project- ing them onto a two-dimensional space using PCA for dimensionality reduction. The representations are shown in Figure 5 for different types of per- turbations. For both settings, we observe similar trends where the introduction of redundancy and ambiguity results in more scattered internal repre- sentations with respect to the original dataset. Only the queries vary in the oracle setting, as the docu- ments inserted are identical across all runs. These results show that the perturbations in queries scatter the internal representations despite the existence of golden documents. 6 Recommendations As a results of our broad experiments across differ- ent retrievers, generator models (i.e.