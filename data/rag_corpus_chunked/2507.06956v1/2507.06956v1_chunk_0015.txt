joint effect of combining different elements to form an end-to-end RAG sys- tem. This setting differs from the oracle experi- ments defined earlier in that the system includes a non-ideal retriever which can return irrelevant documents. Figure 4 and 9 display the average end-to-end results of the pipeline reported in "Match" metric. Each window incorporates a single retrieverâ€™s data while different generator combinations are colored accordingly. The red curve on the plots shows the retrieval scores using the Recall@5 metric while the horizontal axis shows the perturbation types. These results indicate that the performance trends observed under various perturbations are pre- dominantly characterized by the performance of the retriever. This is most evidently demonstrated in the case of the NQ dataset, as illustrated in Figure Figure 4: The average end-to-end results on NQ dataset according to "Match" metric. 4, where the RAG outcomes manifest as retriever performance trends. However, it is evident that the retriever performance is not fully reflected in the end-to-end performance on the BioASQ dataset when BGE Base or Contriever is used in combina- tion with different LLMs, as shown in Figure 9. In this scenario, despite the low performance changes observed in the retriever performance, RAG perfor- mance exhibits significant declines, particularly in the cases of ambiguity and redundancy introduc- tions. To further explore the underlying causes of these observations, we conduct a more in-depth analysis. Correlation to the Individual Module Perfor- mances: We investigated the Pearson correla- tion scores between the retriever, generator, and end-to-end performances. First, the performance discrepancy between each perturbed sample and its original non-perturbed counterpart was deter- mined using the metrics "Recall@5" for retrievers and "Match" for generator and end-to-end perfor- mances. The Pearson correlation coefficients cal- culated for retrieval-RAG and generator-RAG set- tings can be found in Table 2 for