of the analysis of this work. This also includes the analysis of another cat- egory of methods in relation to query perturbations, namely the query transformations. The robustness of these methods and their effect within the scope of RAG pipelines when faced with various input variations are not addressed in this study. Lastly, while the investigation of LLM internal represen- tations under different perturbations is included in our analysis, its dedicated in-depth analysis is still of interest as a promising research direction. We recognize that the absence of these points in our analysis is a limitation and will address these approaches as a part of our future study. References Negar Arabzadeh, Radin Hamidi Rad, Maryam Khod- abakhsh, and Ebrahim Bagheri. 2023. Noisy per- turbations for estimating query difficulty in dense retrievers. In Proceedings of the 32nd ACM Inter- national Conference on Information and Knowledge Management, pages 3722–3727. Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun. 2023. Benchmarking large language mod- els in retrieval-augmented generation. Preprint, arXiv:2309.01431. Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xi- aojun Chen, and Ruifeng Xu. 2024. Enhancing noise robustness of retrieval-augmented language models with adaptive adversarial training. Preprint, arXiv:2405.20978. Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al- Dahle, Aiesha Letman, Akhil Mathur, Alan Schel- ten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mi- tra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, and 542 others. 2024. The llama 3 herd of models. Preprint, arXiv:2407.21783. Rujun Han, Peng Qi, Yuhao Zhang, Lan Liu, Juliette Burger, William Yang Wang, Zhiheng Huang, Bing Xiang, and Dan Roth. 2023. Robustqa: Benchmark- ing the robustness of domain adaptation for open- domain question answering. In Findings of the As- sociation for Computational Linguistics: ACL 2023, pages 4294–4311. Jennifer Hsia, Afreen Shaikh, Zhiruo