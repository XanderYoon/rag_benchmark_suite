designed in CRAG demonstrates the advantages of being quite lightweight (0.77B). Algorithm 1: CRAG Inference Require :E (Retrieval Evaluator), W (Query Rewriter), G (Generator) Input : x (Input question), D = {d1, d2, ..., dk} (Retrieved documents) Output : y (Generated response) 1 scorei = E evaluates the relevance of each pair (x, di), di âˆˆ D 2 Confidence = Calculate and give a final judgment based on {score1, score2, ...scorek} // Confidence has 3 optional values: [CORRECT], [INCORRECT] or [AMBIGUOUS] 3 if Confidence == [CORRECT] then 4 Internal_Knowledge = Knowledge_Refine(x, D) 5 k = Internal_Knowledge 6 else if Confidence == [INCORRECT] then 7 External_Knowledge = Web_Search(W Rewrites x for searching) 8 k = External_Knowledge 9 else if Confidence == [AMBIGUOUS] then 10 Internal_Knowledge = Knowledge_Refine(x, D) 11 External_Knowledge = Web_Search(W Rewrites x for searching) 12 k = Internal_Knowledge + External_Knowledge 13 end 14 G predicts y given x and k 4.3 Action Trigger To correct the irrelevant documents and refine the target documents as needed, actions should be exe- cuted discriminately. Based on the aforementioned confidence score for each retrieved document, three types of actions are designed and triggered accord- ingly where the upper and lower thresholds are set. If the confidence score is higher than the upper threshold, the retrieved document is identified as Correct, while identified as Incorrect if below the lower threshold. Otherwise, a more soft and intermediate action, i.e., Ambiguous is executed. Each retrieved document is conducted individually and integrated eventually. Correct Here, a retrieval is assumed Correct when the confidence score of at least one retrieved document is higher than the upper threshold. If so, it means that there are relevant documents in the retrieved results, and the knowledge from the retrieval results is supposed to be more reliable and accurate. However, even if