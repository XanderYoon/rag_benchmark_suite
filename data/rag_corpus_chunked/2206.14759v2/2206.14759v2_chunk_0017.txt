53.45 ±32.14 monoBERT 23.08±28.71 23.58 ±28.22 46.97 ±34.95 47.11 ±35.49 41.79 ±36.16 42.48 ±36.39 monoT5 20.13 ±26.77 20.15 ±26.64 35.68 ±31.69 36.46 ±31.88 29.86 ±28.24 30.31 ±28.27 PACRR 42.41 ±44.86 42.43 ±44.67 35.79 ±33.71 36.28 ±33.83 34.76 ±36.45 35.70 ±36.87 T est leak. Duet 90.04 ±26.98 90.65 ±26.41 45.78 ±30.03 46.55 ±30.34 46.31 ±29.85 46.35 ±30.13 KNRM 89.95 ±26.43 91.20 ±25.24 47.37 ±32.80 47.49 ±32.81 50.53 ±32.40 50.13 ±32.26 monoBERT 47.01±31.84 47.39 ±31.80 46.64 ±31.51 47.12 ±31.51 43.19 ±31.51 44.04 ±31.66 monoT5 45.28 ±32.09 45.37 ±31.96 46.35 ±31.47 47.45 ±31.83 40.16 ±31.18 40.95 ±31.24 PACRR 80.89 ±34.05 82.60 ±33.07 53.59 ±31.49 52.91 ±31.26 52.25 ±32.69 52.28 ±32.32 Table 5 shows the ﬁve-fold cross-validated eﬀectiveness on the TREC 2018 CommonCore track fortheﬁvemodelswhenoptimizing eachfold fornDCG@10, MFR, or Precision@1 in a grid search. In contrast to Robust04 and the 2017 edi- tion of the Common Core track, training with MSM leakage improves the eﬀec- tiveness in all cases for all three measures. While most of the leakage-induced eﬀectiveness improvements are not statistically signiﬁcant, the model order even changes on the top MFR position, where PACRR with MSM leakage would overtake monoT5 without leakage. Discussion. The results in Tables 3–5 show that leakage from MS MARCO / ORCAS(MSM)canhaveanimpactontheretrievaleﬀectiveness,evenwhenonly a small number of instances are leaked, as in our experiments. While the changes on Robust04 are rather negligible, the impact is larger for the Common Core tracks with document publication dates closer to the ones from MS MARCO. In- terestingly, MSM leakage-induced nDCG@10 improvements sometimes can lead to swaps in model ordering despite the improvements not being signiﬁcant in most cases. This exempliﬁes that experimental eﬀectiveness comparisons might be invalid when some models had access to leaked instances during training. Memorization of Leaked Instances.To analyze whether the models memorize leaked instances, we compare the retrieval