L., Graesser, L., Nangia, N., Evci, U.: Natural language under- standing with the Quora question pairs dataset. CoRRabs/1907.01041 (2019) [41] Shokri, R., Stronati, M., Song, C., Shmatikov, V.: Membership inference attacks against machine learning models. In: Proc. of SP 2017, pp. 3–18, IEEE (2017) [42] Voorhees, E.: The TREC Robust Retrieval track. SIGIR Forum39(1), 11– 20 (2005) [43] Wahle, J.P., Ruas, T., Meuschke, N., Gipp, B.: Are neural language models good plagiarists? A benchmark for neural paraphrase detection. In: Proc. of JCDL 2021, pp. 226–229 (2021) [44] Xiong, C., Dai, Z., Callan, J., Liu, Z., Power, R.: End-to-end neural ad- hoc ranking with kernel pooling. In: Proc. of SIGIR 2017, pp. 55–64, ACM (2017) 16 Fröbe et al. [45] Yates, A., Arora, S., Zhang, X., Yang, W., Jose, K., Lin, J.: Capreolus: A toolkit for end-to-end neural ad hoc retrieval. In: Proc. of WSDM 2020, pp. 861–864, ACM (2020) [46] Zhan, J., Xie, X., Mao, J., Liu, Y., Zhang, M., Ma, S.: Evaluating extrap- olation performance of dense retrieval. CoRRabs/2204.11447 (2022) [47] Zhang, X., Yates, A., Lin, J.: A little bit is worse than none: Ranking with limited training data. In: Proc. of SustaiNLP 2020, pp. 107–112, Association for Computational Linguistics (2020) [48] Zobel, J., Rashidi, L.: Corpus bootstrapping for assessment of the properties of eﬀectiveness measures. In: Proc. of CIKM 2020, pp. 1933–1952, ACM (2020)