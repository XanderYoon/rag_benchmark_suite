to answer user questions or synthesize comprehensive, multi-modal research reports. The open-source release of HetaRAG currently offers the following core features: •Multimodal document parsing: decomposing the input document into semantically dis- tinct segments—text, images, tables, mathematical formulas, etc. •Heterogeneous storage index construction: simultaneous indexing into vector databases, knowledge graphs, full-text engines, and relational databases. •Deep research report generation: transforms unstructured documents into verified, query-aligned Markdown reports by fusing text, tables, and visuals via LLM synthesis and vector retrieval. •Complex question answering via iterative, reasoning: iteratively rewrites queries and retrieves evidence until a coherent, cross-source answer emerges. 2 Related Work 2.1 Bottlenecks and Drivers for RAG System Improvement With the development of large language models (LLMs), retrieval-augmented generation (RAG) has become a crucial approach to addressing knowledge staleness and reducing hallucinations. How- ever, practical applications still face several challenges. First, there exists a knowledge conflict issue, where retrieved content may contradict internal model knowledge, leading to unfaithful or erroneous outputs [1, 2]. Second, noise interference and irrelevant information significantly degrade output quality due to redundant or misleading documents [3, 4]. In multi-hop question-answering tasks, reasoning path deviation and cascading errors can lead to systemic failures in subsequent retrieval and generation steps [5, 6]. Moreover, most RAG systems lack effective dynamic retrieval mecha- nisms, failing to determine when retrieval is necessary, which affects response efficiency [7, 8, 9]. Finally, knowledge boundary identification remains inadequate, as many models cannot effectively respond with “I don’t know” when facing questions beyond their knowledge scope [10, 8]. 2 2.2 Technological Pathways to Address RAG Challenges To tackle these challenges, recent studies have proposed various technical approaches. Preference modeling and gain assessment have emerged as promising strategies for improving paragraph fil- tering accuracy, exemplified by GainRAG, which quantifies the contribution of each paragraph to the correct answer