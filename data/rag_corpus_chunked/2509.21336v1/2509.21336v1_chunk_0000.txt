HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores Guohang Yan, Yue Zhang, Pinlong Cai ∗, Ding Wang, Song Mao, Hongwei Zhang Yaoze Zhang, Hairong Zhang, Xinyu Cai, Botian Shi ∗ Shanghai Artificial Intelligence Laboratory, Shanghai, China Abstract:Retrieval-augmented generation (RAG) has become a dominant paradigm for mitigating knowledge hallucination and staleness in large language models (LLMs) while preserving data security. By retrieving relevant evidence from private, domain-specific corpora and injecting it into carefully engineered prompts, RAG delivers trustworthy responses without the prohibitive cost of fine- tuning. Nevertheless, existing systems remain brittle when confronted with (i) multimodal evidence that spans text, images, and structured graphics; (ii) com- plex queries requiring compositional reasoning over long, noisy contexts; and (iii) continuously evolving knowledge scattered across heterogeneous corpora. Tra- ditional retrieval-augmented generation (RAG) systems are text-only and often rely on a single storage backend—typically a vector database. In practice, this monolithic design suffers from unavoidable trade-offs: vector search captures se- mantic similarity yet loses global context; knowledge graphs excel at relational precision but struggle with recall; full-text indexes are fast and exact yet se- mantically blind; and relational engines such as MySQL provide strong trans- actional guarantees but no semantic understanding. We argue that these hetero- geneous retrieval paradigms are complementary, and propose a principled fusion scheme to orchestrate them synergistically, mitigating the weaknesses of any sin- gle modality. In this work we introduce HetaRAG, a hybrid, deep-retrieval aug- mented generation framework that orchestrates cross-modal evidence from hetero- geneous data stores. HetaRAG handles multimodal documents—text, diagrams, tables, mathematical notation, and more—and performs sophisticated, compo- sitional reasoning over long-form, noisy contexts. We plan to design a system that unifies vector indices, knowledge graphs, full-text engines, and structured databases into a single retrieval plane, dynamically routing and fusing evidence to maximize recall, precision, and contextual fidelity.