frameworks use multi-agent collaboration to integrate historical retrieval results, dynamically adjust queries, and filter noise, thus improving retrieval efficiency and quality [17]. Additionally, self-refinement mechanisms play a role in formalization tasks, with LTRAG building a thought-guided knowledge base to assist the formalization process and integrating symbolic solvers for dynamic optimization [18]. 2.4 Graph Enhancement and Structured Knowledge Modeling Structured knowledge sources, such as knowledge graphs and causal graphs, are playing an increas- ingly important role in RAG. SimGRAG transforms user queries into structured graph patterns and uses graph semantic distance to measure matching accuracy, thereby improving knowledge graph- driven retrieval effectiveness [19]. GEAR introduces a graph expansion mechanism (SyncGE) com- bined with a multi-step retrieval agent framework to support diverse path exploration in multi-hop QA tasks [20]. FRAG customizes retrieval workflows for queries of varying complexity, leveraging KG to provide explicit entity relationship support [21]. CausalRAG further introduces causal graphs to guide information filtering during retrieval, enhancing contextual coherence and reasoning accu- racy [22]. RAKG effectively addresses cross-document relation extraction and entity disambigua- tion by introducing a RAG-based document-level pre-entity retrieval and knowledge construction pipeline, enhancing knowledge graph accuracy [23].These methods collectively push RAG toward structured knowledge fusion and graph-enhanced reasoning. 2.5 Cross-modal and Fine-grained Retrieval As application scenarios expand, RAG is gradually extending into visual, tabular, and multi-modal domains. Fine-Grained VQA-RAG proposes a multi-modal knowledge unit (KU) combining im- ages and textual descriptions to achieve zero-shot cross-modal retrieval and reasoning [24].VaLiK leverages vision-language models for image-text alignment and semantic verification, enabling unla- beled multimodal knowledge graph construction to enhance LLM reasoning [25]. CoRE Framework focuses on structured data processing (e.g., tables), generating experience trajectories via Monte Carlo Tree Search (MCTS) and combining contrastive prompt design to enhance model reasoning [26]. Additionally, PIC chunking method proposes pseudo-instruction-based semantic segmenta- tion