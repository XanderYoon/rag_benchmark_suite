Mao, P. Cai, G. Yan, Y . Chen, Z. Bian, B. Shi, and D. Wang. Aligning vision to language: Text-free multimodal knowledge graph construction for enhanced llms reasoning.arXiv preprint arXiv:2503.12972, 2025. [26] J. Gu, Z. Xian, Y . Xie, Y . Liu, E. Liu, R. Zhong, M. Gao, Y . Tan, B. Hu, and Z. Li. Toward structured knowledge reasoning: Contrastive retrieval-augmented generation on experience. arXiv preprint arXiv:2506.00842, 2025. [27] A. A. submission. Document segmentation matters for retrieval-augmented generation.open- review, 2025. [28] S. Liu, X. Li, Z. Liu, Y . Yan, C. Yang, Z. Zeng, Z. Liu, M. Sun, and G. Yu. Judge as a judge: Improving the evaluation of retrieval-augmented generation through the judge-consistency of large language models.arXiv preprint arXiv:2502.18817, 2025. [29] T. Hwang, S. Cho, S. Jeong, H. Song, S. Han, and J. C. Park. Exit: Context-aware extractive compression for enhancing retrieval-augmented generation.arXiv preprint arXiv:2412.12559, 2024. [30] W. Hu, W. Zhang, Y . Jiang, C. J. Zhang, X. Wei, and Q. Li. Removal of hallucination on hallucination: Debate-augmented rag.arXiv preprint arXiv:2505.18581, 2025. [31] Z. Wang, J. Yu, D. Ma, Z. Chen, Y . Wang, Z. Li, F. Xiong, Y . Wang, L. Tang, W. Zhang, et al. Rare: Retrieval-augmented reasoning modeling.arXiv preprint arXiv:2503.23513, 2025. [32] X. Jiang, Y . Fang, R. Qiu, H. Zhang, Y . Xu, H. Chen, W. Zhang, R. Zhang, Y . Fang, X. Chu, et al. Tc-rag: Turing-complete ragâ€™s case study on medical llm systems.arXiv preprint arXiv:2408.09199, 2024. [33] J. Chen, A. Myrzakhan, Y . Luo, H. M. Khan, S. M. Bsharat, and Z. Shen. Drag: Distilling rag for slms from llms to transfer knowledge and mitigate hallucination via evidence and graph- based distillation.arXiv preprint arXiv:2506.01954, 2025. 13 [34] A. A. submission. Unirag: Unified query understanding method for retrieval augmented gen- eration.openreview, 2025. [35]