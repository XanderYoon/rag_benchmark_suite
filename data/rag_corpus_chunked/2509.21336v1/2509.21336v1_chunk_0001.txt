cross-modal evidence from hetero- geneous data stores. HetaRAG handles multimodal documents—text, diagrams, tables, mathematical notation, and more—and performs sophisticated, compo- sitional reasoning over long-form, noisy contexts. We plan to design a system that unifies vector indices, knowledge graphs, full-text engines, and structured databases into a single retrieval plane, dynamically routing and fusing evidence to maximize recall, precision, and contextual fidelity. To achieve this design goal, we carried out preliminary explorations and constructed an initial RAG pipeline; this technical report provides a brief overview. The partial code is available at https://github.com/KnowledgeXLab/HetaRAG. Keywords:retrieval-augmented generation, heterogeneous data stores, deep re- trieval, large language model 1 Introduction With the rapid development of information technology and the explosion of data volume, efficiently acquiring and utilizing knowledge has become crucial for the advancement of intelligent systems. A knowledge engine, as a decision-support system that integrates data, models, and inference rules, plays an essential role in transforming unstructured and non-centralized data into structured knowl- edge, enabling effective information retrieval, reasoning, and decision-making in specific domains. ∗Corresponding authors arXiv:2509.21336v1 [cs.IR] 12 Sep 2025 In recent years, large language models have demonstrated remarkable capabilities in natural lan- guage understanding and generation. However, when applied to specialized domains or high- precision tasks, these models often lack sufficient factual grounding, resulting in unreliable or inac- curate outputs. Therefore, integrating external knowledge sources with large language models has become essential to enhance their practical applicability. By leveraging a knowledge engine capable of providing accurate and multimodal information, large language models can better perform infor- mation extraction, retrieval matching, and content generation—ultimately improving the efficiency and quality of knowledge processing. Despite the availability of several knowledge engine products, these systems still exhibit notable limitations. For instance, they are primarily designed for individual users uploading small volumes of documents, with limited scalability in document