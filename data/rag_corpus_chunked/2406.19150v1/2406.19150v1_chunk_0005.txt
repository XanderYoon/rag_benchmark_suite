et al., 2020), RAG (Lewis et al., 2020), and FiD (Izacard and Grave, 2021). By retrieving and conditioning on relevant Wikipedia passages, these models can better perform knowledge-intensive downstream tasks like question answering. Over- all, retrieval augmentation has proven to be a highly effective way of injecting knowledge into language models to improve their capabilities. The techniques have progressed from simple cor- pus retrieval to integrated and scalable architec- tures that retrieve from large knowledge bases like Wikipedia. Figure 1: Illustration of our RA VEN framework. Given an input image, we retrieve image-text pairs from an external memory. Subsequently, we use a multitask pretrained base vision-language model (VLM) to encode the retrieved samples along with the query and decode to generate an output by attending over both the query and retrieved samples. 2.3 Retrieval Augmented Generation in VLMs Recent years have seen significant progress in ex- tending retrieval-augmented generation to vision- language models. One of the earliest works is Multimodal Retrieval-Augmented Transformer (MuRAG) which utilizes non-parametric multi- modal memory for language generation improve- ment (Chen et al., 2022a). In image-to-text genera- tion, Smallcap (Ramos et al., 2023b), exhibits com- petitive performance on COCO and other domains through retrieval from target-domain data. Sarto et al.(Sarto et al., 2022) use kNN memory for image captioning, enhancing knowledge retrieval from external corpora. Re-ViLM (Yang et al., 2023), built upon the Flamingo (Alayrac et al., 2022), and supports retrieving the relevant knowledge from the external database for zero and in-context few- shot image-to-text generations. Recently, Iscen et al. (Iscen et al., 2023) proposed to equip con- trastive vision-text models with the ability to refine their embedding with cross-modal retrieved infor- mation from a memory at inference time, which greatly improved their zero-shot predictions. Hu et al. (Hu et al., 2023) presented REVEAL that learns