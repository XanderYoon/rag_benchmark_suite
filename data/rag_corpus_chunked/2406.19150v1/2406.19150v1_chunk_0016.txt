proved less useful (see Table 3), we hypothesize that captions serve as good aux- iliary information in image-to-text tasks, while similar/retrieved images are less informative, since the content of the image and the objects contained is often very correlated with the question and an- swer. Therefore, in the VQA ablations, we exclu- sively consider text concatenation scenarios. This involves combining one or more of the top cap- tion, all captions, and alt text when available. In instances where the retrieved sample is missing, we concatenate with an empty string. Retrieval Modality MSCOCO NoCaps Image Text # of Parameters Ablation Description BLEU@4 CIDEr CIDEr Our Approach (Image, Text, Image+Text Retrieval) - - - retrieval only 0.1905 74.98 71.68 - - 182M zero shot in-context retrieval with top caption + all captions0.3777 128.91 103.99 - - 182M no retrieved samples 0.4102 137.25 106.69 - ✓ 182M top caption 0.4102 138.23* (+0.98) 109.76 - ✓ 182M alt text 0.4125 137.19 106.81 - ✓ 182M all captions concatenated 0.4057 137.70 109.72 - ✓ 182M top caption + all captions 0.4108 138.17* (+0.92)111.00 (+ 4.31) - ✓ 182M top caption + all captions + alttext 0.4104 138.03 109.88 ✓ - 182M image 0.4087 136.95 106.22 ✓ ✓ 182M image + top caption + all captions 0.4081 136.85 107.28 Image Captioning Baselines (Fine-tuning) - - 420M Re-ViLM (base, (Yang et al., 2023)) 0.378 129.1 105.2 - - 364M Flamingo (base, re-implementation from (Yang et al., 2023))0.370 128.0 102.8 - - 252M BLIPCapFilt-L(Li et al., 2022) 0.404 136.7 113.2 - - 172M VL-T5 (Cho et al., 2021) 0.346 116.1 4.4 - - 1.4B SimVLM (huge, (Wang et al., 2021)) 0.406 143.3 110.3 - - 5.1B GIT2 (current SOTA (Wang et al., 2022a)) 0.432 146.4 126.9 *Gain with respect to the non retrieved baseline is comparable to the