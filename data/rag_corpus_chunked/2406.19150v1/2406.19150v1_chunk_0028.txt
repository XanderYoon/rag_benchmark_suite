Dai, Yu- lia Tsvetkov, and Yuan Cao. 2021. Simvlm: Simple visual language model pretraining with weak super- vision. arXiv preprint arXiv:2108.10904. Zhuolin Yang, Wei Ping, Zihan Liu, Vijay Kor- thikanti, Weili Nie, De-An Huang, Linxi Fan, Zhid- ing Yu, Shiyi Lan, Bo Li, et al. 2023. Re-vilm: Retrieval-augmented visual language model for zero and few-shot image captioning. arXiv preprint arXiv:2302.04858. Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023. Retrieval- augmented multimodal language modeling. In Pro- ceedings of the 40th International Conference on Machine Learning, ICML’23. JMLR.org. Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason Corso, and Jianfeng Gao. 2020. Unified vision- language pre-training for image captioning and vqa. In Proceedings of the AAAI conference on artificial intelligence, pages 13041–13049. Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592.