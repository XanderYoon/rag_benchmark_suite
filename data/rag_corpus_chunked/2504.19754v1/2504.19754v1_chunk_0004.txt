models to evaluate their impact on retrieval accuracy and downstream performance in RAG systems. 3.1 RQ#1: Early or Late Chunking? In this workflow, the main architectural modification compared to the standard RAG lies in the document embedding process Figure 3.1. Specifically, we experi- ment with various embedding models to encode document chunks, tailoring them 3 https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_ chunking/ 4 J. Singh and C. Merola to align with the early and late chunking strategies under evaluation. This ad- justment allows us to explore how different embedding techniques influence the retrieval quality and, subsequently, the overall performance of the RAG system. Additionally, we test dynamic segmenting models to further refine the chunk- ing process, providing an adaptive mechanism that adjusts chunk sizes based on content characteristics. By evaluating the impact of these dynamic segmenting models,weaimtoimprovetheoverallretrievalefficiencyandresponsegeneration within the RAG framework. Early Chunking. Documents are segmented into text chunks, and each chunk is processed by the embedding model. The model generates token-level embed- dings for each chunk, which are subsequently aggregated using mean pooling to produce a single embedding per chunk. Late Chunking. Late chunking [9] defers the chunking process. As shown in Figure 3.1, instead of segmenting the document initially, the entire document is first embedded at the token level. The resulting token embeddings are then segmentedintochunks,andmeanpoolingisappliedtoeachchunktogeneratethe final embeddings. This approach preserves the full contextual information within the document, potentially leading to superior results across various retrieval tasks. It is adaptable to a wide range of long-context embedding models and can be implemented without additional training. The two approaches are tested with different embedding models. 3.2 RQ#2: Early or Contextual Chunking? In this workflow, traditional retrieval is compared to Contextual Retrieval with Rank Fusion technique. This has been introduced by Anthropic in September 2024.4 Three steps are added to the Traditional RAG process: Contextualization,