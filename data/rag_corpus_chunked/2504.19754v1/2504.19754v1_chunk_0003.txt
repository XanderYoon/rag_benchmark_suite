metrics such as cosine similarity or Euclidean distance, which identify the most relevant chunks. Seminal works like [15] and [13] have demonstrated the effectiveness of RAG in tasks such as open-domain question answering. More recent studies, includ- ing [7], have introduced advancements in scalability and embedding techniques, further establishing RAG as a foundational framework for knowledge-intensive applications. Document Segmentation.Document segmentation is essential for processing long texts in RAG workflows, with methods ranging fromfixed-size segmentation[7] to more adaptive techniques likesemantic segmentation,3 which detect semantic breakpoints based on shifts in meaning. Recent advancements includesupervised segmentation models[14,12]and segment-then-predict models,trainedend-to-end without explicit labels to optimize chunking for downstream task performance [17]. In 2024,late chunkingand contextual retrievalintroduced novel paradigms. Both techniques have proven effective in retrieval benchmarks but remain largely untested in integrated RAG workflows. Despite several RAG surveys [7,6,8], no prior work has compared these methods within a comprehensive evaluation framework. This study addresses this gap by holistically analyzing late chunking and contextual retrieval, offering actionable insights into their relative strengths and trade-offs. 3 Methodology To guide our study, we define the following research questions (RQs), aimed at evaluating different strategies for chunking and retrieval in RAG systems: – RQ#1: Compares the effectiveness ofearly versus late chunkingstrate- gies, utilizingdifferent text segmentersand embedding models to evalu- ate their impact on retrieval accuracy and downstream performance in RAG systems. – RQ#2: Compares the effectiveness ofcontextual retrieval versus tra- ditional early chunkingstrategies, utilizingdifferent text segmenters and embedding models to evaluate their impact on retrieval accuracy and downstream performance in RAG systems. 3.1 RQ#1: Early or Late Chunking? In this workflow, the main architectural modification compared to the standard RAG lies in the document embedding process Figure 3.1. Specifically, we experi- ment with various embedding models to encode document chunks, tailoring them 3 https://docs.llamaindex.ai/en/stable/examples/node_parsers/semantic_ chunking/ 4 J. Singh