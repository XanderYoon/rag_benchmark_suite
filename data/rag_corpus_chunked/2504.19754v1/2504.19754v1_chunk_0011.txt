approaches, for this work- flow, dynamic segmentation was tested, testing two models to assess their perfor- mance.Thefirstmodel, simple-qwen-0.5,isastraightforwardsolutiondesigned to identify boundaries based on the structural elements of the document. Its sim- plicity makes it efficient for basic segmentation needs, offering a computationally lightweight approach. The second model, topic-qwen-0.5, inspired by Chain-of-Thought reason- ing, enhances segmentation by identifying topics within the text. By segmenting text based on topic boundaries, this approach captures richer semantic relation- ships, making it suitable for tasks requiring a deeper understanding of document content. RQ#2: In this workflow, for the ContextualRankFusion evaluation, contextual- ization of the chunks before the embedding is necessary. To contextualize each chunk, we prompt Microsoftâ€™s LLM modelPhi3.5-mini-instruct to generate a brief summary that situates the chunk within the overall document, formatting the prompt with the chunk and its relative original document. 7 https://jina.ai/embeddings/ Reconstructing Context 9 4.2 Retrieval Evaluation RQ#2: In this workflow, specifically for the ContextualRankFusion retrieval, the document retrieval has been enhanced with two additional steps (see Sec- tion 3.2). In the reranking step, Rank Fusion was allowed throughMilvus Vec- tor Database, which integrates withBM25 through the BM25EmbeddingFunction class, enabling hybrid search across dense and sparse vector fields. After retrieving the top documents, these are reordered through the reranker model Jina Reranker V2 Base model,8 that employes a cross-encoder archi- tecture that processes each query-document pair individually, outputting a rel- evance score. This design enables the model to capture intricate semantic rela- tionships between the query and the document before being given to the LLM. Scorings. For both approaches in RQ#1 and RQ#2, when querying the embed- ding database (generated in 4.1), the output will be a ranked list of chunks, ordered from the most similar to the query to the least similar. We employ a straightforward aggregation strategy to transition