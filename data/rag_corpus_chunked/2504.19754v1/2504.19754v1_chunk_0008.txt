placed at the top of the list presented to the user. This method ensures that the most pertinent information is readily accessible, improving the overall effectiveness of the retrieval system. Implementing this reranking step ad- dresses potential limitations of the initial retrieval process, such as the inclusion of less relevant chunks or the misordering of pertinent information. 5 https://github.com/anthropics/anthropic-cookbook/blob/main/skills/ contextual-embeddings/guide.ipynb Reconstructing Context 7 4 Experimental Setup This study has focused on testing these techniques with open-source models. A particular focus was also given to resource usage, for real-world scenarios that lead towards the choice of the LLM for the question answering task to Microsoft’sPhi-3.5-mini-instruct,6 quantized to 4 bits. [1] This language model is designed to operate efficiently in memory- and compute-constrained environments which is a crucial aspect of our work. The same language model has been used also to generate additional context to prepend to each chunk in the Contextual Retrieval Setup. For what regards the embedding models these ones have been tested:Jina V3 [20], Jina Colbert V2 [10], Stella V5 and BGE-M3 [4], all present in the MTEB [18] leaderboard (see Table 1 for more details). Dataset and Hardware. There are severe limitations in current datasets avail- able for RAG systems evaluation. Many don’t include together the labels for retrieval quality evaluation and answers labels for the quality of the genera- tion in a question answering system. In our system initial Retrieval performance has been tested on theNFCorpus [3] dataset, while the subsequent Generation performance in question answering has been conducted overMSMarco[2]. Another important note for Contextual Retrieval ( RQ#2). The NFCorpus dataset is characterised by a long average document length. Here appear the first limitations of the Contextual Retrieval approach to RAG. For the intrinsic nature of this approach, the segmented chunks are enhanced with a generated context