without considering semantic bound- aries can result in chunks that lack sufficient context, impairing the model’s ability to generate accurate and coherent responses. –Incomplete Information Retrieval:important information split across chunks may not be effectively retrieved or integrated. To address these issues, we analyse and compare two recent techniques— contextual retrieval1 and late chunking [9]—within a unified setup, evaluating their strengths and limitations in tackling challenges like context loss and incom- plete information retrieval. Contextual retrieval preserves coherence by prepend- ing LLM-generated context to chunks, while late chunking embeds entire docu- ments to retain global context before segmenting. Our study rigorously assesses their impact on generation performance in question-answering tasks, finding that neither technique offers a definitive solu- tion. This work highlights the trade-offs between these methods and provides practical guidance for optimizing RAG systems. To further support the community, we release all code, prompts, and data under the permissive MIT license, enabling full reproducibility and empowering practitioners to adapt and extend our work.2 2 Related Work Classic RAG. A standard RAG workflow involves four main stages: document segmentation, chunk embedding, indexing, and retrieval. During segmentation, documents are divided into manageable chunks. These chunks are then trans- formed into vector representations using encoder models, often normalized to 1 https://www.anthropic.com/news/contextual-retrieval 2 https://github.com/disi-unibo-nlp/rag-when-how-chunk Reconstructing Context 3 ensure unit magnitudes. The resulting embeddings are stored in indexed vector databases, enabling efficient approximate similarity searches. Retrieval involves comparing query embeddings with the stored embeddings using metrics such as cosine similarity or Euclidean distance, which identify the most relevant chunks. Seminal works like [15] and [13] have demonstrated the effectiveness of RAG in tasks such as open-domain question answering. More recent studies, includ- ing [7], have introduced advancements in scalability and embedding techniques, further establishing RAG as a foundational framework for knowledge-intensive applications. Document Segmentation.Document segmentation