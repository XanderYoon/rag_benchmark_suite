Contextualization of each chunk is performed prior to embedding. The doc- ument is divided into chunks, and a prompt is used to query an LLM to generate contextual information from the document for each chunk. The context is prepended to the chunk, which is then processed by the embedding model to produce the final chunk embedding. embedding vectors and 0.25 for the BM25 sparse embedding vectors. This ratio reflects Anthropic weight assignment.5 By applying these weights, dense embed- dings are emphasized more heavily, while still incorporating the contributions of the BM25 sparse embeddings. This weighted rank fusion approach leverages the complementary strengths of semantic embeddings and lexical matching, aiming to improve the accuracy and relevance of the retrieved results. Reranking Step. To boost and obtain consistent improved performance, the re- trieval and ranking stages have been separated. This two-stage approach im- proves efficiency and effectiveness by leveraging the strengths of different mod- els at each stage. After retrieving the initial set of document chunks, we im- plement an additional reranking step to enhance the relevance of the results to the userâ€™s query. This process involves reassessing and reordering the retrieved chunks based on their pertinence, prioritising the most relevant information. The reranker operates by evaluating the semantic similarity and contextual relevance between the query and each retrieved chunk. It assigns a relevance score to each chunk, and the chunks are then reordered based on these scores, with higher- scoring chunks placed at the top of the list presented to the user. This method ensures that the most pertinent information is readily accessible, improving the overall effectiveness of the retrieval system. Implementing this reranking step ad- dresses potential limitations of the initial retrieval process, such as the inclusion of less relevant chunks or the misordering of pertinent information. 5 https://github.com/anthropics/anthropic-cookbook/blob/main/skills/ contextual-embeddings/guide.ipynb