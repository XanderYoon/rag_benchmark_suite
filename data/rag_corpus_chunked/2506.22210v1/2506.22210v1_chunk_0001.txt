Natural language generation; • Information systems → Information extraction. Keywords Retrieval-augmented generation; Query Rewriting; Grounding 1 Introduction The increasing reliance on conversational assistants such as Chat- GPT for complex open-ended queries [2, 9, 42] presents challenges in factual correctness [16, 18, 35], source attribution [32], informa- tion verifiability [23], consistency, and coverage [ 11]. Although retrieval-augmented generation models aim to build responses based on retrieved sources [ 11, 14, 22], they often struggle with transparency and source attribution. Current generative search This work is licensed under a Creative Commons Attribution 4.0 International License. engines frequently produce unsupported claims and inaccurate ci- tations [23], underscoring the need for more reliable grounding. Although injecting evidence into prompts can mitigate hallucina- tions, long and redundant contexts can lead to the “lost in the middle” problem, where relevant information becomes inaccessi- ble [24]. A post-retrieval refinement step is recommended to retain only essential details while preserving key information [10]. To address these limitations, we use a modular system for retrieval- augmented nugget-based response generation. It combines a strong retrieval pipeline with query rewriting, sparse and dense retrieval, and reranking with Grounded Information Nugget-Based GEnera- tion of Responses (GINGER) [21] (see Figure 1). Unlike traditional RAG approaches, our method operates on atomic units of relevant information, called information nuggets [26]. Response generation involves identifying and clustering nuggets detected in retrieved passages, ranking clusters by relevance, summarizing them to elim- inate redundancy, and then refining these summaries into a final, cohesive response. This process ensures comprehensive yet concise answers, maintains strong source attribution, and, as demonstrated in the TREC RAG’24 augmented generation task, significantly out- performs strong baselines. The core strength of GINGER lies in the granular, nugget-based processing of highly relevant information. When developing our pipeline for the LiveRAG Challenge,1, we conducted experiments on the