arXiv:2506.22210v1 [cs.IR] 27 Jun 2025 UiS-IAI@LiveRAG: Retrieval-Augmented Information Nugget-Based Generation of Responses Weronika Łajewska University of Stavanger Stavanger, Norway weronika.lajewska@uis.no Ivica Kostric University of Stavanger Stavanger, Norway ivica.kostric@uis.no Gabriel Iturra-Bocaz University of Stavanger Stavanger, Norway gabriel.e.iturrabocaz@uis.no Mariam Arustashvili University of Stavanger Stavanger, Norway mariam.arustashvili@uis.no Krisztian Balog University of Stavanger Stavanger, Norway krisztian.balog@uis.no Abstract Retrieval-augmented generation (RAG) faces challenges related to factual correctness, source attribution, and response completeness. The LiveRAG Challenge hosted at SIGIR’25 aims to advance RAG research using a fixed corpus and a shared, open-source LLM. We propose a modular pipeline that operates on information nuggets— minimal, atomic units of relevant information extracted from re- trieved documents. This multistage pipeline encompasses query rewriting, passage retrieval and reranking, nugget detection and clustering, cluster ranking and summarization, and response flu- ency enhancement. This design inherently promotes grounding in specific facts, facilitates source attribution, and ensures maximum information inclusion within length constraints. In this challenge, we extend our focus to also address the retrieval component of RAG, building upon our prior work on multi-faceted query rewrit- ing. Furthermore, for augmented generation, we concentrate on improving context curation capabilities, maximizing the breadth of information covered in the response while ensuring pipeline efficiency. Our results show that combining original queries with a few sub-query rewrites boosts recall, while increasing the number of documents used for reranking and generation beyond a certain point reduces effectiveness, without improving response quality. CCS Concepts • Computing methodologies → Natural language generation; • Information systems → Information extraction. Keywords Retrieval-augmented generation; Query Rewriting; Grounding 1 Introduction The increasing reliance on conversational assistants such as Chat- GPT for complex open-ended queries [2, 9, 42] presents challenges in factual correctness [16, 18, 35], source attribution [32], informa- tion verifiability [23], consistency, and coverage [ 11]. Although retrieval-augmented generation models aim to