benchmarks. Datasets (→) Robust04 News21 Core17 FollowIR DD-15 DD-16 DD-17FR-21 FR-22Bright Metrics (→) MAPp-MRRnDCGp-MRRMAPp-MRRscorep-MRRnDCG nDCG nDCGnDCG nDCGnDCG Base Size: < 1B parameters e5-base-v2 13.4 -6.7 20.9 -2.0 14.0 -2.9 16.1 -3.9 40.3 31.5 32.7 29.4 61.5 3.7+InF-Embed 14.0 6.9 23.8 3.2 11.6 5.3 16.5 5.1 47.5 35.5 32.9 49.8 78.9 8.4e5-large-v2 17.4 -4.2 24.3 0.9 17.0 0.1 19.6 -1.1 41.1 35.6 32.7 15.6 51.1 7.6+InF-Embed 17.5 9.4 26.6 2.0 16.0 7.1 20.0 6.2 51.4 37.9 34.7 57.0 89.2 9.2 ModernBERT-base4.29 -5.8 4.3 -1. 5.7 -0.5 4.8 -0.3 2.3 3.6 8.7 3.0 5.4 0.5+InF-Embed 10.0 0.3 6.0 0.1 9.8 2.9 8.6 1.1 44.8 31.8 35.8 50.6 69.0 7.8 Large Size: 1-5B parameters Llama-3.2-1B 8.0 -1.5 17.7 1.5 9.8 0.4 11.8 0.1 3.1 5.4 8.3 3.2 26.4 0.1+InF-Embed 16.8 6.0 20.8 0.7 13.9 3.8 17.2 3.5 50.5 36.8 36.7 57.1 87.0 9.1Llama-3.2-1B-Inst8.6 -2.1 11.1 0.6 8.7 0.2 9.5 -0.4 8.3 14.9 18.3 4.6 42.1 0.4+InF-Embed 19.1 5.6 26.1 3.8 15.2 1.9 20.2 3.8 50.7 36.5 38.9 54.6 81.4 10.9 Qwen2.5-1.5B 4.7 -0.5 7.5 -0.2 5.9 1.6 6.0 0.3 1.0 2.7 2.4 1.5 5.5 0.2+InF-Embed 16.8 4.9 14.1 2.7 12.7 1.9 14.5 3.2 42.0 27.2 36.0 43.5 45.2 8.5Qwen2.5-1.5B-Inst4.7 -1.2 9.8 2.3 6.4 0.8 7.0 0.6 0.5 2.2 2.4 1.6 4.4 0.1+InF-Embed 17.9 3.9 17.5 0.7 13.6 3.8 16.3 2.8 48.4 35.3 35.3 39.0 40.6 8.4 Qwen2.5-3B 5.0 -0.8 8.3 0.8 5.8 1.1 6.3 0.4 1.0 3.2 2.3 1.5 7.5 0.2+InF-Embed 17.6 4.3 19.5 1.1 12.2 3.6 16.4 3.0 49.2 30.1 34.0 53.2 75.3 10.5Qwen2.5-3B-Inst5.0 -1.3 9.7 2.4 6.6 -0.4 7.1 0.2 1.3 3.1 2.2 1.7 8.8 0.3+InF-Embed 19.6 3.3 22.4 1.8 14.6 3.7 18.9 2.9 45.3 29.2 35.0 55.4 72.7 10.6 6 Experiments 6.1 Experiments Setup Evaluation Datasets. We conduct a comprehensive evaluation across the following representative instruction-following retrieval datasets: (1) FollowIR