exp sim(pi,iqi,i)  P m∼B exp sim(pm,iqi,i)  + P j∼B exp sim(pi,iqj,i)  + P k∼B exp sim(pi,iqk,k)  # , (21) D Evaluation Dataset Details Here are the details for each instruction-following retrieval dataset used in our experiments: • FollowIR (Weller et al., 2024) assesses IR models based on their responsiveness to detailed and realistic instructions extracted from TREC narrative annotations. These narratives encom- pass explicit inclusion and exclusion criteria. It features queries sourced from TREC Robust 2004 (V oorhees, 2004), TREC Common Core 2017 (Allan et al., 2017), and TREC News 2021 (Soboroff, 2022), enriched with professional narrative annotations and further refined through targeted human reviews. It employs pairwise annotations to effectively measure models’ adaptability to evolving instructions. • MAIR (Sun et al., 2024) provides a comprehensive evaluation of instruction-tuned IR models across 126 distinct tasks spanning multiple domains such as academic literature, code retrieval, legal documents, finance, and medical search. It incorporates 10,038 queries paired with 805 distinct instructions sourced from public datasets, TREC tracks, and established IR benchmarks. Each task features meticulous manual annotations that define relevance across diverse query- document-instruction contexts. • Bright (Su et al., 2024) presents reasoning-intensive retrieval tasks that extend beyond con- ventional lexical or semantic matching, incorporating complex scenarios from diverse domains such as coding, mathematics, economics, and science. Bright contains 1,384 real-world queries drawn from 12 varied datasets, including StackExchange, LeetCode, and AoPS, among others. Documents consist of referenced web pages, programming syntax manuals, and solution expla- nations unified by shared logical, algorithmic, or theoretical foundations. Relevance labels are human-validated, ensuring alignment with intricate reasoning criteria. E Baseline Details Here are the details for each instruction-following retrieval baseline used in our experiments: • Contriever (Izacard et al., 2021) is a bi-encoder dense retriever trained via unsupervised con- trastive learning