for both embedding models and LMs. The batch size is set to 4 per device. To prevent test set contamination (Oren et al., 2023) in external evaluations, we have conducted a string-matching analysis, where we do not observe any overlap between the training data in InF-IR and the evaluation datasets utilized in this study. Additional details of the implementation are available in appendix F. 6.2 Main Experiment Results Table 2 presents comprehensive comparative results between various baselines and their corresponding variants enhanced by our proposedInF-Embed. We observe several key findings: (i) Embedding-based models trained on InF-IR achieve notable instruction-following improvements (+1.36@p-MRR) and enhanced overall retrieval performance; (ii) Auto-regressive LMs, initially limited in retrieval, significantly benefit fromInF-IR, achieving retrieval effectiveness (@nDCG) comparable to similarly sized embedding models; (iii) Fine-tuning previously trained retrievers (e.g., e5-base-v2) on InF-IR further boosts retrieval scores (+14.3@nDCG) and substantially improves instruction-following ability (+8.2@p-MRR), highlighting the broad utility and effectiveness of InF-Embed. We also compare our best-performing checkpoints from various backbone models against state-of-the- art retrieval models in Figure 5. The results show that the InF-Embed models consistently outperform 8 InF-Embed (large)InF-Embed (base) flan-t5-largeflan-t5-basee5-large-v2monot5-basebge-large-enbge-base-en monobertcontrievere5-base-v2 instructor-basetart-contrieverInF-Embed (1B)InF-Embed (1.5B) monot5-3Btart-flan-t5-xlinstructor-xl google-gecko GritLM-7B cohere-embedOpenAI-v3-large repllama-7Be5-mistral 4 2 0 2 4 6 Score / p-MRR Base Size (<1B) Large Size (1-5B) XL Size (for reference) Score* p-MRR Figure 5: Comparative analysis of instruction-following capabilities on the Follow-IR benchmark across model architectures of varying scales. Models are grouped by parameter count and ranked by p-MRR scores within each category. Standard retrieval metrics (score∗) are normalized by a factor of 10 to facilitate visual comparison with p-MRR values. Table 3: Configuration comparison on Follow-IR (Weller et al., 2024) benchmarking multiple loss function designs and varying sizes of backbone LMs. Category (→) Encoder Decoder Base Model (→) ModernBERT Llama-3.2 Llama-3.2 Qwen2.5 Qwen2.5 Qwen2.5 Qwen2.5Model