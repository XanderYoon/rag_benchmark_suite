rely on powerful yet inefficient and less scalable auto- regressive LMs, we hypothesize that embedding models as retrieval backbones can effectively address diverse user requests through advanced instruction-aware representation learning. 3 Passage ğ‘ƒ! Existing Works Query ğ‘„! Instruction ğ¼! IrrelevantInstruction ğ¼" Passage ğ‘ƒ! IrrelevantPassage ğ‘ƒ" InF-IR (Ours) NegativePassage ğ‘ƒ#" Query ğ‘„! Passage ğ‘ƒ! Query ğ‘„! Instruction ğ¼! Passage ğ‘ƒ! IrrelevantQuery ğ‘„" Instruction ğ¼! Query ğ‘„! IrrelevantInstruction ğ¼" NegativePassage ğ‘ƒ$" Contrast Contrast Golden ElementsSynthetic NegativesOther Negatives Figure 2: Hard negative samples in InF-IR generated by poisoning both instructions and queries. 3 Preliminaries Noise Contrastive Estimation. We begin by formulating a ranking-based noise contrastive estima- tion (NCE) objective (Ma & Collins, 2018; Gutmann & HyvÃ¤rinen, 2010; Henderson et al., 2017; Yang et al., 2019) from a conditional modeling perspective. Specifically, consider a model that estimates a conditional distribution P(y | x), where x and y represent arbitrary combinations of target variables. We define a scoring function sÎ¸ (x, y) parameterized by learnable parameters Î¸, quantifying the relevance between a given pair (x, y). Given a training set D = {xi, yi}n i=1 and an arbitrary minibatch B âŠ† D 2 sampled during training, we introduce a predefined negative sampling distribution Pâˆ’ B (Â·) for generating negative examples within each minibatch. The resulting NCE objective using in-batch negatives is formulated as follows: â„“NCE(Î¸) = âˆ’Eiâˆ¼B " log exp (sÎ¸ (xi, yi))P ykâˆ¼Pâˆ’ B (y) exp (sÎ¸ (xi, yk)) # . (1) Dense Passage Retrieval with Instructions. Consider a corpus P = {Pi}N i=1 comprising a large set of candidate retrieval passages. Given a query Q paired with an instruction I provided by the user, an instruction-following retrieval model aims to retrieve a concise subset of passages from P that best satisfies the instruction and query. We denote this targeted positive subset as P