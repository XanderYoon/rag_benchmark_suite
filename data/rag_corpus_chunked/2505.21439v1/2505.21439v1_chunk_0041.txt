annotators and LLMs using Cohen’s Kappa statistics, which measures inter-rater reliability while accounting for agreement occuring by chance. Subsequently, we computed the average consistency between human judgments and predictions from several large language models, including o3-mini, FollowIR-7B, gpt-4o-mini, and gpt-4o. As shown in Figure 4, o3-mini consistently achieved the highest Cohen’s Kappa scores with human annotators, outperforming the other models evaluated. These results underline the alignment of o3-mini’s judgments with human intuition and confirm the robustness and effectiveness of our automated filtering strategy for maintaining high-quality synthetic datasets. G Additional Experimental Results G.1 Additional Instruction-Following IR Results Table 5 presents additional results of various baselines on instruction-following IR datasets. Key additional insights from this evaluation include: • Sparse vs. Dense Retrieval. Dense retrieval models consistently outperform traditional sparse retrieval methods such as BM25, particularly in instruction-following tasks, highlighting the advantage of semantic embedding-based approaches. • Model Size and Effectiveness. Larger model sizes generally exhibit stronger retrieval and instruction-following performance. Models in the XL size category (over 5B parameters), such as GritLM-7B and promptriever-llama2-7b, deliver state-of-the-art results, demonstrating the benefit of increased parameter count and training scale. 19 Table 5: Additional results of various baselines on multiple instruction-following IR datasets. Evaluation Datasets (→) Robust04 News21 Core17 FollowIR DD-15 DD-16 DD-17FR-21 FR-22MAIR Baselines (↓) / Metrics (→) MAPp-MRRnDCGp-MRRMAPp-MRRscorep-MRRnDCG nDCG nDCGnDCG nDCGnDCG Sparse Retrieval BM25 (2009) 12.1 -3.1 19.3 -2.1 8.1 -1.1 13.2 -2.1 – – – – – – Base Size: < 1B parameters e5-base-v2(109M) (2022a) 13.4 -6.7 20.9 -2.0 14.0 -2.9 16.1 -3.9 40.3 31.5 32.7 29.4 61.5 39.1InF-Embed(e5-base-v2) 14.0 6.9 23.8 3.2 11.6 5.3 16.5 5.1 47.5 35.5 32.9 49.8 78.9 48.9contriever(109M) (2021) 19.7 -6.1 22.9 -2.8 15.3 -2.5 19.3 -3.8 – – – – – –bge-base-en(v1.0/1.5)(109M) (2024)16.8 -6.5 20.0 -0.1 14.6 -2.7 17.1 -3.1 21.0 16.7 33.5 25.1 29.6