and generated tokens. We observe that increasing the retrieval chain lengthL results in substantial performance improve- ments when L is small, but the gains diminish as L increases. This observation aligns with the intuition that longer chains can encapsulate more reasoning steps and allows for trial-and-error explo- ration of various query rewriting strategies. Several examples are provided in Appendix Table 11. Conversely, increasing N for best-of-N sampling yields mixed effects depending on the dataset. For the most challenging dataset, MuSiQue, in terms of EM score, a larger N enhances performance, whereas for the less challenging dataset, 2WikiMultihopQA, a smaller N suffices. We defer the further exploration of tree search to future work, as it is considerably more computationally expensive than greedy decoding and best-of-Nsampling. The Pareto frontier between the EM score and token consumption approximately follows a log-linear trajectory for up to 128k tokens, although the scaling behavior varies across different datasets. This observation assists practitioners in making informed decisions regarding the allocation of test-time compute based on the quality requirements. It is important to note that we make several simplifications 7 in this scaling study, such as treating the prompt tokens equivalently to the generated tokens and ignoring the retrieval costs. A more rigorous analysis could take these factors into account. 5 Analysis Table 3: Ablation study results. “Iterative training” employs a trained CoRAG model for another round of rejection sampling. “Distill from GPT-4o” leverages the GPT-4o model to generate retrieval chains. “Weak-to-strong Generalization” utilizes weaker LLMs for retrieval chain generation while using stronger LLMs (Llama-3.1-8B-Inst.) for training. “Different Retrievers” replaces the text retriever at test time. 2WikiQA HotpotQA Bamboogle MuSiQue EM F1 EM F1 EM F1 EM F1 CoRAG-8B (L=6, greedy) 70.6 75.5 54.4 67.5 48.0 63.5 27.738.5 ▷iterative training 72.2 76.9 53.4 66.5 45.6 60.9 26.6 37.6