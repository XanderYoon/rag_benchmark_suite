retriever, we substitute it with two weaker alternatives in a plug-and-play fashion: E5-base and BM25. Across all datasets, we observe consistent performance gains when investing more test-time compute, although stronger retrievers continue to outperform in terms of absolute performance. Improvements to text retriever quality represent an orthogonal dimension that can further amplify CoRAGâ€™s performance gains. Weak-to-strong GeneralizationDue to the need of repeated sampling and autoregressive generation, the retrieval chain generation process costs more GPU hours than the model training. To mitigate this cost, one strategy is to employ weaker LLMs for retrieval chain generation and subsequently fine-tune stronger LLMs on the augmented datasets, similar to the weak-to-strong generalization setting [4]. The results in Table 3 demonstrate that utilizing Llama-3B achieves very close performance compared to the 8B model, whereas Llama-1B exhibits a noticeable performance drop. Manual inspection re- veals that the 1B model frequently struggles to follow the given instructions, resulting in sub-optimal retrieval chains. Employing weaker LLMs also lowers the barrier to adopting more computationally expensive tree search strategies during data generation, which show great potential in mathematical reasoning tasks [7]. In contrast, distilling from a stronger model like GPT-4o yields a further perfor- mance boost, indicating that the quality of the retrieval chains is crucial for the final performance. 8 5.3 Does Chain-of-Retrieval Always Help? 2 4 6 8 10 Chain Length 90 91 92 93 94 95EM FEVER greedy best-of-4 best-of-8 2 4 6 8 10 Chain Length 87 88 89 90 91EM TQA greedy best-of-4 best-of-8 2 4 6 8 10 Chain Length 59 60 61 62 63 64 65 66Accuracy NQ greedy best-of-4 best-of-8 Figure 4: Scaling test-time compute across three datasets from the KILT benchmark. We report scores on the public validation set. Multi-hop QA datasets are specifically designed to evaluate complex reasoning capabilities