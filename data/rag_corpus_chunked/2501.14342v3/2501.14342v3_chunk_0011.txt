tokens. For the KILT benchmark, we fine-tune an E5-Mistral retriever [ 35] and a RankLLaMA re-ranker [ 24] on the respective training set to boost the ranking quality. Further implementation details are provided in Appendix A. 5 Table 1: Results on multi-hop QA datasets. We report the performance of CoRAG-8B using various decoding strategies and retrieval chain lengths L. The “Few-shot w/o Retrieval” configuration utilizes only QA pairs without retrieval augmentation. Both DRAG and IterDRAG are based on Gemini 1.5 Flash [31], while Search-o1-32B is based on QwQ [37] and the Bing Search API. 2WikiQA HotpotQA Bamboogle MuSiQue EM F1 EM F1 EM F1 EM F1 F ew-shot w/o Retrieval 3-shot Llama-3.1-8B-Inst. 27.6 32.1 20.8 28.8 17.6 21.3 3.4 9.7 3-shot GPT-4o 39.5 47.3 38.2 51.2 49.6 61.5 15.8 27.2 w/ Retrieval 3-shot Llama-3.1-8B-Inst. 30.7 39.9 34.1 46.6 28.0 37.3 7.7 15.4 3-shot GPT-4o 49.0 56.2 45.8 59.4 53.6 63.8 15.7 25.8 Self-RAG-7B 12.2 24.1 16.6 29.4 5.6 16.8 4.6 13.2 ITER-RETGEN 35.5 47.4 45.1 60.4 40.0 50.7 26.1 42.0 DRAG (32k) 45.9 53.7 46.9 60.3 48.8 59.2 15.4 26.0 IterDRAG (32k) 44.3 54.6 38.3 49.8 46.4 56.2 12.5 23.1 Search-o1-32B 58.0 71.4 45.2 57.356.067.8 16.6 28.2 Fine-tuned Llama-8B w/ E5large 55.1 60.7 50.3 63.5 40.8 53.7 17.4 28.1 CoRAG-8B (Ours) ▷ L=1, greedy 56.5 62.3 50.1 63.2 37.6 51.4 18.6 29.3 ▷ L=6, greedy 70.6 75.5 54.4 67.5 48.0 63.5 27.7 38.5 ▷ L=6, best-of-471.7 76.5 55.3 68.5 51.2 63.1 28.1 39.7 ▷ L=6, tree search 71.7 76.4 55.8 69.0 48.8 64.4 29.0 40.3 ▷ L=10, best-of-872.5 77.3 56.3 69.854.468.3 30.9 42.4 4.2 Main Results Multi-hop QAIn Table 1, we present a comparative analysis of CoRAG-8B against several models, including few-shot Llama-3.1-8B-Instruct [5], GPT-4o [10], Self-RAG-7B [1], ITER-RETGEN [30], DRAG, IterDRAG [42], and Search-o1-32B [ 22]. For a fair