we propose using Fusion-in-Decoders (FiD), a family of models [12] that are com- putationally efficient in modelling multiple evidence documents. We demonstrate their effectiveness in simultaneously modeling the collection (user queries and retrieved documents) and generating questions, in a way that eliminates the need for an intermediate step of facet or keyword extraction and increases the ability to model larger parts of the corpus when generating questions. Furthermore, to ensure dynamic and adaptive nature of clarify- ing question generation and avoid "hallucinations", we enhance the training setup of question generation models. We find that current datasets [40] suffer from a disconnect between document evidence gathered from search engine results pages and the ground truth clarification questions derived from user reformulations, negatively impacting the question generator. In light of this, we further ex- plore the relationship between question generation and evidence documents. We find that aligning evidence and generation during training is critical towards preventing "hallucinations" [ 15] and ensuring the generated question remains faithful to evidence docu- ments, ie. the retrieval corpus. Having trained an effective and grounded question generator, our focus shifts to retrieving evidence during inference. To ensure evidence documents encompass all existing information facets of arXiv:2409.18575v1 [cs.IR] 27 Sep 2024 the original queries, we experiment with inducing novelty in ev- idence documents to improve facet generation. Yet, we find that capturing the ground truth facets present in current datasets with such methods remains a challenge. Our main research question ishow can we train an end-to-end sys- tem that explicitly models the retrieval corpus and generates Corpus- informed clarifying questions? Specifically, we aim to answer the following research questions: RQ1 Can we generate Clarifying Questions end-to-end with Re- trieval Augmented Generation models? RQ2 What is the optimal evidence set for training and evaluating that support Corpus-informed Retrieval-Augmented Genera-