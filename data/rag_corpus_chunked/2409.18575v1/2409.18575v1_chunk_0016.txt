outperforming BART for larger n-grams. In gen- eral, BART achieves higher Recall while FiD is stronger in terms of Precision. This comparison between FiD and BART is impor- tant, because FiD fuses document embeddings in the decoder and therefore can model lengthier or more evidence documents than BART, with the same GPU memory footprint. The benefits of this efficiency are not visible here and are explored in Section 5.2.4, due to the evidence snippets being few and very short in length. Comparing ğ¹ğ‘–ğ· with Faspects, a Recall-optimized ensemble that contains BART, we observe that this trend is magnified further. Faspects produces more facets which at times leads to better Recall, at the cost of much lower metrics in terms of Precision as well as Set-BERT and Set-BLEU measures. Furthermore, we assess whether FiD can successfully compose answers that depend on multiple evidence documents. It is im- portant to assess how the information bottleneck of FiD affects aspect generation performance, because FiD models are widely used on open-domain QA, a task that in contrast to ours does not necessarily require compositionality across evidence documents. To do so, we run an oracle experiment where we provide the target facets directly as evidence documents, either in the form of a sin- gle evidence document (ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ ) or in multiple and independently encoded evidence documents (ğ‘œğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ âˆ’ ğ‘ğ‘œğ‘šğ‘ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘’ğ‘‘ ). We observe only a slight drop in performance, and hence we conclude that FiD models can successfully utilise all evidence documents towards the generation. Lastly, we perform closed-book generation (without using evidence passages), we observe a big drop across performance metrics. By manual inspection, we observe that closed-book models are able to generate facet words for some queries, while they often resort in capturing reoccurring patterns from the training set (eg. on shopping related queries: