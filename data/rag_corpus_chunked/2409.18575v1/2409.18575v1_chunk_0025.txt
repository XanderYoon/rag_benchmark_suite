MMR (ğœ† = 0.5) 0.3052 0.2763 0.2790 0.0559 0.0458 0.0485 0.4216 0.4441 0.4284 0.3772 0.3179 0.2861 0.2670 [Contr-FT|Q,F] MMR (ğœ† = 0.7) 0.3085 0.2767 0.2807 0.0575 0.0471 0.0496 0.4217 0.4444 0.4286 0.3776 0.3174 0.2852 0.2660 [Contr-FT|Q,F] MMR (ğœ† = 0.9) 0.3132 0.2784 0.2835 0.0598 0.0484 0.0512 0.4187 0.4416 0.4257 0.3758 0.3164 0.2844 0.2653 Contr-FT-Train 0.3001 0.2715 0.2738 0.0560 0.0451 0.0482 0.4198 0.4416 0.4262 0.3655 0.3070 0.2762 0.2578 Contr-FT-Train-WarmedUpQ 0.3150 0.2935 0.2909 0.0723 0.0639 0.0652 0.4340 0.4553 0.4402 0.3795 0.3209 0.2899 0.2710 Table 6: Effect of evidence diversification methods in performance In Figure 1, we observe that increasing the number of context docu- ments leads to performance improvements only forğ¶ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘Ÿ |ğ‘„, ğ¹ . This shows that the question generator can be improved with more documents, as long as noise is minimised in the evidence pool. This requires not only that retrieval is bounded towards the facets to be generated, but also that the retriever is of high quality (Contriever finetuned on the ranking task). For instance, performance quickly deteriorates when adding more ğµğ‘€ 25|ğ‘„, ğ¹ documents, probably due to adding irrelevant documents to the pool. All in all, these results strengthen our motivation to use Fusion-in-Decoder models for this task, since they can effectively and efficiently model larger parts of the corpus than other seq2seq counterparts. Section Conclusions. Experimental results on this Section high- light a significant gap between ground truth clarifications and the retrieval corpus in current datasets. When this gap appears models do not remain faithful to the facets present in the collection, ie. clarifications are not corpus-informed, which can severely harm search engine user experience. We show that evidence grounding can mitigate this issue and significantly boost performance. We further verify the suitability of FiD models for this task by showing that (i) it can effectively extract facets/topics