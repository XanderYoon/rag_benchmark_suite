include many different components (eg. keyword extraction, generation) that work in a disconnected way from each other. Last there is work that focuses on enhancing the training of au- toregressive models for generating clarification facets, which are by nature unordered. Next token prediction objectives could unfairly penalize the models for predicting facets in a different ordering. To tackle this, Hashemi et al. [10] generate all possible permutations of facets and backpropagate the minimum loss during training. Ni et al. [21] does a thorough comparison of training objectives and conclude that training on one-facet-at-a-time basis increases per- formance but hurts facet diversity. This work is orthogonal to ours and can also be applied to our models. 3 METHODOLOGY Problem definition. In this work we investigate the problem of clarifying question generation for Web Search, where clarifying questions are presented through a clarification pane in the Search Engine Result Page (SERP). In this setting, the user has a search intent ğ‘”ğ‘– âˆˆ ğº and searches for a set of relevant documents ğ‘…ğ‘– in a corpus of documents ğ¶. To express his information need ğ‘”ğ‘–, the user issues an ambiguous or faceted query ğ‘ to the search engine. The SERP presents the top ranking results along with a clarification pane that tries to clarify the ambiguity of ğ‘. The clarification pane consists of a clarifying question ğ¶ğ‘„ and some potential answers ğ¹ to this clarifying question ğ¶ğ‘„. Those answers are basically possible search intents, facets or aspects of query ğ‘. The goal of asking a good clarification question becomes directly related to finding the possible search intents (facets) ğ¹ that query ğ‘ engulfs. To find such search intents ğ¹, it is important to take into account the document collection ğ¶ the user searches through. In failing to do so, we risk presenting search