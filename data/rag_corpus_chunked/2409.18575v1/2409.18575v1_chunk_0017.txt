can successfully utilise all evidence documents towards the generation. Lastly, we perform closed-book generation (without using evidence passages), we observe a big drop across performance metrics. By manual inspection, we observe that closed-book models are able to generate facet words for some queries, while they often resort in capturing reoccurring patterns from the training set (eg. on shopping related queries: â€œAre you shopping for:ğ‘šğ‘’ğ‘›, ğ‘¤ğ‘œğ‘šğ‘’ğ‘› , ğ‘˜ğ‘–ğ‘‘ğ‘  ?â€). Our results in this Section suggest thatRAG models and in partic- ular FiD can be used to effectively and efficiently model the retrieval corpus and generate clarifying questions end-to-end. Overall, we answer RQ1 positively and conclude that Retrieval- Augmented-Generation models such as FiD are effective in jointly modelling the query, collection and generating clarifying ques- tions in an end-to-end way. We find that thoseFiD is competitive with more computationally expensive baselines such as BART, sug- gesting that it can be effectively used to model larger parts of the collection and therefore generate more informed clarifying ques- tions. Further, we verify the finding of previous works [ 29, 32] that evidence documents are crucial for generating good clarify- ing questions and strengthen our motivation towards performing Corpus-informed Clarifying Question Generation . Collection Retriever Term Overlap Exact MatchEvidence set typeRecall Recall Bing snippets [40]ğµğ‘–ğ‘›ğ‘” 0.518 0.185 diversified MSMarco-passageğµğ‘€25|ğ‘„ 0.448 0.151 non-diversified MSMarco-passageğ¶ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘Ÿâˆ’ğ¹ğ‘‡|ğ‘„ 0.434 0.124 semantic MSMarco-passageğµğ‘€25|ğ‘„, ğ¹ 0.813 0.380 aligned-lexical MSMarco-passageğ¶ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘Ÿâˆ’ğ¹ğ‘‡|ğ‘„, ğ¹ 0.761 0.345 aligned-semantic Table 2: Alignment statistics between evidence documents and target facets in clarifying question 5.2 Building evidence sets to support Corpus-informed Retrieval-Augmented Generation of Clarifying Questions In this section, we focus on the role of retrieval and evidence docu- ments, as those are fundamental to generating good clarifications. Our hypothesis here is that if evidence documents and ground truth facets are not aligned during training, that is if ground truth