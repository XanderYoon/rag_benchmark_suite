gap appears models do not remain faithful to the facets present in the collection, ie. clarifications are not corpus-informed, which can severely harm search engine user experience. We show that evidence grounding can mitigate this issue and significantly boost performance. We further verify the suitability of FiD models for this task by showing that (i) it can effectively extract facets/topics from evidence without the need of finding them verbatim in the text, and (ii) its efficiency benefits can be used towards modelling larger parts of the collection and leading to generating better clarifying questions. 5.3 Introducing novelty in the evidence pool to assist facet extraction at test time In previous sections, we showed thatùêπùëñùê∑ is effective for generating grounded Clarifying Questions end-to-end. So far, we bounded the evidence pool towards the target facets, which is not possible at inference time. In this Section, we explore how we can relax this condition and capture the ground truth facets in an open-domain setting. To that end, we first examine whether grounded generators perform better than ungrounded generators in this non-bounded setting (Section 5.3.1). Second, we use a grounded generator that, as shown in Section 5.2 is capable to extract the facets of the evidence pool, and investigate whether diversifying the evidence pool with- out constraining it towards the ground-truth facets can improve results. 5.3.1 Is evidence-facet alignment during training enough to improve facet extraction? In Table 5 we use three different evidence sets at inference time and measure performance of models trained in different ways. We observe that differences in performance metrics are minimal within groups, while models trained and tested with evidence pools from the same evidence distribution as the test distribution is somewhat better. This comes in contrast to the large differences observed in Table 3, where alignment brought more