GPP. Beyond relevance and perplexity,query-agnosticdocument quality charac- teristics such as readability and relevance priors may also influence the utility of retrieved contexts and the quality of generated answers. As an analogy, for human readers, overly complex text can limit usability [25], and low-quality documents may fail to support any query [4]. In this work, we examine two variants of RPP and GPP: (a)pre-generation (PreGen) and (b)post-generation(PostGen). The PreGen predictor relies solely on information from the retriever, making it more efficient since it does not require the generator’s output. By contrast, the PostGen predictor can exploit additional signals, such as the perplexity of the generated answers [52], thereby offering improved effectiveness at the expense of a modest reduction in efficiency. Our Contributions.In summary, the main contributions of this paper are: –We apply existing QPP approaches for two novel prediction tasks in a RAG setting: retrieval performance prediction (RPP), and generation performance prediction (GPP). –In addition to relevance estimation via QPP, we further propose to leverage context perplexity and query-agnostic document quality measures to improve RPP and GPP. –We show that an ensemble of predictors learned via linear regression consis- tently outperforms the individual predictors across different retrieval models and context sizes. 2 Related Work Predicting RAG Performance.In retrieval-augmented generation (RAG), standard IR metrics (e.g., nDCG) are insufficient proxies for utility because re- 4 Tian et al. trieved documents are consumed by an LLM rather than directly by human users [46]. Prior work shows that context utility depends on multiple factors, including the context length [55], relevant document position [39], prompt struc- ture[12],andknowledgeconflictsbetweentheretrieveddocumentandtheLLM’s parametric knowledge [41]. Existing approaches to predicting RAG answer qual- ity mainly focus on uncertainty estimation. Answer-level semantic uncertainty is used to infer generation quality [14,22,47,52], but typically requires multiple sampled generations, limiting its practicality. Token-level uncertainty has also