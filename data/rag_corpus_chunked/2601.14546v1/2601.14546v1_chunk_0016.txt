most effec- tive QPP predictor varies with the retriever model used â€“ consistent with earlier findings that QPP accuracy is ranker-dependent [23]. For BM25 and MonoT5, DenseQPP leads to the best GPP results indicating that the density of the doc- ument embeddings is a useful indicator of the answer quality. However, the ef- fective performance of MaxScore with MonoT5 and A-pair ratio on E5 indicates that no QPP approach works consistently the best across all rankers. To conclude for RQ-1, existing QPP approaches exhibit different appli- cability to RPP and GPP in the RAG pipeline. While some approaches achieve good accuracy, their accuracy is not consistent across retrieval configurations. Predicting Retrieval Utility and Answer Quality in RAG 11 RQ-2: Effectiveness of combining QPP approaches with context per- plexity (PerpC).Table 2 reports results when combining multiple predictors using linear regression as introduced in Section 3.3. The first row in the upper part shows that aggregating multiple QPP predictors generally outperforms the best individual QPP method in Table 1, especially for BM25 and E5. The second row in Table 2 shows the results of combining QPP and reader- centric PerpC. Adding PerpCconsistently improves prediction accuracy in GPP across all retrievers (e.g., the significant improvement from 0.2454 to 0.2821 with BM25), confirming our hypothesis that context perplexity influences the LLM to digest the context and produce high-quality answers. For RPP, however, gains in prediction accuracy appear only with BM25. This suggests that PerpCis more discriminative for weaker retrievers, where the perplexity of retrieved contexts varies more sharply between low- and high-utility cases. To conclude for RQ-2, combining PerpCwith QPP predictors yields more significant gains in accuracy with weaker retrievers and is especially effective for predicting answer quality rather than predicting context utility. RQ-3: Effectiveness of leveraging query-agnostic predictors.The last two rows in the