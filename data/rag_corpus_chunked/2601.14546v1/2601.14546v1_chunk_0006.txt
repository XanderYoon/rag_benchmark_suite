inherent quality of a document may also limit its usefulness, with some documents containing little or no valu- able information [4]. Recent approaches, such as QualT5 [8], explicitly estimate query-agnosticdocumentquality.InRAG,whethertheseconstraintsaffectLLMs as the new “readers” remains underexplored, highlighting potential differences in how humans and LLMs use retrieved text. Research Gap.Prior work has not yet systematically studied context utility and answer quality prediction in RAG. The closest effort, [61], assesses the utility of individual retrieved documents rather than predicting the utility of RAG contexts concatenated from multiple documents. Moreover, it relies on LLM- based utility estimation and does not explore the use of existing retrieval analysis tools, such as QPP or document quality signals, in the RAG setting. Predicting Retrieval Utility and Answer Quality in RAG 5 3 Predicting Retrieval Utility and Answer Quality In this section, we formally define the tasks of RPP and GPP along with their prediction targets. We then introduce three types of predictors and propose combining them to improve prediction accuracy. 3.1 Prediction Task Description Preliminaries.Letθ R denote a retriever that maps a queryqto a ranked list of documents{d 1, . . . , dk}, andθ G denote a generator that maps a prompt to an answera. Thek-shot answer is denoted asa k =θ G(q;θ R(q)k), where the prompt consists of the queryqandθ R(q)k, the latter denoting the top-k retrieved documents obtained fromθR as context forq. Similarly, we can obtain a zero-shot answer, asa0 =θ G(q;∅). Ifk-shot RAG is helpful, we would expect the generated answera k to be enhanced compared to the zero-shot answera0. Indeed, [55] definedcontext utilityas the actual influence of retrieved documents on downstream answer quality. Specifically, similar to [55], we define the utility Uof the top-kretrieved documents (when used as RAG context) as: U(θ R(q)k) =P(θ G(q;θ R(q)k))−P(θ G(q;∅)),(1) wherePis a task-specific performance