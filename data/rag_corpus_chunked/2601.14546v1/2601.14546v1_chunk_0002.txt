models [18,21,28] leads to effective adaptive IR pipelines [17]. This motivates us to hypothesise that accurately predicting both the utility of retrieved documents as RAG context, where utility is defined as the answer quality gain ofk-shot generation relative to zero-shot (U in Figure 3) [55], and the quality of the generated answers can further enhance RAG effectiveness. The primary objective of this work is therefore to investigate methods for estimating context utility and answer quality in RAG, while leaving the downstream integration of these estimators into adaptive RAG systems for future research. To further clarify the two types of predictors examined in this paper, we consider two central questions when predicting RAG performance: –Do the retrieved documents improve answer quality compared to zero-shot generation? We call this taskretrieval performance prediction (RPP). –Do the retrieved contexts provide sufficient information for the LLM to gen- erate correct answers that satisfy the query’s information need? We denote this asgeneration performance prediction (GPP). These two predictor components are illustrated in the bottom-right part of Fig- ure 1. In addressing both RPP and GPP, we posit that the relevance of retrieved documents is a likely indicator of both context utility and answer quality, as con- ditional generation with relevant documents potentially leads to factually cor- rect and relevant answers [55]. However, since the ground-truth relevance is not known to a RAG system, the relevance estimated from existing QPP approaches may act as an effective proxy [54]. Predicting Retrieval Utility and Answer Quality in RAG 3 However, different from standard IR, where the end user of the retrieved documents is a human, in RAG, the retrieved documents are consumed by an LLM [46]. As a result, RPP and GPP should account not only for topical rele- vance but also for how the context interacts with the