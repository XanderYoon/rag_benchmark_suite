a retrieved context causes a lower perplexity as analysed by an LLM, it may indicate greater consistency with the model’s expectations and inherent knowledge. To distinguish it from post- generation PerpA, we refer to this measure ascontext perplexity(PerpC). Predicting Retrieval Utility and Answer Quality in RAG 7 You are an expert at answering questions based on your own knowledge and related context. Please answer this question based on the given context within 5 words. You should put your answer inside <answer> and </answer>. Question:Who won the most MVP awards in the NBA? Doc 1: .... Doc 2: .... Now start your answer. <answer> Fig.2: RAG prompt for generating answers for NQ datasets. The first part of an answer unit <answer> is put at the end to prompt the LLM to yield immediate answers. Document quality measurements.Unlike the previous two categories, the third category of predictors isquery-agnostic, providing estimations from the in- trinsic complexity and quality of the retrieved documents. Readability measures assess text difficulty through factors such as word familiarity, sentence structure, and character statistics [27]. More recently, supervised quality models estimate theinherentusefulnessofadocumentindependentofanyquery[8].Thesepredic- torscomplementretriever-centricandreader-centricsignalsbyofferingabaseline view of the context’s quality, regardless of query or model interpretation. 3.3 Combining Multiple Predictions Each potential predictor for RPP and GPP captures a different aspect of RAG performance. Hence by combining them, we can potentially perform a more comprehensive [5] analysis of the retrieval results and generated answers. By leveraging the complementary benefits of the predictors, such combinations can potentially lead to better estimates for both RPP and GPP, as also observed in QPP applications [23]. In particular, we construct an ensemble of the predictors by applying linear regression to capture the relationship between their outputs and the target values —context utility for RPP and answer quality for GPP—on training queries. Formally, L(Φ, Y;w) =