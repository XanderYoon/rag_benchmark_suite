use the same training configurations as for the mBERT-based xDR trained on XOR-TyDi but using the Natural Questions (NQ) training data [ 15] which contains English-only query-passage training samples. 5 RESULTS 5.1 Main results Table 1 presents the effectiveness of xDR models initialized with the XLM-R and mBERT backbone PLMs and trained on the XOR- TyDi dataset. Zero-shot denotes the models trained only on the English subset of the NQ dataset. In these experiments, we use all the queries generated by our xQG and set the augmentation ratio to ùõº = 0.01 for augmenting the passage embeddings of the xDRs. For the R@2kt metric, the xDR initialized with mBERT out- performs the xDR initialized with XLM-R, achieving an average R@2kt score of 44.1, while XLM-R achieves an average score of 27.5. Our xQG passage embedding augmentation approach improves the XLM-R xDR, achieving an average score of 29.8, which is a statistically significant improvement compared to its baseline effect- iveness (ùëù < 0.05). Similarly, mBERT‚Äôs effectiveness improves with xQG, achieving an average score of 46.2, which is also a statistically SIGIR ‚Äô23, July 23‚Äì27, 2023, Taipei, Taiwan Shengyao Zhuang, Linjun Shou, and Guido Zuccon Figure 3: Impact of the augmentation ratio ùõº. Scores are averaged across all languages. Statistical significant improvements over no augmentation (ùõº = 0) are labelled with stars ( ùëù < 0.05). significant improvement compared to its corresponding baseline (ùëù < 0.05). The zero-shot mBERT model achieves an average R@2kt of 33.0; this also improves when combined with xQG, achieving an average score of 36.0. This improvement is statistically significant (ùëù < 0.05). Similar trends are found for R@5kt. Overall, we find that our xQG can significantly improve all investigated xDR models. In terms of per language effectiveness, xQG improves almost all models across all languages with the