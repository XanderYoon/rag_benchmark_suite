the target language set and ğ‘„ğ‘ is the set of all generated queries for passage ğ‘ which includes ğ‘› generated queries for each target language. In our experiments, we use a top- ğ‘˜ sampling scheme [7] to generate queries, and set ğ‘˜ = 10. We find that these simple language-specific prompts can effectively lead the T5 model to generate the desired output in that language. For the embedding aggregation function, we use a Rocchio- like aggregation function that is similar to previous works that aggregated dense representations [16, 47]. We use this aggregation function to obtain the embeddings of all passages in the corpus: ğ‘’ğ‘šğ‘ (ğ‘, ğ‘„ğ‘, ğœƒ, ğ›¼) = (1 âˆ’ ğ›¼) Â· ğœƒ (ğ‘) + ğ›¼ âˆ‘ï¸ ^ğ‘ğ‘¡ âˆˆğ‘„ğ‘ ğœƒ ( ^ğ‘ğ‘¡ ), (3) where ^ğ‘ğ‘¡ is a generated query for target language ğ‘¡, ğœƒ is the xDR encoder model and ğœƒ (.) is the text embedding given by the xDR encoder. The hyper-parameter ğ›¼ is the augmentation ratio, ğ›¼ âˆˆ [0, 1]. This ratio is used to control the weights assigned to the original passage embedding and the generated query embeddings. 4 EXPERIMENTAL SETTINGS We design our experiments to answer the research questions: RQ1: How does the number of generated queries affect xDR ef- fectiveness? RQ2: How does the augmentation ratio ğ›¼ impact xDR effective- ness? RQ3: How do the queries generated for each language impact xDR effectiveness? Datasets and Evaluation. We train and evaluate our approach on XOR-TyDi [1], a cross-lingual open retrieval question answering benchmark dataset. The dataset contains approximately 15k an- notated relevant passage-query pairs in the training set and 2k passage-answer pairs in the dev set. Queries in both the train and dev sets are in seven typologically diverse languages (Ar, Bn, Fi, Ja, Ko, Ru, and Te), while passages are in English.