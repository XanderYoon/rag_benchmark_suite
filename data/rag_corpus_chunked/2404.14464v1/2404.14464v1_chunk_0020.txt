reasoning paths while 8 reducing ineffective path expansion. We believe that TOR can serve as a robust baseline model for future research in multi-hop question-answering tasks. Moreover, we hope our framework can be extended to more complex reasoning tasks. Limitations TOR has requirements for the capabilities of the base models, including 1) The model should have zero-shot or few-shot CoT reasoning abilities. 2) The model should support long-text inputs, as we need to include retrieved paragraphs and few-shot demonstrations in the prompts. 3) The model should have good instruction-following capabili- ties, as Paragraph Reviews require the model to output intermediate results step-by-step according to the instructions. The model needs to understand the instructions and output in a specific format. Regarding the results returned by LLM, we will parse them according to its prompt. The parsing will fail if the model fails to generate results in that format. The parsing success rate represents LLM’s ability to follow complex instructions. Mod- els that meet our requirements tend to have a larger number of parameters. In contrast, smaller models (with fewer than 20B parameters) often lack sat- isfactory instruction-following capabilities for our tasks. (with the parsing success rates of output be- low 85%, compared to 98.6% for GPT-3.5-Turbo). This limits the generality of our method. How- ever, as large language models continue to develop, smaller models will meet the above requirements, enhancing our approach’s practicality. TOR incurs a significant time cost, as our frame- work calls the LLM at each node, which improves retrieval performance but introduces additional computational overhead. Although we have de- signed two different pruning strategies to alleviate this issue, an average of 16 LLM calls still exists. In future work, we plan to optimize the framework in the following ways: 1) Implement a more fine- grained repetitive pruning strategy,