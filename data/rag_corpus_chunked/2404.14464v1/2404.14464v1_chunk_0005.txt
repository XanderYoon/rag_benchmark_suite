2 like HotpotQA, they rely on expensive manual an- notation and specific training. However, in practi- cal application scenarios like New Bing and Per- Plexity.AI, the indexed document scope is broader, and the retrieval source is updated in real-time. In this case, the supervised models are likely to fail. Retrieval-Augmentation for Complex Problems The Retrieval-Augmented Generation (RAG) sys- tem typically retrieves additional knowledge from specific corpora, such as Wikipedia, to alleviate the hallucination problem of Large Language Mod- els (LLMs), thereby significantly enhancing the performance of LLMs in various tasks (Lewis et al., 2020; Guu et al., 2020; Ram et al., 2023). Early research on RAG typically employs a one- step retrieval approach, which is ineffective in ad- dressing composite problems. To tackle compos- ite problems, Self-Ask (Press et al., 2023) poses sub-questions before answering the main question, optimizing complex composite problems through multiple retrievals.IRCoT (Trivedi et al., 2023) trig- gers retrieval on each sentence of the CoT. ITER- RETGEN (Shao et al., 2023) connects the complete CoT reasoning steps generated in the previous turn with the original question for the next turnâ€™s gen- eration query. However, these methods all adopt a chain-like structure for reasoning. If an error occurs at any step in the reasoning path, it could potentially cause the reasoning path to deviate. Tree-like Reasoning for Complex Problems The tree is an efficient structure for solving com- plex reasoning problems (Yao et al., 2023a). Tree of Thought(ToT) enhances the problem-solving ca- pabilities of Large Language Models (LLMs) by introducing a tree-like structure during the reason- ing process, simulating the human problem-solving process. This allows the model to consider multi- ple reasoning paths and self-evaluate to decide the following action. Asai et al. (2020) trained a re- triever that dynamically retrieves information from Wikipedia graphs. However, this method