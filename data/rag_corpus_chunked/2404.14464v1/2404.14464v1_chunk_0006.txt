enhances the problem-solving ca- pabilities of Large Language Models (LLMs) by introducing a tree-like structure during the reason- ing process, simulating the human problem-solving process. This allows the model to consider multi- ple reasoning paths and self-evaluate to decide the following action. Asai et al. (2020) trained a re- triever that dynamically retrieves information from Wikipedia graphs. However, this method relied on a hyperlink graph constructed from Wikipedia, which fails when the path related to the problem is not included. Some researchers decompose com- plex problems into a static problem tree with sev- eral sub-problems. Then, answer each sub-problem by utilizing language models and additional re- trieval information (Cao et al., 2023) or calculating the probability of reasoning paths (Zhang et al., 2023), ultimately solving the complex problem. However, the decomposition of the question and the construction of the tree lack the assistance of ex- ternal knowledge and information on the reasoning path, which can easily lead to incorrect decomposi- tion, possibly affecting the correctness of the final answer. In contrast, our work is the first to propose a retrieval framework that uses a tree-like structure to dynamically initiate requests based on external knowledge and information on the reasoning path. LLMs can decide dynamically whether to initi- ate further retrieval and what requests to generate based on this information. We have designed two search optimization strategies to reduce the time overhead of tree structure searching and enhance the diversity of initiating requests: pruning and effective expansion. 3 Tree of Reviews Framework 3.1 Overall The task is to answer a multi-hop question Q based on a retrieval corpus D. As illustrated in Figure 2, we introduce TREE OF REVIEWS (TOR), a tree- based dynamic retrieval framework. In this frame- work, the root node is the question Q, while each subsequent node