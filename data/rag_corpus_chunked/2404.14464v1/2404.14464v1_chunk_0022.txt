the APIs we have employed may also be deprecated at some point in the future, we intend to release all prompts and code to make our research easier to replicate for future study. Lastly, the performance of TOR on other com- plex reasoning tasks still requires further verifi- cation. We have only validated the effectiveness of the TOR framework on the multi-hop question- answering task. We believe that introducing a tree- like structure in complex reasoning tasks is a viable approach, and we hope that future work can lever- age this concept to achieve favorable results in a broader array of complex reasoning tasks. Ethical Considerations It is well known that Large Language Mod- els(LLMs) suffer from hallucination, privacy, secu- rity, and bias during their usage. Although TOR employs retrieval augmentation that can alleviate the hallucination problem to some extent, it still cannot fully address these issues. Moreover, our framework does not consider bias, security, and pri- vacy concerns. If our framework is to be deployed in practical application scenarios, certain restric- tions should be implemented to prevent generating harmful information. 9 References Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. 2020. Learn- ing to retrieve reasoning paths over wikipedia graph for question answering. In 8th International Confer- ence on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020 . OpenReview.net. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma- teusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances