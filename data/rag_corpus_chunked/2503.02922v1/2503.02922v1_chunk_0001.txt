scalable, graph-based AI solutions. 1 INTRODUCTION Traditionally, knowledge workers—such as executives, managers, and analysts—relied on data warehousing and operational databases to make faster, more informed decisions [4]. Today, the range of decision support tools has expanded to include foundational mod- els, with AI software spending projected to reach $297.9 billion by 2027 [15]. Although the modern knowledge worker operates in a vastly different environment, one not limited to carefully curated data warehouses with complex multi-dimensional models for on- line analytical processing (OLAP) or highly structured operational databases supporting online transaction processing (OLTP) [4], the core challenges and types of questions that these decision support systems address remain highly relevant. The need for decision support tools capable of processing vast amounts of unstructured data at scale is particularly evident in open-domain question answering (QA). This field, which spans Nat- ural Language Processing (NLP), Information Extraction (IE), and Information Retrieval (IR), focuses on answering questions without relying on predefined context [50]. Large language models (LLMs) such as GPT [ 42], Claude [ 2], and Llama [ 41] have emerged as powerful tools for this purpose, generating human-like responses to complex queries while processing extensive text inputs. In vari- ous enterprise applications that leverage LLMs, user queries can often be classified as either OLTP or OLAP. OLTP-style queries are simple, fact-based questions that can be answered through direct key-value lookups, retrieval from single text snippets, or by locally traversing multiple related pieces of text, while OLAP-style queries are open-ended, thematic, and require aggregating, synthesizing and abstracting information across multiple documents [47]. Just as operational databases are optimized for OLTP tasks and data warehouses for OLAP workloads, specialized LLM applications are now emerging to address these distinct query types, with tailored approaches for both OLTP-like and OLAP-like QA tasks. Retrieval-augmented generation (RAG) has become