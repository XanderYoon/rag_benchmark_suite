content is not explicitly included in the ground truth annotations, leading to an apparent drop in precision. This highlights a fundamental limitation in evaluation: ground truth labels often underrepresent Optimizing open-domain question answering with graph-based retrieval augmented generation the full range of relevant information, making precision an inher- ently conservative metric. These findings emphasize the trade-off between high recall and precision and the need for retrieval strate- gies that maximize informative content inclusion while minimizing irrelevant context, ensuring optimal QA performance. Table 3: MSMarco Precision-Recall Results with Standard Deviation in Parentheses GlobalSearch LocalSearch RAPTOR Precision 0.000 (0.00) 0.002 (0.00) 0.025 (0.02) Recall 0.000 (0.00) 0.577 (0.49) 0.598 (0.49) Token Precision 0.000 (0.00) 0.000 (0.00) 0.001 (0.00) Token Recall 0.033 (0.04) 0.033 (0.04) 0.033 (0.04) HybridSearch TREX Precision 0.107 (0.11) 0.103 (0.11) Recall 0.507 (0.50) 0.490 (0.50) Token Precision 0.122 (0.12) 0.117 (0.11) Token Recall 0.564 (0.47) 0.562 (0.47) Table 4: HotPotQA Precision-Recall Results With Standard Deviation in Parentheses GlobalSearch LocalSearch RAPTOR Precision 0.000 (0.00) 0.001 (0.00) 0.002 (0.00) Recall 0.619 (0.27) 0.988 (0.082) 0.904 (0.21) HybridSearch TREX Precision 0.004 (0.00) 0.004 (0.00) Recall 0.988 (0.07) 0.988 (0.07) 5.1.2 HotPotQA. On the dev split of the HotPotQA benchmark, TREX achieves an accuracy of 80.9% on a filtered set of 5,491 ques- tions, outperforming GraphRAG, RAPTOR, and Hybrid Search. This accuracy approaches the Oracle benchmark of 85.2%, which as- sumes ideal context. In terms of cost, RAPTOR and TREX offer savings over GraphRAG, with approximately a 10x reduction in indexing costs when using GPT-4o, as shown in Table 1. Querying costs are also generally lower for RAPTOR and TREX, as summa- rized in Table 2. Precision and recall are calculated here based on the ground truth entities specified in Wikipedia that are necessary to answer each query. Given that ground truth entities