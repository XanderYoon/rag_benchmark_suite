three-stage post-processing procedure on the raw data to produce the finalNyxQAdataset. â€¢ Error Filtering.Questions with explicit contextual refer- ences (e.g., phrases like â€œin this documentâ€) are removed using rule-based filters. In addition, we ensure imageâ€“text consistency by verifying that the image tags mentioned in the generated question correspond to actual images present in the chunkğ‘‘ ğ‘–. â€¢ QA Refinement.We further refine the filtered QA pairs using a VLM to enhance clarity and completeness. Each re- tained pair (ğ‘raw ğ‘– ğ‘— , ğ‘raw ğ‘– ğ‘— ) is compressed to its essential content, eliminating redundancy while preserving factual accuracy. This process yields concise, self-contained questions and answers that align closely with the corresponding gold doc- umentğ‘‘ + ğ‘– , resulting in the refined set(ğ‘‘ + ğ‘– , ğ‘ğ‘– ğ‘—, ğ‘+ ğ‘– ğ‘—). â€¢ Option Generation.For each refined QA, an LLM gener- ates three semantically plausible distractors {ğ‘âˆ’ ğ‘– ğ‘— } for the question ğ‘ğ‘– ğ‘—. After shuffling the distractors with the correct answer, we finalize each sample with the question, four op- tions, and the gold document, forming our multiple-choice datasetD NyxQA ={(ğ‘ ğ‘– ğ‘—,{ğ‘ + ğ‘– ğ‘—, ğ‘âˆ’ ğ‘– ğ‘— }, ğ‘‘+ ğ‘– )}. Hard Negative Mining.To enhance retriever pretraining, we construct contrastive triplets usingDNyxQA. Each questionğ‘ğ‘– ğ‘— serves as a query, with its corresponding gold document ğ‘‘ + ğ‘– designated as the positive sample. We then employ mmE5 [2] to retrieve the top- 10 relevant documents from the mixed-modal corpus Cmix. From these, we select five documents that differ from ğ‘‘ + ğ‘– as hard nega- tives {ğ‘‘ âˆ’ ğ‘– ğ‘— }, prioritizing the highest-ranked candidates. This yields the pretraining dataset Dpretrain ={(ğ‘ ğ‘– ğ‘—, ğ‘‘+ ğ‘– ,{ğ‘‘ âˆ’ ğ‘– ğ‘— })} , a contrastive training set specifically designed for mixed-modal retrieval. 3.3Nyx: Training Paradigm Overview.Our goal is to build