Cmix. From these, we select five documents that differ from ğ‘‘ + ğ‘– as hard nega- tives {ğ‘‘ âˆ’ ğ‘– ğ‘— }, prioritizing the highest-ranked candidates. This yields the pretraining dataset Dpretrain ={(ğ‘ ğ‘– ğ‘—, ğ‘‘+ ğ‘– ,{ğ‘‘ âˆ’ ğ‘– ğ‘— })} , a contrastive training set specifically designed for mixed-modal retrieval. 3.3Nyx: Training Paradigm Overview.Our goal is to build a unified retriever capable of handling mixed-modal queries and documents across diverse real- world scenarios. To this end, we begin by pretrainingNyxon a large-scale corpus that includes both public and synthetic datasets spanning various modality configurations. This initialization equips the retriever with general-purpose retrieval capabilities across text- only, image-only, and multimodal pairs. However, generic pretraining may not fully align with the spe- cific information needs of downstream VLMs during generation. Therefore, in the second stage, we fine-tuneNyx-pretrained through a feedback-driven learning process, leveraging VLM responses to construct high-quality examples that reflect the actual relevance signals needed for multimodal generation. Throughout both stages, we employ contrastive learning with Ma Matryoshka Representation Learning [28] to ensure scalable and efficient embedding quality under varying dimensional constraints. We detail our training objective and the two-stage procedure below. Training Objective.We build our retriever on top of a pre- trained VLM, Qwen-2.5-VL-3B-Instruct [ 1], as the backbone en- coder. Given an input sequence, we use the hidden representation of the final<EOS>token as the global embedding for retrieval. Following established practices in embedding model training, we construct each training instance as a triplet {ğ‘, ğ‘‘+,{ğ‘‘ âˆ’ ğ‘› }ğ‘ ğ‘›=1}, where ğ‘ is a query, ğ‘‘ + is a positive document, and {ğ‘‘ âˆ’ ğ‘› } are ğ‘ negative documents. An instruction string is prepended to each query before encoding. Both queries and documents may come from mixed modalities (e.g., text, image, or interleaved image-text), allowingNyxto operate in