sampled chunk ğ‘‘ğ‘–, whether text- only or containing images, we use a VLM to generate up to five context-independent raw QA pairs (ğ‘raw ğ‘– ğ‘— , ğ‘raw ğ‘– ğ‘— ), ensuring that each question can be answered solely based on its associated chunk. For chunks with images, we specifically prompt the VLM to create questions that reference the visual content. Since the model outputs text only, we use special tags such as <image k> to denote the ğ‘˜-th image within the chunk. This process produces the raw QA dataset Draw ={(ğ‘‘ ğ‘–, ğ‘raw ğ‘– ğ‘— , ğ‘raw ğ‘– ğ‘— )}, which contains diverse samples ranging from pure text to multi-image questions, thereby enriching the modality diversity ofNyxQA. Post-Processing.The initial set Draw of generated QA pairs is of suboptimal quality, containing various errors that could adversely WWW â€™26, April 13â€“17, 2026, Dubai, UAE Zhang et al. Top-4Doc (a)ModelArchitecture (b)ContrastiveLearningwithMRL (c)VLM-GuidedFeedbackLargeLanguageModel VisionEncoder â€¦he was furious, and would have hurled him into the sea, had he not fled to the protection of Nyx, as Zeusâ€¦ â€¦In the works of Greekpoets,Thetisis a Nereid who attracts the attention of bothZeusandPoseidon,â€¦ â€¦â€¦â€¦â€¦â€¦<EOS> Embedding MatryoshkaRepresentation QueryEmbeddingPos.DocumentEmbeddingNeg.DocumentEmbedding pull push To p-1 To p-Kâ€¦ To p-3 VLM(Generator) SlidingWindow(Length=L) RetrievedDocsInputContext Prompt QuestionAnswers Ldocumentsinthewindow Answer1Answer2 AnswerK-L+1 Answer3Answer4â€¦ Oneinstanceofthedownstream preference datasetQuestionQuery PositiveDocument NegativeDocuments â€¦ Generates answers for each input context Judgetheanswers Top-1DocTop-3DocTop-KDocâ€¦Top-2DocTop-5Doc To p-2 Figure 3: Overview of theNyxarchitecture and its training paradigm. affect subsequent training and evaluation. Therefore, we perform a three-stage post-processing procedure on the raw data to produce the finalNyxQAdataset. â€¢ Error Filtering.Questions with explicit contextual refer- ences (e.g., phrases like â€œin this documentâ€) are removed using rule-based filters. In addition, we ensure imageâ€“text consistency by verifying that the image tags mentioned in the generated question correspond to actual images present in the chunkğ‘‘ ğ‘–. â€¢ QA Refinement.We further