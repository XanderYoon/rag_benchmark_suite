faithful grounding but also for mitigating noise from irrelevant evidence. Future improve- ments may arise from modelling VLM preferences on non-golden evidence, which can sometimes diverge from human intuition. 6 Conclusion To enable Universal Retrieval-Augmented Generation (URAG) over arbitrarily mixed-modal questions and corpora, we constructed NyxQA, the first large-scale and comprehensive dataset that faith- fully reflected real-world URAG scenarios, where text, images, and their interleaved combinations naturally coexisted. Building on this foundation, we introducedNyx, a unified multimodal retriever Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation WWW ’26, April 13–17, 2026, Dubai, UAE explicitly optimized for such settings.Nyxwas initially pretrained via contrastive learning with Matryoshka Representation Learn- ing on a diverse mixture of public and synthetic data, and was subsequently fine-tuned using feedback from a downstream vision- language generator, thereby better aligning retrieval relevance with generation utility. Extensive experiments demonstrated that this simple yet effective pipeline achieved consistent and substantial improvements over both unimodal and multimodal baselines across all modality combinations, underscoring the promise of unified mixed-modal retrieval for next-generation URAG systems. References [1] Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, Humen Zhong, Yuanzhi Zhu, Ming-Hsuan Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, and Junyang Lin. 2025. Qwen2.5-VL Technical Report.CoRRabs/2502.13923 (2025). arXiv:2502.13923 doi:10.48550/ARXIV.2502.13923 [2] Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, and Zhicheng Dou. 2025. mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data.CoRRabs/2502.08468 (2025). arXiv:2502.08468 doi:10.48550/ARXIV.2502.08468 [3] Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation.CoRRabs/2402.03216 (2024). arXiv:2402.03216 doi:10.48550/ARXIV.2402.03216 [4] Mingyang Chen, Tianpeng Li, Haoze Sun, Yijie