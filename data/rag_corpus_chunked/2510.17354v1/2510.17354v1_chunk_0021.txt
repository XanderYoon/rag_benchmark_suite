training data and the quality of retrieval model embeddings [2, 16]. In this section, we further examine how the scale of training data affectsNyx’s per- formance in the URAG setting. As illustrated in Figure 4, the performance trend closely follows a logarithmic-linear curve, consistent with previous findings. The steady improvement of URAG performance with increasing data scale further confirms the high quality and diversity of our training data. This indicates that enhancements in the retriever’s indepen- dent capabilities translate proportionally into gains in end-to-end URAG performance. Thus, increasing training data is expected to predictably enhance URAG scenario generalization. log(2.88k)log(5.76k) log(14.40k) log(57.60k)log(144.00k)log(288.00k)log(576.00k)log(1241.86k) # Training Samples 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85Accuracy y = 0.1204 * log(x) + 0.1041 Trend Linear Fit Performance Figure 4: Impact of training data scale onNyxQAaccuracy when trainingNyxwith varying sample sizes. 0 1 2 4 8 16 # In-Context Documents 0.5 0.6 0.7 0.8Accuracy ( a ) RAG with mmE5 RAG with Nyx-pretrained RAG with Nyx 2 B 8 B 14 B 38 B 78 B Generator VLM 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Accuracy ( b ) Direct Answer RAG with Nyx-pretrained RAG with Nyx Figure 5: Impact of (a) the number of in-context documents and (b) feedback-based retriever fine-tuning on downstream generation performance. Results are shown onNyxQAusing InternVL3 models of varying sizes, respectively. 5.2 Effect of Retrieved Document Count To examine how the number of retrieved documents influences gen- eration quality, we vary the number of documents fed into Qwen2.5- VL-7B from 0 to 16, evaluating the URAG results ofmmE5,Nyx- pretrained, andNyx. As shown in Figure 5(a), adding more doc- uments consistently improves all retrievers, though the gains di- minish as the count increases.Nyxconsistently outperforms both Nyx-pretrained and mmE5, demonstrating robust performance even with fewer documents and confirming the effectiveness of