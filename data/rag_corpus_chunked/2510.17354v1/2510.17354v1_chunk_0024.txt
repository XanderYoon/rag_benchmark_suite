versions maintain strong per- formance. These results highlight MRL’s ability to provide efficient, resource-aware retrieval with graceful performance degradation under limited memory or latency budgets. Table 3: Performance ofNyxonNyxQAunder different out- put dimensions Setting Output Embedding Dimension 2048-dim 1024-dim 512-dim 256-dim Weight1.0000 1.0000 0.2000 0.2000 Accuracy0.8183 0.8100 0.7800 0.7467 5.5 Impact of Retrieved Docs on Generation To investigate the impact of retrieved documents on generation, we begin with a case study on MMQA. As shown in Figure 7, we examines how retrieval influences the produced answers. Unlike MMEB, which assumes modality-specific similarity computation, real-world retrieval entails cross-modal relevance estimation across multimodal documents. In this example, mmE5 retrieves an image- text pair focused solely on “face, ” missing the query subject;Nyx- pretrained correctly identifies “Felicia Day” but provides the textual evidence that fails to support the answer; in contrast,Nyxretrieves the correct entity along with both the proper title and visual infor- mation, directly grounding the generated response. Building on these qualitative observations, we further perform a quantitative analysis on theNyxQAdataset to study the rela- tionship between retrieval correctness and answer correctness. The retrieval quality is visualized in Figure 6 using Sankey diagrams. The results reveal two key trends: (1) higher proportions of golden docu- ments lead to higher answer accuracy; and (2) even with non-golden documents, nearly half of the answers remain correct, demonstrat- ing the robustness of VLMs. These findings suggest that improving retrievers is crucial not only for ensuring faithful grounding but also for mitigating noise from irrelevant evidence. Future improve- ments may arise from modelling VLM preferences on non-golden evidence, which can sometimes diverge from human intuition. 6 Conclusion To enable Universal Retrieval-Augmented Generation (URAG) over arbitrarily mixed-modal questions and corpora, we constructed NyxQA, the first large-scale and comprehensive dataset that faith- fully reflected real-world URAG scenarios, where