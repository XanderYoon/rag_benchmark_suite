each training instance as a triplet {ğ‘, ğ‘‘+,{ğ‘‘ âˆ’ ğ‘› }ğ‘ ğ‘›=1}, where ğ‘ is a query, ğ‘‘ + is a positive document, and {ğ‘‘ âˆ’ ğ‘› } are ğ‘ negative documents. An instruction string is prepended to each query before encoding. Both queries and documents may come from mixed modalities (e.g., text, image, or interleaved image-text), allowingNyxto operate in a unified embedding space. To learn discriminative representations, we adopt the InfoNCE loss for contrastive learning. Leth ğ‘ âˆˆR ğ‘‘,h + âˆˆR ğ‘‘, and {hâˆ’ ğ‘› }ğ‘ ğ‘›=1 âŠ‚ Rğ‘‘ denote the embeddings of the query, the positive document, and the negative documents, respectively. We apply Matryoshka Representation Learning (MRL) [ 28], which encourages the full Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation WWW â€™26, April 13â€“17, 2026, Dubai, UAE embeddingh âˆˆR ğ‘‘ to remain informative even when truncated to lower-dimensional subspaces. This enables flexible trade-offs between retrieval performance and memory efficiency. Specifically, for a set of target dimensions{ğ‘‘1, ğ‘‘2, . . . , ğ‘‘ğ¾ }, where ğ‘‘ğ‘˜ <ğ‘‘ , we truncate each embedding to its first ğ‘‘ğ‘˜ dimensions, denoted ash (ğ‘‘ğ‘˜ ) âˆˆR ğ‘‘ğ‘˜ . For each ğ‘‘ğ‘˜, we compute an InfoNCE loss as: L (ğ‘‘ğ‘˜ ) Info =âˆ’log ğœ™(h (ğ‘‘ğ‘˜ ) ğ‘ ,h +(ğ‘‘ğ‘˜ ) ) ğœ™(h (ğ‘‘ğ‘˜ ) ğ‘ ,h +(ğ‘‘ğ‘˜ ) ) + Ãğ‘ ğ‘›=1 ğœ™(h (ğ‘‘ğ‘˜ ) ğ‘ ,h âˆ’ (ğ‘‘ğ‘˜ ) ğ‘› ) ,(1) where ğœ™( a, b)=exp (sim(a,b)/ğœ ), and sim(Â·,Â·) denotes cosine sim- ilarity with temperature hyperparameter ğœ> 0. Here,h +(ğ‘‘ğ‘˜ ) and hâˆ’ (ğ‘‘ğ‘˜ ) ğ‘› correspond to the positive and the ğ‘›-th negative sample document embeddings, respectively. The final training objective aggregates the InfoNCE losses over all truncated dimensions as a weighted sum: LMRL = ğ¾âˆ‘ï¸ ğ‘˜=1 ğ‘¤ ğ‘˜ Â· L(ğ‘‘ğ‘˜ ) Info ,where ğ¾âˆ‘ï¸ ğ‘˜=1 ğ‘¤ ğ‘˜ =1,(2) with