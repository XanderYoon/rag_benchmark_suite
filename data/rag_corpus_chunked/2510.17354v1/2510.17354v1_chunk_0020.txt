[32] 27.0 4.2 33.9 47.0 25.2 OpenCLIP [7] 47.8 10.9 52.3 53.3 39.7 E5-V [23] 21.8 4.9 11.5 19.0 13.3 MagicLens [52] 38.8 8.3 35.4 26.0 27.8 MMRet [56] 47.2 18.4 56.5 62.2 44.0 VLM2Vec [24] 52.8 50.3 57.8 72.3 55.9 mmE5 [2] 67.6 62.8 70.9 89.7 69.8 mmE5-Qwen-3B 56.6 56.0 59.4 71.5 59.0 Nyx-pretrained 55.2 53.7 58.4 70.5 57.5 Nyx57.9 57.5 61.8 75.7 61.1 its training data consisting of MMEB-labelled data together with the retrieval and VQA subsets of the mmE5 synthetic data, serving as the ablation setting. Compared to mmE5,mmE5-Qwen2.5-3Bperforms worse across all capabilities, which can be attributed to its smaller backbone size and the exclusion of the classification subset from the mmE5 synthetic data (to maintain alignment withNyx-pretrained and Nyxsettings). Nevertheless, it still surpasses other baseline mod- els. When OOD pure text data andNyxQAmixed-modal data are included, the mismatch with the MMEB evaluation pattern results in a 1.5% overall performance drop. However, after fine- tuning with feedback from a VLM on OOD datasets with entirely different tasks,NyxoutperformsmmE5-Qwen2.5-3Bacross all ca- pabilities, achieving a 2.1% overall improvement. These findings further demonstrate that incorporating VLM feedback not only improves the performance of URAG systems but also enhances the embedding capability of dense retrievers themselves. 5 Quantitative Analysis 5.1 Impact of Data Scale on URAG Performance The scalability of training data is crucial for building effective re- trievers. Prior studies have shown an approximately logarithmic- linear relationship between the volume of training data and the quality of retrieval model embeddings [2, 16]. In this section, we further examine how the scale of training data affectsNyxâ€™s per- formance in the URAG setting. As illustrated in Figure 4, the performance trend closely follows a logarithmic-linear curve, consistent with previous findings. The steady improvement of URAG performance with increasing data scale further confirms the