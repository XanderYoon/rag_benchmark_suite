held-out samples for evaluation. For the four text-only datasets above, we construct two separate Wikipedia-derived corpora—one for training and one for evaluation. To build the training corpus, we aggregate all training questions and retrieve their top-20 relevant Wikipedia passages using the E5 retriever over the full Wikipedia dump. The retrieved passages are then deduplicated to form the final training corpus. Similarly, Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation WWW ’26, April 13–17, 2026, Dubai, UAE the evaluation corpus is constructed by collecting all test ques- tions and retrieving their top-20 Wikipedia passages, followed by deduplication. The training corpus is used during the feedback col- lection stage, whereNyx-pretrained retrieves relevant passages to construct the “downstream VLM preference dataset” for fine- tuning. The evaluation corpus is used for benchmarking on the four text-only datasets during the final testing stage. MultimodalQA[41] is a challenging question-answering dataset that necessitates joint reasoning across text, tables, and images. It includes 23,817 training examples and 2,411 testing examples. We combined text, tables, and images to create a large mixed-modal corpus containing 285,370 instances for this MMQA task. ScienceQA[ 35] is a large-scale multimodal science question dataset that annotates answers with detailed lectures and explanations. Each question is accompanied by context, either in the form of natural language or an image. For this dataset, we constructed two corpora: one consists of all the lectures appearing in the dataset, with duplicates removed to form the lecture corpus; the other con- tains the question-answer pairs from the training set, forming the example QA corpus. During testing, we retrieve one lecture and two example QAs to serve as external support information. The training set contains a total of 12,726 examples, while the testing set has 4,241 examples. D Details for Raw QA Generation In this section, we provide additional details on