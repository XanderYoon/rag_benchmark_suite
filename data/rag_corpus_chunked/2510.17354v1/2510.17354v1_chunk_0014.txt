VLM-Guided Feedback. WhileNyx-pretrained demonstrates strong retrieval performance, it is not explicitly optimized for supporting downstream generation by VLMs. To bridge this gap, we introduce a fine-tuning stage that leverages feedback from a VLM to align the retriever with the actual information needs during generation. Given a datasetğ·={(ğ‘ ğ‘–, ğ‘ğ‘– )} of queries and their corresponding answers, along with a retrieval corpus C, we proceed as follows. For each query ğ‘ğ‘–, we first useNyx-pretrained to retrieve the top-ğ¾ candidate documents {ğ‘‘1, ğ‘‘2, . . . , ğ‘‘ğ¾ }. Then, using a sliding win- dow of length ğ¿, we construct a sequence of candidate contexts by grouping contiguous subsets of the retrieved documents. Each context window is concatenated with the query and fed into the VLM to generate an answer. We select the first context window that either yields a correct answer or exceeds a pre-defined generation metric threshold (e.g. EM, F1). The first document in this window is treated as the positive sample ğ‘‘ +, and the remainingğ¾âˆ’ 1documents are used as negative samples {ğ‘‘ âˆ’ ğ‘› }. If no window meets the quality threshold, the entire instance is discarded from the feedback dataset. By applying this procedure to all queries in ğ·, we construct adownstream preference datasetfrom the feedback ğ·pref = {(ğ‘ ğ‘–, ğ‘‘+ ğ‘– ,{ğ‘‘ âˆ’ ğ‘–,ğ‘› })} , which reflects the actual preferences of the VLM in real generation scenarios. We then fine-tuneNyx-pretrained on this dataset using the same contrastive learning framework described earlier, thus obtaining the final retrieverNyx. 4 Main Experiments Our main experiments consist of two parts, where we first evaluate the generation performance in URAG scenarios and then examine the embedding performance, given that the model is inherently an embedding model. All experiments were conducted on a single node equipped with 8 Ã—NVIDIA A800-SXM4-80GB GPUs.