τ denotes the temperature hyperparameter controlling the softness of the similarity distribu- tion. The model is trained using an InfoNCE loss (Oord et al., 2018): L=−1 N NX i=1 log es(Qi,C+ i ) PN j=1es(Qi,C+ j ) +PK k=1es(Qi,C− k ) (7) 4 Experiments and Analysis 4.1 Experimental Datasets and Settings We utilize three information retrieval datasets for evaluation in the BEIR benchmark (Thakur et al., 2021). SciFact (Wadden et al., 2020) pro- vides expert-written scientific claims with evidence- annotated research abstracts for claim verifica- tion. NF-Corpus (Boteva et al., 2016) focuses on medical information retrieval, while Trev-COVID (V oorhees et al., 2021) specializes in COVID-19- related retrieval. Three widely-used embedding models are employed: E5-base-v2 (Wang et al., 2022), BGE-base-en-v1.5 (Xiao et al., 2024), and Jina-embeddings-v2-small (Günther et al., 2023). We also utilize a specialized embedding model MedEmbed-small-v0.1 (Balachandran, 2024) for medical and clinical corpus. Among them, Jina is a long text embedding model with a capacity of 8192 tokens, while both E5, BGE, and MedEmb are regular models with a capacity of 512 tokens. We conducted our end-to-end RAG experiments on five widely-used datasets: PopQA (Mallen et al., 2023) is a curated question set from diverse on- line platforms. NQ dataset (Kwiatkowski et al., 4 DatasetEmbModelMethod chunk size=16 chunk size=32 chunk size=64 chunk size=128 nDCG@1 nDCG@10nDCG@1 nDCG@10nDCG@1 nDCG@10nDCG@1 nDCG@10 SciFact Jina Naive 45.33% 58.74% 53.33% 64.23% 56.00% 66.29% 53.00% 64.79% Late 55.00% 66.63% 55.33% 66.86% 54.00% 66.05% 54.67% 66.12% HeteRAG58.67% 68.90% 57.33% 68.51% 57.00% 67.83% 56.00% 67.50% BGE Naive 53.67% 66.76% 57.33% 69.68% 59.00% 70.87% 61.33% 73.09% Late 60.00% 72.10% 59.33% 71.91% 59.00% 71.70% 59.33% 71.94% HeteRAG63.00% 74.54% 64.33% 75.89% 64.00% 75.54% 60.33% 73.49% E5 Naive 44.00% 58.53% 52.33% 64.03% 51.33% 63.75% 47.67% 58.90% Late 53.00% 66.79% 53.67% 66.77% 53.00% 66.79% 52.67% 66.56% HeteRAG60.33% 71.74% 60.00% 71.04% 58.67% 70.16%