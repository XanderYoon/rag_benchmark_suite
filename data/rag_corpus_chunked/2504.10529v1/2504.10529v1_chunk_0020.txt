and end-to-end genera- tion pipelines validate that HeteRAG significantly outperforms baseline methods. These results high- light the importance of tailoring knowledge repre- sentations to the unique demands of retrieval and generation steps. In general, this work provides a principled direction for advancing RAG systems by harmonizing the dual objectives of retrieval pre- cision and generation quality. 8 Limitations While HeteRAG demonstrates promising results, this work has two main limitations that suggest di- rections for future research. First, the experimental validation currently focuses on several widely-used benchmark datasets from selected domains. Al- though these datasets represent important applica- tion areas for RAG systems, our findings may not fully generalize to emerging domains with distinct knowledge characteristics. Future work should validate the of HeteRAG across more diverse do- mains and emerging application contexts. Second, our framework primarily focuses on optimizing the retrieval side knowledge chunk representations, while employing relatively straightforward repre- sention for generation side. Prompt token compres- sion techniques could potentially better preserve critical information while further improving genera- tion efficiency. This presents a promising direction for subsequent research to enhance the generation- side optimization while maintaining the decoupling paradigm of our framework. We exclusively uti- lize generative AI to refine the writing and verify grammatical accuracy in this paper. References Anthropic. 2024. Introducing contextual retrieval. Ac- cessed: 2025-02-01. Abhinand Balachandran. 2024. Medembed: Medical- focused embedding models. Vera Boteva, Demian Gholipour, Artem Sokolov, and Stefan Riezler. 2016. A full-text learning to rank dataset for medical information retrieval. In Ad- vances in Information Retrieval: 38th European Con- ference on IR Research, ECIR 2016, Padua, Italy, March 20–23, 2016. Proceedings 38, pages 716–722. Springer. Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024a. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation. arXiv preprint arXiv:2402.03216. Xinyue Chen,