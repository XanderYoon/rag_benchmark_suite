evaluate the effectiveness of HeteRAG on the BeIR bench- mark, comparing against two baseline retrieval methods: naive RAG and late chunking. Late chunking method (GÃ¼nther et al., 2024) embeds all tokens in a document before applying chunk- ing with a long text embedding model, to preserve full contextual information and improve retrieval performance. For the Jina model, since it is specifi- cally designed for long texts, late chunking can be applied directly. For the other two models, a variant called long late chunking is used, which employs a sliding window approach to concatenate embed- dings. Table 1 presents the retrieval performance across three representative datasets (SciFact for sci- entific claims, nfCorpus for medical information, and TREC COVID for COVID-19-related articles) using three embedding models with distinct archi- tectures: Jina-v2 (long-text optimized), E5-v2, and BGE-v1.5 (both standard-length models). From the experimental results, we made the fol- lowing observations: First, HeteRAG consistently outperforms baseline methods in almost all cases. Our method achieves average improvements of 9.43% (nDCG@1) and 7.76% (nDCG@10) over naive RAG across all datasets and models, with par- ticularly notable gains on TrecCOVID (+11.73% nDCG@10). While the absolute performance of all three embedding models varies due to their inher- ent capacity differences, HeteRAG maintains sta- ble relative advantages regardless of the backbone model, suggesting effective decoupling of knowl- edge chunk modeling strategy from fundamental capabilities of embedding model. This may be be- cause of the context-enriched strategy of HeteRAG on the retrieval side successfully models more com- prehensive and rich information, thereby increasing recall accuracy. Second, the late chunking method shows better performance on long text embedding models (Jina-v2) compared to naive RAG; however, on regular embedding models (E5-v2 and BGE- v1.5), the performance of the late chunking method declines. We attribute this to the mismatch be- tween the full-document