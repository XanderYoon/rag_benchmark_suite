the retrieval side successfully models more com- prehensive and rich information, thereby increasing recall accuracy. Second, the late chunking method shows better performance on long text embedding models (Jina-v2) compared to naive RAG; however, on regular embedding models (E5-v2 and BGE- v1.5), the performance of the late chunking method declines. We attribute this to the mismatch be- tween the full-document encoding of late chunking (which Jina-v2 natively supports) and the sequence length constraints of regular models. Furthermore, the late chunking method only applies to embed- ding models that use mean pooling and performs poorly on CLS-pooling models. In contrast, Het- eRAG achieves better model-agnostic robustness. Third, varying chunk sizes from 16 to 128 tokens cause fluctuations in the performance of naive RAG. Overall, smaller chunk sizes lead to lower retrieval performance due to the reduced amount of infor- mation. Late chunking is less affected by chunk size due to its global modeling characteristics. Het- eRAG also demonstrates strong stability through its multi-granular retrieval side modeling. In other words, HeteRAG can effectively adapt to differ- ent chunking sizes and strategies corresponding to various corpora. These findings collectively vali- date advantages of HeteRAG in cross-domain gen- eralization, model compatibility, and operational robustness for real-world retrieval scenarios. 4.3 Evaluation on Adaptive Prompt Tuning As demonstrated in Table 2, the experimental re- sults validate the effectiveness of the fine-tuning strategy described in Section 3.3 for HeteRAG. We 6 Model Dataset w/o RAG Naive RAG HeteRAG EM F1 Recall EM F1 Recall EM F1 Recall Llama3-8b PopQA 18.70% 22.96% 25.80% 24.00% 39.75% 58.66% 32.70% 52.25% 76.19% HotpotQA 19.70% 28.03% 28.06% 21.70% 30.56% 32.53% 30.80% 42.48% 43.32% TriviaQA 51.60% 58.94% 60.47% 52.40% 61.04% 63.65% 58.70% 68.56% 71.87% Squad 20.40% 27.09% 28.48% 28.90% 36.49% 40.11% 32.60% 40.34% 44.17% NQ 22.40% 32.61% 37.45% 29.80% 40.25% 47.01% 36.10% 48.24%