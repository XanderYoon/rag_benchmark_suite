the few-shot examples guide themodel to generate contextually relevant questions for new passages. How- ever, the quality of the generated questions relies heavily on the representativeness of the provided examples. On the other h and, RAG, as proposed by [23], enhances the generation process by in- tegrating a retrieval mechanism into the generation pipeli ne. It retrieves semantically relevant external documents and co mbines them with the input text to generate more informed and contex tu- ally rich questions. This is especially beneﬁcial in educat ional con- texts where the provided passage may lack suﬃcient informat ion, and the retrieval of supplementary resources can add depth a nd detail to the generated questions. RAG is useful when additi onal Conference’17, July 2017, Washington, DC, USA Maity et al. context from sources like textbooks, research papers, or on line en- cyclopedias is needed to create high-quality, domain-speciﬁc ques- tions. Despite their promise, both ICL and RAG have certain limita- tions when applied independently in the educational AQG domain. ICL is limited by the quality and coverage of the few-shot exa m- ples, often generating questions that are too similar to the input examples or fail to address the nuanced details of the input p as- sage. RAG, while eﬀective at incorporating external knowle dge, can sometimes retrieve irrelevant or redundant documents [9], lead- ing to questions that are either oﬀ-topic or overly complica ted. In this paper, we propose that combining the strengths of ICL and RAG can signiﬁcantly improve the quality of educational ques- tion generation. We hypothesize that a hybrid approach, whi ch ﬁrst retrieves relevant external documents (as in RAG) and t hen uses a few-shot learning mechanism (as in ICL) to guide quest ion generation, will result in questions that are not only conte xtually relevant but