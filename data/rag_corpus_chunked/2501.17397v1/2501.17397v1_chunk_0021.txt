in generating educational ques- tions. In future work, we plan to expand evaluations to diverse datasets and educational domains to better assess the generalizability of our models. We also aim to incorporate feedback from educators a nd students to reﬁne our approaches, ensuring they meet curric ulum Leveraging ICL and RAG for Automatic /Q_uestion Generation in Ed ucational Domains Conference’17, July 2017, Washington, DC , USA standards and eﬀectively support learning outcomes. In add ition, we plan to explore other state-of-the-art LLMs, such as Gemi ni and Llama-2-70B, for in-context learning. These initiatives will im- prove the development of more eﬀective and contextually accurate AQG systems. ACKNOWLEDGMENTS The ﬁrst two authors gratefully acknowledge the Ministry of Hu- man Resource Development (MHRD), Government of India, for funding their doctoral research. The authors also thank the anony- mous reviewers for their valuable feedback and insightful s ugges- tions, which signiﬁcantly enhanced this work. Additionall y, they acknowledge the use of ChatGPT for proofreading, polishing , and enhancing the clarity and style of their initial drafts, as w ell as for reviewing the ﬁnal manuscript prior to submission. REFERENCES [1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad , Ilge Akkaya, Flo- rencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sa m Altman, Shya- mal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023). [2] Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemo yer, and Marjan Ghazvininejad. 2022. In-context Examples Selection for Ma chine Translation. arXiv:2212.02437 [cs.CL] https://arxiv.org/abs/2212.0 2437 [3] Said Al Faraby, Adiwijaya Adiwijaya, and Ade Romadhony. 2023. Review on neural question generation for education purposes. International Journal of Ar- tiﬁcial Intelligence in Education (2023), 1–38. [4] Fernando Alva-Manchego, Carolina Scarton, and Lucia Sp ecia. 2021. The (Un)Suitability of Automatic Evaluation Metrics for Te xt Sim- pliﬁcation. Computational Linguistics 47, 4