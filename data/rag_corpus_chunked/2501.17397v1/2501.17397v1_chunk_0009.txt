task is extended by incorporating an external retrieval mechanism. Given a pas sage /u1D443 , the model retrieves a set of relevant documents { /u1D4451, /u1D445 2, . . . , /u1D445 /u1D458} from an external corpus. These documents provide additiona l con- text, and the ﬁnal question /u1D444 is generated as: /u1D444 = /u1D453RAG( /u1D443, { /u1D445/u1D456} /u1D458 /u1D456=1) 3.5 Hybrid Model Our proposed Hybrid Model combines the advantages of both ICL and RAG. The model ﬁrst retrieves a set of documents { /u1D445/u1D456} /u1D458 /u1D456=1 for the input passage /u1D443 , and then uses few-shot learning to generate the question /u1D444 based on both the passage and retrieved documents: /u1D444 = /u1D453Hybrid ( /u1D443, { /u1D445/u1D456} /u1D458 /u1D456=1, {( /u1D443 /u1D456, /u1D444 /u1D456)} /u1D45A /u1D456=1) Here, the retrieval step enriches the context for question g en- eration, while the few-shot examples (i.e., /u1D45A examples) help guide the model towards generating pedagogically relevant quest ions. 4 DATASET We used the EduProbe dataset [27], which comprises 3,502 question- answer pairs across various subjects: 858 pairs related to H istory, 861 pairs related to Geography, 802 pairs related to Economics, 606 pairs related to Environmental Studies, and 375 pairs related to Sci- ence. The dataset was curated from segments of varying lengt hs, extracted from a diverse range of chapters in National Counc il of Educational Research and Training (NCERT) 1 textbooks across several subjects, covering standards from 6/u1D461ℎto 12/u1D461ℎ. Each entry in the dataset includes a context (or passage), a long prompt, a short prompt, and a question. For our experiments, we extracted only the context (or passage) and question, focusing on evaluating how well the models generate questions based on the provided context s (or passages). We used the same training and test datasets as in [ 27]. 5