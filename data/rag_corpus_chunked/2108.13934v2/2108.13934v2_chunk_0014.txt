KGI0 96.24 97.53 69.58 77.24 KGI1 98.60 99.70 71.32 78.85 T-REx RAG-KKS 63.28 67.67 RAG+BM25 46.40 67.31 69.10 73.11 RAG+DPRN Q 53.04 65.54 73.02 76.97 KGI0 61.30 71.18 76.58 80.27 KGI1 74.34 82.89 84.04 86.89 Table 4: Dev sets performance for different retrieval methods with only RAG training on KILT (RAG+DPRN Q). We use the approach explained in Section 3 to train both the DPR and RAG models. KGI0 is a version of our system using DPR with hard negative samples from BM25. The successor system, KGI1 incorporates DPR training using DNS. The metrics we report include accuracy and F1 on the slot ﬁller, where F1 is based on the recall and precision of the tokens in the answer, allowing for partial credit on slot ﬁllers. Our systems, except for RAG-KKS, also provide provenance information for the top answer. R-Precision and Recall@5 mea- sure the quality of this provenance against the KILT ground truth provenance. Finally, KILT-Accuracy and KILT-F1 are combined metrics that measure the accuracy and F1 of the slot ﬁlleronly when the correct provenance is provided. Table 4 reports an evaluation on the develop- ment set, while Table 5 reports the test set per- formance of the top systems on the KILT leader- board. KGI0 and KGI1 are our systems, while DensePhrases, GENRE, Multi-DPR, RAG for KILT and BARTLARGE are explained brieﬂy in Section 2. KGI1 gains dramatically in slot ﬁlling accuracy over the previous best systems, with gains of over 14 percentage points in zsRE and even more in T-REx. The combined metrics of KILT-AC and KILT-F1 show even larger gains, suggesting that the KGI1 approach is effective at providing justify- ing evidence when generating the correct answer. We achieve gains of 21 to 41 percentage points in KILT-AC. Relative to Multi-DPR, we see the beneﬁt of