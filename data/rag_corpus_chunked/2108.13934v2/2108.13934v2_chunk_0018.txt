corpus frequency of the head or tail entity. To test it, we group the Dev instances in T-Rex according to the decile of the head or tail entity frequency. We compute a macro-accuracy, weight- ing all relations equally. Figure 5 shows the macro- accuracy of BARTLARGE and KGI1 for each decile of head and tail entity frequency. Although there is a general trend of higher accuracy for more fre- quent tail entities and lower accuracy for more fre- quent head entities, there is no pattern to the gain of explicit knowledge over implicit knowledge from entity frequency. There is a similar picture when considering the decile of the minimum of the head or tail entity frequency. This falsiﬁes our second hypothesis and suggests implicit knowledge is dis- tinct in kind from explicit knowledge, rather than merely under-trained for low frequency entities. 0 0.2 0.4 0.6 0.8 1 1 2 3 4 5 6 7 8 9 10 Macro Accuracy Frequency Decile BART by head KGI by head BART by tail KGI by tail Figure 5: Performance as a function of entity frequency 5 Domain Adaptation Experiments In this section, we evaluate the domain adaptation capability of KGI. For this purpose, we re-organize a dataset speciﬁcally designed to evaluate standard supervised relation extraction models, such as TA- CRED, with the aim to create a zero-shot (and few- shot) slot ﬁlling benchmark where the documents are written with a different style than Wikipedia, and the relations in the KG are different from those in Wikidata. In order to perform an in-depth com- parison and analysis, we also propose a new set of ranking baselines and use metrics which are suitable to better evaluate the slot ﬁlling task in a zero-shot setup. 5.1 Zero-shot TACRED The TACRED dataset was originally proposed by Zhang