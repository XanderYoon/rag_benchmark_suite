2020; Petroni et al., 2020), has opened tasks such as zero-shot slot ﬁlling to pre-trained transformers. Furthermore, the introduction of re- trieval augmented language models such as RAG (Lewis et al., 2020b) and REALM (Guu et al., 2020) also permit providing textual provenance for the generated slot ﬁllers. KILT (Petroni et al., 2021) was introduced with a number of baseline approaches. The best per- forming of these is RAG (Lewis et al., 2020b). The model incorporates DPR (Karpukhin et al., 2020) to ﬁrst gather evidence passages for the query, then uses a model initialized from BART (Lewis et al., 2020a) to do sequence-to-sequence generation from each evidence passage concate- nated with the query in order to generate the answer. In the baseline RAG approach only the query en- coder and generation component are ﬁne-tuned on the task. The passage encoder, trained on Natural Questions (Kwiatkowski et al., 2019) is held ﬁxed. Interestingly, while it gives the best performance of the baselines tested on the task of producing slot ﬁllers, its performance on the retrieval metrics is worse than BM25 (Petroni et al., 2021). This sug- gests that ﬁne-tuning the entire retrieval component could be beneﬁcial. Another baseline in KILT is BARTLARGE ﬁne-tuned on the slot ﬁlling tasks but without the usage of the retrieval model. In an effort to improve the retrieval performance, Multi-task DPR (Maillard et al., 2021) used the multi-task training of the KILT suite of benchmarks to train the DPR passage and query encoder. The top-3 passages returned by the resulting passage index were then combined into a single sequence with the query and a BART model was used to produce the answer. This resulted in large gains in retrieval performance. DensePhrases (Lee et al., 2021) is a different approach to knowledge intensive tasks with a short