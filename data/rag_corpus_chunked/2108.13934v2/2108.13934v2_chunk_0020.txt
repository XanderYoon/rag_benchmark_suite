be used for slot ﬁlling evalua- tion5; 3) we remove all the triples from the original test set where the subjects are pronouns. The result- ing KG consists of 2673 slot ﬁllingtest instances. Similarly, we acquire a KG from the train/dev sets to further ﬁne-tune theKGI system as described in the next section. To enable zero-shot experiments, we also convert each relation label into a relation phrase by removing the namespaces per: and org:, and replacing the ‘_’ character with a space. Fi- nally, for each pre-annotated entity in the corpus, we pre-compute an inverted index consisting of a list of co-occurring entities in the textual passages. We use this inverted index to compare our model with a set of ranking baselines. An example of the obtained ground truth is illus- trated in Table 7: given the query[Dominick Dunne, employee of, ?] , a slot ﬁlling system is supposed to identify the missing slot with V anity Fair, i.e. the gold standard object in the KG, by retrieving it 579.5% of the overall instances are labeled as no relation. We exclude these instances from the ground truth KG, but we retain them in the textual corpus. from the collection of passages. 5.2 Slot Filling Evaluation Task Given a slot ﬁlling query(e, s, ?) and a list of possible slot values [v1, ..., vn], where e is the entity as subject, s is the slot/relation and vi are the object candidates that co-occur withe in the corpus, we can frame the zero-shot slot ﬁlling as a ranking problem: argmaxi scoreM (e, s, vi). scoreM is a function that takes as input a triple and provide a score based on the model M. Turning the slot ﬁlling into a ranking problem has two advantages: 1) we can compare the generative approach with