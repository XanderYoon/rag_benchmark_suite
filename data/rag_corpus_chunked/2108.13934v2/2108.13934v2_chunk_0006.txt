(128) space. It also uses the inverse cloze pre-training task for retrieval, while DPR does not use retrieval speciﬁc pre-training. 3 Knowledge Graph Induction Figure 2 shows KGI, our approach to zero-shot slot ﬁlling, combining a DPR model and RAG model, both trained for slot ﬁlling. We initialize our mod- els from the Natural Questions (Kwiatkowski et al., 2019) trained models for DPR and RAG available from Hugging Face (Wolf et al., 2020)2. We then employ a two phase training procedure: ﬁrst we train the DPR model, i.e. both the query and con- text encoder, using the KILT provenance ground truth. Then we train the sequence-to-sequence gen- eration and further train the query encoder using only the target tail entity as the objective. It is important to note that the same query encoder com- ponent is trained in both phases. Query Encoder Generator Passage Encoder DPR RAG KILT Knowledge Source head [SEP] relation tail Passages ANN Index Figure 2: KGI Architecture 3.1 DPR for Slot Filling Our approach to DPR training for slot ﬁlling is an adaptation of the question answering training in the 2https://github.com/huggingface/ transformers original DPR work (Karpukhin et al., 2020). We ﬁrst index the passages using a traditional keyword search engine, Anserini3. The head entity and the relation are used as a keyword query to ﬁnd the top- k passages by BM25. Passages with overlapping paragraphs to the ground truth are excluded as well as passages that contain a correct answer. The re- maining top ranked result is used as a hard negative for DPR training. This is the hard negative mining strategy used by DPR (Karpukhin et al., 2020) and Multi-DPR (Maillard et al., 2021). head1 [SEP] relation1 head2 [SEP] relation2 head3 [SEP] relation3 Passage1 + Passage1 - Passage2 + Passage2 - Passage3 + Passage3 -