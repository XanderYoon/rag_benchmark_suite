selection in determining the overall performance. While larger MLLMs typi- cally demonstrate superior results, our Qwen2-7B-VL-Cog closely approximates the performance of Qwen2-VL-72B-Instruct across most evaluation metrics. This finding serves to validate the efficacy of our fine-tuning strategy. Under the CogPlanner framework, our results demonstrate that it is indeed possible to deploy a resource- efficient planning expert, leading to enhanced performance of the MRAG system. Specifically, the Qwen2-7B-VL-Cog emerges as a compelling alternative. 6.3.2 Efficiency Evaluation.We compare the efficiency of CogPlan- ner with Qwen2-VL-72B-Instruct and Qwen2-7B-VL-Cog as the planning expert. Specifically, we use total token generation and latency as the primary evaluation metrics, excluding the cost associ- ated with final answer generation to isolate planning efficiency. As shown in Table 4, our findings indicate that Qwen2-7B-VL-Cog con- stitutes a significantly more lightweight module for MRAG systems, incurring only a 10% increase in token consumption, but reducing latency to just 30% compared to the Qwen2-VL-72B-Instruct model. It emerges as a practical compromise between performance and computational efficiency, particularly well-suited for deployment in real-world industrial settings. Furthermore, the parallel execu- tion model exhibits superior performance relative to the sequential modeling approach across both efficiency metrics, aligning with our design expectations. CogPlanner: Unveiling the Potential of Agentic Multimodal Retrieval Augmented Generation with Planning SIGIR-AP 2025, December 7-10, 2025, Xiâ€™an, China Table 4: End-to-end performance and efficiency evaluation of Qwen2-VL-72B-Instruct and Qwen2-7B-VL-Cog as planning experts, with response generation models consistently using Qwen2-VL-72B-Instruct. Planning Expert Precision Recall F1 Avg # Total Tokens Latency(s) CogPlanner With Parallel Modeling Qwen2-VL-72B-Instruct 32.45 36.90 21.74 30.36 9.76 (14.9%) 1.209 Qwen2-7B-VL-Cog 31.97 32.65 21.46 28.69 7.58 (9.8%) 0.484 CogPlanner With Sequential Modeling Qwen2-VL-72B-Instruct 31.79 36.33 20.65 29.59 13.56 (21.6%) 1.842 Qwen2-7B-VL-Cog 32.50 33.10 21.38 29.00 7.59 (11.9%) 0.545 Table 5: The proportion of retrieval actions of different methodologies, # No, #