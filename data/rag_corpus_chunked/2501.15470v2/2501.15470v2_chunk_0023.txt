7-10, 2025, Xiâ€™an, China Trovato et al. experts. We evaluate three distinct approaches: parallel modeling, sequential modeling, and direct reformulating query through GPT- 4o with optimized prompt engineering. The comparative analysis employs standard metrics, including BLEU [22], ROUGE [18], and F1 scores to assess the quality and relevance of the reformulated query outputs against established ground truth. 6.1.3 Implementation Details.In our retrieval process, we retain the top five results from a web search, each result containing a max- imum of 800 tokens. For fine-tuning the Qwen2-7B-VL-Cog model, we leverage the Llama-Factory framework [37] with a learning rate of 2e-6. A cosine learning rate scheduler is employed, and training proceeds for 2 epochs with a batch size of 32 and a warm-up ratio of 0.1. To ensure computational efficiency and prevent indefinite reasoning loops, we impose an upper bound of three iterations on the CogPlanner planning process. Our experiments are conducted on 8 NVIDIA A800 GPUs. 6.2 CogPlanner Performance 6.2.1 End-to-end Performance.Table 2 presents a comprehensive comparison of the end-to-end performance of various MLLMs inte- grated with current MRAG methodologies and our proposed Cog- Planner. The following observations can be drawn based on these results: (1)Enhanced Performance with CogPlanner: Notably, CogPlanner with GPT-4o consistently yields best performance com- pared to all other configurations. Specifically, it delivers substantial improvements over baseline MRAG systems, with end-to-end per- formance gains ranging from 12.4% to 52.5%, and at least a 41.45% improvement over self-reflective MRAG variants. This enhance- ment is attributed to its ability to decompose and refine complex queries. By simplifying these queries, CogPlanner facilitates the dynamic determination of necessary retrieval actions, thereby en- suring the acquisition of accurate, complementary information. These results highlight the critical role of MRAG Planning in op- timizing the performance of MRAG systems. (2)Weakness of Fixed Search Strategies: The