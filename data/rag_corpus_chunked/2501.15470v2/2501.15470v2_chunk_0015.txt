their contextual captions to provide relevant semantic grounding. Furthermore, to enhance system efficiency and responsiveness, we incorporate caching mech- anisms for both text and image retrieval modules. This iterative cycle culminates when the planning expert collec- tively assesses that the acquired information is sufficiently compre- hensive and the formulated query exhibits adequate clarity. Upon reaching this convergence criterion, the planning procedure is final- ized, and CogPlanner proceeds to generate the ultimate response. 4.3 Compatibility The CogPlanner framework is inherently agnostic to the specific model employed, making it easy to be integrated into any MRAG system and immediately enhancing their performance, demonstrat- ing stunning flexibility in real-world applications. The planning 2https://github.com/jina-ai/reader expert responsible for query reformulation and determining the appropriate retrieval action can be any MLLM, or even a traditional classification model. For the planning expert, we exclusively employ a diverse set of advanced MLLMs as the foundation. Specifically, we leverage both closed-source APIs and open-source MLLMs. The closed-source models include GPT-4o [9], while the open-source models consist of the Qwen-VL series [3] and the Pixtral series [7]. 5 CogBench Construction In this section, we present CogBench, a benchmark specifically developed for the MRAG planning task. CogBench comprises over 5,000 data samples, with a high-quality test set containing more than 400 samples. This benchmark is designed to facilitate the assess- ment of the effectiveness of our proposed CogPlanner framework, as well as other MRAG planning frameworks. Moreover, CogBench can be leveraged to enhance the decision-making capabilities of various MLLMs, particularly resource-efficient models, through fine-tuning. In the following subsections, we detail the construc- tion process of CogBench and demonstrate how the benchmark enables lightweight integration of CogPlanner with the Qwen2-VL- 7B-Instruct. 5.1 Query Collection The rapid evolution of MLLMs has underscored the need for evalu- ation on increasingly complex user queries that