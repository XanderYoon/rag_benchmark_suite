(4) each query should target specific information, asking about concrete aspects of the image. For each image, the 1–5 most compelling queries, which highlight the potential of multimodal retrieval, are retained. 5.2 MRAG Planning and Generation The MRAG planning and generation process is central to the Cog- Planner framework, as detailed in Section 4.2. We employ the GPT- 4o API for executing the planning process. This implementation records each iteration of the planning process, encompassing the series of actions taken, the multimodal document sets retrieved, and the responses generated. Following response generation, the expert 3https://www.anthropic.com/news/claude-3-5-sonnet SIGIR-AP 2025, December 7-10, 2025, Xi’an, China Trovato et al. Table 1: Key statistics of CogBench. # Query # Domians # Query Len. # Answer Len. # Images 5718 9 8.95 40.13 1381 Reasoning Steps Answer Type 1-hop 2-hop > 2-hop open-ended close-ended 1166 1882 2666 1383 4334 20.39% 32.91% 46.62% 24.19% 75.80% annotators conduct a thorough examination to review and regular- ize the entire chain of actions, and manually annotate the golden answer. Each data sample in the CogBench, therefore, contains a multimodal query, the retrieval actions, reformulated queries at each iterative step, the documents retrieved, and the final golden answer. To be noticed, we do not define a fixed gold standard for the multimodal query processing, as manual annotation of informa- tion collection paths does not yield a unique or definitive reference. Instead, we focus on the correctness and completeness of the final answer. Finally, the CogBench dataset is divided into training and test sets, comprising 5307 and 401 samples, respectively. 5.3 CogBench Analysis As shown in Table 1 and Figure 3, CogBench contains 5718 user queries spanning 9 distinct cognitive domains. We identify several fundamental characteristics that distinguish CogBench from exist- ing benchmarks. (1) Unlike previous benchmarks, which focus pri- marily on