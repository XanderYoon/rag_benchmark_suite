through online gaming store Steam have exceeded 21 million copies to date… Astro Bot has sold 1.5 million copies so far, Sony has announced. As part of its latest financial results… Iteration 1 Iteration2 Figure 1: An example of current MRAG system with the ben- efits of incorporating MRAG Planning. 1 Introduction Retrieval-Augmented Generation (RAG) has been shown to signifi- cantly enhance the performance of large language models (LLMs) by grounding generation in retrieved knowledge [ 10, 15]. More recently, the emergence of agentic RAG frameworks, exemplified by web agents [17, 29], has highlighted the potential of autonomous reasoning and information seeking capabilities within RAG systems. Howevewr, the increasing demands of real-world applications have necessitated a natural extension of RAG beyond purely texts to en- compass multimodal data (e.g., images, videos). This development has led to the advent of Multimodal Retrieval-Augmented Genera- tion (MRAG) [23], which equips multimodal large language models (MLLMs) with the ability to retrieve and exploit external multi- modal knowledge sources, thereby reducing hallucinations and improving reliability [35]. Existing MRAG frameworks generally adhere to a rigid pipeline characterized by a predetermined retrieval action, either exclusively textual or exclusively visual [5, 38], which manifests several critical limitations: • Blind Information Acquisition: As demonstrated in recent studies [2, 25], this compulsive retrieval mechanism without proper consideration of necessity or relevance can introduce ir- relevant contextual information that undermines the MLLM’s capability for accurate responses. Moreover, it neglects the inher- ent capabilities of MLLMs to reason and process multimodal data, rendering the retrieval step redundant or counterproductive. • Inadequate Query Formation: The visual incompleteness, tex- tual ambiguity, and conciseness create a fundamental impediment that fails to retrieve pertinent information. Furthermore, these 1∗ These authors contributed equally to this work. 2† Corresponding author. arXiv:2501.15470v2 [cs.IR] 31 Oct 2025 SIGIR-AP 2025, December