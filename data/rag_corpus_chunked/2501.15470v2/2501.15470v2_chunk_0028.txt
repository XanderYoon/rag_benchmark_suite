[6, 32]. Among the models examined, the Qwen2-VL- 72B-Instruct exhibits the most pronounced mismatch, performing over two rounds of processing even for 1-hop queries, which is counterintuitive when compared to its behavior on more complex, multi-hop queries. In contrast, the Qwen2-7B-VL-Cog model pro- duces the most reasonable number of retrieval actions. Additionally, comparing sequential and parallel modeling paradigms reveals a substantial reduction in redundant retrieval actions. This is attrib- uted to the query reformulation step, which allows the CogPlanner to better evaluate whether further search is genuinely necessary, resembling a reflective thought process. (2) From the data presented in Table 5, it is evident that the Qwen2-7B-VL-Cog model predomi- nantly relies on textual search. This trend is also observable when average 1-hop 2-hop 3-hop 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3Average Action Nums The average of retrieval actions under parallel modeling. Pixtral-Large-Instrcut Qwen2-VL-72B-Instruc Qwen-7b-VL-Mind average 1-hop 2-hop 3-hop 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3Average Action Nums The average of retrieval actions under sequential modeling. Pixtral-Large-Instrcut Qwen2-VL-72B-Instruc Qwen-7b-VL-Mind Figure 4: The average number of retrieval actions of different MLLMs across queries with different reasoning steps. comparing the two modeling paradigms. These results suggest that text-based retrieval remains the most preferred and fundamental method for acquiring information in MLLMs. Furthermore, the prevalence of redundant retrieval actions in this domain could be attributed to the tendency of models to perform additional web searches for reassurance, which does not necessarily harm overall performance. (3) Notably, most tasks appear to be resolved around 2-hop retrieval steps, even for more complex queries requiring greater than 2 hops. Determining an optimal retrieval strategy that aligns with the modelâ€™s knowledge base and reasoning capabilities remains a challenging task for current MLLMs. 7 Conclusion This work introduces Multimodal Retrieval Augmented Generation Planning (MRAG Planning)