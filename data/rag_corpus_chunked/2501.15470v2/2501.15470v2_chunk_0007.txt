visual question answering (VQA) benchmarks [30]. Recent advancements in MRAG have demon- strated notable progress. For instance, MuRAG [5] highlights how CogPlanner: Unveiling the Potential of Agentic Multimodal Retrieval Augmented Generation with Planning SIGIR-AP 2025, December 7-10, 2025, Xi‚Äôan, China incorporating visual information retrieved from external sources significantly improves the system performance. Other prominent approaches include Plug-and-Play [26], which transforms visual content into textual descriptions to facilitate integration with con- ventional text-based question-answering mechanisms. Additionally, RAMM [31] enhances the generation process by incorporating both text-to-image retrieval and subsequent fusion of the representa- tions for more accurate answer generation. Further innovations include Wiki-llava [ 4] and mR2AG [ 33], which enable retrieval from online knowledge bases, such as Wikipedia, via image-based queries, to provide more contextually informed responses to user queries. M2RAG [21] extends these efforts by enabling concurrent retrieval of both textual and visual elements in response to multi- modal queries, allowing for more robust query understanding and generation capabilities. Additionally, benchmarks such as MRAG- Bench [8] and MMSearch [12] have been introduced to evaluate MRAG performance, particularly in tasks with image-to-image re- trieval, addressing challenges related to incomplete or insufficient image data. The prevailing methodologies predominantly adhere to a rigid, single-modality search paradigm. However, in authentic user scenarios, knowledge acquisition can originate from diverse sources, contingent upon the specific query and the underlying domain. To this end, we introduce the novel task of MRAG Plan- ning. The primary goal of MRAG Planning is to systematically determine the most effective query processing strategy tailored to each multimodal query and the underlying MLLMs. 3 Task Formulation Consider a multimodal query Q0 =(ùëû, ùë£) where ùëû represents the textual component and ùë£ represents the visual component (e.g., an image). The objective of MRAG is to retrieve pertinent informa- tion from a document