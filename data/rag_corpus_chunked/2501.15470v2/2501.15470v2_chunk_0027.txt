Recall F1 Avg # Total Tokens Latency(s) CogPlanner With Parallel Modeling Qwen2-VL-72B-Instruct 32.45 36.90 21.74 30.36 9.76 (14.9%) 1.209 Qwen2-7B-VL-Cog 31.97 32.65 21.46 28.69 7.58 (9.8%) 0.484 CogPlanner With Sequential Modeling Qwen2-VL-72B-Instruct 31.79 36.33 20.65 29.59 13.56 (21.6%) 1.842 Qwen2-7B-VL-Cog 32.50 33.10 21.38 29.00 7.59 (11.9%) 0.545 Table 5: The proportion of retrieval actions of different methodologies, # No, # Text, # Image represents no search, text search and image search, respectively. Model Category # No # Text # Image Pixtral-Large-Instruct Parallel 11.51% 65.24% 23.25% Sequential 8.43% 84.28% 18.00% Qwen2-VL-72B-Instruct Parallel 13.38% 59.87% 26.75% Sequential 11.46% 66.07% 22.47% Qwen2-7B-VL-Cog Parallel 5.25% 80.43% 14.32% Sequential 5.25% 80.42% 14.43% 6.4 Analysis 6.4.1 Analysis on planning procedure of Cogplanner.We conduct an analysis to explore the adaptive decision-making capabilities of CogPlanner, which emulates human cognition by tailoring its planning processes to the specific knowledge bases of different MLLMs. Specifically, we examine the length of decision chains and the distribution of retrieval actions across the Pixtral-Large-Instruct, Qwen2-VL-72B-Instruct, and Qwen2-7B-VL-Cog. The results are summarized in Table 5 and Figure 4. The following observations can be drawn from these analyses: (1) As shown in Figure 4, the distribution of retrieval actions indicates that all the MLLMs tend to perform more actions than are typically expected by human annotators. The expected behavior would be a gradual progression of actions. However, MLLMs generally opt to acquire more infor- mation and make conservative decisions in an attempt to ensure accuracy [6, 32]. Among the models examined, the Qwen2-VL- 72B-Instruct exhibits the most pronounced mismatch, performing over two rounds of processing even for 1-hop queries, which is counterintuitive when compared to its behavior on more complex, multi-hop queries. In contrast, the Qwen2-7B-VL-Cog model pro- duces the most reasonable number of retrieval actions. Additionally, comparing sequential and parallel modeling paradigms reveals a