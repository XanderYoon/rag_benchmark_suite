contextual alignment of each candidate item. The workflow begins with the applying a regular RAG for retriev- ing the an initial set of larger recall set of items. Then, an NLI Agent evaluates whether each candidate item supports or aligns with this inferred user intent by analyzing its textual metadata (e.g., title, description, reviews). Then, a context summary agent summarizes the retrieved context by NLI agent. In parallel to this workflow, the ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation SIGIR, July 13-17, 2025, Padova, Italy User Understanding Agent, generates a natural language summary of user preferences based on the session context. This helps with identifying generic long-term interests of the user. Finally, the Item Ranker Agent integrates these signals to produce a final ranked list of items, prioritizing those most relevant to both the userâ€™s cur- rent and historical preferences. This agentic collaboration enables ARAG to perform fine-grained relevance assessment and produce recommendations that are both context-aware and semantically grounded. 2.1 Formal Problem Statement To formalize the methodology, the input to the system consists of two components: (i) Along-term context, ğ¶lt, capturing the userâ€™s historical interactions, and (ii) A current session, ğ¶st, reflecting recent user behaviors. We let u = ğ¶lt, ğ¶ st  denote the combined user context. Let I = {ğ‘–1, . . . , ğ‘–ğ‘ } be the set of all candidate items, each having associated textual metadata ğ‘‡ (ğ‘–) (e.g., title, description, reviews). Our goal is to produce a final ranking, or a permutation ğœ‹ over the I: ğœ‹ = ğ‘“Rank (u, I), which orders items by their relevance to the userâ€™s contextu. 2.2 ARAG framework In this subsection we formally introduce the components of ARAG. 2.2.1 Initial cosine similarity-based RAG. We use a RAG framework to obtain an initial subset I0 âŠ† I of