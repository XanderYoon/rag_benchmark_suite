is to produce a final ranking, or a permutation ğœ‹ over the I: ğœ‹ = ğ‘“Rank (u, I), which orders items by their relevance to the userâ€™s contextu. 2.2 ARAG framework In this subsection we formally introduce the components of ARAG. 2.2.1 Initial cosine similarity-based RAG. We use a RAG framework to obtain an initial subset I0 âŠ† I of candidate items. Assume there is an embedding function: ğ‘“Emb : I âˆª { u} â†’ Rğ‘‘, which maps both items and user context into a sharedğ‘‘-dimensional embedding space. We measure similarity between two embeddings via sim(Â·, Â·), e.g., cosine similarity. The top-ğ‘˜ retrieved items are chosen by: I0 = argtopğ‘˜ n sim ğ‘“Emb (ğ‘–), ğ‘“Emb (u) ğ‘– âˆˆ I o . This yields an initial recall set of size ğ‘˜ that will be refined by subsequent agents. 2.2.2 NLI Agent for Contextual Alignment. A Natural Language Inference (NLI) Agent evaluates each item ğ‘– âˆˆ I 0 to check how well its metadata ğ‘‡ (ğ‘–) aligns with the user context. Let ğ‘ NLI (ğ‘–, u) = Î¦ ğ‘‡ (ğ‘–), u, denote the alignment score produced by the NLI Agent, where Î¦ is an LLM-based function. A high score indicates that ğ‘– strongly supports or matches the userâ€™s interests. 2.2.3 Context Summary Agent. A Context Summary Agent(CSA) then summarizes the textual metadata of only those candidate items that the NLI Agent has deemed sufficiently aligned with the user context. Formally, define I+ = { ğ‘– âˆˆ I 0 | ğ‘ NLI (ğ‘–, u) â‰¥ ğœƒ }, where ğ‘ NLI (ğ‘–, u) is the NLI alignment score and ğœƒ is a threshold above which an item is considered accepted. The Context Summary Agent then produces a concise summary, ğ‘†ctx = Î¨ n ğ‘‡ (ğ‘–) ğ‘– âˆˆ I + o , where Î¨(Â·) is an LLM-driven summarization