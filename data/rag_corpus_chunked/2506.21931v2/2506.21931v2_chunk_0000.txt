ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation Reza Yousefi Maragheh∗ Reza.YousefiMaragheh@walmart.com Walmart Global Tech Sunnyvale, California, USA Pratheek Vadla∗ Pratheek.Vadla@walmart.com Walmart Global Tech Bellevue, Washington, USA Priyank Gupta∗ Priyank.Gupta@walmart.com Walmart Global Tech Bellevue, Washington, USA Kai Zhao∗ Kai.Zhao@walmart.com Walmart Global Tech Sunnyvale, California, USA Aysenur Inan∗ Aysenur.Inan@walmart.com Walmart Global Tech Sunnyvale, California, USA Kehui Yao∗ Kehui.Yao@walmart.com Walmart Global Tech Bellevue, Washington, USA Jianpeng Xu Jianpeng.Xu@walmart.com Walmart Global Tech Sunnyvale, California, USA Praveen Kanumala Praveen.Kanumala@walmart.com Walmart Global Tech Sunnyvale, California, USA Jason Cho Jason.Cho@walmart.com Walmart Global Tech Sunnyvale, California, USA Sushant Kumar Sushant.Kumar@walmart.com Walmart Global Tech Sunnyvale, California, USA Abstract Retrieval-Augmented Generation (RAG) has shown promise in en- hancing recommendation systems by incorporating external con- text into large language model prompts. However, existing RAG- based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval- Augmented Generation framework for Personalized Recommenda- tion, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user prefer- ences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outper- forms standard RAG and recency-based baselines, achieving up to ∗These authors contributed equally to this work. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that