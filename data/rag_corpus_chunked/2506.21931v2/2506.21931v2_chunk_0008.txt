style preferences. Formally, the model returns a permutation over the ğ‘Ÿ candidate items: ğœ‹ = ğ‘“rank (ğ‘†user, ğ‘†ctx, I), ğœ‹ = {ğ‘Ÿ1, ğ‘Ÿ2, . . . , ğ‘Ÿğ‘ } where each ğ‘Ÿ ğ‘— âˆˆ { 1, 2, . . . , ğ‘} denotes the index of item in rank ğ‘— in the final ranked list. As one can see under ARAG NLI, context summary, and user understanding agents collectively act as a memory moderation scheme for the final ranking task. These agents are utilized to make sure the userâ€™s long-term and short-term behavioral context is properly integrated into the final ranking task. 2.3 Agent Collaboration Protocol To better explain the implementation workflow, we also clarify the collaboration protocol for agents in ARAG. ARAG is implemented as a blackboard-style multi-agent system [11] in which all agents read from and write to a shared, structured memory B. Each agent contributes a message object m containing a JSON schema {id, role, content, score, timestamp}, so that subsequent agents can reason not only over the raw user and item data, but also over the rationales produced by their peers. (1) Parallel inference. The User-Understanding Agent (UUA) and the NLI Agent are executed concurrently. The UUA writes a preference summary muser to B, while the NLI Agent writes a support/contradiction judgement vector mnli = ğ‘ NLI (ğ‘–, u)  ğ‘– âˆˆ I0. (2) Cross-agent attention. The Context-Summary Agent (CSA) attends to both muser and mnli: it uses the user summary as a SIGIR, July 13-17, 2025, Padova, Italy Maragheh et al. Performance of Benchmark Versus ARAG Clothing Electronics Home NDCG@5 Hit@5 NDCG@5 Hit@5 NDCG@5 Hit@5 Recency-based Ranking 0.30915 0.3945 0.22482 0.3035 0.22443 0.2988 Vanilla RAG 0.29884 0.3792 0.23817 0.321 0.22901 0.3117 Agentic RAG 0.43937 0.5347 0.32853 0.4201 0.28863 0.3834 % Improvement 42.12% 35.54% 37.94% 30.87% 25.60%