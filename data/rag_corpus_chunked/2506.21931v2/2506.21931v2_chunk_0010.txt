alization: The final score reflects the user’s unique and evolving preferences, ensuring recommendations remain both relevant and adaptable. 3 Experiments 3.1 Dataset Our experiments utilize the widely-adopted Amazon Review dataset (He & McAuley, 2016), a large-scale collection of product reviews and metadata spanning multiple product categories on Amazon.com. This dataset contains millions of customer reviews, ratings, and product interactions across diverse categories including Electronics, Books, Clothing, and Home & Kitchen, making it particularly suit- able for evaluating cross-category recommendation performance. For our experiments, we selected a subset of user-item interactions from 10,000 randomly sampled users across these categories. Each review entry contains rich contextual information including times- tamps, ratings, textual feedback, and product metadata, providing comprehensive user preference signals. This dataset presents re- alistic challenges for recommendation systems, including sparse interaction matrices, shifting user preferences over time, and di- verse product taxonomies—making it an ideal testbed for evaluating the ARAG framework’s ability to leverage complex user contexts. 3.2 Benchmark Models The Recency model adopts a simple temporal heuristic, assuming that a user’s most recent interactions best reflect current prefer- ences. It appends these recent items directly to the LLM prompt without further filtering. This model operationalizes recency by directly appending the user’s most recent historical interactions to the large language model’s input prompt, without additional filter- ing or transformation mechanisms. By prioritizing chronologically recent user behavior over potentially more relevant but temporally distant interactions, this approach benefits from simplicity and computational efficiency. The Vanilla RAG (Retrieval-Augmented Generation) approach implements a more sophisticated information retrieval mechanism that moves beyond simple temporal ordering. This benchmark lever- ages embedding-based retrieval to identify semantically relevant items from the user’s interaction history, selecting items based on their embedding similarity rather than recency. After retrieving these relevant historical items, the model appends them to the LLM