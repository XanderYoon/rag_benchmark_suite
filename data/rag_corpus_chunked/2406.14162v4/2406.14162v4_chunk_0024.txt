(2023b,a); Pradeep et al. (2023); Qin et al. (2024) find that SOTA generic LLMs are good rerankers and such ability can be distilled to open-sourced LLMs. These studies all focus on pairwise or listwise ranking methods, and discusses that pointwise methods may not work due to bad calibration (Qin et al., 2024). How- ever, when it comes to relevance annotation in- stead of reranking, pointwise relevance prediction is more suitable because it: (1) analyzes and anno- tates (query, document) pairs one-by-one, thus is more efficient and may better consider relevance definitions; and (2) can annotate both document rank and binary relevance labels (relevant or ir- relevant) which are important for RAG in order to decide what information should be passed to the generator. We also show pointwise annotation works better with proper calibration method (Tian et al., 2023). 7 Conclusion In this work, we introduce the DIRAS pipeline to fine-tune open-source LLMs to calibrated anno- tators. The DIRAS approach has two significant advantages: (1) it is case-specialised allowing the incorporation of domain-specific knowledge into definitions, and (2) it helps to efficiently label a huge amount of documents with calibrated rele- vance scores. Limitations As with every work, this has limitations. First, our results show that DIRAS fine-tuning grants small student LLMs GPT-4-level performance on spe- cific domains, but GPT-4 is not guaranteed to be perfect in all domains and cases. In certain niche domains, it might be necessary to augment GPT- 4 with domain knowledge or agentic designs to achieve human-level performance in relevance an- notation, and then create reliable training data for DIRAS. Although performance not always guaran- teed, LLM annotation for document relevance is still necessary due to the sheer volume of (query, document) pairs and selection bias of human anno- tation. Second, this project focuses on text