GPT- 4 with domain knowledge or agentic designs to achieve human-level performance in relevance an- notation, and then create reliable training data for DIRAS. Although performance not always guaran- teed, LLM annotation for document relevance is still necessary due to the sheer volume of (query, document) pairs and selection bias of human anno- tation. Second, this project focuses on text documents. This means we do not evaluate the performance of the DIRAS pipeline on graph and table con- tent. While this also presents a general limita- tion of modern-day RAG systems, we believe it is a crucial future step to generalize DIRAS’s idea of scalable information retrieval benchmarking to multi-modality. Our third limitation, and also a viable option to address multi-modality, lies in the recent intro- duction of long-context LLMs. These may make the role of information retrieval in RAG less cru- cial as entire documents can be used to answer a question. At the same time, we observe that long- context models are good in needle-in-a-haystack problems but not as good when multiplied needles exist (Team et al., 2024a). Thus, even for long- context LLMs, an efficient system like DIRAS could enable improving algorithms for finding and using multiple relevant pieces of information or help improve the model’s ability to do so. Ethics Statement Human Annotation: In this work, all human an- notators are Graduate, Doctorate researchers, or Professors who have good knowledge about sci- entific communication and entailment. They are officially hired and have full knowledge of the con- text and utility of the collected data. We adhered strictly to ethical guidelines, respecting the dignity, rights, safety, and well-being of all participants. Data Privacy or Bias: There are no data privacy issues or biases against certain demographics with regard to the data collected from real-world appli- cations and