embedding models text- embedding-3-small, and text-embedding-3-large; and BGE Gemma reranker4, a popular LLM-based reranker for general domain. As Fig. 4 shows, fine-tuning improves original models in all settings. Furthermore, Table 2 shows the results of all fine-tuned student models in com- parison to all baselines. We observe that Ms-Tok outperforms other settings for all LLM architec- tures. The best setting Llama3-Tok achieves GPT-4 level performance in calibration and IR on unseen questions and reports. Interestingly, we find that omitting the chain of thought usually leads to a performance increase for all three LLM architectures. CoT sometimes leads to a limited increase when asking for calibration (Ask), but constantly results in a performance drop when calibrated with token-level probability (Tok). Therefore, Ms should be fine-tuned without CoT for inference efficiency. Moreover, Tok rarely un- derperforms Ask, different from Tian et al. (2023)’s finding and our observations in Table 1. Thus, fu- ture work may consider probabilities of important tokens (e.g., Yes/No in our prompt template) as a promising calibration tool. 4 Real-World Applications Having established and benchmarked the design choices of DIRAS student LLMs, we now investi- gate their real-world application capabilities. First, we showcase how the DIRAS Ms can assist IR annotation in a real-world setting, leveraging the ClimRetrieve dataset (Schimanski et al., 2024b) (§ 4.1). Second, we show the DIRAS pipeline is also applicable for general domain QA (§ 4.2). 4https://huggingface.co/BAAI/bge-reranker-v2-gemma Setting nDCG nDCG@5 nDCG@10 nDCG@15 Random 71.04 50.88 52.77 54.45 Small-embed 74.52 61.28 60.36 61.69 Large-embed 76.30 63.13 63.36 64.67 GPT-3.5 74.62 60.08 61.49 61.91 GPT-4 75.55 60.89 63.23 65.26 Llama3-Ask 77.23 67.60 66.18 67.57 Llama3-Tok 76.55 67.20 66.23 65.83 Table 3: Performance on ranking the relevant (query, document) pairs in ClimRetrieve. 4.1 Applying to ClimRetrieve ClimRetrieve (Schimanski et al., 2024b) records human analysts’ real-life workflow of reading