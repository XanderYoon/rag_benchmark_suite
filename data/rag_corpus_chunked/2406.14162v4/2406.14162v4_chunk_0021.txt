are selectively annotated. DIRAS achieves high accuracy in Irr. disagreements. Therefore, we reaffirm the notion that applying DIRAS to annotate broader (query, document) pairs can effectively reduce annotation selection bias, and thus improve IR recall bench- marking. All implementation details are in App. M. 5 Recommendation for Future RAG Avoiding Top-K Retrieval: Naive RAG systems (Ni et al., 2023) usually retrieve top-k (a fixed number k) documents to augment LLM generation. However, different questions tend to have different amounts of relevant information.Advanced RAG employs query routers to pick retrieval strategies (Gao et al., 2024). However, choosing the proper k without access to full documents is still hard. To demonstrate this, we average the relevance score (predicted by Llama3-Tok) over all documents for each question in ClimRetrieve. The resulting aver- age relevance score will be a proxy for the amount of relevant information on the question in all re- ports. As Fig. 5 shows, different questions vary considerably in the amount of relevant information. Therefore, we suggest not using top-k IR, avoiding the prior determined k that does not fit the actual amount of relevant information. Given the calibrated prediction of DIRAS Ms, an alternative way is to retrieve all documents whose relevance scores exceed a pre-defined thresh- old. Thus, different questions can retrieve differ- ent amounts of information depending on whether passing the relevance threshold. Advanced RAG designs can even strategically pick the calibrated threshold for different questions, for example, al- lowing more partial relevance for summary queries. Fig. 6 shows the F1 Scores of GPT-4 and Llama3- Tok with different relevance thresholds. Llama3- Tok achieves good F1 scores over a wide range of thresholds. Thanks to its compact size (8B), it can be efficiently deployed as a reranker in RAG systems. Optimizing Relevance Definitions: Results in Ta- ble 2