to derive automatically the domains of documents and queries used to train the supervised gating mechanisms; We evaluate our proposal against state-of-the-art baselines with reproducible ex- periments on three different datasets 4. The results of the experiments show that DESIRE-ME consistently improves the performance of the underlying dense re- triever with an increase of up to 12% in NDCG@10 and 22% in P@1, outlining 4 The code is available at this link: https://github.com/pkasela/DESIRE-ME. DESIRE-ME 3 the potential of the proposed model for the open-domain Q&A task. Further- more, we utilize a fourth dataset having similar characteristics to investigate the generalization capabilities of DESIRE-ME in a zero-shot scenario. Even in this case, we observe a significant performance boost over the underlying dense retriever. The paper is organized as follows. Section 2 discusses the relevant related work. Section 3 formally introduces the DESIRE-ME architecture and method- ology while Section 4 discusses the results of our experimental analysis on public datasets. Finally, Section 5 concludes the work and drafts some future work. 2 Related Work 2.1 Open Domain Q&A Models most commonly used for open-domain Q&A in IR can be broadly clas- sified into five different families based on their architecture: Lexical models, Neural Sparse models, Late-interaction models, Re-ranking models, and Dense retrieval models. Lexical models include all adaptations to open-domain Q&A of classical IR models, such as BM25 [23], that do lexical matching. Neural Sparse models leverage deep neural networks to enhance and overcome some of the limitations of the lexical models, e.g. query-document vocabulary mismatch. They include models such as docT5query [21] that uses sequence-to-sequence models to expand document terms by generating possible queries for which the document would be relevant. Late-interaction models rely on a bi-encoder ar- chitecture to encode the query and documents at a token level. The relevance