3D reconstruction and extension of the user’s physical space. Out of the five distortion treatments, three treatments are designed to impact the user’s directional motion pattern (move- ment along an axis, refer to Fig. 2a for axis directions), whereas the other two treatments are designed to impact the user’s motion to and from the room center (distance-to-center). Our study examines natural locomotion and visual perception. We selected RealityShader to simulate distortion treatments because it seamlessly blended projected and physical environments while the physical layout remained undistorted [61]. AR headsets with see-through waveguide displays, such as HoloLens 2 or Magic Leap arXiv:2510.23840v1 [cs.HC] 27 Oct 2025 Figure 2: a. Top view of the 4.5 m x 5.5 m room with furniture where the study and distortion effects were conducted. Left: Floor layout as scanned by Kinect v2 sensor cameras. Right: Digital Double 3D model of room. b. Left: Using SLAM (Simultaneous Localization and Mapping), a live 3D reconstruction of the room from a side angle. Right: Digital Double 3D model of the room from the same angle. Figure 3: a. First-person point of view (POV) from the perspective of a user viewing a virtually extended space in the room. b. Over- head view of the room environment where the user experiences the distortion effects. c. First-person POV as seen via head-tracking and perspective correction, where the green area designates the space that is extended through projection using the Elongation Distortion. d. Overhead view of the physical space of the room compared to its virtual extension during the Elongation Distortion. 2, are equipped with relatively small field-of-view displays, which limits immersion. Video pass-through MR, such as the Varjo XR-3 or Meta Quest Pro, is becoming more commonplace but still has fidelity problems. Thus, we opted to run this study in spatial aug-