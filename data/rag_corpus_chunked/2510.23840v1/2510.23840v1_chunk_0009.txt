experiences [5, 10, 21, 36]. While current spatial mapping for VR-AR systems does well with scanning surroundings for planar surfaces, finding usable space to project vir- tual objects, and designing a virtual environment, they are ultimately restricted to the physical layout. The benefits and impacts of a wide field of view beyond our vision are clear [45]. Our projection mapping system utilizes a 3D reconstructed model of the room to create a view from the virtual environment. That view is then projected onto real physical surfaces such as the walls and furniture in the room, simulating the perspective of a co-located virtual world [13] using the real world as a baseline. We conduct our user study in a full-surround spatial augmented reality system, augmenting the entire human field of view and beyond, in order to create the most convincing user experience of the transformation of their surroundings. We designed a set of virtual environments that are aligned or par- tially aligned with the physical room that is deformed, extended, and subtracted from the perspective of the userâ€™s eyes as demonstrated in Remixed Reality [28]. In our system, the user sees the physical world at all times as seen in Fig. 1b. We build the experience around the room layout including the furniture in the room. 3 REALITYDISTORTIONROOM Reality Distortion Room uses the RoomAlive infrastructure [3,18] to deliver a full surrounded augmented reality experience. The room ge- ometry is scanned and loaded into the game environment and Unity workspace where sets of geometric space transformation (distortion treatment) are deployed. Virtual models are placed into the scene in relation to the physical room to project reconstructed geometry. This allows our system to extend the virtual world from the real world, as if the room is transforming, by rendering the physical world within