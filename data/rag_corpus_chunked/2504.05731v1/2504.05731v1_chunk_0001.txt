preference during retrieval and reranking. Then we leverage feedback from the LLM to fine-tune the personalized retriever and reranker, enabling them to retrieve documents that meet the personalized generation needs of the LLM. Experimental results on the Language Model Personalization (LaMP) benchmark ∗Corresponding authors. Work partially done at Engineering Research Center of Next- Generation Intelligent Search and Recommendation, Ministry of Education. Work done when Teng Shi was the intern at Kuaishou. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’25, Padua, Italy. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-1592-1/25/07 https://doi.org/10.1145/XXXXXX.XXXXXX validate the effectiveness of CFRAG. Further analysis confirms the importance of incorporating collaborative information. CCS Concepts •Information systems → Personalization; •Computing method- ologies → Natural language generation. Keywords Large language model; Personalization; Retrieval augmented gen- eration ACM Reference Format: Teng Shi, Jun Xu, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, and Han Li. 2025. Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’25), July 13–18, 2025, Padua, Italy. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/XXXXXX.XXXXXX 1 Introduction Personalizing Large Language Models (LLMs) [ 55] to generate personalized outputs tailored to individual user preferences