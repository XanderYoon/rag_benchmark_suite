use an embedding model (such as BERT [ 6], RoBERTa [ 26], BGE [ 45] etc.) Emb(Â·) to en- code each document in the userâ€™s history Hğ‘¢ to obtain Eğ‘¢ = [e1, e2, . . . , eğ‘ ] âŠº âˆˆ Rğ‘ Ã—ğ‘‘, where eğ‘– = Emb(ğ‘‘ğ‘– ) and ğ‘‘ is the em- bedding dimension. To model the sequential relationships between different documents in the userâ€™s history, we introduce positional embedding P âˆˆ Rğ‘ Ã—ğ‘‘. Afterward, the history Hğ‘¢â€™s embedding becomes bEğ‘¢ = Eğ‘¢ + P. Then, we apply a transformer [ 39] as the user encoder to encode the userâ€™s historybEğ‘¢ and average the trans- formerâ€™s output to obtain the userâ€™s embedding: eğ‘¢ = Encoderğ‘¢ (ğ‘¢) = MEAN(Trm(bEğ‘¢ )) âˆˆ Rğ‘‘, (1) where Encoderğ‘¢ (Â·) â†’ Rğ‘‘ denotes the user encoder,Trm(Â·) denotes a transformer encoder. Next, we train the transformer encoder using contrastive learning. 4.1.2 Data Augmentation. We generate different views ofHğ‘¢ using the following three data augmentation methods: Document Crop. We randomly select a continuous sub-sequence of length ğ¿ğ‘ = âŒŠğœ‚ğ‘ ğ‘ âŒ‹ from Hğ‘¢, where ğœ‚ğ‘ is a hyper-parameter con- trolling the crop ratio. The history after cropping is as follows: H crop ğ‘¢ = [ğ‘‘ğ‘, ğ‘‘ğ‘+1, . . . , ğ‘‘ğ‘+ğ¿ğ‘ âˆ’1]. Document Mask. For the history Hğ‘¢, we randomly mask out ğ¿ğ‘š = âŒŠğœ‚ğ‘šğ‘ âŒ‹ documents Imask = {ğ‘–1, ğ‘–2, . . . , ğ‘–ğ¿ğ‘š }, where Imask is the set of indices corresponding to the masked documents and ğœ‚ğ‘š is a hyper-parameter that controls the mask ratio. The masked documents are replaced with a special token [mask]. The history after masking is as follows: H mask ğ‘¢ = [ Ë†ğ‘‘1, Ë†ğ‘‘2, . . . , Ë†ğ‘‘ğ‘ ], Ë†ğ‘‘ğ‘– = ( ğ‘‘ğ‘–, ğ‘– âˆ‰ Imask, [mask], ğ‘– âˆˆ Imask. â€¦ ğ‘‘1 ğ‘‘ğ‘ ğ’œâ€² â€¦ ğ‘‘1