Retrieval Augmented Generation with Collaborative Filtering for Personalized Text Generation Teng Shi Renmin University of China Beijing, China shiteng@ruc.edu.cn Jun Xu‚àó Xiao Zhang Renmin University of China Beijing, China {junxu,zhangx89}@ruc.edu.cn Xiaoxue Zang Kai Zheng Kuaishou Technology Co., Ltd. Beijing, China xxic666@126.com zhengk92@gmail.com Yang Song Han Li Kuaishou Technology Co., Ltd. Beijing, China ys@sonyis.me lihan08@kuaishou.com Abstract Recently, the personalization of Large Language Models (LLMs) to generate content that aligns with individual user preferences has garnered widespread attention. Personalized Retrieval-Augmented Generation (RAG), which retrieves relevant documents from the user‚Äôs history to reflect their preferences and enhance LLM genera- tion, is one commonly used approach for personalization. However, existing personalized RAG methods do not consider that the his- tories of similar users can also assist in personalized generation for the current user, meaning that collaborative information be- tween users can also benefit personalized generation. Inspired by the application of collaborative filtering in recommender systems, we propose a method called CFRAG, which adapts Collaborative Filtering to RAG for personalized text generation. However, this presents two challenges: (1) how to incorporate collaborative infor- mation without explicit user similarity labels? (2) how to retrieve documents that support personalized LLM generation? For Chal- lenge 1, we use contrastive learning to train user embeddings to retrieve similar users and introduce collaborative information. For Challenge 2, we design a personalized retriever and reranker to re- trieve the top-ùëò documents from these users‚Äô histories. We take into account the user‚Äôs preference during retrieval and reranking. Then we leverage feedback from the LLM to fine-tune the personalized retriever and reranker, enabling them to retrieve documents that meet the personalized generation needs of the LLM. Experimental results on the Language Model Personalization (LaMP) benchmark ‚àóCorresponding authors. Work partially done at Engineering Research Center of Next- Generation Intelligent Search and Recommendation, Ministry of