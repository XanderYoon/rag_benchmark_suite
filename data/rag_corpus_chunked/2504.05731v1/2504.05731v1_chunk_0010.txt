archi- tecture is shown in Figure 2. As mentioned in Section 1, to address SIGIR â€™25, July 13â€“18, 2025, Padua, Italy. Teng Shi et al. Challenge 1, i.e., how to introduce collaborative information, we first train user embeddings using contrastive learning to retrieve the top-ğ‘š most similar users (see Section 4.1). For Challenge 2, which involves retrieving documents that support personalized LLM gen- eration, we fine-tune the personalized retriever and reranker using LLM feedback. The retriever first retrieves the top- ğ‘˜ documents from the history of each of the ğ‘š users, resulting in ğ‘š Ã— ğ‘˜ docu- ments (see Section 4.2). The reranker then reranks these documents to obtain the final top-ğ‘˜ documents as input for the LLM (see Sec- tion 4.3). 4.1 User Retrieval First, we perform user retrieval to get the top-ğ‘š most similar users for user ğ‘¢ to introduce collaborative information. However, we do not have labels indicating which users are similar to each other. To address this, we employ a contrastive learning [15, 44] approach. We apply different data augmentation methods to the user history Hğ‘¢ to obtain different views of the userâ€™s history. We treat different views of the same user as positive samples and the histories of other users as negative samples, and then we use the InfoNCE [28] loss to train user embeddings for retrieval. Figure 3 illustrates the process of training user embeddings using contrastive learning. 4.1.1 User Encoder. Specifically, we first use an embedding model (such as BERT [ 6], RoBERTa [ 26], BGE [ 45] etc.) Emb(Â·) to en- code each document in the userâ€™s history Hğ‘¢ to obtain Eğ‘¢ = [e1, e2, . . . , eğ‘ ] âŠº âˆˆ Rğ‘ Ã—ğ‘‘, where eğ‘– = Emb(ğ‘‘ğ‘– ) and ğ‘‘ is the em- bedding dimension. To model the sequential relationships