see that without fine-tuning based on LLM feedback, using a pre-trained dense retrieval model leads to worse performance. This indicates that retrieval cannot be based solely on semantic relevance, ensuring that the retrieved documents support personalized LLM generation is crucial. Addi- tionally, we analyzed the impact of removing ğ‘†retriever ğ‘¢,ğ‘‘ from Eq. (4) and only using ğ‘†retriever ğ‘,ğ‘‘ from Eq. (3) for retrieval, as indicated in row (4). The results decreased, demonstrating that usersâ€™ personal- ized preferences should also be considered during retrieval, rather SIGIR â€™25, July 13â€“18, 2025, Padua, Italy. Teng Shi et al. Accuracy F10.600 0.616 0.632 0.648 0.664 0.680Accuracy BM25 w/o T uning CFRAG 0.300 0.306 0.312 0.318 0.324 0.330 F1 (a) LaMP-1 ROUGE-1 ROUGE-L0.468 0.472 0.476 0.480 0.484 0.488ROUGE-1 BM25 w/o T uning CFRAG 0.400 0.404 0.408 0.412 0.416 0.420 ROUGE-L (b) LaMP-5 Figure 6: Results using different retrievers and rerankers. â€œBM25â€ indicates using BM25 as both the retriever and reranker, while â€œw/o Tuningâ€ refers to using pre-trained re- trievers and rerankers without LLM feedback fine-tuning. 0 1 2 3 4 5 #Doc from current user 0.600 0.612 0.624 0.636 0.648 0.660Accuracy Accuracy 0.300 0.306 0.312 0.318 0.324 0.330 F1 F1 (a) LaMP-1 0 1 2 3 4 5 #Doc from current user 0.460 0.465 0.470 0.475 0.480 0.485ROUGE-1 ROUGE-1 0.390 0.396 0.402 0.408 0.414 0.420 ROUGE-L ROUGE-L (b) LaMP-5 Figure 7: Performance under different numbers of retrieved documents from the current user ğ‘¢â€™s history in the top- ğ‘˜ documents. than solely focusing on the semantic relevance between the query and documents. 5.3.3 Document Rerank. We also validated the effectiveness of the personalized reranker we designed, as shown in Table 3, rows (5) and (6). First, in row (5), it can be seen that using a pre-trained reranker leads to worse results, highlighting the importance of