Results Figure 2: The architecture of CFRAG. From left to right: (a) User Retrieval retrieves similar users (Section 4.1); (b) Retriever retrieves the top- ğ‘˜ documents from each userâ€™s history (Section 4.2); (c) Reranker reranks the ğ‘š Ã— ğ‘˜ documents to get the final top-ğ‘˜ documents, which are then concatenated with the query and input into the LLM for personalized text generation (Section 4.3). Existing works on LLM personalization mainly include the fol- lowing types of methods: (1) Fine-tuning a personalized LLM for each user [ 36, 37, 42]; Tan et al . [37] fine-tuned the LLM using LoRA [ 12] to get personalized LoRA parameters for each user. (2) Aligning LLMs with user-specific preferences through Rein- forcement Learning from Human Feedback (RLHF) [ 16, 23, 43]; Jang et al. [16] first trained different parameters for various objec- tives using RLHF, then merged these parameters based on usersâ€™ personalized needs. (3) Incorporating user-specific context into the prompt [21, 27, 29, 31, 32, 57]. Richardson et al. [29]used instruction- tuned LLMs to summarize user history and then incorporated it into prompts for generation. Salemi et al . [31, 32] used RAG to retrieve relevant documents from user history based on the input query and incorporated them into the prompt. This paper further introduces collaborative filtering for per- sonalization based on the RAG framework. Collaborative filter- ing has already been applied in fields such as recommender sys- tems [33, 34, 38, 48â€“52] and has been proven effective. It assumes that users who have interacted with similar items share similar preferences, and recommending items from similar users to the current user can meet their needs. Some works [11, 46] learn the collaborative information between users and items through matrix factorization [19], while others [10, 40] further explore higher-order collaborative information between users and