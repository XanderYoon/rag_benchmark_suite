of each frame, guiding how information from the sequence is aggregated into the [CLS] representation. This representation is then passed through a residual feed-forward block with LayerNorm to yield the final pooled embeddingh∈Rdw. Projection Head (Fig. 2.c).The pooled vectorhis finally projected into the 768-dimensional lyric-informed embedding space through a four-layer MLP with hidden sizes [3072, 2048, 2048, 1536]—a configuration selected based on empir- ical validation, totaling 13.6M trainable parameters. Each intermediate layer is followed by LayerNorm and a ReLU activation, while the final layer outputs the audio embeddinga i used in the downstream retrieval task. Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings 9 5 Experiments Training Configuration.Training runs for three epochs with batch size 128 on a single NVIDIA RTX A5000 (24GB), taking about 33 hours. We use AdamW (weight decay0.01,β= (0.9,0.98)) with a fixed learning rate of10−4 and linear warmup over the first10k steps. Mixed precision is enabled for the Whisper encoder, while the rest of the model is trained in full precision. Early stopping is applied based on the average cosine similarity between audio and text em- beddings on the validation set. For data, we use a subset of 679,692 entries from Discogs-VI [3], linked to a proprietary catalog to recover the corresponding .mp3 audio. Training pairs(zi, ti)are formed by (i) precomputing log-Mel spec- trogramsz i with Whisper’s feature extractor on extracted 30s vocal segments xi (Section 4.1), and (ii) deriving lyrics embeddingsti through the pipeline de- scribed in Section 4.2. We retain a subset of 1.5M pairs, of which 1.2M are used for training, 170k for validation and 170k for testing (80/10/10 split). Benchmarks.We use the standard Covers80 [21] and SHS100k-TEST [7], along withthetestsetofDiscogs-VI[3],restrictedtoentrieswithanavailableYouTube link. All datasets follow the same preprocessing pipeline: (1) tracks are linked to a proprietary catalog via fingerprinting after matching against YouTube