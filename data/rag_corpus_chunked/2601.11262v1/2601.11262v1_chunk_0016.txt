Underline indicates the best result within each row. the upper bound of text embedding performance, we further assess the models on editorial lyricsℓ i rather than transcriptions, thus eliminating transcription noise. This evaluation is limited to subsets of the datasets for which editorial lyrics are available in our proprietary catalog, yielding 116, 167, and 4,623 tracks for Covers80, SHS100k, and Discogs-VI. Among the six candidates,gte-multilingual-baseemerges as the most effective since it ranks first across nearly all metrics on Discogs-VI, the largest and most representative benchmark of real-world conditions. Its performance approaches the ceiling defined by editorial lyrics, underscoring both its robustness to tran- scription noise and its suitability as the backbone of our pipeline. Additionally, results show that most multilingual encoders achieve competitive scores and, no- tably, reach ceiling performance on Covers80 when provided with editorial lyrics. This underscores the role of lyrics as a stable and discriminative signal for Music Cover Retrieval and validates the lyrics-informed embedding space as a robust supervisory signal: it captures the semantic structure necessary to distinguish versions. In our case, we rely on off-the-shelf multilingual models without addi- tional fine-tuning, as they already provide strong results. We leave task-specific fine-tuning for future work, where it could further enhance performance. 5.2 V alidation of the V ocal Detection Model To assess the gains of the proprietary vocal detection model over Whisper’s inte- gratedVocalActivityDetection(VAD)module,weevaluatetranscriptionquality on the Discogs-VI test set restricted to tracks with editorial lyrics (4,623 tracks). We compare Word Error Rate (WER) between editorial lyrics and Whisper tran- scriptions obtained either from vocal segments extracted with the proprietary model or from non-overlapping 30-second segments processed with Whisper’s VAD. In addition, we analyze hallucinated outputs commonly observed in Whis- per transcriptions of non-spech audio (e.g., “thank you”, “music”, “subtitle”) [6]. 5 gte-multilingual-base (gte-b), multilingual-e5-{small, large, large-instruct}