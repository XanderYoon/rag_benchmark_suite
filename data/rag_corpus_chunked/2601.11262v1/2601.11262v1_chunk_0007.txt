corresponding lyric embeddings. Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings 5 Its key drawback lies in the reliance on transcription, where the ASR autore- gressive decoder introduces considerable computational overhead. To overcome this, LIVI discards the decoder and trains an audio encoder to map latent ASR statesdirectlyintothelyric-informedembeddingspacederivedfromthepipeline. This removes the need for full transcription while preserving retrieval accuracy, resulting in a more efficient and scalable solution. 3.1 Problem F ormulation We formulate Music Cover Retrieval as a similarity ranking problem over em- beddings produced by an encoderg. LetCbe a catalog of music tracks and g:C →R d map each trackx∈ Cto an embeddinge x ∈R d. Given a queryq∈ C (i.e., a song), the system assigns to eachx∈ C \ {q}a cosine similarity score s(q, x) = cos(e q,e x) = e⊤ q ex ∥eq∥2 ∥ex∥2 and returns the catalog ordered in descending order bys(q,·). LetV(q)⊂ C denote the set of versions of q. The desired ranking property is s(q, v+)> s(q, v −)∀v + ∈ V(q), v − ∈ C \ V(q) Accordingly, the encoder must learn an embedding space in which versions are embedded more closely than to non-versions. 3.2 F ramework Overview We first define the lyrics-informed embedding space, demonstrating the effective- ness of lyric semantic similarity for cover song retrieval. This embedding space then serves as supervision for training the audio encoder. Given an audio excerpt xi from a trackx∈ C, its lyrics embeddingt i ∈R d is obtained by composing an encoder-decoder ASR modelftransc with a pre-trained text embedding model ftext. This composition can be seen as a fixed encoder: gtext =f text ◦f transc : ( C →R d xi 7→t i Next,wedefineanaudioencoderthatprojectsrawaudiointothelyrics-informed embedding space. Given the same audio excerptxi, latent features are extracted from the ASR encoder viaf extract and projected byf