In: Interspeech 2022. pp. 4187–4191 (2022). https://doi.org/10.21437/Interspeech.2022-10600 [27] Huang, Q., Jansen, A., Lee, J., Ganti, R., Li, J.Y., Ellis, D.P.W.: Mulan: A joint embedding of music audio and natural language. In: Proceedings of the 23rd International Society for Music Information Retrieval Confer- ence (ISMIR) (2022),https://archives.ismir.net/ismir2022/paper/ 000067.pdf [28] Koenecke, A., Choi, A.S.G., Mei, K.X., Schellmann, H., Sloane, M.: Careless whisper: Speech-to-text hallucination harms. In: The 2024 ACM Conference on Fairness, Accountability, and Transparency. p. 1672–1681. FAccT ’24, ACM (Jun 2024).https://doi.org/10.1145/3630106.3658996,http:// dx.doi.org/10.1145/3630106.3658996 [29] Li, L., Zhao, Y., Jiang, D., Zhang, Y., Wang, F., Gonzalez, I., Valentin, E., Sahli, H.: Hybrid deep neural network–hidden markov model (dnn-hmm) basedspeechemotionrecognition.In:2013HumaineAssociationConference on Affective Computing and Intelligent Interaction. pp. 312–317 (2013). https://doi.org/10.1109/ACII.2013.58 [30] Liu, F., Tuo, D., Xu, Y., Han, X.: Coverhunter: Cover song identification with refined attention and alignments. In: 2023 IEEE International Con- ference on Multimedia and Expo (ICME). pp. 1080–1085 (2023).https: //doi.org/10.1109/ICME55011.2023.00189 [31] Mancini, E., Serrà, J., Torroni, P., Mitsufuji, Y.: Leveraging whisper em- beddings for audio-based lyrics matching (2025),https://arxiv.org/abs/ 2510.08176 [32] Meseguer-Brocal, G., Cohen-Hadria, A., Peeters, G.: Dali: A large dataset of synchronized audio, lyrics and notes, automatically created using teacher- student machine learning paradigm. (2018).https://doi.org/10.5281/ ZENODO.1492443 [33] Müller, M.: Dynamic Time Warping, pp. 69–84. Springer Berlin Heidelberg, Berlin, Heidelberg (2007).https://doi.org/10.1007/ 978-3-540-74048-3_4 Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings 17 [34] Pons, J., Serra, X.: musicnn: Pre-trained convolutional neural networks for music audio tagging (2019),https://archives.ismir.net/ismir2019/ latebreaking/000038.pdf [35] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., Sutskever, I.: Learning transferable visual models from natural language supervi- sion. In: International Conference on Machine Learning (2021),https: //api.semanticscholar.org/CorpusID:231591445 [36] Radford, A., Kim, J.W., Xu, T., Brockman, G., McLeavey, C., Sutskever, I.: Robust speech recognition via large-scale weak supervision (2022),https: //arxiv.org/abs/2212.04356 [37] Radford,