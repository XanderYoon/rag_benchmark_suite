within the Sentence-BERT framework [39], which maps full sentences into fixed-size embeddings that preserve semantic proxim- ity—even in multilingual settings. Based on an evaluation of six multilingual text embedding models for the downstream task (see 5.1), we selectgte-multilingual- base[56], an encoder-only Transformer that produces 768-dimensional embed- dings across more than 70 languages. It achieves SOTA results in multilingual retrieval for models of comparable size [56] and outperforms alternatives in our evaluations. In our case, we rely on this off-the-shelf model without additional fine-tuning, as it already provides strong results. We leave task-specific fine- tuning for future work, where it could further enhance performance. 4.3 Audio Encoder The audio encoderg audio (Figure 2) maps an audio excerptxi ∈ Cto an em- beddinga i ∈R d aligned with its lyric-based counterpartti =g text(xi). Built on top of Whisper’s frozen encoder, which provides frame-level representations sub- sequently aggregated by an attention-based pooling mechanism, the projection head refines Whisper’s latent space rather than learning cross-modal alignment from scratch. This design keeps the model compact and computationally efficient during both training and inference. 8 J. Affolter et al. Fig. 2: Architecture of the audio encoderg audio.(a) Raw audio is first processed by the Whisper encoder to obtain hidden representations. (b) A [CLS] token is appended to aggregate frame-level features using an attention pooling mechanism. (c) A multi-layer perceptron projects the pooled representation into the lyrics-informed embedding space, yielding the final audio embeddingai. Feature Extractor (Fig. 2.a).We adopt the encoder of the Whisper model used in the lyrics-informed embedding space as our audio backbone. This choice is motivated by two considerations: (i) its internal representations, shaped by the ASR training objective, are expected to capture phonetic and linguistic infor- mation [24] that makes them suitable for alignment with lyrics embeddings; and (ii) reusing the encoder from