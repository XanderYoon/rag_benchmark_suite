retrieval or |E| > 0 for unstructured retrieval —the Wrapper module integrates the acquired context and generates a prompt for the Large Language Model (LLM). The LLM then performs Answer Generation, creating a detailed response to the user’s question. b) RAG Architecture: The RAG architecture of the MoRSE system, which is used in both the Structured (III-D) and Unstructured RAG (III-E), follows the same underlying logic shown in Figure 3. This architecture is divided into two parts: 1) The Retrieval part, which consists of Parallel Retrievers used to collect relevant information for the query. 2) The Generation part, in which the Large Language Model (LLM) uses the context provided in the Prompt to generate responses. After the retrieval phase, the collected information (info 1 to info N) is merged into a Context, which is Wrapped, along with the user query, in a Prompt used by LLM to generate the Answer. The logic of the architecture is formalized in the Algorithm 1. C. Query Handling This component improves the intelligence of the MoRSE system by managing complex query types and enriching the context. Below are the specific functions and the composition of this component: 1) Functionalities: • Multi-Hop Question Handling : Deals with queries in- volving multiple related entities and allows the system to handle and answer complex multi-hop questions. Existing Retrieval Augmented Generation systems struggle with multi-hop queries due to their design limitations and the lack of a dedicated benchmark dataset for this type of query [48], [49]. • Context Enriching: Generates additional questions from each identified entity, expanding and enriching the con- text available for generating informed answers. • Solving the CVE-CWE Conundrum : Effectively han- dles queries related to Common Vulnerabilities and Ex- posures (CVE) and Common Weakness Enumerations (CWE), which are challenging for generative models due to