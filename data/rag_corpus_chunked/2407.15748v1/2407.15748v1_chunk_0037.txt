(see Figure 4). We have individually multiplied the retrievers’ failure rates listed in Table VII, determining a collective probability of failure at approximately 0.2569%, equal to an empirical rate ( ˆp) of 0.0026. When assessing reliability, we used a 95% confidence interval [62], the empirical rate, a z-score of 1.96, and the Failure Rates (Fail.Rate) from Table VII. This analysis shows that the maximum failure rate under the tested conditions does not exceed 0.46%, which confirms the robustness of the system when processing text-based queries. V. R ELATED WORK We now overview recent developments in Named Entity Recognition (NER), Knowledge Graphs (KGs), and Large Language Models (LLMs) that have contributed to more sophisticated, automated, and adaptive cybersecurity systems. a) Named Entity Recognition in Cybersecurity : Significant progress has been made in the evolving landscape of Named Entity Recognition (NER) for cybersecurity. In particular, the use of BERT and its Whole Word Masking variant with a BiLSTM-CRF framework has shown remarkable improve- ments in entity recognition metrics [63]. Similarly, by fusing rule-based, dictionary-based methods and CRF, the RDF- CRF model has significantly improved entity recognition in the cybersecurity domain [64]. In addition, a hybrid model that combines deep learning with dictionary-based methods has significantly improved precision and recognition in the identification of complex entities [65]. A study by Srivastava et al. [66] highlighted the differential effectiveness of word embeddings such as fastText, GloVe and BERT, with fine- tuned BERT embeddings with a feed forward network achiev- ing an F1 score of 0.974, highlighting the importance of model adaptation to specific domains. In addition, the introduction of the JCLB model, which combines contrastive learning with a Belief Rule Base [67], showed improved accuracy through semantic expansion and optimized BRB parameters. Li et al. developed NEDetector [68], which improves NER by identifying cybersecurity