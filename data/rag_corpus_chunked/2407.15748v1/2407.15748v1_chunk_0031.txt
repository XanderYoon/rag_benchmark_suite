in Table V, MoRSE leads with the highest Elo score of 1244 and an MLE Elo of 1252.43, indicating superior performance in general cybersecurity knowledge. It has a strong bootstrap score of 1225.54, indicating consistent results within the 1275-1175 confidence interval. It is followed by GPT-4 with an Elo of 1083 and MLE Elo of 1107.07, also showing reliable performance. GEMINI and MIXTRAL show moderate performance, with Elo ratings of 926 and 885, respectively. HACKERGPT performs the worst with the lowest Elo score. 10 b) Performances on Multi-Hop Cybersecurity Questions: As shown in Table V, in Multi-Hop queries, MoRSE again excels with an Elo of 1280 and an MLE Elo of 1323.67. Its bootstrap score of 1170.62 with a narrow interval indicates a high stability of performance. GPT-4 remains a competitive second with an Elo of 1157. MIXTRAL, despite its lower performance on general questions, performs better on Multi-Hop questions with a better Elo of 921, while GEMINI struggles, as reflected in its Elo of 907. HACKERGPT continues to show less stability in this area as well. c) Complete Questions Insights : Considering 156 General Questions and 150 Multi-Hop Questions , MoRSE stands out with an Elo of 1267 and an MLE Elo of 1294.66, com- plemented by a solid bootstrap score within a trustworthy interval, proving its robustness. GPT-4â€™s performance is also solid with an Elo of over 1100. The performances of GEMINI and MIXTRAL are very similar, with Elo Ratings between 900 and 950. HACKERGPT remains less consistent overall. D. Third Test Suite: LLM as Judge with Five-Level Judgment Criteria Based on Top-Scoring References Prompt 2: The prompt for Five-Level Judgment Criteria Referencing the Top-Scoring Reference. Task Description: A Question, a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing