privacy and ethics highlight the need for further research before widespread adoption. Yoo et al. [87] use CNN classifiers and AI chatbot to detect and combat SNS phishing attacks before they can occur. This is more promising than traditional methods because it provides real-time support and actions on Telegram, with validated effectiveness against LSTM models. Iqbal et al. [88] explore the dual utility of ChatGPT in cybersecurity, highlighting its benefits for defense strategies and the risks of its misuse in cyberattacks, and call for more research on its offensive capa- bilities. Chamberlain and Casey [89] examine the application of ChatGPT in penetration testing and CTF exercises, pointing to its potential to create dynamic scenarios and enhance the learning process. Aghaei et al. [90] developed SecureBERT, which automates critical cybersecurity tasks by introducing a specialized language model for Cyber Threat Intelligence (CTI) that uses a customized tokenizer and pre-trained weights for improved performance on NLP tasks. Ameri et al. [91] use BERT for feature classification and achieves improved accuracy from 76% to 94.4% by optimizing the hyperparam- eters. It demonstrated robustness with a standard deviation of ±0.6% across all validations and outperformed models such as GPT2, ULMFiT, ELMo, CNN, LSTM and BiLSTM on cybersecurity tasks. V oros et al. [92] use knowledge distillation from LLMs to efficiently categorize URLs, reduce the number of parameters and improve inline scanning. Happe et al. [93] use GPT-3.5 to extend penetration testing and demonstrates LLMs as AI sparring partners in security testing. Lu et al. [94] integrate graph structural information and in-context learning into LLM-based software vulnerability detection, significantly outperforming conventional models. Yu et al. [95] use GPT- 3 to generate semantic honeywords containing users’ PII, which improves their indistinguishability and increases de- fenses against security breaches. Unlike traditional LLMs and chatbots, MoRSE stands out