This is fundamental to the system’s ability to retrieve contextually relevant content, essential for generating well-informed and accurate answers [38]. • Embeddings are numerical representations of text that assign a low dimension to a term. Within this context, embedding vectors of analogous terms exhibit proximity, encapsulating semantic meaning. This facilitates the com- parison between queries and the knowledge base [39]. • Context refers to the relevant information or data re- trieved by the system, which surrounds and informs a particular query. The model requires this contextual information to formulate answers that are precise, com- prehensive, and directly linked to the content found in the knowledge base [40]. • Prompt refers to the structured input that is created from the retrieved context, which is then fed into the generative model. This prompt guides the model in generating a coherent, contextually relevant response that directly addresses the user’s request [41]. • Semantic Similarity evaluates how closely the content of a user’s query matches the information in the knowledge base, focusing on meaning rather than word-for-word matching. This evaluation guarantees the relevance and accuracy of the retrieved data and supports the generative model in creating appropriate answers. In MoRSE, we use Cosine Similarity [42] to measure the proximity of embedding vectors because it has a high correlation with human judgment [43]. • Multi-hop queries are defined as requests for infor- mation that necessitate indirect reasoning over multiple pieces of interconnected data. They typically arise in complex question-answering tasks where a single piece of evidence is insufficient to resolve the query, and the sys- tem must hop across different data points or documents to piece together a response. III. M ORSE A RCHITECTURE This section describes the structure of the MoRSE system in detail. It explains the function of the individual components and how