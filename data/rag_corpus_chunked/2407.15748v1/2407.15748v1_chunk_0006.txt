performed to evaluate the performance of MoRSE, including a comparative analysis with known commercial models. Section V provides an overview of related research work that includes various cybersecurity tools such as knowledge graphs, entity extraction tools, chatbots, and cyber threat intelligence (CTI). The conclusions and future work directions are presented in Section VI. II. BACKGROUND This section provides an overview of the basic concepts necessary for understanding the architecture of MoRSE. A. Large Language Models Large language models (LLMs) represent a significant ad- vancement in the field of Natural Language Processing (NLP) and are based on the Transformer model [25]. These models are trained on large text datasets and are able to generate coher- ent and contextually relevant texts based on input prompts. The 9https://github.com/Mixture-of-RAGs-Security-Experts/MoRSE 2 capabilities of LLMs go beyond text generation and include tasks such as language translation, summarizing, answering questions, etc. The introduction of models such as GPT [26] and BERT [27] has demonstrated the potential of LLMs to revolutionize language understanding and generation through unsupervised and bidirectional training [26], [28]. With the development of GPT-3 [29], the scalability of these models reached new heights, illustrating their ability to perform a wide range of NLP tasks without task-specific training. Despite their advantages, LLMs face several challenges. Ethi- cal considerations, such as the spread of bias and misinforma- tion, are a major concern [30]. In addition, the environmental impact of training and operating these computationally inten- sive models has raised questions about their sustainability [31]. Efforts to overcome these challenges include research into more efficient training methods and models that are able to understand and generate texts with greater accuracy and less bias [32]. B. Retrieval Augmented Generation Retrieval-Augmented Generation (RAG) combines traditional language models with external databases to improve natural language processing (NLP) tasks [33], [34], [35].