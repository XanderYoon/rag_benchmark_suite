priority across all sectors, with a 15% increase in three years 1 on data breaches only. In recent years, the amount of cybersecurity- related information has exploded, providing important re- sources to protect against these threats by mitigating risk and improving cybersecurity measures. However, this rapid proliferation of information has led to a cluttered and often unstructured data landscape, complicating the task of deriving actionable insights for professionals [1], [2]. In fact, a timely, accurate, and comprehensive understanding of vulnerabilities, exploits, and defense tactics is crucial, as the promptness of such information can significantly impact cybersecurity decisions [3], [4]. Recently, large language models (LLMs) have become important tools for synthesizing huge amounts of information in various fields, including cybersecurity [5]. However, their reliability varies for technical topics where inaccuracies are critical [6], [7], [8], [9]. LLMs can produce hallucinatory responses, meaning that they produce answers that are not true or reliable, especially struggling with the dynamic and evolving nature of cyber threats [10], [11], [12]. This problem is particularly pronounced in code generation 1https://bit.ly/3zxkf2y tasks, where LLMs often produce non-functioning code for complex queries [13]. Specifically, when the model does not know the correct answer, hallucinations are inevitable (Epistemic [14]). This can happen if the model does not have enough training data or if its capacity is limited. An example of hallucination in cybersecurity is shown in Example 1 (ground truth) and Example 2 (the answer of GPT-4) to the question: What is CVE-2017-5162? . This shows that GPT-4 is not able to provide the correct answer. To overcome these limitations, it is crucial to build continuous learning mechanisms into LLMs that allow them to dynamically update their knowledge base with the latest information [15]. Although retraining can be time-consuming, updating with new information is essential to maintain the relevance