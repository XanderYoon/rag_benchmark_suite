a feed forward network achiev- ing an F1 score of 0.974, highlighting the importance of model adaptation to specific domains. In addition, the introduction of the JCLB model, which combines contrastive learning with a Belief Rule Base [67], showed improved accuracy through semantic expansion and optimized BRB parameters. Li et al. developed NEDetector [68], which improves NER by identifying cybersecurity neologisms with 89.11% accuracy, outperforming traditional trending tools in detecting threats on platforms like Twitter. Extractor distills attack behavior from CTI reports into clear, actionable insights and leverages 12 TABLE VII: Performance summary of Structured and Unstructured RAG components tested on CPU and GPU (NVIDIA A100 80GB). Fail. Qs. states for Failed Test Queries, while Tot. Qs. states for Total Test Queries Component Mean Time (s) Time Std. Fail. Qs Tot. Qs Fail. Rate Size Embed. Thres. No. Doc. GPU CPU GPU CPU Structured RAG Retrievers Malware Retriever 0.061 0.110 0.009 0.013 6 100 6% 3.9MB α 0.7 ∼ 1000 Metasploit Retriever 0.995 1.367 0.592 1.307 5 100 5% 40MB α 0.75 ∼ 4900 ExploitDB Retriever 1.254 2.377 0.998 1.198 8 100 8% - - - ∼ 13000 CWE Retriever 0.083 0.108 0.056 0.019 28 100 28% 5.86MB α 0.73 ∼ 1000 MITRE Retriever 0.057 0.13 0.07 0.029 19 100 19% 3.2MB α 0.7 ∼ 800 Entity Retriever 0.250 0.268 0.078 0.018 23 100 23% 554MB β 0.5 ∼ 7000 Question Ret. Sys. 2.492 2.536 0.298 0.338 21 100 21% 3.863GB β 0.6 ∼ 7000 Unstructured RAG Components PAPER BUFFERS 0.838 39.8 0.139 2.94 1 100 1% 86.4MB β Top 5 ∼ 380 TEXT BUFFERS 1.789 85.22 0.298 6.29 1 100 1% 185MB α Top 5 ∼ 6000 CODE BUFFERS 0.416 19.81 0.069 1.46 8 100 8% 43.0MB α Top 5 ∼ 1000 METASPLOIT BUFFERS 1.799 85.68 0.299 6.32 5