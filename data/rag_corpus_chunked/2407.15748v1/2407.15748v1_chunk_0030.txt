set equal to 4, controls the volatility of the rating, S denotes the actual match outcome (1 for a win, 0.5 for a tie, and 0 for a loss), and E is the expected outcome, as calculated in Equation 6: E = 1 1 + 10 Rnew −Rold 400 . (6) • Maximum Likelihood Estimation: Utilizing logistic re- gression for MLE, we further analyzed the pairwise com- parisons, deducing each model’s probability of outper- forming another, thereby enriching our evaluative scope with probabilistic insights. The logistic regression model used for MLE can be formalized in Equation 7: log  p 1 − p  = β0 + β1X1 + · · · + βpXp, (7) where p is the probability of model A winning over model B, Xi represents the feature vector indicating the participation of models in each match, and βi are the coefficients learned by the regression, correlating with the Elo scores. The computed coefficients βi are then scaled and adjusted to derive the final Elo scores for each model. • Bootstrap-enhanced Elo Ratings: To address potential biases related to battle sequencing, we employed a Boot- strap approach, enhancing the robustness of Elo ratings and facilitating confidence interval estimations for a more reliable assessment. The Bootstrap method involves: sam- pling battles, calculating Elo ratings, forming a rating distribution across rounds, and determining confidence intervals (median, 2.5%, and 97.5% percentiles). a) Performances on General Cybersecurity Question : As shown in Table V, MoRSE leads with the highest Elo score of 1244 and an MLE Elo of 1252.43, indicating superior performance in general cybersecurity knowledge. It has a strong bootstrap score of 1225.54, indicating consistent results within the 1275-1175 confidence interval. It is followed by GPT-4 with an Elo of 1083 and MLE Elo of 1107.07, also showing reliable performance.