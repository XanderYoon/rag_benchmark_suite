https://proceedings.mlr.press/v162/borgeaud22a.html [18] S. Masoudnia and R. Ebrahimpour, “Mixture of experts: a literature survey,” Artificial Intelligence Review, vol. 42, pp. 275–293, 2014. [19] A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bam- ford, D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand et al. , “Mixtral of experts,” arXiv preprint arXiv:2401.04088 , 2024. [20] S. Caltagirone, A. D. Pendergast, and C. Betz, “The diamond model of intrusion analysis,” 2013. [Online]. Available: https: //api.semanticscholar.org/CorpusID:108270876 [21] J. Wang and B. Xia, “Relationships of cohen’s kappa, sensitivity, and specificity for unbiased annotations,” in Proceedings of the 4th International Conference on Biomedical Signal and Image Processing, ICBIP 2019, Chengdu, China, August 13-15, 2019 . ACM, 2019, pp. 98–101. [Online]. Available: https://doi.org/10.1145/3354031.3354040 [22] M. McHugh, “Interrater reliability: The kappa statistic,” Biochemia medica : ˇcasopis Hrvatskoga druˇstva medicinskih biokemiˇcara / HDMB, vol. 22, pp. 276–82, 10 2012. [23] S. Es, J. James, L. Espinosa Anke, and S. Schockaert, “RAGAs: Automated evaluation of retrieval augmented generation,” in Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations , N. Aletras and O. De Clercq, Eds. St. Julians, Malta: Association for Computational Linguistics, Mar. 2024, pp. 150–158. [Online]. Available: https://aclanthology.org/2024.eacl-demo.16 [24] L. Zheng, W.-L. Chiang, Y . Sheng, S. Zhuang, Z. Wu, Y . Zhuang, Z. Lin, Z. Li, D. Li, E. Xing et al. , “Judging llm-as-a-judge with mt-bench and chatbot arena,” Advances in Neural Information Processing Systems, vol. 36, 2024. [25] A. Vaswani et al., “Attention is all you need,” in Proceedings of the 31st International Conference on Neural Information Processing Systems , 2017. [26] A. Radford et al. , “Improving language understanding by generative pre-training,” OpenAI Blog, 2018. [27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep