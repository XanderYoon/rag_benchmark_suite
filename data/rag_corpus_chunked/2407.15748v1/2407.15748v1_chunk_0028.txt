by two AI assistants to the user question displayed below. Your evaluation should consider correctness and helpfulness. You will be given a reference answer, assistant A’s answer, and assistant B’s answer. Your job is to evaluate which assistant’s answer is better. Begin your evaluation by comparing both assistants’ answers with the reference answer. Iden- tify and correct any mistakes. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the responses to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. After providing your explanation, output your final verdict by strictly following this format: “[A]” if assistant A is better, “[B]” if assistant B is better, and “[C]” for a tie. [User Question] Insert user question here. [The Start of Reference Answer] Insert reference answer here. [The End of Reference Answer] [The Start of Assistant A’s Answer] Insert Assistant A’s answer here. [The End of Assistant A’s Answer] [The Start of Assistant B’s Answer] Insert Assistant B’s answer here. [The End of Assistant B’s Answer] 9 MalwareMetasploitExploitDB CWEMITREEntity Q. Ret. Sys. 0 20 40 60 6.1 8.6 7 7 9 21.7 56.3 Impact (%) (a) Impact of Retrievers on General Questions MalwareMetasploitExploitDB CWEMITREEntity Q. Ret. Sys. 0 20 40 6.3 12 6 5 7 28.3 35.4 Impact (%) (b) Impact of Retrievers on MultiHop Questions MalwareMetasploitExploitDB CWEMITREEntity Q. Ret. Sys. 0 20 40 1 31 18 10 5 10 14 Impact (%) (c) Impact of Retrievers on CVE Questions Fig. 6: Impact of Retrievers on General, MultiHop and CVE Questions In our evaluation, we used GPT-4 0125-Preview as a judge to evaluate and compare the performance of MoRSE, GPT-4 0125-Preview, MIXTRAL 7X8, GEMINI 1.0 Pro and HACK-