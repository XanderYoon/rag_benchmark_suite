of buffers: • Text Buffers: Process content from websites and blogs with five separate buffers, each analyzing data using the (α) embedding. • Metasploit Buffers : five buffers containing entire codes from the Metasploit framework that uses the ( α) embed- ding for effective processing. • Code Buffers : A single buffer processes code snippets from Exploit DB and also uses (α) embedding for optimal analysis. • Paper Buffers: Academic papers are managed by three buffers that use the ( β) embedding to better handle the complex language typical of academic content [57]. This choice is based on the higher performance values of embedding, which indicate better retrieval capabilities. The process Context Transformation refines information from buffers through four phases: • Splitting Stage: Document are split into 300-character chunks, improving relevance selection and reducing noise from larger chunks. • Redundant Content Removal: In this phase, β embed- dings are used to remove redundant content from the segmented chunks and improve the clarity and uniqueness of the output. • Filtration Stage: Relevant data chunks are selected using (β) embeddings with a threshold of 0.6 set to the third quartile (Q3) of similarity results from tests with 156 queries to ensure relevance from the knowledge base. • Reordering Phase: Finally, the data is ordered according to the ( Lost in the Middle ) principle to prioritize the visibility of important information in the response. IV. EXPERIMENTS AND EVALUATION The evaluation of Retrieval Augmented Generation systems and Large Language Models in the field of cybersecurity is particularly challenging due to their dual role in information retrieval and content generation. The lack of standardized benchmarks covering a wide range of real-world operational cyber tasks complicates the evaluation of LLMs for cyberse- curity [23], [58], [59]. Key evaluation challenges include verifying the accuracy of the