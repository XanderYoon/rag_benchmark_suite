and culinary domain information present in the general Wikipedia corpus, which was the only Knowledge corpus for QZero. These results highlight the promising potential of QZero as a cost-eﬀective solution for domain adaptation challenges. Our results also demonstrate that retrieval-augmented query re- formulation is eﬀective for classifying topics outside of the model’s training data. By transforming the input query into a knowledge space the model is more familiar with, reformulation bridges the gap between the model’s knowledge and unfamiliar topics. This enhances the model’s adaptability, allowing it to handle a wider range of tasks and domains without extensive retraining. Addi- tionally, this reformulation provides support for a more eﬀective representation, leading to models that are better equipped to tackle unseen data or generalize across domains. Interestingly, we observed that across datasets, QZero rarely hurts the performance of the static word embedding models, and in cases where it does, the performance decline is typically mini- mal, under 1.00%. However, the impact on larger models is more diverse, especially for common evaluation sets like DBpedia and Yahoo Answers. Here, QZero’s eﬀect can vary in magnitude, with the largest decrease observed in TE-3-large. This disparity might be linked to the training data used for these larger models. The Yahoo Answers dataset, for instance, was part of the training data Retrieval Augmented Zero-Shot Text Classification ICTIR ’24, July 13, 2024, Washington DC, DC, USA Table 4: Model Performance Summary across Six Datasets. QZero CTV (Contriever) represents the intervention of QZero using the dense retriever, and QZero BM25 represents the intervention of QZero using the sparse retriever. Models TagMyNews (%) AG News (%) Ohsumed (%) Yummly (%) DBpedia (%) Yahoo (%) Base +QZero BM25 +QZero CTV Base +QZero BM25 +QZero CTV Base +QZero BM25 +QZero CTV Base +QZero BM25 +QZero CTV Base +QZero BM25 +QZero