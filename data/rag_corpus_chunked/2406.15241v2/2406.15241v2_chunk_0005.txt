tions when used in diﬀerent contexts, capturing the nuances of its meaning based on surrounding words. QZero’s query reformulation pipeline adapts to the type of em- bedding model employed. For contextual embedding models, the concatenation of the categories serves as the reformulated input. Static word embedding models, on the other hand, utilize keywords and frequencies extracted from the retrieved categories. Conse- quently, the model utilizes this reformulated input to generate embeddings for downstream text classi/f_ication tasks. Our focus is speci/f_ically on improving models designed to pro- duce embeddings, not generative or prompting models. Hence, we evaluate QZero on six diverse datasets, using embedding models of diﬀerent sizes, ranging from a simple Word2Vec to Open AI’s text embeddings. Our results demonstrate that QZero bene/f_its models of all scales. Notably, the additional context provided by QZero acts as a knowledge boost for smaller models, allowing them to achieve performance levels comparable to larger models. This trans- lates to signi/f_icant computational cost savings, as smaller models require less processing power. In addition, QZero oﬀers meaning- ful insights that illuminate query context and verify topic (class) relevance, aiding in understanding model predictions. 2 RELATED WORK 2.1 Zero-shot Text Classi/f_ication with Generative LLMs Zero-shot classi/f_ication has seen signi/f_icant advancements through various approaches. One prominent avenue utilizes large-scale gen- erative models, like GPT(Generative Pre-trained Transformer) [3], for inference tasks. Trained on massive text datasets, these models excel at understanding and generating natural language, making them attractive for zero-shot classi/f_ication tasks. However, their immense size and computational demands limit their accessibility and eﬃciency for resource-constrained environments. In addition, these models tend to make predictions outside the scope of user- de/f_ined classes, hindering the model’s applicability in scenarios where class-based predictions are required. 2.2 Zero-shot Text Classi/f_ication via Semantic Comparison Beyond large generative models, an alternative approach leverages