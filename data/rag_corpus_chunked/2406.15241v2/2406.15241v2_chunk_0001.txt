and domains with constantly evolving information. 1 CCS CONCEPTS • Information systems → Clustering and classi/f_ication. KEYWORDS Retrieval augmented learning, Query reformulation, Zero-shot text classi/f_ication, Text embeddings ACM Reference Format: Tassallah Abdullahi, Ritambhara Singh, and Carsten Eickhoﬀ. 2024. Retrieval Augmented Zero-Shot Text Classi/f_ication. InProceedings of the 2024 ACM SIGIR International Conference on the Theory of Information Retrieval (ICTIR ’24), July 13, 2024, Washington DC, DC, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3664190.3672514 1code available at :https://github.com/rsinghlab/QZERO This work is licensed under a Creative Commons Attribution International 4.0 License. ICTIR ’24, July 13, 2024, Washington DC, DC, USA © 2024 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-0681-3/24/07 https://doi.org/10.1145/3664190.3672514 1 INTRODUCTION Zero-shot learning enables classi/f_iers to handle unseen classes eﬃ- ciently, alleviating the need for task-speci/f_ic training data. Unfortu- nately, supervised classi/f_ication models encounter signi/f_icant chal- lenges in scenarios that are characterized by an unconstrained label space [1, 7]. For example, consider the task of classifying recipes into categories based on their ingredients or regional cuisines. The diversity of culinary traditions and the continuous emergence of new dishes create an expansive and evolving label space. This com- plexity makes it diﬃcult to de/f_ine and collect labeled data for all possible label types, thus limiting the model’s ability to classify novel or unique recipes accurately. The conventional practice of retraining a model for each new label set becomes impractical due to the substantial increase in expenses associated with annotation and computation. This has necessitated the widespread adoption of zero-shot text classi/f_ication. Generative Large Language Models (LLMs) have revolutionized the /f_ield of natural language processing [3, 23], especially for zero- shot learning. Their remarkable zero-shot abilities enable them to tackle diverse tasks with impressive eﬃciency and adaptability. However, applying generative LLMs directly for zero-shot text clas- si/f_ication tasks presents challenges due