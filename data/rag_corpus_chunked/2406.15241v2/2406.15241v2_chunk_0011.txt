to emphasize their potential importance. We explore the use case of the reformulated queries for contex- tual models that are optimized for generating meaningful embed- dings from sentences and static word embedding models optimized for word inputs (details in Section 3.6). The reformulated query for the contextual embedding models comprises a concatenation of all the retrieved categories. This concatenation process is executed following the order of their respective articles’ ranks, as depicted in Figure 1 and outlined in the equation below: /u1D465ĩ Ď = (/u1D4361, /u1D4362, . . . , /u1D436Ĥ ) In the above equation, /u1D4361 represents the retrieved categories for an article. Post-retrieval, the categories for each article are denoted as /u1D436ğ, where i signi/f_ies the rank of the article (1 for the top-ranked article). Therefore, the reformulated query /u1D465ĩ Ď is the concatenation of the retrieved categories in the sequence of their corresponding article’s rank. While contextual embedding models oﬀer advantages, they have limitations regarding the number of input tokens. Concatenating too many categories can introduce noise into the reformulated query, and processing longer queries increases computational cost. To address these limitations, we restrict all contextual embedding models to use only the /f_irst 512 tokens of the concatenated cate- gories as their re/f_ined queries. Static word embedding models are limited to single words as inputs; thus, we extracted keywords /u1D43Efrom the reformulated query using the appropriate strategy from Section 3.4 based on the dataset. Upon obtaining our keywords, we assign weights /u1D464to them based on their frequency across the reformulated query, facilitating eﬀec- tive measurement of each keyword’s importance (since keywords will be repeated across the reformulated query). This results in a re- /f_ined query where each keyword is paired with its weight, forming a structured representation as a list of tuples expressed as: /u1D465ĭ Ď =