data—such as addresses or product pages—are often highly similar, making it challenging to distinguish between them accurately [B,K] To solve these challenges, the critical importance of data quality was highlighted [A,M]. They recommended investing substantial time and effort in data preparation, as high-quality data leads to significantly better results. Retriever: The second category of challenges is related to the retriever component of the RAG system. Determining the appropriate chunking and embedding strategies further complicates the process. B, E, and L explained that while a basic RAG system can be easily adopted with good initial results, working with real-world data is far more complex. In practice, selecting and collecting the right data and then choosing an optimal chunking and embedding approach proved to be a significant challenge. Even deciding on the best way to perform chunking was a problem. In terms of chunking strategies, they advised maintaining an optimal chunk size—not too small, to avoid fragmented context, and not too large, to prevent overwhelming the LLM with excessive information [B,C]. Generator: The last challenge pertains to the generator component, concrete to the issue of hallucination in LLMs. It was highlighted that hallucinations—instances where the model generates incorrect or misleading information—are a significant obstacle during implementation [A]. Specifically, the LLM may fail to accurately convey the information retrieved by the retriever component, or it may introduce erroneous details that were not part of the retrieved data. It also depended heavily on the user, as the results varied significantly when different prompts were used [C]. To address this challenge of inconsistent outcomes caused by varied user prompts or hallucination, a solution mentioned was to implement a RAG system where user input is automatically refined and improved by the LLM [A,C]. This approach minimizes the impact of poorly crafted prompts, ensuring more accurate and