Another aspect of RAG is system enhancement, as highlighted by [Zhao et al., 2024], who identify several RAG improvements in the literature, including input enhancements as a key category. One type of input enhancement is query transformation, which involves approaches such as refining or rewriting the input query to improve retrieval effectiveness [Chan et al., 2024, Tayal and Tyagi, 2024], while another is data augmentation, wherein semantic-preserving transformations are applied to enhance the database, as demonstrated in the pre-training of code retrieval models [Lu et al., 2022]. The second category of enhancements centers on retriever improvements, including techniques such as recursive retrieval [Yao et al., 2023], hybrid retrieval [Yu et al., 2022], re-ranking methods [Glass et al., 2022], and chunk optimization strategies [Sarthi et al., 2024]. The third category is generator enhancements, which includes techniques like prompt engineering [Wei et al., 2023] and fine- tuning of the decoder [Jin et al., 2023] to improve the performance of the generation component. The fourth category is result enhancement, which involves techniques for rewriting or refining the generated output [Liu et al., 2024]. Finally, the fifth category is RAG pipeline enhancement, which refers to the development of new or optimized RAG pipeline architectures [Zhang et al., 2023b]. Evaluating RAG systems. Quality is a critical aspect of RAG systems, with several evaluation frameworks designed to measure various quality requirements. One such framework is RAGAS [Es et al., 2023], which assesses retriever quality by evaluating the relevance of retrieved documents. This can be done using an LLM [Es et al., 2023], an already prepared test set with labeled datasets [Tang and Yang, 2024], or human judgment [Afzal et al., 2024]. Another important aspect is the generator quality, where the generated answer is evaluated for quality attributes like faithfulness [Es et al., 2023]. In this case,