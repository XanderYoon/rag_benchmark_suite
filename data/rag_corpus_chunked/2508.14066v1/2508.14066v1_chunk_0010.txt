is to combine the retrieval of relevant information with the execution of operational tasks. Leveraging access to internal wikis, ticketing systems, and source code repositories, the RAG system can, for example, create new tickets, initiate projects, or generate structured reports based on the retrieved information. Furthermore, RAG systems are also being adopted to replace legacy systems [M]. Last but not least, one use case involves document formatting. In this context, documents are provided as examples of the desired format, and the LLM is expected to generate outputs that adhered to the same structure and style. This functionality was integrated into a larger application and represented one step within a broader automation workflow [K]. The last use case fits in theText generation and Summarization category of [Arslan et al., 2024]. Table 2: List of use cases by interview participants Category ID Primary Use Case Question Answering A Search Assistant for Support B Medical QA D Chat Assistant with Specific Expertise E Find Information from Repository F Search Assistant for Different Tools G Modular RAG System for Companies H Get Information About Other Employees/Team Group Messages I QA for Ticketing System J Automatic Customer Support L Search Documentation Decision Making and Application C Chatbot for Customer with ChatOps M Automation of Legacy Systems Text Generation and Summarization K Contract Formatting Another important aspect of the identified use cases is understanding the underlying goals for adopting RAG systems. The first perspective that emerged was the rationale for choosing RAG over other technologies, such as standalone LLMs. One key reason was the ability to easily update and expand the knowledge base with company-specific information [C,E,L]. This offered greater flexibility compared to fine-tuning a model, which is more static and resource-intensive. With RAG, the underlying LLM could also be swapped out for a more advanced