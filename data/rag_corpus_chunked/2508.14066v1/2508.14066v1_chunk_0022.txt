to collect employee data [H]. Such misuse can have serious privacy and security implications. Participants B and E expressed difficulties in keeping up with the fast-moving technologies . They found that by the time one method was implemented, it was often already outdated due to the emergence of new, more efficient approaches. This constant evolution creates uncertainty, as there is no established best practice for implementing and maintaining RAG systems. It also complicates efforts to address the previously mentioned challenges. The quality evaluating of the RAG system quality is also problematic. Unlike traditional software, where formal benchmarks can be applied, RAG performance is highly context- dependent, varying based on user input. C noted that different users adapt to the technology at different speeds. Implementation Recommendation and Lessons Learned We can outline several recommendations for implementing a RAG system: The first and most critical step is identifying a suitable use case. This use case must have a clearly defined process, including a well-documented and justified automation goal [F,I,M]. Once the use case is established, the next step is data selection. The data must be tailored specifically to the chosen use case and should not be overloaded with excessive or irrelevant details [B,C]. It is essential to focus on a narrow and consistent domain, avoiding overlap with other departments or projects [D,F]. Ideally, a separate RAG implementation should be created for each project or department, with a clearly scoped and precise objective [D,F]. Following this, significant effort should be invested in data preparation and preprocessing to ensure high-quality inputs for the RAG system [A,M]. To support this, it is crucial to identify an effective chunking strategy. Chunks should be large enough to contain sufficient context for answering questions accurately, but not so large that they overwhelm the generator or exceed processing limits