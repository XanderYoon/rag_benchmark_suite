generated by the RAG system. This includes the quality of the underlying data, the retriever component, and the generated answers. Initially, we identified RAG quality and answer quality as separate requirements, but we extended this to include data quality after it was explicitly mentioned by participants [C,D,H,I,J,M]. The intent behind this requirement is to ensure that the RAG consistently delivers high-quality, relevant, and accurate responses. All participants rated this requirement as highly relevant, with scores of 8 or higher, except for one [K], who rated it a 3. In that specific use case, RAG was only a small component within a larger process, and low-quality outputs could simply be discarded without affecting the overall system. Usability is defined as how easy and intuitive the RAG system is for users to interact with. The perceived importance of usability varied among participants. Some stated that usability was not a major concern because users were already familiar with similar chat interfaces, for example ChatGPT or Gemini, making adaptation straightforward and requiring minimal effort [A,E]. Others emphasized that usability is crucial, as users are more likely to adopt the system if it is intuitive and easy to use [C,G]. Overall, we conclude that usability is important but generally easy to achieve, given that conversational interfaces are now common [C,D]. Explainability/Transparency refers to the extent to which the RAG system provides clear and understandable explanations for its answers. This is closely tied to the configuration of the RAG, where the system must present the sources of information transparently. Specifically, the retrieved documents supporting each part of the answer should be visible, allowing users to understand why the system generated a particular response based on these documents. Nine participants rated this requirement as relevant, assigning it a score of seven or higher. Performance covers aspects related