user, as the results varied significantly when different prompts were used [C]. To address this challenge of inconsistent outcomes caused by varied user prompts or hallucination, a solution mentioned was to implement a RAG system where user input is automatically refined and improved by the LLM [A,C]. This approach minimizes the impact of poorly crafted prompts, ensuring more accurate and consistent results. Additionally, users should be made aware that RAG systems do not always produce correct answers. It is important to emphasize the need for critical evaluation of the output, as errors may occur and should always be taken into account [A] Ensuring that the RAG system consistently produces reliable answers was challenging, and evaluating this consistency proved equally difficult [I]. Another critical challenge is prompt engineering . It can be difficult to design the right prompt for a specific model to achieve optimal results [A,C,K]. A emphasized that even slight modifications to the system prompt can significantly disrupt the entire systemâ€™s performance. Overlapping concerns: One challenge, as highlighted by D, is determining the right scope for RAG implementation. Companies must decide whether to include all organizational data or focus on a limited, specialized subset. Defining the appropriate amount of knowledge and setting clear boundaries is a complex task. The next challenge is related to safety issues of the RAG systems. Participants raised concerns about potential risks, such as jailbreaking the model to bypass restrictions [M] or exploiting user interactions to collect employee data [H]. Such misuse can have serious privacy and security implications. Participants B and E expressed difficulties in keeping up with the fast-moving technologies . They found that by the time one method was implemented, it was often already outdated due to the emergence of new, more efficient approaches. This constant evolution creates uncertainty, as there is