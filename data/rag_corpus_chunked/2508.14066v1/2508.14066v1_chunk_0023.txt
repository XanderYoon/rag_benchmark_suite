[D,F]. Following this, significant effort should be invested in data preparation and preprocessing to ensure high-quality inputs for the RAG system [A,M]. To support this, it is crucial to identify an effective chunking strategy. Chunks should be large enough to contain sufficient context for answering questions accurately, but not so large that they overwhelm the generator or exceed processing limits [B,C]. Striking the right balance is essential to ensure both retrieval relevance and generation quality. Regarding the generator component, it may be beneficial to integrate additional modules that modify or structure the prompt automatically. This can help mitigate the risk of poor prompting by end users and improve the overall quality of the generated responses [A,C]. As a general recommendation, the system should be designed with a modular architecture. Each component should be easily replaceable, allowing for the seamless integration of new LLMs or emerging technologies [F]. However, not every new advancement should be adopted immediately. If an existing system is stable and performs well, it is often more efficient to continue using it rather than investing significant time and resources into integrating newer solutions [B,E]. This also highlights that there is no ”one-size-fits-all “solution when it comes to choosing an LLM or other components for RAG systems [B,E,H]. Instead, each RAG may require a different architecture, depending on the specific use case, data type, and desired outcomes. Nonetheless, regular and systematic evaluation should be conducted, particularly after any changes to the system. If the underlying data or any parameter of a component is modified, a comprehensive re- evaluation is necessary. Continuous evaluation should also be part of the deployment phase to ensure the system maintains consistent performance in real- world conditions [B,I,K]. 4.4 RQ4: Industrial RAG-Evaluation In research, various evaluation frameworks have been proposed [Brehme et al., 2025b], ranging