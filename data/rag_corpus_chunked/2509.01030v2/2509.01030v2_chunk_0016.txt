experiments. Indexer and ranker. We set kranker as 10, meaning that the indexer-ranker will select the top-10 triplets from the 10K triplets retrieved from the searcher. The knowledge graph extracted by the searcher was split by subject in the triple; each chunk is regarded as a document for ColBERTv2. The maximum length for input is set to 256 tokens. As presented in Table 2, we developed five versions of ColBERT (C0, C1, C2a, C2b, C2c) that underwent different fine-tuning procedures. C0 [∅] is the original ColBERT without fine-tuning; C1 [/commen◎s] is fine-tuned on DS:QALD9RDF/XML; C2a [/gl⌢be-asia+ /commen◎s] is fine-tuned on DS:GeoNamescountry and then DS:QALD9RDF/XML; C2b [/gl⌢be-asia/ci◎y+ /commen◎s] is fine-tuned on DS:GeoNames and then DS:QALD9RDF/XML; and C2c [/gl⌢be-asia/commen◎s] is fine-tuned on both DS:GeoNames and DS:QALD9RDF/XML, where the two datasets are fed into ColBERTv2 simultaneously with shuffling. Table 2. Versions of ColBERT that are fine-tuned on different combination of datasets, where ∅ represents the corresponding dataset is not utilized. The notations 1⃝ and 2⃝ represent that the corresponding dataset is utilized for fine-tuning, where 1/2 represents the order of the dataset introduced during fine-tuning. Version of The fine-tuning is carried out on the following datasets: ColBERT DS:GeoNamescountry /gl⌢be-asiaDS:GeoNames /gl⌢be-asia/ci◎yDS:QALD9RDF/XML /commen◎s C0 [∅] ∅ ∅ ∅ C1 [/commen◎s] ∅ ∅ 1⃝ C2a [/gl⌢be-asia+ /commen◎s] 1⃝ ∅ 2⃝ C2b [/gl⌢be-asia/ci◎y+ /commen◎s] ∅ 1⃝ 2⃝ C2c [/gl⌢be-asia/commen◎s] 1⃝ ∅ 1⃝ StreetToPerson. This model successfully extracted 261 compatible pairs “street- person” in Australia from the English Wikidata and Wikipedia as a training dataset. Even if the streets of Melbourne are part of the test dataset, we decided to include the 22 streets detected in Melbourne in the training dataset for three reasons. First, we want to characterize the streets in Melbourne to improve inference, hence it is necessary to have data for this area. Second, the