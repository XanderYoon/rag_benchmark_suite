evident answer appears quickly in the highest ranks. We observe that MAP ∗ sem is between .1 and .2: an interpretation is that, on average, 1 or 2 retrieved items among the set of top-10 contain relevant information. Nonetheless, certain names like Flinders Street are more specific thanRainbow Alley, which increases the chances to have more than 2 items instead of 0. Mentions toAustralia or Victoria are good markers as the top-10 is likely to contain at least one related element in more than 75% of the recommendations when we consider HR∗ geo vic or 93% with HR∗ geo aus, as well as the first two elements out of 10 might be linked to these places (MRR∗ geo aus@10 ≥ .6). When the knowledge graph does not mention any relevant origin. In these cases, the sem score has no useful information but in contrast, the ranker is expected to manipulate more information related to geo aus or geo vic. In practice, we observe that the models do not fully exploit the spatial filters written in the context (in the anchor-question) as a discriminating criterion. An efficient ranker should first prioritize passages that do contain the origin of a place name. This origin can be explicitly given in the passage, or inferred with multiple passages eventually with the internal knowledge of language models. As a second order Horde Vo, Duckham, He, and Benli (a) C0 ( ∅) - not trained on a spatial dataset (b) C2a ( /gl⌢be-asia+ /commen◎s) - trained on a spatial dataset Figure 2. Retrieved items for 15 place names regarding geo aus and geo vic. A fine-tuning is expected to highlight spatially related candidates at the highest ranks, which is characterized by the nDCG@10. of priority, human understanding would focus on spatial similarities, as indicated in the