knowledge graphs. However, the quality of the top-k candidates is not high with respect to their spatial distribution, particularly with the nDCG compared with fine-tuned models. To evaluate the models in detail, we must distinguish two cases: firstly, can a model retrieve an information that does exist? Secondly, if missing, can a model retrieve information that is at least spatially related to the query? 3For example, where the documentation specifies “this street is named after a former person who lived in the street” but does not explicitly name that person. This qualification was subjectively defined by the annotator. Identifying Origins of Place Names Via Retrieval Augmented Generation Table 4. Evaluation of the performances of C0, C1, C2a, C2b and C2c after the ranker (@ k = @10) for the different types of observations (relevance of the semantic evaluation sem, or spatial evaluations geo aus or geo vic). First, the scores are calculated for all the data in DS:Gazetteer and second, on the a subset where the extracted knowledge graph KG from the searcher contains a mention of the origin: these scores are marked with ∗. The notation x denotes averaged results on the dataset; MAP is the mean average precision (namely P@10). Each street in DS:Gazetteer ( N = 248) represents one independent sample; results are averaged on N = 248 elements. Ranker Scores on DS:Gazetteer (N = 248) ... restricted to the streets where @k = @10 the KG mentions an origin (N∗ = 93) Model Type MRR nDCG MAP HR MRR∗ nDCG∗ MAP∗ HR∗ C0 [∅] sem .232 .170 .063 .216 .445 .412 .143 .506 geo aus .684 .777 .501 .883 .831 .854 .578 .933 geo vic .476 .539 .243 .703 .628 .646 .313 .753 C1 [/commen◎s] sem .253 .186 .080 .243 .475 .421 .177 .528 geo aus