query. We developed the indexer and ranker based on ColBERTv2 [1], a pre- trained LM designed to compute the closeness between a pair of query and a triplet document in terms of semantic similarity. Here, the texts associated with a set of triplets related to one subject can be treated as one triplet document, and thus the semantic similarity between a query and a triplet document is measured as the similarity between their latent embeddings produced by a text encoder. ColBERTv2 enhances the efficiency of similarity computation by grouping and indexing the triplet documents into several clusters, where passages within the same cluster are more similar to each other. The ranker ranks all triplet documents based on their similarities to the query and returns the top-kranker documents as the result. The model is trained to rank documents related to the query (positive samples) higher than the documents that are irrelevant to the query (negative samples). We chose ColBERTv2 because it offers a balance between language understanding and computational efficiency. However, most LMs are not specifically trained to understand spatial concepts; ColBERTv2 is trained on general knowledge such as texts crawled from Wikipedia. To answer spatial queries, a system needs to handle spatial concepts accurately. Continuing our example query, “Who is the person that the Batman Street in Melbourne is named after?”; an accurate query response should respect common spatial knowledge such as “Melbourne is contained in Victoria” and “Melbourne is a city in Australia.” To inject spatial knowledge to the indexer-ranker, we fine-tuned the base model ColBERTv2 on two datasets curated for spatial understanding: DS:GeoNames and DS:GeoNamescountry. Further, we note that the base ColBERTv2 model was pre-trained on pure natural language text. Although RDF/XML format presents a structure that is mostly human readable, it still involves RDF/XML-specific syntax in its