a city in Australia.‚Äù To inject spatial knowledge to the indexer-ranker, we fine-tuned the base model ColBERTv2 on two datasets curated for spatial understanding: DS:GeoNames and DS:GeoNamescountry. Further, we note that the base ColBERTv2 model was pre-trained on pure natural language text. Although RDF/XML format presents a structure that is mostly human readable, it still involves RDF/XML-specific syntax in its format, which may be harder for the base model to interpret. Hence, we fine-tuned the indexer-ranker on a dataset that we curated, namely DS:QALD9RDF/XML. 2Uniform Resource Identifier Horde Vo, Duckham, He, and Benli Fine-tuning the indexer-ranker. We fine-tuned the base language model ColBERTv2 using three datasets. DS:GeoNames and DS:GeoNames country were utilized for improving spatial understanding, while DS:QALD9RDF/XML was used for improving the understanding of RDF/XML formats. DS:GeoNamescountry. This dataset contains questions and answer pairs about countries that are neighboring to one another. We extracted countries from Geonames and constructed a graph Gcountry = {V country,Ecountry}. Here,V country is the node set with each node representing one country, and Ecountry represents the set of edges. Given country [countryi] and [country j] that share borders, we added an edgeecountry i, j to set E to represent the adjacency relationship. We generated one question-answer pair for edgeecountry i, j using the following template:  X = ‚Äú Give a country that shares a border with [countryi]. ‚Äù y+ = ‚Äú [country j] shares a border with [countryi].‚Äù  ‚àÄecountry i, j ‚ààEcountry (1) Here, y represents a country that is a positive answer to the question X. To fine-tune ColBERTv2, we also generated negative samples to the same question X, so that the model can learn to discriminate the spatial context involved in X. Specifically, we randomly sampled a country [countryk] that does not share border with [countryi] and generated a negative