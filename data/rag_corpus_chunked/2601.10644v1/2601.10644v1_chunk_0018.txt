the same GPU using the Huggingface Transformer. The index is served with Anserini via PyJNIus. â€“Dense retrieval using Qwen3 Embedding [53] with a FAISS index [10] using vLLM.15 The Qwen3 Embedding model is served with vLLM with parame- ters cast to FP16 to fit on the TITAN RTX GPU. The document embeddings are indexed with FAISS using product quantization of 2048 dimensions and 4-bit fast scan (PQ2048x4fs). We experimented with two request modes: batched and sequential. When queries are batched, we issue all 76 queries with asynchronous HTTP requests to theRoutIRendpoints and report the throughput, i.e., the number of queries processed per second. In the sequential mode, we issued the next query after receiving results from the previous one and report the latency, i.e., the number of seconds to process each query. As shown in Table 2, all three models demonstrate strong throughput, al- though LSR with Anserini is the slowest. However, it can be greatly accelerated with tools such as Seismic [3] that are tailored for LSR searching. All three mod- els are able to take advantage of batched queries to provide faster overall speed. 15 https://github.com/vllm-project/vllm 12 E. Yang et al. 1class L i v e R A G _ P L A I D X _ S e a r c h () : 2def __init__ ( self , query : str , ** kwargs ) : 3self . url = os . getenv ( " R E T R I E V E R _ E N D P O I N T " ) 4self . query = query 5 6def g e t _ c o n t e n t ( self , collection , doc_id ) : 7return requests . post ( self . url + " / content " , json