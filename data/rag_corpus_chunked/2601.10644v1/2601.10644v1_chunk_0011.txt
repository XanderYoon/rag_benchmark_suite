them to all parallel pipelines. }xx Result Fusion Fuse retrieval results from parallel pipelines with methodxx. els, including those supported by PyTerrier and Anserini, to efficiently embed them in a RAG system pipeline. Furthermore, processors also cache retrieval results to prevent duplicate re- quests to the Engine instance.RoutIRsupports both in-memory and Redis caches, which provides flexibility to support different cache integrity needs. 3.3 On-demand Pipeline Construction In addition to serving the query with a single retrieval model,RoutIRsupports on-demand pipeline construction from the end user request. This is illustrated in Figure 2, where the pipeline combines the results of two first-stage retriev- ers using reciprocal rank fusion and reranks the fused results.RoutIRparses the pipeline string provided by the user. It understands that the Engines corre- sponding to the two first-stage retrievers can be run in parallel and that fusion and reranking are sequential steps with the>>pipe operator. In addition, asyn- chronous requests are issued to prioritize throughput when producing the final retrieval results. The pipeline string is defined using a context-free grammar that supports the construction of linear pipelines. Table 1 summarizes the operators available 8 E. Yang et al. for the pipeline construction string. Dynamic pipeline construction allows a user or RAG system to control the pipeline as needed on the fly to accommodate runtime constraints such as latency, coverage, and query difficulty. The context- free grammar can even be part of the input to the language model, enabling it to generate the pipeline as part of an agentic workflow. 4 Serving Models usingRoutIR In this section, we describe howRoutIRcan be configured and extended to serve different retrieval models. This serves as an introduction to all the fea- tures provided byRoutIR; readers are encouraged to explore further in the documentation and the source code on GitHub. 4.1 Resource and Setup