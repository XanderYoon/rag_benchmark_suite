evaluation across multiple bias dimensions. 5.1 Scaffolding mechanisms Scaffolding mechanisms of the tool can be further developed by supporting diverse engagement patterns while addressing user trust. 5.1.1 AI use informed by bias implications. Tools can help students understand the broader implications of different types of biases in academic contexts. For example, anchoring bias identification is particularly relevant when addressing the pitfalls of AI collaboration that favors automation (i.e., completing tasks by finding answers to questions) over augmentation (i.e., critically questioning the questions themselves) [40]. Communicating bias implications in relation to AI capabilities and limitations can further promote ethical AI use. Manuscript submitted to ACM DeBiasMe: De-biasing Human-AI Interactions with Metacognitive AIED (AI in Education) Interventions 7 5.1.2 Developing for Specific Bias-A ware Use Cases. Future tools could explore two potential directions of development: (1) training instruments for bias awareness, developing metacognitive skills in controlled educational environments where biases can be safely identified with pre-defined scenarios and discussed; and (2) real-time assistants integrated into students’ everyday AI use workflows, detecting and flagging biases in different task contexts. Specific scaffold- ing mechanisms could focus on designing different modular components to support either workflow depending on institutional, educator, and learner needs, and developing appropriate evaluation methods for each approach. 5.1.3 Addressing User Trust in AI for Learning Support. The relationship between user bias and system bias detection creates complex trust dynamics that require further examination. When users’ biases align with AI system biases, users may resist or reject the tool’s feedback [17]. When there is alignment between user and system biases, identified or flagged biases from the tool can trigger defensive reactions [ 8] . While the tool is designed as an exploratory tool, determining whether certain features require compulsory engagement depends on educational needs and engagement patterns across users with varying levels