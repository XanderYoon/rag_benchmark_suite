MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation Daeyong Kwon1 , SeungHeon Doh1 , Juhan Nam1 1Graduate School of Culture Technology, KAIST, South Korea ABSTRACT Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs’ effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we proposeMusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context information when generat- ing answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine- tuning approaches in enhancing LLMs’ music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA bench- marks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency. 1. INTRODUCTION Recent advancements in Large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks, thanks to their massive scale and ability to generalize across diverse domains. However, LLMs still face significant limitations in music-related applications due to the relatively small amount of music-specific knowl- edge in their training data. To effectively deploy general LLMs in music-related domains such as music recommen- dation systems and chatbots, a deep understanding of Mu- sic Question Answering (MQA) in text-only settings is es- sential. Mastering text-based MQA would enable LLMs to provide more accurate and contextually aware responses to