efficient in- dex for MusWikiDB. This allowed us to quickly retrieve relevant information during RAG-based inference, improv- ing the accuracy and relevance of answers. The resulting MusWikiDB provides a scalable, up-to-date knowledge base that enhances the performance of RAG in MQA tasks, allowing the system to answer complex, domain-specific music-related questions with more accuracy and context. 4.2 ArtistMus The existing text-only MQA benchmarks have focused on multimodal music understanding [11, 12] or musicology topics such as melody, chords, and history [12, 13]. How- ever, there has been no benchmark that focuses on mu- sic metadata, particularly the artist, which is crucial in music listening contexts [30, 31]. Therefore, we created the ArtistMus to test the performance of LLMs in artist- related QA, using artist-related data from MusWikiDB. We grouped sections into five categories: biography, career , discography, artistry, and collaborations . Token lengths ranging from 500 to 2000 were considered. Genre normalization [32] was applied by first converting all genre labels to lowercase, and then removing spaces, hyphens (- ), and slashes (/). We obtained 48 root genres from [33], and after retaining only the data corresponding to the top 300 most frequent genres, each genre was mapped to the 20 final genre labels. To extract artists’ regional informa- tion, we provided the abstract of pages to the Llama 3.1 8B Instruct [34] to extract information on the country of the artist. The country list was obtained from the pycoun- try library. Then, we select a diverse range of 500 artists based on topic, genre, and country. Country was set as the highest priority, with a preference for artists from minor countries. Subsequently, popular genres and topics were replaced with less common ones. We generated one fac- tual and one contextual question for each artist to evalu- ate the LLM’s