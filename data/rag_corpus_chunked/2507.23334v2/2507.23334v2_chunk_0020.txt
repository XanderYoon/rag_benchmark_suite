Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human lan- guage technologies, volume 1 (long and short papers) , 2019, pp. 4171–4186. [19] G. Izacard, M. Caron, L. Hosseini, S. Riedel, P. Bo- janowski, A. Joulin, and E. Grave, “Unsupervised dense information retrieval with contrastive learning,” arXiv preprint arXiv:2112.09118, 2021. [20] Y . Wu, K. Chen, T. Zhang, Y . Hui, T. Berg-Kirkpatrick, and S. Dubnov, “Large-scale contrastive language- audio pretraining with feature fusion and keyword-to- caption augmentation,” inICASSP 2023-2023 IEEE In- ternational Conference on Acoustics, Speech and Sig- nal Processing (ICASSP). IEEE, 2023, pp. 1–5. [21] I. Manco, E. Benetos, E. Quinton, and G. Fazekas, “Contrastive audio-language learning for music,” inIS- MIR, 2022. [22] S. Doh, M. Won, K. Choi, and J. Nam, “Toward uni- versal text-to-music retrieval,” in ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) . IEEE, 2023, pp. 1–5. [23] S. Doh, M. Lee, D. Jeong, and J. Nam, “Enriching mu- sic descriptions with a finetuned-llm and metadata for text-to-music retrieval,” in ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) . IEEE, 2024, pp. 826– 830. [24] S. Wu, Z. Guo, R. Yuan, J. Jiang, S. Doh, G. Xia, J. Nam, X. Li, F. Yu, and M. Sun, “Clamp 3: Uni- versal music information retrieval across unaligned modalities and unseen languages,” arXiv preprint arXiv:2502.10362, 2025. [25] C. Wade and J. Allan, “Passage retrieval and eval- uation,” Center for Intelligent Information Retrieval Department of Computer Science University of Mas- sachusetts Amherst, MA, vol. 1003, 2005. [26] K. Shuster, S. Poff, M. Chen, D. Kiela, and J. Weston, “Retrieval augmentation reduces hallucination in con- versation,” arXiv preprint arXiv:2104.07567, 2021. [27] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican,