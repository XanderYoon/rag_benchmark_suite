spectrum of music-related knowledge. A significant shortcoming of existing benchmarks is their inadequate representation of rich metadata about tracks, artists, and albums—information crucial for every- day music listening contexts. Current text-only QA bench- marks inadequately address common music information needs, lacking comprehensive coverage of details that lis- teners frequently seek: complete discographies, artist col- laboration networks, creative evolution across albums, and notable career achievements. This pronounced disparity between current MQA capabilities and the practical infor- mation demands of music consumers highlights the press- ing need for benchmarks specifically designed to evaluate responses to artist-centric quetions. 3. RETRIEV AL AUGMENTED GENERATION 3.1 RAG Framework Retrieval-Augmented Generation (RAG) enhances the ca- pabilities of LLMs by combining their generative abili- ties with access to external knowledge. Instead of relying solely on parametric memory, RAG retrieves relevant pas- sages from an external database during inference time to ground responses in factual context. 3.1.1 Indexing The first step in RAG is constructing a searchable knowl- edge database. This involves segmenting a large corpus into fixed-size text passages (chunking), followed by rep- resenting each passage using an embedding models. Vari- ous embedding models can be used for indexing: Sparse Embeddings [16, 17] use term frequency-based scoring to match exact keywords, offering fast and inter- pretable retrieval for large-scale datasets. Dense Embeddings [17–19] map questions and docu- ments into a shared vector space, enabling semantic match- ing beyond keyword overlap. Audio-Text Joint Embeddings [20–24] extend this fur- ther by jointly embedding text with the audio modality. By leveraging contrastive learning between audio and text, they can serve as more domain-specialized text embedding models for music-related tasks. 3.1.2 Retrieval Formally, the retriever R is defined as a function: R : (q, D) → c where q is the input question, D is the entire database of text passages,