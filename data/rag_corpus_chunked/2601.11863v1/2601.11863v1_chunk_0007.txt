the fused index. Since document embeddings are already L2-normalized, leaving the query unnormalized does not affect ranking under cosine similarity: Scoresum(q, i;α) = cos etext q ,e sum i (α)  .(2) For inner-product distance, bothetext q ande sum i (α)should be L2-normalized to emulate cosine. Eqs. (1)–(2) yield a single index of dimensiond, without doubling as in concatenation. They keep metadata and text separable until fusion and avoid runtime score fusion. Dual Encoder with Late-Fusion ScoringAlternatively, we maintain two indices (content and metadata) and combine scores at query time. Late fusion exposesαat query time, which is useful for diagnostics, but requires two lookups. Given a query text embeddingetext q and document embeddings(etext i ,e meta i ), we compute Scorelate(q, i;α) = (1−α) cos etext q ,e text i  +αcos etext q ,e meta i  , α∈[0,1].(3) 3.3 Query-Side Strategies: Metadata-aware Reformulation WeapplyanLLM-basedreformulationoperatortoincorporateschemacues(e.g., company, form, year, section) into the query, which is then embedded with the text encoder: ϕtext(q) =Reformulate(q). This reformulated query can be used with both metadata-as-text retrieval and dual-encoder variants but it adds extra overhead during query time. Query re- formulation is implemented as a single LLM call conditioned on the metadata schema (Table 1) and a small set of example values per field. Given a query, the LLMextractsexplicitmetadataconstraintsandrewritesthequerytoincorporate them. Retrieval then uses the rewritten query embedded with the same frozen text encoder as all other methods, leaving the retrieval pipeline unchanged. Utilizing Metadata for Better Retrieval-Augmented Generation 7 3.4 Embedding-Space Theory of Metadata Integration We consider a metadata-informed embedding˜e⋆ i that augments a chunk embed- dinge i =f θ(ci)with structured metadata, either through token-level prefixing (MaT) or vector-level fusion (Unified, see Sec. 3.2). Letd∈ Ddenote a doc- ument (e.g., a company–year SEC filing) andi∈da chunk belonging tod. The following propositions describe how such