retrieval signal. Our work differs by treating metadata as a first-class retrieval signal, comparing simple metadata- as-text strategies with modular dual-encoder designs. 3 Metadata as a First-Class Signal We begin with the simplest approach to metadata integration: concatenating structured metadata fields directly to the chunk text before embedding. This Utilizing Metadata for Better Retrieval-Augmented Generation 5 technique treats metadata as part of the semantic input (metadata-as-text, MaT) and encodes it into the same vector space as content. 3.1 Metadata as Text: A Minimal Baseline Let the corpus be a set ofNdocument chunks with associated structured meta- data: D={(m i, ci)}N i=1, wherec i is the text of thei-th chunk, andmi is a key–value map of structured fields (e.g., company, form_type, section, year). We define a serialization function that produces a compact, human-readable header from the metadata: s(mi) = “company:{...};f orm:{...};section:{...};year:{...} ′′. Using this header, we construct a metadata-prefixed chunk string via a concate- nation operator: ˜ci =concat s(mi), c i  . We also evaluate a suffix variant that appends the metadata header after the chunk:˜csuf i =concat ci, s(m i)  . We report results for both prefix(˜c pre i = concat s(mi), c i  )and suffix in Table 2, while figures use the prefix variant unless explicitly noted. An off-the-shelf text encoderfθ (frozen) maps strings tod-dimensional vec- tors: ˜ei =f θ(˜ci)∈R d. Given a user queryq, we compute its embeddinge q =f θ(q)and retrieve by cosine similarity over the single MaT index: ScoreMaT(q, i) = cos eq, ˜ei  ,rank by Score MaT. 3.2 Dual Encoders: Modular Integration Flattening metadata into the chunk text (Section 3.1) improves retrieval but is computationally expensive, since any metadata update requires re-embedding the full chunk index. To address this, we design dual-encoder approaches that embed content and metadata separately, making updates