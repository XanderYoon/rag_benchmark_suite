Utilizing Metadata for Better Retrieval-Augmented Generation Raquib Bin Yousuf1[0009−0001−1245−0450], Shengzhe Xu1[0009−0008−8589−6526], Mandar Sharma1[0000−0002−7012−9323], Andrew Neeser1, Chris Latimer2, and Naren Ramakrishnan1[0000−0002−1821−9743] 1 Virginia Tech, Virginia, USA {raquib, shengzx, mandarsharma, aneeser24, naren}@vt.edu 2 Vectorize.io, Colorado, USA chris.latimer@vectorize.io Abstract.Retrieval-Augmented Generation systems depend on retriev- ingsemanticallyrelevantdocumentchunkstosupportaccurate,grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flat- ten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late- fusion retrieval, and metadata-aware query reformulation. Across multi- pleretrievalmetricsandquestiontypes,wefindthatprefixingandunified embeddings consistently outperform plain-text baselines, with the uni- fied at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that meta- data integration improves effectiveness by increasing intra-document co- hesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evalua- tion framework, and theRAGMATE-10Kdataset are publicly hosted3. Keywords:Retrieval-Augmented Generation (RAG)·Metadata-aware Retrieval·Dense Retrieval·Query Reformulation·Benchmark Datasets 1 Introduction Large Language Models (LLMs) have become central to information access, en- abling systems that answer questions, summarize documents, and reason over 3 https://github.com/raquibvt/RAGMate arXiv:2601.11863v1 [cs.IR] 17 Jan 2026 2 Yousuf et al. (a) General questions (b) In-depth questions Fig.1: Context@K and Title@K metric improvement in retrieval when using and not using metadata across query types (Dual Encoder Unified Embeddings) unstructured corpora [29,4]. Retrieval-Augmented Generation (RAG) architec- tures extend these models by first retrieving relevant context and then con- ditioning generation on it [22].