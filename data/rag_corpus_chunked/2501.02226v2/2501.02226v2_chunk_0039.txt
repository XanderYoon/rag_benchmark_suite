evaluate the impact of the number of GNN layers on model performance. We vary the numbers of the GNN layer numbers in the range of {3, 4, 5} and test on the Amazon Book dataset and LLama-2-7b across three metrics. As observed in Table 10, the model performance first improves and then decreases as the number of GNN layers increases, and the model achieves the best results across the three metrics when setting the number of GNN layers is set to four. Therefore, a smaller number of GNN layers may not have suffi- cient depth to capture the intricate relationships and dependencies in the graph, leading to sub-optimal performance. On the other hand, too many layers can result in indistinguishable node representations. Thus, selecting the optimal number of GNN layers is crucial for effective model training. A.12 Used Prompt In this part, we present the prompts designed for movie recommendations and book recommenda- tions. We show two examples in Table 11, and set the candidate items M equal to 20. For inference, we leverage the model to make the prediction based on the userâ€™s recent watching history and candidate items. 0.0 0.2 0.4 0.6 0.8 1.0 threshold p 0.40 0.41 0.42 0.43 0.44 0.45ACCURACY (a) Accuracy 0.0 0.2 0.4 0.6 0.8 1.0 threshold p 0.70 0.72 0.74 0.76 0.78 0.80RECALL@5 (b) Recall@5 0.0 0.2 0.4 0.6 0.8 1.0 threshold p 0.4 0.6 0.8 1.0 1.2 1.4 1.6Inference Time (s) (c) Inference Time Figure 4: Effect of popularity selective retrieval policy threshold p on MovieLens-1M and LLama-2-7b across metrics Accuracy, Recall@5 and inference time (seconds) for K-RagRec. 0 2 4 6 8 K 0.40 0.42 0.44 0.46 0.48 0.50 0.52ACCURACY (a) Amazon Book: Accuracy 0 2 4 6 8 K 0.56 0.58 0.60 0.62 0.64 0.66 0.68 0.70RECALL@3 (b) Amazon Book: