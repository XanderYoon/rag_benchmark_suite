on Information and Knowledge Management, pages 4967–4973. Zihuai Zhao, Wenqi Fan, Jiatong Li, Yunqing Liu, Xi- aowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xi- angyu Zhao, Jiliang Tang, et al. 2024. Recommender systems in the era of large language models (llms). IEEE Transactions on Knowledge and Data Engi- neering. A Appendix A.1 Implementation Details The hyper parameters used for K-RagRec and their corresponding values are shown in Table 4. The first part provides the general training setting for K-RagRec. The second part presents the details of (GNNIndexing, GNNEncoding). Then we list the Lora and acceleration settings. Lastly, we provide the hyper parameters for retrieval, including candi- date item number M, popularity selective retrieval policy threshold p, retrieve knowledge sub-graphs numbers K, and re-ranking knowledge sub-graphs numbers N. If not specified, we run all methods three times with different random seeds and report the averaged results. Table 3: Basic statistics of three datasets and the KG. "Items in KG" indicates the number of items that ap- peared in both the KG and the dataset. DatasetsMovieLens-1MMovieLens-20MAmazon Book User 6,038 138,287 6,106,019Item 3,533 20,720 1,891,460Interaction575,281 9,995,410 13,886,788Items in KG3,498 20,139 91,700 Entitys 250,631 1,278,544 186,954Relations 264 436 16KG triples 348,979 1,827,361 259,861 A.2 Graph Neural Networks GNNs are a critical technique in graph machine learning and are widely employed in various graph tasks. By iteratively updating node representations through aggregating information from neighboring nodes, GNNs effectively capture the underlying topology and relational structure of graphs. For- mally, a typical GNN operation can be formulated as follows: x(l+1) j = x(l) j ⊕ AGG(l+1) n x(l) i | i ∈ N xj o , (10) where x(l+1) j express node j’s feature on the l-th layer, and N (xj) is the set of neighbours of node j. AGG is a aggregation function to