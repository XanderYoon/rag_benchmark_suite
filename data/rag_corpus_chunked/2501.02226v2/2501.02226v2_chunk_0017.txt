A.12. 4.2 Overall Performance Comparison We compare the recommendation performance of K-RagRec with various baselines on three open- Table 1: Performance comparison of different KG RAG-enhanced LLM recommendations. The best performance and the second-best performance are marked in red and blue, respectively. ACC and R@k denote Accuracy and Recall@k, respectively. Models Methods MovieLens-1M MovieLens-20M Amazon Book ACC R@3 R@5 ACC R@3 R@5 ACC R@3 R@5 LLama-2 Inference-only KG-Text (Wu et al., 2023b)0.076 - - 0.052 - - 0.058 - -KAPING (Baek et al., 2023)0.079 - - 0.069 - - 0.063 - - Frozen LLM w/ PT PT w/ KG-Text 0.0780.1910.3080.0510.1520.2500.0740.1650.245GraphToken w/ RAG (Perozzi et al., 2024)0.2680.4210.4660.1860.4330.5760.3260.5150.624G-retriever (He et al., 2024)0.2740.5320.6500.3420.6190.7390.2750.4870.612K-RagRec 0.4350.7250.8310.6000.8500.9130.5080.6900.780 Improvement 58.6%33.0%27.8%75.4%37.3%23.5%55.8%34.0%25.0 % Fine-tuning Lora w/ KG-Text 0.4020.7180.8330.6090.8480.9050.4460.6480.758Lora w/ K-RagRec 0.4660.7700.8630.6370.8720.9270.5160.7200.799 Improvement 15.9%7.2% 3.6% 4.5% 2.7% 2.4% 15.7%11.1%5.4% LLama-3 Inference-only KG-Text (Wu et al., 2023b)0.095 - - 0.060 - - 0.054 - -KAPING (Baek et al., 2023)0.084 - - 0.069 - - 0.062 - - Frozen LLM w/ PT PT w/ KG-Text 0.1340.2940.4330.0940.2050.2960.0830.2070.314GraphToken w/ RAG (Perozzi et al., 2024)0.3550.6220.7370.4730.7190.8050.4280.5670.661G-retriever (He et al., 2024)0.3520.6320.7460.5020.7360.7960.4170.5840.682K-RagRec 0.4720.7040.7650.6340.7790.8180.5140.6620.723 Improvement 32.9%11.4%2.5% 26.3%5.8% 1.6% 20.0%13.4%6.0% Fine-tuning Lora w/ KG-Text 0.4490.6940.7500.6480.7570.7900.4900.6380.698Lora w/ K-RagRec 0.4980.7120.7710.6740.7860.8170.5460.6720.733 Improvement 10.9%2.6% 2.8% 4.0% 3.8% 3.4% 11.4%5.3% 5.0% QWEN2 Inference-only KG-Text (Wu et al., 2023b)0.160 - - 0.174 - - 0.194 - -KAPING (Baek et al., 2023)0.196 - - 0.208 - - 0.220 - - Frozen LLM w/ PT PT w/ KG-Text 0.1900.3710.4990.2590.3970.4940.3030.4510.553GraphToken w/ RAG (Perozzi et al., 2024)0.2590.4870.6080.3700.5500.6320.3650.5680.658G-retriever (He et al., 2024)0.3040.5510.6440.3890.6060.6850.3550.5520.658K-RagRec 0.4160.7120.8290.5860.8420.9040.5020.6860.767 Improvement 36.8%29.2%28.4%50.6%38.9%32.0%37.5%20.8%16.6 % Fine-tuning Lora w/ KG-Text 0.4000.7010.8150.6010.8420.9060.4780.6670.751Lora w/ K-RagRec 0.4660.7630.8600.6310.8680.9280.5100.7040.780 Improvement 16.5%8.8% 5.5% 5.0% 3.1 %2.4% 6.7% 5.5% 3.9% source backbone LLMs: LLama-2-7b (Touvron et al., 2023), LLama-3-8b (Dubey et al., 2024), and QWEN2-7b (Yang et al., 2024). We present the results in Table 1. From the comparison, we have the following main observations: â€¢ Naively retrieve