while parameters δ of LLM backbone are frozen. We update the parameters ϕ1, ϕ2 and θ through the Cross-Entropy Loss L(Y, A), where Y is the ground-truth and A is LLM’s prediction. 4 Experiment In this section, we evaluate the effectiveness of our proposed framework through comprehensive exper- iments. First, we present the experimental settings, including details about the datasets, compared base- lines, evaluation metrics, and the parameter config- urations. Then, we report the main experimental results, highlighting the performance of the pro- posed framework compared with various baseline methods. Finally, we analyze the contributions of individual model components and the impact of parameters used in our framework. We also assess the generalizability of K-RagRec in the zero-shot setting. We present the generalizability study in Appendix A.7. 4.1 Experimental Settings 4.1.1 Datasets To evaluate the performance of our K-RagRec framework, we adopt three real-world datasets. MovieLens-1M1 is a dataset containing approx- imately one million movie ratings and textual de- scriptions of movies (i.e., “title”). MovieLens- 20M2 is a large-scale movie ratings dataset encom- passing over 20 million ratings from more than 138,000 users on 27,000 movies. Amazon Book3 is a book recommendation dataset that records more than 10 million user ratings of books and the titles of the books. In addition, we adopt the popular knowledge graph Freebase4 and filter out the triples related to the three datasets to recon- struct the KG. The statistics of these three datasets and KG are presented in Table 3. 4.1.2 Baselines In the realm of LLM-based recommendation re- search, our work pioneers the investigation of re- trieving knowledge from KGs to enhance the rec- ommendation capabilities of LLMs. Therefore, to evaluate the effectiveness, we compare our pro- posed framework with a series of meticulously crafted KG RAG-enhanced LLM recommendation baselines. We first include