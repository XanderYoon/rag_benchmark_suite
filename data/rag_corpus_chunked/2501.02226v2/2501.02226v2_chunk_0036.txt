21.6% improvement over SOTA baselines on the MovieLens-20M dataset. Furthermore, despite the differences between the book recommendation and movie recommendation tasks, the model trained on MovieLens-1M delivers about 8.7% improvement in the zero-shot setting compared to prompt-tuned baselines on the Amazon Book dataset. The experi- mental results demonstrate that K-RagRec exhibits strong generalization capabilities and is adaptable across different domains. A.8 Study of Hallucination In this section, we present a qualitative analysis of hallucinations in the LLama-2-7b and QWEN2 models on the MovieLens dataset. Specifically, we include a few fictional movies in the candi- date items to observe the probability of the fic- tional movie being recommended. We compare direct recommendations and recommendations aug- mented with K-RagRec, and the results are shown in Table 7. We note that K-RagRec significantly reduced hallucinations by 93.1% compared to di- rect inference on LLama-2. In contrast to LLama- 2, QWEN2 rarely recommends fictional movies. Nevertheless, K-RagRec reduced hallucinations by Table 8: Performance comparison of different KG RAG- enhanced LLM recommendation methods on the cold- start dataset and QWEN2 across three metrics. The best performances are labeled in bold. ACC and R@k denote Accuracy and Recall@k, respectively. Methods ACC R@3 R@5 PT w/ KG-Text 0.106 0.239 0.395 GraphToken w/ RAG0.258 0.473 0.620 G-retriever 0.185 0.384 0.488 K-RagRec 0.406 0.705 0.834 Table 9: Comparison of different GNN Encoders on the MovieLens-1M dataset and LLama-2-7b across three metrics. We use bold fonts to label the best performance. ACC and R@k denote Accuracy and Recall@k, respec- tively. GNN Types ACC R@3 R@5 GCN (Kipf and Welling, 2016)0.397 0.704 0.809 GAT (Velickovic et al., 2017)0.420 0.693 0.804 Graph Transformer (Shi et al., 2020)0.429 0.711 0.779 GraphSAGE (Hamilton et al., 2017)0.418 0.699 0.823 80.9%, demonstrating the effectiveness of our ap- proach in addressing hallucinations. A.9 Study of Cold Start