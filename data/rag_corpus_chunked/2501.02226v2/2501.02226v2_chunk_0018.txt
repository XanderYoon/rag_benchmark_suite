2024)0.3040.5510.6440.3890.6060.6850.3550.5520.658K-RagRec 0.4160.7120.8290.5860.8420.9040.5020.6860.767 Improvement 36.8%29.2%28.4%50.6%38.9%32.0%37.5%20.8%16.6 % Fine-tuning Lora w/ KG-Text 0.4000.7010.8150.6010.8420.9060.4780.6670.751Lora w/ K-RagRec 0.4660.7630.8600.6310.8680.9280.5100.7040.780 Improvement 16.5%8.8% 5.5% 5.0% 3.1 %2.4% 6.7% 5.5% 3.9% source backbone LLMs: LLama-2-7b (Touvron et al., 2023), LLama-3-8b (Dubey et al., 2024), and QWEN2-7b (Yang et al., 2024). We present the results in Table 1. From the comparison, we have the following main observations: • Naively retrieve KG and augment LLM with text methods (i.e., KG-Text and KAPING), have limited recommendation accuracy on the MovieLens-1M and MovieLens-20M and Ama- zon Book datasets. • Compared to other prompt tuning RAG methods, K-RagRec with LLama-2-7B as the backbone LLM leads to an average of 41.6% improvement over the sub-optimal baseline across all datasets. With LLama-3-8B and QWEN2-7B as the back- bone LLM, K-RagRec also brought an average of 13% to 32% improvement, highlighting the effec- tiveness of our proposed method in augmenting LLMs’ recommendation performance. • Compared to the LoRA fine-tuning with the naive RAG approach, K-RagRec with prompt tuning achieves close to or better performance in most settings. Notably, K-RagRec achieves the best performance when fine-tuned with LoRA. 4.3 Ablation Study To evaluate the impact of each component in our proposed framework, we conduct the ablation study to compare the K-RagRec with four ablated vari- ants on MovieLens and Amazon Book datasets, us- ing LLama-2-7B as the backbone LLM. Details of each ablation variant are provided in Appendix A.6. The results are illustrated in Figure 3. Observing the experiment results, we find that eliminating any component of the framework leads to a decrease in the overall performance of the recommendations, demonstrating the effectiveness of each module. Secondly, removing the GNN Encoder leads to a 37% decrease and a 45.9% decrease in the ac- curacy of the model on MovieLens and Amazon Book datasets, respectively, highlighting the signif- icance