method by packaging a series of tasks from mining patent text to populating facts. 3.3. Alternative Approaches. Apart from relation identification and elicitation, we experimented link prediction approach (as depicted in Figure 3) for populating facts from a sentence. Prior knowledge extraction algorithms include link prediction as the approach to extracting relationships between entities (Sun and Grishman, 2022; Zhong and Chen, 2021). In our work, we perform link prediction between pairs of entities and relationships to construct facts. For this approach, entity and relationship tokens must be identified beforehand. Hence, we train a tagger using spaCy (as in Section 3.2) to classify tokens as “ENT”, “REL” and “OTH”. For 44,227 sentences split 4:1 training/testing, the resultant model exhibits tagger accuracy of 0.93 and losses being 2041.07 (transformer) and 29211.12 (tagger). Figure 3: Link prediction between pairs of entities and relationships to construct facts. As a fact includes ENT and REL tokens, the associations among the terms could be ENTREL, RELREL, and RELENT as shown in Figure 3. A pair of entity or relationship terms could be syntactically dependent and/or placed adjacent to each other. This approach examines how well these dependencies translate to associations that form facts. To predict associations between pairs of these terms, we train neural networks that include 1) Multi-Layer Perceptron38 (MLP) and 2) various convolutional layers39 built for Graph Neural Networks (GNNs). To incorporate node features, we fine-tune BERT for masked language modelling40 (training loss = 0.009) and concatenate with one-hot encoding of parts of speech. The performances of these layers summarised in Table 3 suggest that GNNs offer poor performance despite capturing the whole sentence as a graph object. While MLP offers relatively better performance, its usage on external examples reveals that prepositions like ‘of’ and ‘at’ are always associated by RELREL and with other