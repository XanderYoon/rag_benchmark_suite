to :: computer program Compound Entities “An alternative is to read a write power setup value ΔP for the optical disc…”35 a write power setup value :: :: ΔP The hierarchical relationships are given by “include”, “comprise” etc., and attribute relationships as in “has” or “of” are quite common. Verbs are often used in combination with prepositions to represent behavioural relationships. The relationships including “from” and “to” express a transition from one state to another. Some examples show the tail entity is placed before the head entity and the relationships are intricately placed in text. For example, although “administering” and “to” are placed alongside each other, these tokens belong to separate facts. The additional examples that follow showcase how entities are exemplified, introduced, and combined. 3.2. Relation Extraction. While populating the dataset of over 50,000 sentences, we selected pairs of entities among the noun phrases and relationships from the remaining tokens. From this dataset, we formulate training examples as explained using Figure 1, wherein, for each fact in a sentence, we mark a pair of entities using {HEAD ~ ...} and {TAIL ~ …}. Existing knowledge extraction algorithms have adopted innovative marking strategies as well (Soares et al., 2019; Zhang et al., 2019; Zhong and Chen, 2021). Using the examples thus formulated, we fine-tune language models to predict the relation using token tags (relation identification) or as text output (relation elicitation). These two training approaches are depicted in Figure 2. Figure 2: Fine-tuning language models for A) Relation Identification and B) Relation Elicitation. In relation identification, as depicted in Figure 2A, we create training examples as tokens with labels (HEAD, REL, TAIL, and OTH) and fine-tune language models for token classification. o Since our entities are selected from noun phrases given by spaCy transformers36, we leverage the training module for