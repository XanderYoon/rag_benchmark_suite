and real-world data collection, refining the knowledge graph for enhanced filtering, and specializing the reranker for specific code completion tasks. Acknowledgments We thank the ServiceNow AI team for their support and feedback throughout this project. We also acknowledge the contributions of the open-source community for providing the foundational models and tools that made this research possible. Declaration on Generative AI The author(s) have not employed any generative AI tools in the preparation of this work. References [1] ServiceNow, Script includes, https://www.servicenow.com/docs/bundle/zurich-api-reference/ page/script/server-scripting/concept/c_ScriptIncludes.html, 2025. ServiceNow Zurich API Refer- ence Documentation. Released: July 2025. [2] S. Robertson, H. Zaragoza, The probabilistic relevance framework: Bm25 and beyond, Foundations and Trends®in Information Retrieval 3 (2009) 333–389. [3] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang, M. Zhou, Codebert: A pre-trained model for programming and natural languages, in: Findings of the Association for Computational Linguistics: EMNLP 2020, 2020, pp. 1536–1547. [4] X. Li, K. Dong, Y. Q. Lee, W. Xia, H. Zhang, X. Dai, Y. Wang, R. Tang, Coir: A comprehensive benchmark for code information retrieval models, arXiv preprint arXiv:2407.02883 (2024). [5] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Ott, W.-t. Chen, A. Conneau, et al., Retrieval-augmented generation for knowledge-intensive nlp tasks, in: Advances in Neural Information Processing Systems, volume 33, 2020, pp. 9459–9474. [6] X. Li, H. Wang, Z. Liu, S. Yu, S. Wang, Y. Yan, Y. Fu, Y. Gu, G. Yu, Building a coding assistant via the retrieval-augmented language model, ACM Transactions on Information Systems 43 (2025). doi:10.1145/3695868. [7] M. Allamanis, E. T. Barr, P. Devanbu, C. Sutton, A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR) 51 (2018) 1–37. [8] L. Gao, X. Ma, J. Lin, J.