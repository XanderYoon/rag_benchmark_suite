cost. This matters in production: a 0.6B model fits tighter memory budgets, runs with higher concurrency, and reduces tail latency. Our SFT+RL results now exceed the 8B baseline while keeping the 2.5x latency gain, which makes the approach deployment-ready. 7.1. Training Dataset A critical challenge in training our reranker was ensuring no training contamination from our evaluation datasets. To address this, we constructed completely fresh training datasets using previously unused Script Include namespaces. 7.1.1. Dataset for SFT We constructed a comprehensive dataset for supervised fine-tuning using subsets of the CodeR-Pile dataset, focusing on JavaScript and TypeScript samples to establish a robust foundation for code understanding. This dataset provides the necessary diversity and scale for effective SFT training. 7.1.2. Synthetic Dataset for RL For reinforcement learning we reused Script Include namespaces that never appeared in our training or evaluation data. First, we pulled 892 such namespaces (about 5.9K methods) that had been left out of earlier extraction runs. We then generated fresh JSDoc signatures with an LLM so every namespace had structured documentation in the index. Claude 3.7 analyzed each script and produced synthetic triplets— code_before, code_middle, code_after—with the target usage placed in code_middle. We cleaned the pool in three passes. We removed 30 samples where the ground-truth namespace leaked into code_before or code_after, dropped another 10–15 samples that still mentioned the namespace nearby, and finally used fuzzy matching to cut 894 close variants. This left 285 strong exam- ples. From these we kept 204 samples that offered enough hard negatives via the sentence-transformers mine_hard_negativeshelper; the remaining 81 lacked suitable negatives, so we discarded them. 7.2. Training Pipeline Our training approach addressed the challenge of training a small model on limited data without overfitting or catastrophic forgetting. The pipeline consisted of three main stages: 7.2.1. Supervised Fine-Tuning (SFT) We began with