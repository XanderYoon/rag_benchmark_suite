the raw code, we created a structured index. All methods belonging to a single Script Include are grouped under their parent namespace. This index is further enriched with SI code metadata and their corresponding structured JSDoc, including API usage example. This organization helps the embedding model better distinguish between different functionalities and reduces ambiguity during retrieval. • LLM-Powered Code Expansion:Developer’s partial code often lacks sufficient context for effective retrieval. To address this, we experimented using a Large Language Model (LLM) at runtime to generate more descriptive and effective queries. By analyzing the partial code, the LLM can infer the developer’s intent and produce a more complete code expansion, which in turn leads to more accurate results from the embedding model. • Reranking:The initial retrieval stage may return the correct Script Include but not necessarily at the top of the list (e.g., within the top-5 results). For effective code generation, the downstream LLM needs a small, highly relevant set of options. Therefore, we employ a reranking stage using a cross-encoder or LLM reranker to improve the position of the most relevant candidates, aiming to move them from higher K values to lower K values (e.g., top-40 into the top-5). This ensures better performance, as it is easier for the code generation model to process fewer, higher-quality context options. • Post-training optimization:We develop a comprehensive training pipeline that optimizes compact reranker models through synthetic dataset generation, supervised fine-tuning, and reinforcement learning, enabling smaller models to achieve performance comparable to much larger models while maintaining significantly reduced latency. This multi-stage process, combining a knowledge-informed search space, enriched indexing, advanced query generation, and re-ranking, forms a robust pipeline that significantly outperforms vanilla retrieval methods([2]) for code generation tasks. 4. Dataset and Index Construction 4.1. Dataset Construction We constructed a custom evaluation dataset from real-world