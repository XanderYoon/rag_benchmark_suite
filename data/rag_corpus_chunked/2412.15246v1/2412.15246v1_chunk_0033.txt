data in SRAM consumes 39 fJ per bit, while LPDDR memory access requires 4 pJ per bit [13]. Since these energy values depend on the underlying technology node, we scaled them to correspond to a 16nm technology node for consistency [79]. 6.2 Software configuration Google’s Natural Questions (NQ) dataset [38; 39] is used for the evaluation of models. Meta’s KILT benchmark [65] divides these into training (nq-train) and validation (nq-dev) datasets. For the retrieval phase, we use a BERT base (uncased) model trained to perform similarity searches between questions and their supporting documents innq-train. The document corpus is constructed as described in [30], and an index is created using Faiss [ 27] to perform the similarity search 3. Across ENNS and ANNS, Faiss is used for index management. The only change made in our evaluation is the use of Intel’s OneMKL BLAS backend for ENNS for all batch sizes, as this 3We adapt the Faiss implementation of ENNS by using Intel MKL as the BLAS backend, using BLAS for all batch sizes, and increasing the corpus block size from 1024 to 16384. See appendix A. 0.0010.0100.1001.00010.000100.000 CPUAMXGPU (1x)GPU (2x)GPU (4x)GPU (8x)IKS (1x)IKS (4x)CPUAMXGPU (1x)GPU (2x)GPU (4x)GPU (8x)IKS (1x)IKS (4x)Batch Size 1Batch Size 16 Retrieval Time (Seconds) 50 GB200 GB512 GB1024 GB2048 GB Fig. 9. Comparison of ENNS retrieval time for CPU, AMX, GPU (1, 2, 4, and 8 devices), and IKS (1, and 4 devices) for various corpus sizes. The absence of bars in specific GPU and IKS configurations indicates that the corpus exceeds the capacity of the accelerator memory. The Y-axis is in log-scale. provided better performance than the default Faiss search scheme, which uses only BLAS for batch sizes 20 and above. FiDT5 Application: For testing the accuracy of FiDT5, as described in [26], the generator is initialized