ENNS is considered to be perfect, and the recall score of an ANNS algorithm is the proportion of relevant documents retrieved by both ENNS and ANNS algorithm compared to the total number of relevant documents retrieved by ENNS. Generation accuracy refers to how well an end-to-end RAG system answers questions. For details on the evaluation of generation accuracy, see Section 6.2. 3.1 Tuning RAG Software Parameters Both the retrieval phase and generation phase of the RAG sys- tems that we use offer support for batching of queries in order to improve data reuse and to amortize data movement over- heads over several queries. However, batching is not always an option in practice, particularly in the case of latency-critical applications. We consider batch sizes of 1 for latency-critical uses across all applications and 16 for throughput-optimized applications. Batch size does not impact generation accuracy and only affects execution time. An important parameter in RAG is â€œKâ€ or thenumber of documentsretrieved and fed to the language model for text generation. Increasing the document count significantly impacts the generation time. The computa- tion required for transformer inference scales at least linearly with the input size [93], and if we concatenate the retrieved documents, we face significant computation and memory overhead [14; 112]. In particular, the memory required to store a key-value cache entry for a single token can be computed as follows: ğ‘›layers Ã—ğ‘›KV-heads Ã—ğ‘‘head Ã—ğ‘›bytes Ã— 2, where ğ‘›bytes refers to the size of the number format [46]. For Llama-8B with a 16-bit number format, this is32Ã—8Ã—128Ã—2Ã—2 = 131 kB per token. While exact token counts depend on the tok- enization process, each document (for all applications) is 100 words long; forLlama-8B and Llama-70B, this averaged 127 tokens per document across our evaluation dataset. 3.2 Examining Approximate Search for RAG An important