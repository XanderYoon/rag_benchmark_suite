absence of bars in specific GPU and IKS configurations indicates that the corpus exceeds the capacity of the accelerator memory. The Y-axis is in log-scale. provided better performance than the default Faiss search scheme, which uses only BLAS for batch sizes 20 and above. FiDT5 Application: For testing the accuracy of FiDT5, as described in [26], the generator is initialized as a pretrained T5-base model (220 million parameters), then fine-tuned to predict answers from question-evidence pairs in thenq-train dataset. To evaluate FiDT5 on the nq-dev dataset, we use the ex- act match metric [69], which normalizes answers and com- pares them against a list of acceptable answers. For FiDT5, generation accuracy scores refer to the percentage ofnq-dev questions for which the RAG application generates a correct answer based on this exact match criterion. Llama-8B and Llama-70B Applications: To evaluateLlama-8B and Llama-70B on the nq-dev dataset, we guide the model via prompting and evaluategeneration accuracy using a Rouge-L “recall” metric [47], which scores answer predictions based on the proportion of the correct answer that is continuously present in the predicted answer. The model is instructed to give a short answer and to answer only if it is “completely sure. ” The prompting approach is used over fine-tuning to reflect an implementation that preserves the generality of the models. However, the downside of this approach is that evaluation is limited by prompt adherence, which is why the “recall” metric is used over precision or F1-Score. When eval- uating end-to-end RAG systems, the applications process a batch of queries by first performing retrieval, then generation, before processing the next batch. 7 Experimental Results 7.1 Effectiveness and Scalability of IKS Retrieval Figure 9 compares the performance of IKS with CPU, AMX (idealized, based on speedup for matrix multiplication), and GPU ENNS retrieval. IKS provisions