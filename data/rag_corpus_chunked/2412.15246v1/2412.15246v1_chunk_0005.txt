1.7â€“26.3Ã— end-to-end inference speedup for representative RAG applications. 2 Background 2.1 Information Retrieval in RAG Recent advancements in RAG indicate superior outcomes when employing dense retrieval over other methods, for uni- modal [25; 26; 41] and multi-modal [ 19; 71; 74] scenarios. Consequently, our emphasis in this study centers on dense retrieval models, exploring their efficiency-related aspects. In the context of dense retrieval, a query encoder, denoted as ğ¸ğ‘, and a document encoder, denoted asğ¸ğ‘‘, are trained to en- code queries and documents, respectively, and map them into a high-dimensional vector space. The similarity score between a document1 ğ‘‘ and a queryğ‘ is calculated asğ‘ ğ‘‘ = ğ¸ğ‘ (ğ‘) Â·ğ¸ğ‘‘ (ğ‘‘), where ğ¸ğ‘ (ğ‘) âˆˆ Râ„, ğ¸ğ‘‘ (ğ‘‘) âˆˆ Râ„ and â„ is the hidden dimen- sion of query and document encoders. Then documents are sorted based on their similarity scores and top documents are retrieved [30]. In a real RAG implementation, in an offline phase, all the documents are encoded into embedding vectors. The embedding vectors are stored in a vector database for dense retrieval. In the paper, we refer to the encoded docu- ments as embedding vectors and the vectors generated by the retriever model asquery vectors. 1The term â€œdocumentâ€ refers to any retrievable item from the knowledge source. Accelerating Retrieval-Augmented Generation For dense retrieval, two distinct search algorithms are prevalent: Exact Nearest Neighbor Search (ENNS) and Ap- proximate Nearest Neighbor Search (ANNS). ENNS exhaus- tively computes the complete pairwise distance matrix be- tween embedding and query vectors. In ANNS, however, strategies such as Product Quantization (PQ) [28], Inverted File with Product Quantization (IVFPQ) [7], and Hierarchical Navigable Small World (HNSW) [52], are employed to reduce the search space, seeking to trade off a small amount of search accuracy for higher search efficiency. 2.2 Applications of RAG RAG has