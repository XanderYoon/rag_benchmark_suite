0%25%50%75%100% 50 GB200 GB512 GB1024 GB2048 GB50 GB200 GB512 GB1024 GB2048 GB50 GB200 GB512 GB1024 GB2048 GBFiDT5Llama-3-8BLlama-3-70B Retrieval (ENNS on CPU)Generation (H100) 0.62s1.24s3.11s6.23s12.46s0.62s1.24s3.11s6.23s16.84s0.62s1.24s3.11s6.23s16.86s (a) Sensitivity to corpus size. All configurations use K=16. 0%25%50%75%100% K = 1K = 4K = 16K = 32K = 1K = 4K = 16K = 32K = 1K = 4K = 16K = 32FiDT5Llama-3-8BLlama-3-70B Retrieval (ENNS on CPU)Generation (H100) 0.62s0.62s0.62s0.62s0.62s0.62s0.62s0.62s0.62s0.62s0.62s0.62s (b) Sensitivity to K. All configurations use a 50 GB corpus. Fig. 3. Latency breakdown of FiDT5, Llama-8B, Llama-70B for various val- ues of K, corpus sizes. All configurations use batch size 1. Retrieval is ENNS and runs on CPU, generation runs on a single NVIDIA H100 (SXM) for all generative models. The value in each bar shows the absolute retrieval time. Batch Size 1 16 Corpus Size 50 GB 512 GB 50 GB 512 GB CPU 1 1 1 1 AMX 1.05 1.02 1.10 1.09 GPU 5.2 36.9 6.0 43.7 Table 1.Speedup of Intel AMX and GPU for ENNS, relative to a CPU baseline. AMX speedup is flat for very small batch sizes, due to the memory-bound nature of similarity search. For 50GB and 512GB corpus size, 1 and 8 H100 GPUs are used, respectively. ANNS), as shown in Figure 3b, increasing K would increase the generation time and is costly in terms of time to first token. The two phases in a RAG pipeline have different charac- teristics: ENNS is extremely memory bandwidth-bound, and generation is relatively compute-bound. Nevertheless, the cur- rent state-of-the-art focus in building AI systems is only on ac- celerating the generation phase [1; 5; 17; 34; 48; 53; 63; 82; 100; 101; 104]. Next, we discuss the feasibility of accelerating high- quality nearest neighbor search for future RAG applications. 3.4 High-Quality Search Acceleration Given the sensitivity of RAG generation accuracy,