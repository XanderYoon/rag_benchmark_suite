and pro- viding 68 GFLOPS (16-bit floating point multiply-accumulate operations) compute throughput; therefore saturating the 136 Accelerating Retrieval-Augmented Generation GBps memory bandwidth of the LPDDR5X channels. Each MAC unit evaluates the similarity score between the query (stored in the query scratchpad) and an embedding vector that is read from DRAM inVD (Vector Dimension) cycles. All the processing engines operate on the same data that is read from the DRAM; in other words, each processing engine evaluates the similarity score between different query vectors and the same set of embedding vectors. Therefore, for a batch size of one, only one processing engine is utilized, and for a batch size of 64, all the processing engines are utilized. This way, we reuse the embedding vectors that are read from DRAM across different batch sizes. As illustrated in Figure 5d, within an active dot-product unit, 68 MAC operations are performed in each clock cycle. The first input of the MAC units is dimensionğ‘— of the query vector in processing engineğ‘ƒğ¸ (QV[PE][j]), and the second input is dimension ğ‘— of the embedding vectorsğ‘– to ğ‘– +67 read from DRAM. As mentioned earlier, it takesVD (Vector Dimen- sion) cycles for a dot-product unit to evaluate the similarity score for a block of 68 embedding vectors. Once the similarity score is evaluated, it is loaded into ascore register (shown in Figure 5d) in the next clock cycle, and the MAC unit gets busy evaluating a new similarity score for the next 68 embedding vector block. The score registers (68 per processing engine) are then streamed out to the Top-K unit in the next 68 clock cycles. The Top-K unit maintains an ordered list of the scores by comparing the incoming similarity scores with the head of the ordered list. Figure 5d illustrates the Top-K unit. If