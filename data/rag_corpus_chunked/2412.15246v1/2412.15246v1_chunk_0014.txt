generation is relatively compute-bound. Nevertheless, the cur- rent state-of-the-art focus in building AI systems is only on ac- celerating the generation phase [1; 5; 17; 34; 48; 53; 63; 82; 100; 101; 104]. Next, we discuss the feasibility of accelerating high- quality nearest neighbor search for future RAG applications. 3.4 High-Quality Search Acceleration Given the sensitivity of RAG generation accuracy, latency, and throughput to the retrieval quality, it is imperative to focus exclusively on accelerating the retrieval phase of future RAG applications. In this subsection, we discuss the feasibility of accelerating high-quality ANNS and ENNS. Acceleration of High-Quality ANNS: High-quality ANNS can be as slow as ENNS [45]. There are prior works aimed at building hardware accelerators for high quality ANNS [40; 95] because GPUs are not effective at accelerating key ANNS al- gorithms such as IVFPQ and HNSW [27]. Unfortunately, the complex algorithms and memory access patterns used for ANNS algorithms also make ANNS accelerators highly task- specific; for example, ANNA [40] and NDSearch [95] can only accelerate PQ-based and graph-based ANNS algorithms, re- spectively. However, our experimental results, which are in line with prior findings [94], show that different corpora are amenable to different ANNS algorithms. Acceleration of ENNS: ENNS can be accelerated using con- ventional SIMD processors such as GPUs and Intel AMX because the algorithm is simple and data-parallel. Table 1 compares the speedup of AMX and GPU against a CPU base- line. Although GPUs can significantly speed up ENNS, as the corpus size increases, the cost of offloading ENNS to GPUs in- creases significantly. For example, to fit the 50 GB and 512 GB corpus sizes tested in Table 1, we need to use 1 and 8 H100 GPUs, respectively. One of the key contributors to the cost of GPUs is the high-bandwidth memory (HBM)