precision or F1-Score. When eval- uating end-to-end RAG systems, the applications process a batch of queries by first performing retrieval, then generation, before processing the next batch. 7 Experimental Results 7.1 Effectiveness and Scalability of IKS Retrieval Figure 9 compares the performance of IKS with CPU, AMX (idealized, based on speedup for matrix multiplication), and GPU ENNS retrieval. IKS provisions compute and memory bandwidth to balance the pipeline at the maximum batch size of 64; as such, performance is almost flat for batch sizes less Accelerating Retrieval-Augmented Generation 0.00.51.01.52.02.53.03.54.04.55.0K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=1611611611611650 GB512 GB50 GB512 GBCPU RetrievalIKS Retrieval Time-to-Interactive (seconds) Series1Series2 6.38s6.43s12.81s12.86s (a) FiDT5 0.00.51.01.52.02.53.03.54.04.55.0K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=1611611611611650 GB512 GB50 GB512 GBCPU RetrievalIKS Retrieval Generation (Time-to-Interactive)Retrieval 6.40s6.45s12.83s12.88s (b) Llama-8B 0.00.51.01.52.02.53.03.54.04.55.0K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=16K=1K=1611611611611650 GB512 GB50 GB512 GBCPU RetrievalIKS Retrieval Series1Series2 6.66s7.08s13.09s13.51s (c) Llama-70B Fig. 10. Inference time breakdown of CPU vs. IKS retrieval forFiDT5, Llama-8B, and Llama-70B. Generative model runs on GPU. than 64. As shown, the purposefully built NMA logic for ENNS enables 1 IKS unit to outperform 1 GPU for a 50 GB corpus for batch sizes 1 and 16 by 2.6× and 4.6×, respectively. This counterintuitive speedup of IKS over GPUs, which theoreti- cally have both higher FLOPS and memory bandwidth than IKS, is due to two reasons: (1) top-K tracking and aggregation on GPUs is not efficient, while IKS includes specialized Top-K units; and (2) low utilization of the GPU chip translates to limited memory bandwidth usage, as saturating the entire HBM memory bandwidth requires many streaming multipro- cessors and tensor cores to issue memory accesses to DRAM in parallel. To demonstrate the scalability of IKS, we include the re- trieval time of multi-GPU and multi-IKS setups. Because each H100 GPU can fit 80 GB of embedding vectors, 8 GPUs can ac- commodate maximum corpus size of 640 GB. However, with only four IKS devices,