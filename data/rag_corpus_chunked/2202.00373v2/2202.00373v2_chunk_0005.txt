The λ parameter balances the weight between the two loss functions. Later, we investigate the stability of our model under diﬀerent values ofλ. Since ranking is the target task, and the ranking head is only optimized by the ranking loss, we assign the regularization weight (0 <λ< 1) only to the representation loss. It is noteworthy that at inference time, we only use the ranking head of the MTFT-BERT re-ranker. 4 Experimental Setup Datasets. We ﬁrst evaluate our proposed method on legal case retrieval. The goal of case law retrieval is to retrieve the relevant prior law cases which could act as supporting cases for a given query law case. This professional search task is a query-by-document (QBD) retrieval task, where both the query and the documents are case law documents. We use the test collection for the case law retrieval task of COLIEE 2021 [30]. This collection contains a corpus with 4415 legal cases with a training and a test set consisting of 650 and 250 query cases respectively. In addition, to evaluate the generalizability of our approach, we use another domain-speciﬁc QBD retrieval benchmark, called SciDocs [9]. SciDocs was originally introduced as a representation learning benchmark in the scientiﬁc domain while framing the tasks as ranking; we use the four SciDocs tasks:{citation, co-citation, co-view, and co-read }-prediction to evaluate our method. It is worth mentioning that while the original paper trains the model on a citation graph of academic papers, we take the validation set provided for each task and use 85% of it as training set and the rest as the validation set for tuning purposes. Implementation. We use Elasticsearch1 to index and retrieve the initial rank- ing list using a BM25 ranker. It was shown in prior work that BM25 is a strong baseline [32], and