semantic embeddings for chunk selection. SPLADE-based retrieval results are shown in Table 3. SPLADE uses sparse semantic representations, optimized for balancing lexical precision with semantic flexibility. Comparing the retrieval methods, the BM25-based retriever (Table 1) exhibited a decline in perfor- mance compared to the baseline, particularly at higher values of ğ‘˜, suggesting that lexical retrieval alone is insufficient for effective context selection. The best performance for BM25 was observed at ğ‘˜ = 30 with a mean cosine similarity of 0.9292, which still underperforms our baseline across all metrics. Generally, the variance in cosine similarity and Euclidean distance for BM25-based retrieval was higher than in other retrieval approaches, indicating inconsistent retrieval performance as seen in Fig. 4 and Fig. 5. We have marked the best-performing model in each table by using bold numbers. Lexical approaches rely heavily on exact matching. We hypothesize that this approach struggles because there is no guarantee that our natural language description uses the exact terms that are present in the relevant chunks. The results point to no context being better than misleading or incomplete context, which is supported by current research [23]. Presented in Table 2, the BERT-based retrieval model demonstrated more stable performance across different values of ğ‘˜, achieving a mean euclidean distance of 5.0418 at ğ‘˜ = 50, which is slightly better than the baseline. This suggests that semantic similarity-based retrieval can contribute positively to the overall generation quality. Additionally, the lower variance in cosine similarity and Euclidean distance Table 2 BERT-based retriever Metric k = 10 k = 20 k = 30 k = 40 k = 50 k = 0 (Baseline) Mean CS 0.9265 0.9263 0.9254 0.9259 0.9334 0.9338 Variance CS 0.0045 0.0036 0.0064 0.0050 0.0017 0.0022 Trimmed Mean CS 0.9435 0.9415 0.9437 0.9438 0.9425 0.946 Mean ED 5.2026 5.2436 5.163 5.2477