similarity scores. Conversely, BERT-based retrieval demonstrated relatively stable performance across different k values, with its best performance occurring at ğ‘˜ = 50, as seen in Table 2. Our results suggest that optimizing the retrieval step by carefully selecting an appropriate ğ‘˜ is crucial to maximizing the benefits of retrieval-augmented generation in the OCL domain, and blindly increasing ğ‘˜ can degrade the modelâ€™s effectiveness. Furthermore, the analysis of variance across both evaluation metrics highlights the importance of Figure 3: Comparison of Retriever Models retrieval stability. Models with lower variance in cosine similarity (such as the BERT-based approach at ğ‘˜ = 50) tend to be more reliable in producing overall high-quality outputs, illustrated in Fig 6 and 7. Inversely, higher variance in the BM25-based and SPLADE-based retrieval approaches at almost all ğ‘˜ values suggests inconsistency, potentially due to the inclusion of less relevant chunks in the retrieved context, as illustrated in Fig. 4, 7, 8, and 9. These results indicate that changing the retriever model and parameter ğ‘˜ can have a positive impact on hallucination and reducing outliers, but cannot fully remove them. Depending on the needs and goals of a potential end user, a trade-off between model consistency and model output quality in a large percentage of cases needs to be considered. 3.3. Comparison with PathOCL PathOCL is a novel path-based prompt augmentation method proposed by Abukhalaf et al. [19]. The approach constructs a graph based on the PlantUML of the meta-model, where each class is represented as a node of the graph and associations are directed edges. The direction of the graph is dependent on the type of the association and its direction in the meta-model. PathOCL extracts all simple paths through the graph and ranks them based on their similarity to the natural language specification using either Jaccard or