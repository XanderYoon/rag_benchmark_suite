expansions, combining term matching and the ability to find nearest neighbors. While these methods have been extensively studied in general NLP tasks, their effectiveness in a RAG approach to OCL rule generation remains unexplored. This study bridges that gap by systematically evaluating retrieval strategies and their impact on generation accuracy. We aim to identify optimal configurations for improving OCL constraint generation. We compare our optimal configurations against other state-of-the-art methods for generating OCL constraints. Our evaluation employs quantitative metrics such as Cosine Similarity and Euclidean Distance to assess model output quality. This research contributes to the growing body of work in domain-adapted LLM applications and provides insights into improving automated OCL constraint generation. The results demonstrate that while retrieval strategies can enhance generation quality, they must be carefully tuned to avoid performance degradation due to excessive or irrelevant retrieved information. Our findings highlight the importance of selecting an appropriate retrieval method and the optimal number of retrieved chunks (ùëò) to maximize performance. This study provides insights into the impact of different retrieval techniques and lays the foundation for future improvements in automated OCL rule generation. 2. Methodology 2.1. Pipeline We first give a brief overview of the entire pipeline in this section before going into detail for every step of the pipeline in the subsequent sections. Our pipeline takes as input a natural language specification of an OCL rule and the associated name of the meta-model that we want to generate the OCL rule for. We use both parts of the input in the retrieval stage to find relevant chunks of the meta-model. These retrieved chunks are then incorporated into a prompt alongside the natural language specification and given to a Large Language Model. We then compare the output of the LLM with the actual OCL rule to determine the