0.85and k= 10by default. This approach ensures high-quality se- mantic coverage while requiring no manual annotation. Stage 2: Single-Target Rewriting via Contrastive Prompting.To evaluate fine-grained discrimination, we convert multi-target pools into single-target triplets. From each pool, we randomly sample one target and two con- trastive distractors. An LLM is then prompted with the ref- erence image, original modification, target, and distractors to rewrite the modification text. The new text must preserve the reference context, uniquely describe the target, and ex- clude distractors. This yields more challenging triplets that test precise, compositional reasoningâ€”complementing the broader evaluation enabled by multi-targets. Benchmark CIRCO (mAP@K) CIRR (Recall@K) CIRR (Recallsubset@K) Backbone Method k=5 k=10 k=25 k=50 k=1 k=5 k=10 k=50 k=1 k=2 k=3 ViT-B/32 SEARLE 9.35 9.94 11.13 11.84 24.00 53.42 66.82 89.78 54.89 76.60 88.19 SEARLE + SoFT 12.57 13.12 14.38 15.17 28.05 58.60 71.88 91.78 64.29 82.19 91.61 CIReVL 14.94 15.42 17.00 17.82 23.94 52.51 66.00 86.95 60.17 80.05 90.19 CIReVL + SoFT 19.21 20.04 21.86 22.75 32.94 62.92 74.17 90.70 70.31 86.58 93.78 LDRE 17.96 18.32 20.21 21.11 25.69 55.13 69.04 89.90 60.53 80.65 90.70 OSrCIR 18.04 19.17 20.94 21.85 25.42 54.54 68.19 N/A 62.31 80.86 91.13 ViT-L/14 SEARLE 11.68 12.73 14.33 15.12 24.24 52.48 66.29 88.33 53.76 75.01 88.19 SEARLE + SoFT 15.72 16.45 18.06 18.93 30.29 59.74 71.49 90.65 65.47 83.23 92.29 CIReVL 18.57 19.01 20.89 21.80 24.55 52.31 64.92 86.34 59.54 79.88 89.69 CIReVL + SoFT 23.9024.72 26.94 27.93 35.54 65.25 76.41 91.95 71.59 87.64 94.15 LDRE 23.35 24.03 26.44 27.50 26.53 55.57 67.54 88.50 60.43 80.31 89.90 OSrCIR 23.8725.33 27.84 28.97 29.45 57.68 69.86 N/A 62.12 81.92 91.10 Table 1: Quantitative results on CIRCO and CIRR. 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Score 0 500 1000 1500 2000Frequency CIRR (4181 samples) 0.0 0.2 0.4 0.6 0.8 1.0