drati et al. 2022a; Chen, Gong, and Bazzani 2020; Hossein- zadeh and Wang 2020), where the goal is to retrieve a target image based on a reference image and a natural language modification that describes the desired change. However, the construction of triplet datasets—each consisting of a refer- ence image, a modification text, and a matching target im- age—for supervised CIR (Delmas et al. 2022b; Dodds et al. 2020; Liu et al. 2021a) is costly and often domain-specific, limiting scalability. To address this issue, zero-shot CIR (ZS- CIR) has emerged, aiming to eliminate the need for task- specific training and improve generalization to novel com- positions (Saito et al. 2023; Baldrati et al. 2023a; Gu et al. 2024). While recent ZS-CIR methods (Zhang et al. 2025; Karthik et al. 2024; Tang et al. 2025) have made progress by leverag- ing pretrained vision-language models (Radford et al. 2021; Song et al. 2022; Zhou et al. 2022; Jia et al. 2021), most still rely on single-query matching strategies. In these ap- proaches, all descriptive cues—both visual and textual—are compressed into a single representation, regardless of their relative importance. As a result, critical user requirements arXiv:2512.20781v1 [cs.IR] 23 Dec 2025 that should be strongly enforced are diluted by less rele- vant visual or textual details, compromising retrieval accu- racy (Yang et al. 2024). Moreover, such methods often over- look the need to penalize undesired attributes in retrieval, fo- cusing only on satisfying positive cues. LDRE (Yang et al. 2024) addresses this gap by proposing an ensemble-based approach. However, it still does not explicitly disentangle and control the prescriptive (must-have) and proscriptive (must-avoid) aspects of user intent, as it operates over varia- tions of fused representations. To address these limitations, we proposeSoft Filtering with Textual constraints (SoFT), filtering mechanism tai- lored for the CIR.