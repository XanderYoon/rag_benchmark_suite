Multi-Target FashionIQ, SoFT consis- tently improves performance regardless of the base model (see Sec 4.3). This suggests that while baseline charac- teristics affect stability, the occasional drops on the stan- dard FashionIQ are more likely due to the dataset’s limita- tion—implicitly overlooking semantically valid alternative targets rather than reflecting a failure of SoFT itself. To ensure that the improvements stem from the SoFT rather than LLM differences, we unified CIReVL (originally using GPT-3.5-turbo) and SoFT under GPT-4o and repeated the experiments. The results, reported in the Appendix, show consistent gains across all three benchmarks. 4.3 Re-evaluation on Multi-Target FashionIQ. We re-evaluate the SoFT on our multi-target version of the FashionIQ validation set. As shown in Table 3, both SEARLE and CIReVL consistently benefit from SoFT across all categories, improving R@10 and R@50. We ad- ditionally investigate the effect of the convex combina- 0.2 0.4 0.6 0.8 5 10 15 20 25 30mAP@10 (%) Effect of on CIRCO mAP@10 0.2 0.4 0.6 0.8 5 10 15 20 25 30mAP@50 (%) Effect of on CIRCO mAP@50 0.2 0.4 0.6 0.8 55 60 65 70 75 80Recall@10 (%) Effect of on CIRR R@10 0.2 0.4 0.6 0.8 75 80 85 90 95Recall@50 (%) Effect of on CIRR R@50 0.2 0.4 0.6 0.8 15 20 25 30 35Recall@10 (%) Effect of on FIQ (Avg) R@10 0.2 0.4 0.6 0.8 35 40 45 50 55Recall@50 (%) Effect of on FIQ (Avg) R@50 CIReVL + SoFT CIReVL SEARLE + SoFT SEARLE Figure 5: Effect of the weighting parameterλon retrieval performance across CIRCO, CIRR, and FashionIQ (CLIP L/14). We varyλ∈ {0.1,0.3,0.5,0.7,0.9}, controlling the influence of SoFT in Equation (2). tion weightλ, observing that SEARLE achieves its best performance whenλ= 1, with peak scores of 45.50 (mAP@5) and 39.05 (mAP@25) on average. Additional experiments, including Multi-Target CIRR results