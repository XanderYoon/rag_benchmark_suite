highlighting the need for balanced integra- tion of proscriptive constraints. 5 Conclusion We propose SoFT, a training-free, plug-and-play filtering module for Zero-shot Composed Image Retrieval (ZS-CIR) that leverages dual textual constraints—prescriptive and pro- scriptive—to re-rank retrieval candidates. SoFT addresses the limitations of single fused queries by explicitly captur- ing both positive and negative aspects of user intent. We also introduce a two-stage dataset pipeline that expands CIR benchmarks with multi-target triplets and contrastively re- fined single-target variants. This better reflects the ambigu- ity and diversity of user intent in real-world queries. Applied on top of existing retrievers such as CIReVL and SEARLE, SoFT consistently improves retrieval performance across CIRCO, CIRR and FashionIQ, as well as on the newly constructed Multi-Target variants of CIRR and FashionIQ. These results demonstrate robust generalization and stable gains without any additional training or parameter tuning. 6 Acknowledgments This work was supported by the IITP (Institute of In- formation & Communications Technology Planning & Evaluation)-ICAN (ICT Challenge and Advanced Net- work of HRD) (IITP-2024-RS-2023-00259806, 20%) grant funded by the Korea government(Ministry of Science and ICT) and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (RS-2024- 00354675, 40%) and (RS-2024-00352184, 40%). References Baldrati, A.; Agnolucci, L.; Bertini, M.; and Del Bimbo, A. 2023a. Zero-shot composed image retrieval with textual inversion. InProceedings of the IEEE/CVF International Conference on Computer Vision, 15338–15347. Baldrati, A.; Agnolucci, L.; Bertini, M.; and Del Bimbo, A. 2023b. Zero-shot composed image retrieval with textual inversion. InProceedings of the IEEE/CVF International Conference on Computer Vision, 15338–15347. Baldrati, A.; Bertini, M.; Uricchio, T.; and Del Bimbo, A. 2022a. Effective Conditioned and Composed Image Re- trieval Combining CLIP-Based Features. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 21466–21474. Baldrati, A.; Bertini, M.; Uricchio, T.; and Del Bimbo,