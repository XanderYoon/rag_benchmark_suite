al. 2025). To address this, we introduce amulti-target triplet construction pipeline, which first identifies semantically valid targets per query, then rewrite the modification text via LLMs to generate single-target triplets. This process could also be used to enrich existing multi-target datasets with diversified constraints. Our contributions are twofold: • We propose SoFT, a training-free re-ranking module that leverages prescriptive and proscriptive textual constraints to improve retrieval precision. • We develop a two-stage dataset pipeline that captures both ambiguity and specificity in user intent by construct- ing multi-target triplets and deriving single-target vari- ants through LLM-guided refinement. 2 Related Works Zero-shot Composed Image Retrieval and LLM-based Reasoning.CIR aims to retrieve target images based on a reference image and a modification text describing the desired change. Traditional CIR (V o et al. 2019; Chen, Gong, and Bazzani 2020; Chen and Bazzani 2020; Shin et al. 2021; Lee, Kim, and Han 2021; Delmas et al. 2022a; Baldrati et al. 2022b) methods rely on supervised learn- ing over carefully curated triplet datasets (reference im- age, modification text, and target image), which are labor- intensive and costly to construct. To solve this problem, ZS-CIR approaches have emerged, eliminating the need for triplet supervision and enabling retrieval using pretrained models (Saito et al. 2023; Baldrati et al. 2023a). Most ZS- CIR methods adopt pretrained CLIP (Radford et al. 2021) as the retrieval backbone due to its strong vision-language alignment and zero-shot generalization capabilities. Early methods can be broadly categorized into fusion-based and inversion-based approaches. Fusion-based models (Baldrati et al. 2022a; Zhang et al. 2025) encode the reference image and modification text independently before merging their representations. Inversion-based models (Saito et al. 2023; Baldrati et al. 2023a; Gu et al. 2024; Tang et al. 2024) rein- terpret the image as a pseudo-text token and perform joint encoding