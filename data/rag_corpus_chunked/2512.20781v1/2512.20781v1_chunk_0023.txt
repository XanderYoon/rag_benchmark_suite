retrieval on real-life images with pre- trained vision-and-language models. InProceedings of the IEEE/CVF international conference on computer vision, 2125–2134. Liu, Z.; Rodriguez-Opazo, C.; Teney, D.; and Gould, S. 2021b. Image retrieval on real-life images with pre- trained vision-and-language models. InProceedings of the IEEE/CVF international conference on computer vision, 2125–2134. Niu, X.; Fan, X.; and Zhang, T. 2019. Understanding faceted search from data science and human factor perspectives. ACM Transactions on Information Systems (TOIS), 37(2): 1–27. Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021. Learning transferable visual models from nat- ural language supervision. InInternational conference on machine learning, 8748–8763. PmLR. Saito, K.; Sohn, K.; Zhang, X.; Li, C.-L.; Lee, C.-Y .; Saenko, K.; and Pfister, T. 2023. Pic2word: Mapping pictures to words for zero-shot composed image retrieval. InProceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 19305–19314. Sch¨utze, H.; Manning, C. D.; and Raghavan, P. 2008.In- troduction to information retrieval, volume 39. Cambridge University Press Cambridge. Shin, M.; Cho, Y .; Ko, B.; and Gu, G. 2021. Rtic: Residual learning for text and image composition using graph convo- lutional network.arXiv preprint arXiv:2104.03015. Song, H.; Dong, L.; Zhang, W.; Liu, T.; and Wei, F. 2022. CLIP Models are Few-Shot Learners: Empirical Studies on VQA and Visual Entailment. InProceedings of the 60th Annual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers), 6088–6100. Tang, Y .; Yu, J.; Gai, K.; Zhuang, J.; Xiong, G.; Hu, Y .; and Wu, Q. 2024. Context-i2w: Mapping images to context- dependent words for accurate zero-shot composed image re- trieval. InProceedings of the AAAI Conference on Artificial Intelligence, volume 38, 5180–5188. Tang, Y .; Zhang, J.; Qin, X.; Yu, J.; Gou, G.; Xiong, G.; Lin, Q.;