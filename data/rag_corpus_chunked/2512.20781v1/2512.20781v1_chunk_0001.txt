guide multimodal LLMs to rewrite the modification text to focus on one target, while referencing contrastive distractors to ensure precision. This enables more comprehensive and reliable evaluation under varying ambiguity levels. Applied on top of CIReVL—a ZS- CIR retriever—SoFT raisesR@5to 65.25 on CIRR (+12.94), mAP@50to 27.93 on CIRCO (+6.13), andR@50to 58.44 on FashionIQ (+4.59), demonstrating broad effectiveness. Code— https://github.com/jjungyujin/SoFT Datasets— https://github.com/jjungyujin/SoFT/blob/main/ MultiTarget README.md 1 Introduction Information retrieval (IR) (Sch ¨utze, Manning, and Ragha- van 2008) enables users to find relevant content based on natural language queries. With recent advances in multi- modal representation learning, the field has extended into visual domains, enabling more expressive and personalized Copyright © 2026, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Soft Filtering for CIR (over raw images) Result Hard Filtering in IR (over annotated images) category : t-shirt color : black Reference image : Modification text : Hard filter "make it black" prescriptive: "a black t-shirt" proscriptive: "a white t-shirt" Textual filter Retriever # green # t-shirt # black # dress # white # t-shirt # black # t-shirt - - -- - -- 0.80.85 0.40.8 ++ + ++ + + Re-ranked Result 0.20.64 0.160.60 Figure 1: Comparison of hard filtering in traditional IR and soft filtering for CIR. SoFT re-ranks unstructured image can- didates using LLM-generated constraints. search paradigms. One such task is Composed Image Re- trieval (CIR) (V o et al. 2019; Lee, Kim, and Han 2021; Bal- drati et al. 2022a; Chen, Gong, and Bazzani 2020; Hossein- zadeh and Wang 2020), where the goal is to retrieve a target image based on a reference image and a natural language modification that describes the desired change. However, the construction of triplet datasets—each consisting of a refer- ence image, a modification text, and a matching target im- age—for supervised