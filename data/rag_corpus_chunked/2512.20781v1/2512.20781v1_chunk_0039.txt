better satisfy the modification intent, such retrievals may not be reflected as correct during evaluation, leading to apparent instabil- ity or diminished gains. By explicitly incorporating multiple valid targets per query, the Multi-Target benchmark allevi- ates this issue and provides a more faithful assessment of SoFTâ€™s impact. Overall, these results suggest that the observed instabil- ity of SoFT in the standard FashionIQ setting stems largely from annotation underspecification, rather than from the filtering mechanism itself. When evaluation protocols bet- ter align with the open-ended nature of user intent, SoFT demonstrates consistent and robust improvements across a wide range of configurations. B.3 Qualitative Results We present examples from our multi-target versions of CIRR and FashionIQ in Figure S1 and S2. Each example in- cludes the original triplet, a set of valid target images, and a refined modification text for a randomly selected target (highlighted in red box). These examples illustrate the am- biguity in user intent and how our pipeline resolves it into precise single-target queries. Method CIRR (mAP@k) ViT-L/14 @5 @10 @25 @50 CIReVL 58.04 56.31 53.8 52.33 CIReVL + SoFT (0.1) 58.31 56.54 53.91 52.53 CIReVL + SoFT (0.3) 58.75 56.93 54.31 52.93 CIReVL + SoFT (0.5) 59.53 57.66 54.94 53.53 CIReVL + SoFT (0.7) 60.21 58.23 55.47 54.01 CIReVL + SoFT (0.9) 60.82 58.77 55.92 54.45 CIReVL + SoFT (1.0) 61.12 59.08 56.24 54.74 SEARLE 52.10 50.86 48.15 46.70 SEARLE + SoFT (0.1) 60.22 58.13 54.81 53.38 SEARLE + SoFT (0.3) 62.29 59.66 56.60 54.99 SEARLE + SoFT (0.5) 59.13 56.90 53.86 52.17 SEARLE + SoFT (0.7) 55.35 53.64 50.81 48.94 SEARLE + SoFT (0.9) 52.02 50.45 47.74 45.99 SEARLE + SoFT (1.0) 50.35 49.02 46.40 44.60 Table S9: Multi-Target Evaluation on CIRR. Method Shirt (mAP@k) ViT-L/14 @5 @10 @25 @50 CIReVL 24.14 24.31 23.36 22.01 CIReVL +