64.92 28.55 48.57 CIReVL + Penalty 21.83 25.57 32.92 74.51 28.77 47.13 CIReVL + Reward 22.19 26.00 32.80 74.99 32.57 53.46 CIReVL + SoFT 23.90 27.93 35.54 76.41 31.68 52.53 Table 4: Component-wise ablation of SoFT on CIRCO, CIRR, and FashionIQ. We compare three variants: applying only the reward term (+Reward,s SoFT =s base ·s reward), only the penalty term (+Penalty,s SoFT =s base ·(1− spenalty)), and both (+SoFT, as defined in Equation (1)). Component-wise Analysis of SoFT.To ablate the con- tributions of each constraint in SoFT by comparing three variants: using only the reward term (+Reward), only the penalty term (+Penalty), and both (+SoFT), as shown in Table 4. On CIReVL, both constraints yield additive gains, with the full SoFT achieving the best performance. In con- trast, SEARLE shows strong sensitivity to the penalty term: using it alone leads to a severe performance drop. Never- theless, when combined with the reward term, SoFT con- sistently outperforms the baseline, underscoring the impor- tance of jointly maintaining prescriptive and proscriptive constraints for balanced filtering. In contrast, on FashionIQ, instability induced by the penalty term is observed regard- less of the underlying retriever. This behavior can be at- tributed to the limitations of pretrained CLIP representa- tions: in fine-grained domains, CLIP embeddings often fail to capture subtle visual distinctions, which may result in over-penalizing semantically valid candidates. As a conse- quence, the penalty signal can become unreliable when ap- plied in isolation, highlighting the need for balanced integra- tion of proscriptive constraints. 5 Conclusion We propose SoFT, a training-free, plug-and-play filtering module for Zero-shot Composed Image Retrieval (ZS-CIR) that leverages dual textual constraints—prescriptive and pro- scriptive—to re-rank retrieval candidates. SoFT addresses the limitations of single fused queries by explicitly captur- ing both positive and negative aspects of user intent. We also introduce