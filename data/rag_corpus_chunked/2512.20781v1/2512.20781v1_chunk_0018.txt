CIReVL SEARLE + SoFT SEARLE Figure 5: Effect of the weighting parameterλon retrieval performance across CIRCO, CIRR, and FashionIQ (CLIP L/14). We varyλ∈ {0.1,0.3,0.5,0.7,0.9}, controlling the influence of SoFT in Equation (2). tion weightλ, observing that SEARLE achieves its best performance whenλ= 1, with peak scores of 45.50 (mAP@5) and 39.05 (mAP@25) on average. Additional experiments, including Multi-Target CIRR results and ex- amples of dataset, are provided in the Appendix. 4.4 Ablation Studies Effect of the weightλ.We examine how the interpola- tion weightλin Equation (2) affects performance, varying λ∈ {0.1,0.3,0.5,0.7,0.9}on CIRCO, CIRR, and Fash- ionIQ. As shown in Figure 5, SoFT consistently improves CIReVL across all benchmarks, indicating that constraint- guided reweighting complements the base similarity effec- tively. In contrast, SEARLE exhibits sensitivity to the choice ofλ, with performance generally decreasing asλincreases across benchmarks. Together with the contrasting trends ob- served for different baselines, these results suggest that the balance between the base similarity and SoFT’s filtering signals may vary depending on the retriever. Consequently, treatingλas a tunable parameter rather than a fixed constant may be beneficial for achieving stable performance. Full re- sults are provided in Appendix. CIRCO CIRR FIQ (Avg) mAP@k Recall@k Recall@k Method k=5 k=50 k=1 k=10 k=10 k=50 SEARLE 11.68 15.12 24.24 66.29 25.56 46.23 SEARLE + Penalty 0.28 0.28 4.82 15.49 3.59 7.63 SEARLE + Reward 18.06 22.15 29.08 70.84 25.59 46.42 SEARLE + SoFT 15.72 18.93 30.29 71.49 25.00 45.53 CIReVL 18.57 21.80 24.55 64.92 28.55 48.57 CIReVL + Penalty 21.83 25.57 32.92 74.51 28.77 47.13 CIReVL + Reward 22.19 26.00 32.80 74.99 32.57 53.46 CIReVL + SoFT 23.90 27.93 35.54 76.41 31.68 52.53 Table 4: Component-wise ablation of SoFT on CIRCO, CIRR, and FashionIQ. We compare three variants: applying only the reward term (+Reward,s SoFT =s base ·s reward), only the penalty term