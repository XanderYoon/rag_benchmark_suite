35.54 65.25 76.41 91.95 71.59 87.64 94.15 LDRE 23.35 24.03 26.44 27.50 26.53 55.57 67.54 88.50 60.43 80.31 89.90 OSrCIR 23.8725.33 27.84 28.97 29.45 57.68 69.86 N/A 62.12 81.92 91.10 Table 1: Quantitative results on CIRCO and CIRR. 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Score 0 500 1000 1500 2000Frequency CIRR (4181 samples) 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Score 0 200 400 600 800 1000Frequency FashionIQ - Shirt (2038 samples) 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Score 0 200 400 600 800 1000Frequency FashionIQ - Dress (2016 samples) 0.0 0.2 0.4 0.6 0.8 1.0 Confidence Score 0 200 400 600 800 1000Frequency FashionIQ - Toptee (1961 samples) Figure 4: Confidence scores assigned by the LLM-based evaluator to original ground-truth target images across each dataset, illustrating the consistency and reliability of the scoring method. Dataset Application and Statistics.We apply our pipeline to the validation splits of and CIRR and FashionIQ. Queries with no valid alternative target is identified—i.e., all candidates fall below the confidence threshold—are ex- cluded, slightly reducing in dataset size: CIRR decreases from 4,181 to 4,140 queries, while FashionIQ retains 2,032 for Shirt, 2,011 for Dress and 1,958 for Toptee. Our method substantially enriches each query with multiple valid tar- gets, yielding an average of 2.89 for CIRR, 4.68 (Shirt), 4.93 (Dress) and 4.60 (Toptee) targets for FashionIQ. This diverse target pool supports more reliable evaluation un- der open-ended user intent. Figure 4 shows the confidence scores assigned to original benchmark targets by our LLM- based scoring module. Building on these multi-target sets, we further construct single-target triplets to support precise evaluation under con- trastive conditions. This stage is applied only to queries with at least three valid targets from Stage 1, ensuring that one target and two contrastive distractors can be selected from the