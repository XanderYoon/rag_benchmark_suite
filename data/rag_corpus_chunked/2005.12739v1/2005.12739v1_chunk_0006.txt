of our prior experiment, we applied whitening [17] without Ensemble Model Validation (Acc@10) Test (Acc@10) m4 (baseline) 0.869435 0.840060 m0-13 (w/o m6-9) 0.875656 0.849722 m0-13 (w/o m6-7) 0.876141 0.853057 m0-16 (w/o m7) 0.876868 0.851860 m1-16 (w/o m7) 0.877192 0.851945 m0-17 (w/o m7) 0.876222 0.851945 m1-16 0.888341 0.854168 m1-17 0.888180 0.853356 Table 6: Top-10 accuracy of retrieval ensembled mod- els with W BF 5 bounding boxes on DeepFashion2 valida- tion/test set. Model Detection Search Method Acc@1 Acc@10 m4 W BF5 (590k) NN 0.668740 0.869435 m4 W BF5 (126k) NN 0.650885 0.853761 m4 W BF5 (126k) NN + re-ranking0.661954 0.858124 Table 7: The experimental results using k-reciprocal re- ranking on DeepFashion2 validation set. Year Rank Team Acc@10 2020 1 Alibaba 0.872082 2 NA VER/LINE Vision (Ours)0.854168 3 DeepBlueAI 0.848012 2019 1 Hydra@ViSenze 0.840658 2 MM AI kakao 0.823258 3 DeepBlueAI 0.816460 Table 8: The Ô¨Ånal results of DeepFashion2 clothes retrieval challenge in 2020 and 2019. dimensionality reduction, but that still did not add any im- provements to the overall performance. Thus, we decided to use the full dimensions of the concatenated features to maximize the score. QE and DBA Query expansion (QE) [2] and database-side augmentation (DBA) [20] replaces each feature point with a weighted sum of its top k nearest neighbors and the point itself. The purpose of these techniques is to obtain rich and distinctive image representations by exploiting the nearest neighbors. However, QE decreased in overall performance while DBA gave a negligible increase. We speculate that this is because there were too many similar boxes proposed for the high recall query, hence the weighted sum of those boxes were not an informative image representation. Re-ranking In Table 7, we present the experiment of k- reciprocal encoding [25], a well-known re-ranking tech- nique in the Re-ID task, based on the