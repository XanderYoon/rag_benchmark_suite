we ultimately concatenate l2- normalized feature embeddings to increase our accuracy when retrieving images. This method has a trade-off with computation time and memory being used; however, each addition of features helped to achieve better performance in the task of image retrieval. 3. Experiments In this section, we describe the datasets that were used and report experimental result details. Included are the performances of each component of our retrieval pipeline and discussions about the effectiveness of post-processing methods that were assessed. 3.1. Dataset Table 1 shows various fashion-related datasets that were used in detection and retrieval tasks. Speciﬁcally, original images were used to train detection models while cropped and deduplicated images were for the retrieval models. 3.2. Detection Results We train our detection models on DeepFashion2 train set only, then validate their performances on DeepFashion2 validation set. On Table 2, we summarize the evaluated detection performances on validation set. Param Value Param Value Backbone ResNet152-D [7] Descriptor GeM [14] Input size 224×224 Output dim. 1,024 Total epochs 200 Optimizer SGD Init. LR 0.2 LR decay cosine Losses Softmax + Center [22] + Triplet [16] + MS [21] Table 4: Default settings for training retrieval models. Models W BF1 W BF2 W BF3 W BF4 W BF5 ATSS ✓ ✓ ✓ ✓ ✓ + Cascade Mask R-CNN ✓ ✓ ✓ ✓ + CenterNet ✓ ✓ ✓ + RetinaNet-R101-FPN ✓ ✓ + RetinaNet-X101-FPN ✓ AP50(%) 83.6 84.0 84.9 85.4 85.8 Table 5: Weighted boxes fusion (WBF) results on Deep- Fashion2 validation set . W BFn refers WBF result with n models. There are performance gains as more detection models are added. 3.3. Retrieval Results Table 3 shows the performances of retrieval models us- ing ground-truth bounding boxes on the DeepFashion2 vali- dation set. In addition to the DeepFashion2train set, we ac- cumulated