constraints are more often preferable only in the inference time due to the flexibility and efficiency. Nishino et al. [40, 41] demonstrate the preservation of relative errors of certain loss functions in realizable setting. We instead provide a failure case via establishing the existence of a lower-bound error for auto-regressive models operating under step-wise inference-time constraints. Recent work on controllable text generation ( CTG) in LLMs [see, e.g., 65] also explores imposing constraints during inference without updating the underlying model [10, 19, 35, 36]. Constrained Auto-Regressive Decoding Constrains Generative Retrieval SIGIR ‚Äô25, July 13‚Äì18, 2025, Padua, Italy However, many of these approaches do not focus on strictly en- forcing constraint satisfaction. A few studies [20, 63, 64] propose methods to produce outputs that strictly adhere to constraints, mainly hard keywords inclusion constraints, using tractable proba- bilistic models or policy gradient techniques. Our work differs by focusing on a specific corpus-level constraint, i.e., the set of valid docIDs is sampled from the complete corpus, a problem unique to retrieval tasks. Beam search is a widely used heuristic algorithm for decoding structured predictors and has been applied as a non-maximum in- ner product search (MIPS) setup for large-scale retrieval systems with explicit tree structures [24, 68, 69, 71]. Beam search is known to have a performance deterioration, and only few works provided theoretical insights into this issue. As far as we know, only Zhuo et al. [71]demonstrate a training-test discrepancy in tree-structured models using binary cross-entropy loss. They showed that pseudo- labeling during training does not guarantee that beam search will get the most relevant targets. In our work, we analyze the marginal distribution of an auto-regressive distribution and provide a the- oretical result on the top- 1 and top-ùëò performance under sparse relevance situations. Zhuo et al. [71] also provide a