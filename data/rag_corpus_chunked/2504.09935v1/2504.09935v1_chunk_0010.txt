[2]. Notation. Table 1 lists the main notation used in the paper. For an integer ğ‘›, we denote the set {1, . . . , ğ‘›} by [ğ‘›]. We use bold face to denote random variables. Tokens in a document ğ‘‘ are integers from [ğ‘˜], making ğ‘‘ âˆˆ [ ğ‘˜]ğ‘š, and ğ‘˜ is the vocabulary size. We set the complete corpus D = [ğ‘˜]ğ‘š. We denote the underlying relevance distribution over D given a query ğ‘ as Pr(Â· | ğ‘), where ğ’… âˆ¼ Pr(ğ’… | ğ‘) = Ã Pr(ğ’…ğ‘– | ğ’…<ğ‘–, ğ‘). For simplicity, we focus on a single query ğ‘ and omit it in some context. We use subscripts to indicate a sliced subset or operations at specific steps, i.e., â–¡ğ‘–, and â–¡â‰¥ğ‘–, etc. Particularly, we refer to Dâ‰¥ğ‘– or Dğ‘ â‰¥ğ‘– a branch with root ğ‘‘ğ‘–, under some prefix ğ‘‘<ğ‘–. Downstream corpus and constraints. We construct the down- stream corpus Dğ‘ by sampling. For simplicity, each document is sampled with an equal probability ğ‘. In practice, the sampling is agnostic to the future user queries, and thus independent withPr(Â·). We use ğ¶ to be the event that ğ’… is in Dğ‘, and Pr(Â· | ğ¶) is the distri- bution under the corpus Dğ‘. ğ¶ğ‘– means the ğ‘–-th token of document ğ’… is valid with respect to the downstream corpus constraints, given some context-clear prefix tokens ğ‘‘<ğ‘–, i.e., ğ‘‘ğ‘– is valid if it appears in Dğ‘ for the prefix ğ‘‘<ğ‘–. We use â€œconstraintsâ€, and â€œdownstream corpusâ€ to represent the result of sampling interchangeably. The constrained generation process ğ‘”ğ‘ ğ‘– is applied at the ğ‘–-th step of ğ‘“ . It first zeros out the invalid tokens and then re-normalizes the remaining probabilities. 4 Theoretical analysis We investigate the inherent limitations of GR arising from con- straints and beam search individually.