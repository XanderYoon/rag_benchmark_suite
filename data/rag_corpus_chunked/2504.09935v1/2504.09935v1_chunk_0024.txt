Constrains Generative Retrieval SIGIR â€™25, July 13â€“18, 2025, Padua, Italy 0.8 0.85 0.9 0.95 1.0 1.05 1.1 1.2 Temperature 0.0 0.2 0.4 0.6 0.8 1.0 Recall@#Relevant Branches k = 2 8 k = 2 10 k = 2 12 k = 2 14 Figure 4: The recall of relevant branches cut off at the total number of relevant branches in the first generation step. The synthetic relevance distribution is constructed as Section 4.2. The total number of sampled relevant document is 0.05ğ‘˜. The size of each branch is fixed as ğ‘› = 225. with logit ğ‘ , the score is computed as exp(ğ‘ /ğ‘‡ ). Lower tempera- tures increase the gap between scores for relevant and non-relevant documents. The results are shown in Figure 4. Our findings reveal that recall performance is highly sensitive to temperature, achieving perfection within a narrow range. This confirms the advantage of constructing GR models that capture concentrated distributions effectively. 6.3 Summary The results from the synthetic data distributions validate the theo- retical findings presented in earlier sections. Although these syn- thetic settings are not practical for real-world scenarios, they pro- vide a controlled environment to clearly demonstrate the negative effects of constrained decoding and beam search. 7 Experiments on real-world dataset 7.1 Experimental setups Document identifier design. For the docID design, we adopt the codebook and semantic ID mapping from Zeng et al. [61], which introduces the first effective GR model that outperforms conven- tional retrieval models on the full MS MARCO passage corpus [3]. The codebook size is set to 256. Datasets. We evaluate our approach using the MS MARCO V1 passage corpus [3], which contains 8.8 million passages, along with three evaluation datasets: (i) MS MARCO-dev, consisting of 7k queries; (ii) TREC DL 2019 [14], with 43 queries; and (iii) TREC DL 2020 [13],