10 k = 2 12 k = 2 14 0.5 + max(0, 0.65 â–¡ 0.15 Î» ) Figure 3: The recall of relevant branches cut off at the total number of relevant branches in the first generation step. The synthetic relevance distribution is constructed as Section 4.2. The total number of sampled relevant document is ğœ†ğ‘˜. The size of each branch is fixed as ğ‘› = 225. 6.2 Effects of beam search Verification of theoretical results. We first construct a sparse relevance distribution as outlined in Section 4.2. The results are presented in Figure 3. We evaluate the recall of relevant branches under varying values of ğœ†, which controls the number of relevant documents sampled. Specifically, we compute how many relevant branches are preserved in the top positions during the first gener- ation step. We also examine large ğœ† values, which are beyond the scope of Theorem C.1. For small ğœ†, the recall performance is approximately 0.5. For larger ğœ† values, the recall still aligns with the theoretical bounds. In all cases, the precision@1 remains consistently perfect. Regarding score magnitudes, as each branch has a fixed size ofğ‘› = 225, relevant documents achieve scores around ğ‘’8.6 â‰ˆ 5400, while non-relevant documents score around ğ‘’1 â‰ˆ 2.7. Effects on different degrees of concentration. We also inves- tigate the impact of varying the sharpness of the relevance distri- bution by introducing a temperature parameter ğ‘‡ . For a document Constrained Auto-Regressive Decoding Constrains Generative Retrieval SIGIR â€™25, July 13â€“18, 2025, Padua, Italy 0.8 0.85 0.9 0.95 1.0 1.05 1.1 1.2 Temperature 0.0 0.2 0.4 0.6 0.8 1.0 Recall@#Relevant Branches k = 2 8 k = 2 10 k = 2 12 k = 2 14 Figure 4: The recall of relevant branches cut off at the total number of relevant branches in