al. ğœ‡ğ‘– + ğœğ‘– }, ğ›¿ = ğ‘œ (1) and ğ‘˜ğ›¿ 2 = ğ‘˜ğ‘‚ (1), we have, with probability at least 1 âˆ’ 3 exp âˆ’2ğ›¿ 2ğ‘˜ 2 ğµ2 , where ğµ = Ã ğ‘– âˆˆ [ğ‘˜ ] ğ‘¤ 2 ğ‘– , ğ‘‘TV (ğ‘ƒ, ğ‘„) â‰¥ | ğ‘ƒ (ğ¼ ) âˆ’ ğ‘„ (ğ¼ )| (34) â‰¥ Ã ğ‘– âˆˆğ¼ ğ‘†ğ‘– ğ‘ âˆ’ Ã ğ‘– âˆˆğ¼ ğ‘¤ğ‘– ğ‘Š (35) â‰³ 0.16âˆšğ‘ Ã ğ‘– âˆˆ [ğ‘˜ ] ğ‘¤ğ‘–ğ´ğ‘– Ã ğ‘– âˆˆ [ğ‘˜ ]ğ‘¤ğ‘– . (36) If we set ğ‘Š = 1, it can be simplified as 0.16E[ğ´ğ‘– ]âˆšğ‘ . â–¡ C Recall performance using beam search Theorem C.1 (Top- ğœ†ğ‘˜ recall and top- 1 precision of data model in Section 4.2). Suppose we have ğ‘˜ branches, each with ğ‘› = ğ‘˜ğ‘šâˆ’1 documents (leaves). We randomly select ğœ†ğ‘˜ docs from all branches as the relevant ones, where ğœ† â‰ª 1. We assign each non- relevant doc a score uniformly at random from [âˆ’1, 1], and each relevant doc from [ğ›¿ âˆ’ Î”, ğ›¿ + Î”], where ğ›¿ = 0.5 log(0.8ğ‘›), and Î” = ğ‘‚ (0.5 log logğ‘˜). We then take the exponential of the score for each doc and use the sum of the scores as the ranking score for each branch. Then, we have the following results with high probability: (1) The top- ğœ†ğ‘˜ recall is lower than 0.5 + max{0.65 âˆ’ 0.15/ğœ†, 0}. (2) The top- 1 precision is 1. Proof. First, we show the distribution of values for non-relevant branches. For each non-relevant branch, the score ğ‘† is the sum of ğ‘› i.i.d. random variables from ğ’€ ğ‘– = ğ‘’ğ‘¿ ğ‘– , where ğ‘¿ğ‘– âˆ¼ Uniform(âˆ’1, 1). As E[ğ’€ ] â‰ˆ 1.175, and V[ğ’€ ] â‰ˆ 0.4, we have E[ğ‘º] = 1.175ğ‘› and V[ğ‘º] = 0.4ğ‘›. According to the central