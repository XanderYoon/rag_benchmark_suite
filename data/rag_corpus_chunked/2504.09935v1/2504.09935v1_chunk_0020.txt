filter out the non-maximum successors in the training set, i.e., L𝑖 (𝜃 ) = − ∑︁ 𝑑 ∈ ˜D I[𝑑 ∈ arg max Pr(𝑑>𝑖 | 𝑑 ≤𝑖 )] log Pr(𝑑𝑖 | 𝑑<𝑖 ; 𝜃 ). (14) As we can see, only the most relevant successors are allowed to contribute to the loss function. It not only needs to throw away large amounts of data but also requires more high-quality data and careful filtering strategies. Most retrieval models can be seen to be trained on this loss [ 24], as they are only trained on the labeled relevant documents. However, the quality and quantity of retrieval data are often limited considering that the amount of data needed for a generative model is generally much larger than that for a discriminative model. SIGIR ’25, July 13–18, 2025, Padua, Italy Shiguang Wu et al. 29 211 213 215 217 219 Size of Downstream Corpus 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 KL Divergence k = 2 8 k = 2 10 k = 2 12 k = 2 14 Lower Bound Figure 1: The KL divergence error in the first generation step on synthetic uniform relevance distribution data with uniformly sampled downstream corpus. 6 Synthetic experiments In this section, we experimentally verify the theoretical results and investigate scenarios beyond the assumed data distributions presented in Section 4.1 and Section 4.2. 6.1 Effects of constraints Uniform relevance distribution. We begin by simulating the case of a uniform relevance distribution, as discussed in Section 4.1. Since the lower bound is expressed in terms of the size of the downstream corpus, we vary its size to observe the behavior across different vocabulary sizes. We choose a sufficiently large𝑚 so that the complete corpus of size𝑘𝑚 is much larger than the downstream corpus. For a downstream