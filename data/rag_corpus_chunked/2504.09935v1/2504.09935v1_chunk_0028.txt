like, we fail to provide practical assumptions on the relevance distribution and the structure of docID. Our results are sensitive to the parameters and assumptions, e.g., the sharpness of the relevance distribution for Theorem C.1, and may not accurately reflect practical real-world situations. Besides, we have not studied how the two factors affect each other when using constrained beam search. Concerning the experimental aspects of our work, we only use the docID from Zeng et al. [61] and the MS MARCO V1 passage corpus. 9 Conclusion In this paper, we have provided theoretical results on the effect of constrained beam search for a Bayes optimal GR model. We have considered two separate aspects, constraints and beam search, and examine the root cause of the negative effect on generalization. Both aspects are intrinsically connected to the degree of concentration of the relevance distribution across the complete corpus. When it is more concentrated, the model achieves decent recall performance, provided the marginal distribution aligns closely with the actual one. However, applying downstream corpus constraints increases this marginal distribution gap at the same time. To validate our theoretical findings, we have conducted experiments on synthetic and real-world dataset and have shown the case beyond the as- sumed conditions in the theorem. Overall, we give a systematical investigation from both theory and experiments to the limitation of constrained decoding on retrieval generalization. 3The source code is available at https://github.com/Furyton/constrained-generation- in-gr. Based on our findings, practitioners in the field may consider balancing the degree of concentration when designing and train- ing GR model, and using post-calibration to fix the errors when using the model on a downstream corpus. Other forms of decoding strategies beyond constrained beam search are also suggested. As to future work, we will continue to study how these results can be used