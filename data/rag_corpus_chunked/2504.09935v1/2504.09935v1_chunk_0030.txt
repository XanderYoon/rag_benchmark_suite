(partly) financed by the Dutch Research Council (NWO), DPG Media, RTL, and the Dutch Ministry of Economic Affairs and Climate Policy (EZK) under the program LTP KIC 2020- 2023, and the FINDHR (Fairness and Intersectional Non-Discrimi- nation in Human Recommendation) project that received funding from the European Unionâ€™s Horizon Europe research and innova- tion program under grant agreement No 101070212. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors. Appendix A On the magnitude of vocabulary size In this work, we use a sequence of tokens as the docID to repre- sent the document as a general case. In order for the GR model to generate the docID of relevant documents, the docID faithfully rep- resenting the semantic information is highly perfered. Therefore, the vocabulary size of the docID is a key factor to determine the capacity of the GR model. In this section, we will give a brief per- spective of its magnitude by considering the average information content in real-world documents. Bits per byte (bpb) is a widely used metric to measure the infor- mation content of a document. It is defined as the number of bits required to encode the content in a lossless way. Letğ›¼ be the bpb of general English text, and ğ‘› be the length (in bytes) of a document. The information content of the document is ğ‘›ğ›¼ bits on average. Since the vocabulary size of the GR model is ğ‘˜, the maximum aver- age information in a single token is log2 ğ‘˜ bits. Each docID has ğ‘š Constrained Auto-Regressive Decoding Constrains Generative Retrieval SIGIR â€™25, July 13â€“18, 2025, Padua, Italy tokens, so there will beğ‘š log2 ğ‘˜ bits in total. One would expect that the information content of the docID should