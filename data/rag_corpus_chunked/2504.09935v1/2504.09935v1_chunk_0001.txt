bound of the error, in terms of the KL diver- gence between the ground-truth and the model-predicted step-wise marginal distributions. This error arises due to the unawareness of future constraints during generation and is shown to depend on the average Simpson diversity index of the relevance distribution. ‚àóCorresponding authors. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ‚Äô25, Padua, Italy ¬© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-1592-1/2025/07 https://doi.org/10.1145/3726302.3729934 (ii) For the beam search algorithm used during generation, we re- veal that the usage of marginal distributions may not be an ideal approach. Specifically, we prove that for sparse relevance distribu- tions, beam search can achieve perfect top-1 precision but suffer from poor top-ùëò recall performance. To support our theoretical find- ings, we conduct experiments on synthetic and real-world datasets, validating the existence of the error from adding constraints and the recall performance drop due to beam search. This paper aims to improve our theoretical understanding of the generalization capa- bilities of the auto-regressive decoding retrieval paradigm, laying a foundation for its limitations and inspiring future advancements toward more robust and generalizable generative retrieval. CCS Concepts ‚Ä¢Information systems ‚Üí Retrieval models and ranking . Keywords Generative retrieval; Constrained decoding; Beam search ACM Reference Format: Shiguang