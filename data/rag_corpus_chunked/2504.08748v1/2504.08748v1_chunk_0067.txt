such as text, images, audio, and video. These models leverage the strengths of large language models (LLMs) and extend them to handle and integrate diverse data types, creating rich, coherent, and contextually , Vol. 1, No. 1, Article . Publication date: April 2018. A Survey on Multimodal Retrieval-Augmented Generation 31 Multimodal Generation Modality Augmentation InternLM-XComposer [465], InternLM-XComposer2 [ 67], InternLM-XComposer-2.5 [ 466], MuRAR [ 508], ùëÄ 2ùëÖùê¥ùê∫ [259] MLLM ‚Ä¢ Image ‚äï Text ‚Üí Text BLIP-2 [185], ChatSpot [ 483], OpenFlamingo [ 14], ASM [ 378], Qwen-VL [16], Kosmos-2.5 [ 249], InternLM- XComposer [465], JAM [ 8], Kosmos-1 [ 130], PaLM-E [ 69], ViperGPT [ 343], PandaGPT [ 335], PaLI-X [ 40], LLaVA- Med [182], LLaVAR [478], mPLUG-DocOwl [ 426], P-Former [ 145], MiniGPT-v2 [35], LLaVA [219], MiniGPT-4 [504], mPLUG-Owl [ 427], Otter [ 181], MultiModal-GPT [ 103], CogVLM [ 377], mPLUG-Owl2 [ 428], Monkey [205], DocPedia [ 81], ShareGPT4V [ 37], mPLUG-PaperOwl [ 123], RLHF-V [438], Silkie [ 189], Lyrics [ 241], VILA [209], CogAgent [ 121], Volcano [176], DRESS [ 44], LION [ 31], Osprey [ 443], LLaVA-MoLE [39], VLGuard [ 514], MobileVLM V2 [55], ViGoR [ 417], V* [ 399], MobileVLM [54], TinyGPT-V [444], DocLLM [ 367], LLaVA-Phi [507], KAM-CoT [277], InternLM-XComposer2 [ 67], InternLM-XComposer-2.5 [ 466], MoE-LLaVA [207], VisLingInstruct [505] ‚Ä¢ Image ‚äï Text ‚Üí Image ‚äï Text Visual ChatGPT [ 397], DetGPT [ 295], FROMAGe [165], Shikra [ 36], GPT4RoI [ 472], SEED [ 100], LISA [ 168], GILL [164], Kosmos-2 [ 293], DreamLLM [ 65], MiniGPT-5 [490], Kosmos-G [ 287], VisCPM [ 124], CM3Leon [ 434], LaVIT [155], GLaMM [ 307], RPG [ 418], Vary-toy [392], CogCoM [ 298], SPHINX-X [ 216], LLaVA-Plus [223], PixelLM [310], VL-GPT [506], CLOVA [96], Emu-2 [337], MM-Interleaved [355], DiffusionGPT [301] ‚Ä¢ Video ‚äï Text ‚Üí Text Video-ChatGPT [260],