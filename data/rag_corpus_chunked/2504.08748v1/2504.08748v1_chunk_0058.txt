probabilities and a graph-based aggregation for scoring relevance. Additionally, a post-processing technique [416] refines LLM-generated labels by aligning them with pairwise preferences while minimizing deviations from original values. Listwise methods directly rank document lists by incorporating queries and documents into prompts, instructing LLMs to output reranked document identifiers. RankGPT [341] introduces instructional permutation generation and a sliding window strategy to address context length limits, while LRL [256] reorders document identifiers for candidate documents. However, these methods face challenges: (1) performance is highly sensitive to document order, revealing positional bias, and (2) the sliding window strategy limits the number of documents ranked per iteration. Recent advancements have attempted to address these issues: Tang et al. [349] propose permutation self-consistency to mitigate bias. TourRank [43] introduces a tournament mechanism, parallelizing reranking to minimize the impact of initial document order. TDPart [292] employs a top-down partitioning algorithm, which processes documents to depth using a pivot element. FIRST [ 309] leverages the output logits of the first generated identifier to directly obtain a ranked ordering of candidates. â€“ Reranking for Cross-Model: Prompt-Based Multimodal Reranker uses prompts to guide a MLLM in reranking items. TIGeR [303] proposes a framework leveraging multimodal LLMs for zero-shot reranking via a generative retrieval approach. However, their method is limited to text-only query retrieval tasks. In contrast, Lin et al. [210] extends this scope by utilizing multimodal LLMs to address diverse multimodal reranking tasks, supporting queries and documents in text, image, or interleaved text-image formats. In summary, these approaches leverages the pre-existing knowledge and reasoning capabilities of LLMs, reducing the need for extensive task-specific fine-tuning. Consequently, it provides greater flexibility and resource efficiency, particularly in scenarios with limited labeled data or computational resources. However, its effectiveness depends heavily on the quality and design of the prompts, as well as the