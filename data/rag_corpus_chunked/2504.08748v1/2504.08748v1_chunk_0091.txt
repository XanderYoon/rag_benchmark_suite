from public datasets and the Internet, filtering 13,366 high-quality images for annotation and contributing to 29,429 question-answer pairs that cover 43 subtasks across 5 real-world scenarios. MMStar [38] 2024 contains 1,500 challenging samples, each rigorously validated by humans. It identify 6 core capabili- ties (i.e., coarse perception, fine-grained perception, instance reasoning, logical reasoning, science & technology, mathematics) along with 18 specific dimensions. CV-Bench [359] 2024 provides 2,638 manually-inspected examples, and formulate natural language questions that evaluates 2D understanding via spatial relationships & object counting, and 3D understanding via depth order & relative distance. MDVP [212] 2024 contains 1.6M unique image-visual prompt-text instruction-following samples, including natural images, document images, OCR images, mobile screenshots, web screenshots, and multi-panel images. FOCI [101] 2024 constructed from 5 popular classification datasets for different domains: 1) aircraft contains images of 100 different aircraft types; 2) flowers contains images of 102 different flower species; 3) food covers 101 dishes; 4) pets contains images of 37 cat and dog breeds. 5) cars covers 196 car models. Additionally, FOCI create 4 domain subsets for animals (1322 classes), plants (957 classes), food (563 classes), and man-made objects (2631 classes). MMVP [360] 2024 summarizes 9 prevalent patterns of the CLIP-blind pairs, such as “orientation”, “counting”, and “view- point”. Utilizing the collected CLIP-blind pairs, MMVP design 150 pairs with 300 questions. V*-Bench [399] 2024 It is built based on 191 high-resolution images with an average image resolution of 2246 ×1582. V*- Bench contains two sub-tasks: attribute recognition and spatial relationship reasoning. The attribute recognition task has 115 samples. The spatial relationship reasoning task has 76 samples. MME-RealWorld [480] 2024 contains 29,429 question-answer pairs that cover 43 subtasks across 5 real-world scenarios, where each one has at least 100 questions. Visual COT [324] 2024 438k visual chain-of-thought question-answer pairs spans across five distinct