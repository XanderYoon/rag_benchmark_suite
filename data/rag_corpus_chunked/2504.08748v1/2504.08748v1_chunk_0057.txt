to optimize the ranking of textual documents. Point-wise methods evaluate the relevance between a query and individual documents, reranking them based on relevance scores.. Zhuang et al. [509] integrates fine-grained rele- vance labels into prompts for better document distinction. MCRanker [109] addresses biases in existing point-wise rerankers by generating relevance scores based on multi-perspective criteria. UPR [318] re-scores retrieved passages using a zero-shot question generation model. Zhuang et al. [511] show that LLMs pre-trained without supervised instruction fine-tuning (e.g., LLaMA) also exhibit strong zero-shot ranking capabilities. Despite their effectiveness, these methods often rely on suboptimal handcrafted prompts. To improve prompts for rank- ing tasks, Co-Prompt [52] introduces a discrete prompt optimization method for improving prompt generation in reranking tasks. PaRaDe [70] proposes a difficulty-based approach to select the most challenging in-context demonstrations for prompts, though experiments reveal that this method does not significantly outperform random selection. To improve demonstra- tion selection, DemoRank [228] advances demonstration selection with a dependency-aware demonstration reranker, optimizing top-ranked examples through efficient training sample construction and a novel list-pairwise loss. , Vol. 1, No. 1, Article . Publication date: April 2018. A Survey on Multimodal Retrieval-Augmented Generation 27 Pair-wise methods involve presenting LLMs with a query and a document pair, instructing them to identify the more relevant document. PRP-AllPair [302] generates all possible pairs, assigns discrete relevance judgments, and aggregates these into a final relevance score per document. PRP-Graph [248] improves this by using judgment generation probabilities and a graph-based aggregation for scoring relevance. Additionally, a post-processing technique [416] refines LLM-generated labels by aligning them with pairwise preferences while minimizing deviations from original values. Listwise methods directly rank document lists by incorporating queries and documents into prompts, instructing LLMs to output reranked document identifiers. RankGPT [341] introduces instructional permutation generation and a sliding window strategy to