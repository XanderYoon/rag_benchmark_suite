content, enhancing the utility of multimodal data integration. • Leveraging LLMs and MLLMs for Enhanced Parsing: – LLM/MLLM-Driven Parsing and Indexing: LLMs and MLLMs can be fine-tuned on domain- specific corpora to improve their ability to parse and interpret complex document structures. Leveraging their advanced multimodal understanding, these models can accurately identify and extract key information—such as legal clauses, scientific hypotheses, or technical speci- fications—even from dense or unstructured text. Fine-tuning enhances their proficiency in recognizing domain-specific terminology, relationships, and contextual nuances. Furthermore, LLMs and MLLMs can generate metadata, tags, and summaries. By automatically annotat- ing documents with relevant keywords, classifications, or concise summaries, these models streamline the organization and accessibility of large document repositories. This capability , Vol. 1, No. 1, Article . Publication date: April 2018. A Survey on Multimodal Retrieval-Augmented Generation 53 is particularly valuable in applications like legal case management, academic research, and enterprise knowledge bases. In multimodal contexts, MLLMs extend these capabilities by integrating and interpreting data from diverse sources, such as text, images, tables, and dia- grams. This enables a more comprehensive parsing process, where visual and textual elements are jointly analyzed to extract richer, more accurate information. For example, in scientific documents, MLLMs can parse and correlate data from textual descriptions and accompanying charts, facilitating a deeper understanding of the content. – Bridging the Gap Between LLMs and MLLMs: A promising approach involves hybrid architectures that combine the strengths of MLLMs and LLMs. MLLMs process raw multimodal inputs (e.g., images, audio, video) to extract meaningful representations, while LLMs generate coherent and contextually accurate textual outputs. This division of labor optimizes perfor- mance, as MLLMs excel in multimodal feature extraction and LLMs in linguistic precision. For example, in document parsing, MLLMs analyze visual layouts, tables, or embedded graphics, while LLMs synthesize this information into