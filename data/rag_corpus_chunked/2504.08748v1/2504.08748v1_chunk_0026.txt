Networks) for feature extraction and CTC (Connectionist Temporal Classification)/RNNs (Recurrent Neural Networks) for sequence modeling, with breakthroughs like CRNN enabling unified pipelines and improved accuracy on irregular text. The modern phase leverages transformer architectures [191], achieving global context awareness and robustness to arbitrary-shaped text. Text Parsing reconstructs semantic relationships through three key steps: Layout Analysis segments documents into logical components using rule-based heuristics and graph models based on spatial and typographic cues. Syntactic Parsing extracts structured data from unstructured text using regular expressions and finite-state machines. Post-processing corrects recognition errors through contextual algorithms like language model interpolation (e.g., n-gram models and dictionary lookups). This comprehensive process ensures accurate semantic reconstruction from complex documents. However, the OCR-dependent approach has critical problems: It is not conducive to paralleliza- tion and occupies a large amount of computing resources, besides, errors in the pipeline will propagate downward through the system, affecting the overall performance. In recent years, with the development of Transformer architectures, the aforementioned issues have been effectively addressed. It enhances global context modeling through the self-attention mechanism, signifi- cantly improves processing efficiency by leveraging parallel computing, and directly maps images to structured text in an end-to-end training mode. This effectively eliminates the cumulative error issues associated with the multi-stage cascading of traditional OCR systems. LayoutLM [412] uses the BERT architecture as the backbone and adds two new input embeddings: a 2-D position embedding and an image embedding to jointly model interactions between text and layout information across scanned document images. LayoutLMv2 [413] and LayoutLMv3 [133] further propose a new single multimodal framework to model the interaction among text, layout, and image. DocFormer [12] based on the multimodal transformer architecture proposes a novel multimodal attention layer to fuse text, vision, and spatial features in a document, thereby achieving end-to-end document parsing. â€¢ Multimodal