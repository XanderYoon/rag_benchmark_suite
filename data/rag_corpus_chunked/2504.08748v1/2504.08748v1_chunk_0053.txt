its parameters as a response. Achieving this capability presents significant challenges, particularly in developing effective visual memory and recall mechanisms within MLLMs. IRGen [479] employs a seq2seq model to predict discrete visual tokens (image identifiers) from , Vol. 1, No. 1, Article . Publication date: April 2018. A Survey on Multimodal Retrieval-Augmented Generation 25 query images. Its key innovation is a semantic image tokenizer that encodes global features into discrete visual tokens, enabling end-to-end differentiable search for improved accuracy and efficiency. GeMKR [238] integrates LLMs with visual-text features through a generative multimodal knowledge retrieval framework. It first guides multi-granularity visual learning using object-aware prefix tuning techniques to align visual features with LLMsâ€™ text feature space, then adopts a two-step retrieval process: generating knowledge clues relevant to the query and retrieving documents based on these clues. GRACE [199] assigns unique identifier strings to represent images, training MLLMs to memorize and retrieve image identifiers from textual queries. ACE [76] combines K-Means and RQ-VAE to construct coarse and fine tokens as multimodal data identifiers, aligning natural language queries with candidate identifiers. AVG [195] introduces autoregressive voken (i.e., visual token) generation, tokenizing images into vokens that serve as image identifiers while preserving visual and semantic alignment. By framing text-to-image retrieval as a token-to-voken generation task, AVG bridges the gap between generative training and retrieval objectives through discriminative training, refining the learning direction during token-to-voken generation. 3.3.2 RERANKER. Reranker, as a critical second-stage component in multimodal retrieval, is designed to re-rank a multimodal document list initially retrieved by a first-stage retriever. It achieves this by employing advanced relevance scoring mechanisms, such as cross-attention models, which enable more contextual interactions between queries and documents. Based on the utilization of large models, including LLMs and MLLMs, existing reranking methods can be categorized into two primary paradigms: fine-tuning-as-reranker