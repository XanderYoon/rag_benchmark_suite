warranting separate discussion. In traditional settings, the final output is typically a plain text response. However, the new paradigm enhances the generation module to produce outputs that integrate multiple modalities within a , Vol. 1, No. 1, Article . Publication date: April 2018. A Survey on Multimodal Retrieval-Augmented Generation 9 Please create a pixel art illustration of Huawei Stream Back Slope Village with whimsical fairy tale elements? According to the user‘s description, the generated pictures are as follows. Traditional Multimodal Generation It’s not Huawei Stream Back Slope Village Please create a pixel art illustration of Huawei Stream Back Slope Village with whimsical fairy tale elements? I have found these pictures related to Huawei Stream Back Slope Village. Multimodal Generation with MRAG Good! The final generated pictures are as follows. Fig. 4. The user aims to generate images depicting "Huawei Stream Back Slope Village. " Due to the location’s obscurity and the model’s limited knowledge, it may produce inaccurate representations, such as images of houses by a stream. By integrating retrieval-augmented capabilities, the model can access relevant information beforehand, enabling the generation of precise and contextually accurate images. single response (e.g., combining text, images, or videos). This can be further categorized into three sub-scenarios (see Figure 5). – Multimodal Data is Answer: The query can be answered directly through multimodal data without any text, as the adage "a picture is worth a thousand words" suggests. – Multimodal Data Enhances Accuracy: The integration of multimodal data enhances the accuracy of responses, particularly in instructional contexts such as "How to register for a Gmail account. ". By generating answers that interweave text and image, users can more effectively comprehend and follow the required operations. – Multimodal Data Enhances Richness: While multimodal data is not essential, its inclusion can significantly enhance user experience. For