survey paper. The section 2 presents a compre- hensive overview of multimodal retrieval-augmented generation, covering multiple developmental stages. The section 3 delves into the technical details of multimodal retrieval-augmented generation, focusing on key components such as multimodal retrieval, multimodal generation, etc. In section 4, we discuss how to comprehensively evaluate multimodal retrieval-augmented generation systems using datasets, including specialized assessments for different competency areas. The section 5 introduces relevant metrics for evaluating multimodal retrieval-augmented generation systems. In section 6, we outline the current technical challenges associated with multimodal retrieval- augmented generation. In section 7, based on previous investigation of MRAG, we summarize , Vol. 1, No. 1, Article . Publication date: April 2018. 4 Trovato et al. future work in this field, and provide some suggestions. Finally, we give the conclusion of the paper in section 8. 2 Overview of MRAG Multimodal Retrieval-Augmented Generation (MRAG) represents a significant evolution of the traditional Retrieval-Augmented Generation (RAG) framework, building upon its foundational structure while extending its capabilities to process diverse data modalities. While RAG is limited to processing plain text, MRAG integrates multimodal data, including images, audio, video, and text, enabling it to address more complex and diverse real-world applications where information spans multiple modalities. In the early stages of MRAG development, researchers converted multimodal data into unified textual representations. This approach allowed for a seamless transition from RAG to MRAG by leveraging existing text-based retrieval and generation mechanisms. Although this strategy simplified multimodal data integration and improved the end-to-end user experience, it introduced significant limitations. For instance, the conversion process often resulted in the loss of modality- specific information, such as visual details in images or tonal nuances in audio, restricting the systemâ€™s ability to fully exploit the potential of multimodal inputs. Subsequent research has focused on addressing these limitations by developing