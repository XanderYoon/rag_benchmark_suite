one agent might focus on extracting structured data, while another leverages semantic embeddings or visual-textual alignment for multimodal contexts. The synthesis of these strategies ensures robust and contextually relevant search outcomes, enhancing the system’s ability to handle heterogeneous data sources. 3) Dynamic Resource Allocation: Agents can monitor computa- tional resources and system constraints in real-time, dynamically adjusting retrieval strategies to optimize performance. For example, under limited computational bandwidth, agents might prioritize lightweight retrieval methods or redistribute tasks to balance load. This adaptive mechanism ensures efficient resource utilization while maintaining high-quality query resolu- tion. 4) Integration with MLLMs and LLMs: The collaborative multi-agent framework can be seamlessly integrated with MLLMs and LLMs to enhance their capabilities. MLLMs can serve as central orchestrators, interpreting multimodal inputs and coordinating agent tasks, while LLMs provide deep contextual understanding and reasoning support. This integration enables the system to handle complex, multimodal queries with greater precision and adaptability. – Hierarchical Planning Frameworks: To address the challenges of ambiguous or highly creative queries in multimodal search and planning, integrating human feedback into the , Vol. 1, No. 1, Article . Publication date: April 2018. 54 Trovato et al. decision-making process is essential. Human-in-the-loop (HITL) systems facilitate iterative refinement by leveraging user expertise to guide and validate intermediate results. These interactive systems enable users to dynamically adjust search parameters, prioritize modalities, or correct misinterpretations, ensuring more accurate and contextually relevant outcomes. By combining the strengths of multimodal large language models (MLLMs) with human intuition, HITL systems enhance adaptability, build trust, and improve the robustness of intelligent planning frameworks. This collaborative approach is particularly valuable in domains requiring nuanced understanding, creativity, or domain-specific knowledge. – Reinforcement Learning for Adaptation: Intelligent adaptive planning mechanisms can be developed using reinforcement learning (RL) to enable dynamic, context-aware decision- making. By modeling the