Fig. 1. The architecture of MRAG1.0, often termed "pseudo-MRAG", closely resembles traditional RAG, consisting of three modules: Document Parsing and Indexing, Retrieval, and Generation. While the overall process remains largely unchanged, the key distinction lies in the Document Parsing stage. In this stage, specialized models are employed to convert diverse modal data into modality-specific captions. These captions are then stored alongside textual data for utilization in subsequent stages. by integrating its parametric knowledge with the retrieved external information. This approach enhances response accuracy and timeliness, particularly in domain-specific contexts, while reducing the risk of hallucinations common in LLM outputs. In multi-turn dialogues, the system incorporates conversational history into the prompt, enabling contextually aware and seamless interactions. Despite its initial success, MRAG1.0 exhibited several notable limitations that constrained its effectiveness: • Cumbersome Document Parsing: Converting multimodal data into textual captions introduced substantial complexity to the system. This necessitated distinct models for processing different data modalities, increasing both computational overhead and system intricacy. Additionally, the conversion process frequently often to multimodal information loss. For instance, image captions typically provided only coarse-grained descriptions, failing to capture fine-grained details essential for accurate retrieval and generation. • Bottleneck of Retrieval: While text vector retrieval technology is well-established, MRAG1.0 encountered challenges in achieving high recall accuracy. Similar to traditional RAG, the chunking strategy for text segmentation often fragmented keywords, making some content irretrievable. Additionally, transforming multimodal data into text, while enabling non-textual data retrieval, introduced additional information loss. These issues collectively created a bottleneck, limiting the system’s ability to retrieve comprehensive and accurate information. • Challenges in Generation: Unlike traditional RAG, MRAG1.0 required processing not only text chunks but also image captions and other multimodal data. Effectively organizing these diverse elements into coherent prompts while minimizing redundancy and preserving relevant information posed a significant challenge. Additionally,