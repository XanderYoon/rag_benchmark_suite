relevance signals of TILDE and TILDEv2 are different from that of BM25, to find out if the methods are comple- mentary to each other. To this aim, we will investigate the following research question: RQ3 To what extent do TILDE and TILDEv2 encode a different relevance signal from BM25? To address the question above, as it is described in details in Section 3.3, we will analyze the effect of the interpolation of the scores of TILDE and TILDEv2 with BM25. Since TILDE and TILDEv2 are introduced as re-ranking models, we use four different tasks from the SciDocs evaluation benchmark [5] as a domain-specific QBE benchmark. This benchmark uses scientific paper abstracts as the query and documents. The retrieval setting in these tasks suits as a re-ranking setup because of the number of documents to be ranked for each query. Since that we are working in a domain-specific evaluation setting, we will also address the following research question: RQ4 To what extent does a highly tailored domain-specific pre- trained BERT model affect the effectiveness of TILDE and TILDEv2 in comparison to a BERTbase model? In summary our main contributions in this work are three-fold: • We show that two recent transformer-based lexical models (TILDE and TILDEv2) are less effective in Query-by-Example retrieval than was expected based on results reported for ad hoc retrieval. This indicates that QBE retrieval is structurally different from other IR settings and requires special attention for methods development; • We show that the relevance signals of TILDE and TILDEv2 can be complementary to that of BM25 as interpolation of the methods leads to an improvement in ranking effectiveness; • We also investigate interpolations of BM25 with TILDE and TILDEv2 in an ideal setting where the optimal interpolation weight is known a priori, and by doing so, we