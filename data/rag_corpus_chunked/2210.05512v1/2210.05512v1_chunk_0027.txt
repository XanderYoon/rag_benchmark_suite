optimal values of ùõº per query for the interpolation with TILDEv2 are much higher (bottom part of the table), which indicates that the optimal interpolation setting for the queries are more varied. This observation could give some sense of robustness against query variation for TILDE in comparison to TILDEv2 in this experimental setting. In other words, a query-dependent approach for optimizing ùõº would be more robust against query variation for TILDE than for TILDEv2. 6 CONCLUSION In this paper we investigated the generalizability of two contextu- alized term-based ranking models TILDE and TILDEv2 for a QBE retrieval setting. In QBE, the queries are much longer than in ad-hoc retrieval, and efficient query processing is essential. We were specif- ically interested to see to what extent the relative performance of contextualized term-based ranking models in comparison to both traditional term-based models and the effective cross-encoder BERT ranker is generalizable to a QBE retrieval setting. Our results show that similar to the original papers [ 33, 34], TILDE and TILDEv2 are less effective than a cross-encoder BERT ranker in QBE retrieval despite the context of longer queries. On the other hand, in the original papers, TILDE and TILDEv2 have shown superior ranking quality in comparison to BM25 as a traditional term-based retrieval model. We investigated if the same pattern exists in a query-by-example retrieval setting and our results show that BM25 has a competitive ranking quality compared to TILDE and TILDEv2. In fact, not only is it competitive, but also in some cases it could outperform TILDE and TILDEv2. This finding is important as (1) it sheds light on the challenges of retrieval settings different from the common evaluation bench- marks including MSMARCO and the TREC DL Track; (2) raises the question how effective other contextualized term-based ranking models would be in