retrieval on documents which are expanded at indexing time. To this aim, we use TILDE in the same way as the original paper [33]. TILDE is at an advantage where it is more efficient than doc2query [23]. In this work, using TILDE SciBERT of which we found it performs the best compared to other TILDE models (Table 1), we generate ùëö = 200, and ùëö = 300 expansion terms for TILDEv2SciBERT. It is noteworthy that similar to the original paper [33] not all expansion terms are added to a document, but only new expansion terms ‚Äî that are not yet present in the document ‚Äî are added. 3.5 Domain-Specific BERT in TILDE and TILDEv2 To answer RQ1, and RQ4, we will investigate the power that can be brought by domain-specific pre-training to term-based rank- ing models. To do so, we evaluate the models‚Äô ranking quality in On the Interpolation of Contextualized Term-based Ranking with BM25 for Query-by-Example Retrieval ICTIR ‚Äô22, July 11‚Äì12, 2022, Madrid, Spain. [...] and adapts them to RDF graphs used for building content-based recommender system. We generate sequences by leveraging local information from graph sub-structures and learn latent numerical representations of entities in RDF graphs. Our evaluation on [...] [...] a number of research directions in which the recommender systems can improve their quality, by moving beyond the assumptions of linearity and independence that are traditionally made. These assumptions, while producing effective and meaningful [...] [...] such implicit feedback, or one-class collaborative filtering (OC-CF), problems is SLIM, which makes recommendations based on a learned item-item similarity matrix. While SLIM has been shown to perform well on implicit feedback tasks, we argue that it is hindered by two limitations [...] [...] based on the observed user purchase or recommendation activities. Recently, it has been noticed that side information