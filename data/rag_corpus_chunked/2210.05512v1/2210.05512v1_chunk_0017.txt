is higher be- tween TILDEBERT and TILDESciBERT than between TILDEv2BERT and TILDEv2SciBERT to an extent where TILDESciBERT even outper- forms both TILDEv2BERT and TILDEv2SciBERT. This observation could be due to the fact that the vocabulary mismatch problem caused by exact matching limits the TILDEv2 ranking quality, even if we use a highly tailored domain-specific BERT as its encoder. In this respect, we investigate the impact of token-based query expansion (see section 3.4) with TILDE on the ranking quality of TILDEv2 in our QBE retrieval setting. Lines ğ‘–, and ğ‘— in Table 1 are the ranking results on the documents that are expanded using TILDE with the method introduced by Zhuang and Zuccon [33]. Here, we are interested to find out if using document expansion is able to compensate for the gap in the ranking quality between TILDESciBERT, and TILDEv2SciBERT. As shown in Table 1, TILDEv2SciBERT with ğ‘š = {200, 300} expan- sion terms, is still less effective than TILDESciBERT. Furthermore, ICTIR â€™22, July 11â€“12, 2022, Madrid, Spain. Amin Abolghasemi, Arian Askari, and Suzan Verberne Table 1: Ranking quality on the four SciDocs benchmark tasks using contextualized term-based ranking and cross-encoder BERT. â€œBERTâ€ and â€œSciBERTâ€ refers to the pre-trained model used as the encoder. â€œMSMARCO" indicates the utilization of TILDE or TILDEv2 which are already fine-tuned on MSMARCO. Rowsğ‘– and ğ‘— refer to the experiments on expanded documents with ğ‘š terms using TILDE SciBERT as described in section 3.4. Statistical significance improvements are according to paired t- test (p<0.05) with Bonferroni correction for multiple testing. Rows ğ‘ and ğ‘ are included from Table 2 for ease of comparison. Model Co-view Co-read Co-cite Cite MAP nDCG MAP nDCG MAP nDCG MAP nDCG a) BM25STM2 80.8%ğ‘ğ‘ğ‘‘ ğ‘“âˆ’ğ‘— 0.9032ğ‘ğ‘‘ ğ‘“ ğ‘” ğ‘— 81.31%ğ‘‘ ğ‘“ ğ‘” 0.9112ğ‘ğ‘‘ğ‘” 81.53%ğ‘ğ‘ğ‘‘ ğ‘“ ğ‘” 0.9171ğ‘ğ‘‘ ğ‘“ ğ‘” 79.74%ğ‘ğ‘‘ğ‘” 0.9085ğ‘‘ğ‘”