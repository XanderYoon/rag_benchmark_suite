of documents [ 1, 19, 20, 29]. This retrieval setup is typical in professional, domain-specific tasks such as legal case law retrieval [1, 2], patent prior art search [11, 24, 25], and scientific literature search [1, 19, 20]. While using a document as a query could become challenging due to its length and complex semantic structure, prior work has shown that traditional term- based retrieval models like BM25 [ 27] are highly effective when used in QBE retrieval [1, 2, 28]. Recently, deep contextualized term-based retrieval models have gained attention as they bring the contextualization power of the pre-trained transformer-based language models into the highly efficient term-based retrieval. Examples of such models are Deep- Impact [18], SPLADE [10], SPLADEv2 [9], TILDE [34], TILDEv2 [33], COIL [12], and uniCOIL [ 16]. Here, we specifically investi- gate TILDE, which is a term independent likelihood model, and its follow-up TILDEv2 which is a deep contextualized lexical exact matching model. TILDE and TILDEv2, which are introduced as term-based re- ranking models, follow a recent paradigm in term-based retrieval where term importance is pre-computed with scalar term weights. Besides, to predict the relevance score, both of these models use the BERT tokenizer as their query encoder which means that they do not need to perform any BERT inference at query time to encode the query. However, leveraging tokenizer-based encoding of the query trades off the query representation and therefore effectiveness with higher efficiency at inference time [33]. While the effectiveness of these models is evaluated on tasks and benchmarks where we have short queries, e.g., MSMARCO Passage Ranking [21] and the TREC DL Track [7], in this paper, we evaluate them in the aforementioned QBE retrieval setting where queries are much longer than common keyword queries. In this regard, we address the following research questions: