Description (e.g. movie titles, genres) ID-based Retriever Txt-R. Client 1 Client 2 Client 3 Text-based Retriever Client Training ID-R. ID 1 ID 2 ID 3 CE InfoNCE Global Aggregation Figure 3: The training and aggregation process of GPT-FedRec. On clients, the ID-based retriever and the text-based retriever are trained using local data. them into input texts t and ground-truth text ty using the item meta data (e.g., titles, categories, genres of the items) using the E5 template. t = [t1, t2, ..., tl], where ti = Template1(xi), ty = Template2(y). (2) In Equation 2, Template1 is the E5 template with "query" as prefix, Template2 is the E5 template with "passage" as prefix. (More details about E5 templates in Appendix B.) Then, with prepared text templates, fT is finetuned with the InfoICE loss: Linf o = − 1 |D| |D|X m log es(q(m),p(m)) es(q(m),p(m)) + P n es(q(m),¯p(n)) , where q = fT (t), p = fT (ty), ¯p = fT (¯y), ¯y ∈ I \ y (3) In Equation 3, we use superscript (m) to index dif- ferent users (not client). As for s(q, p), it refers to a scoring function between the encoded query q and an encoded positive passage p or negative pas- sage ¯p. In our implementation, the score function is cosine similarity scaled by a temperature τ: s(p, q) = cos(p, q)/τ. (4) By finetuning E5 using Equation 3, the text-based retriever learns to assign high similarity between user sequences and their ground-truth items in the text space. More importantly, since E5 is pre- trained, it has already encoded prior knowledge of language patterns. Therefore, the text-based re- triever is capable of extracting generalized textual features from item descriptions, despite the data sparsity and data heterogeneity across clients. Finally, after training the ID-based retriever (f k