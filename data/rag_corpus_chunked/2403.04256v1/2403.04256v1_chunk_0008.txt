In compar- ison, a text-based recommender usually transforms discrete item IDs into descriptions: transforming a sequence of items (x) into a sequence of descrip- tions. After trained on such text sequences, the text-based recommender generates textual IDs (i.e., IDs in text format) or item titles as the final recom- mendation. Federated Recommendation. In FR, a central server stores a global recommender, while a set of local clients store their respective datasets. The goal of FR is to collaboratively train the global rec- ommender without clients sharing their private data. Assume there are K clients in an FR application. Each client contains a local dataset Dk with |Dk| item sequences. In FR, the item scopes covered by local datasets may be smaller than the entire item scope: I k ⊆ I and ∪kI k ⊆ I (data spar- sity). In addition, some local clients may contain unique items only present in their datasets (data het- erogeneity). The test user can also introduce new, unseen items (i.e., cold-start users). As in Figure 1, the clients contain disjoint movies, and the test user data involves new, unseen movies. Therefore, the challenges of data sparsity, data heterogeneity and non-generalizabilty on cold-start users drive the development of GPT-FedRec. For simplicity, un- less specified, notations without client index k represent the data of an arbitrary client. 4 Algorithm The overview of GPT-FedRec is in Figure 2. To address the aforementioned challenges, we firstly develop a hybrid retrieval mechanism using a small- scale ID-based retriever and a dense text-based retriever to retrieve generalized candidates (Sec- tion 4.1). Then, based on the retrieved results, we establish a retrieval augmented recommendation pipeline using LLMs (Section 4.2). 4.1 Hybrid Retrieval ID-based Retriever. Given existing ID-based recommenders, any of them could be used by GPT- FedRec to retrieve potential candidates. In