P5, RecFmr, UniSRT and UniSRIT are not originally designed for FR. We use FedAvg as the aggregation protocol to ex- tend them into our FR setting. We did not include LLM-based recommenders as baselines, because existing LLM-based recommenders solely focus on the ranking stage, and could not provide a complete solution for FR: they can only rank ground-truth items along with other sampled negative items. The can not generate candidates from the entire item scope from scratch, which is required by FR. Dataset Metric ID-Based Text-Based Hybrid FedSAS FedLRU CF-FedSR TransFR P5 RecFmr. UniSR T UniSRIT GPT-FedRec Beauty R@5↑ 0.0153 0.0218 0.0204 0.0059 0.0013 0.0313 0.0231 0.0247 0.0348 N@5↑ 0.0101 0.0145 0.0138 0.0037 0.0007 0.0167 0.0159 0.0166 0.0233 R@10↑ 0.0241 0.0336 0.0306 0.0088 0.0024 0.0533 0.0347 0.0349 0.0563 N@10↑ 0.0129 0.0183 0.0170 0.0047 0.0011 0.0238 0.0196 0.0199 0.0302 Games R@5↑ 0.0289 0.0391 0.0366 0.0059 0.0019 0.0399 0.0327 0.0412 0.0471 N@5↑ 0.0195 0.0257 0.0235 0.0037 0.0010 0.0227 0.0218 0.0274 0.0331 R@10↑ 0.0419 0.0613 0.0560 0.0096 0.0042 0.0706 0.0522 0.0621 0.0764 N@10↑ 0.0237 0.0329 0.0298 0.0049 0.0017 0.0326 0.0281 0.0342 0.0406 Toys R@5↑ 0.0094 0.0182 0.0162 0.0067 0.0156 0.0476 0.0323 0.0183 0.0419 N@5↑ 0.0070 0.0133 0.0125 0.0043 0.0080 0.0250 0.0225 0.0125 0.0268 R@10↑ 0.0124 0.0243 0.0211 0.0106 0.0240 0.0739 0.0495 0.0271 0.0720 N@10↑ 0.0080 0.0153 0.0141 0.0055 0.0107 0.0355 0.0280 0.0155 0.0364 Auto R@5↑ 0.0214 0.0607 0.0464 0.0107 0.0060 0.0536 0.0500 0.0464 0.0643 N@5↑ 0.0138 0.0341 0.0294 0.0072 0.0027 0.0264 0.0324 0.0372 0.0390 R@10↑ 0.0357 0.0786 0.0679 0.0143 0.0083 0.0750 0.0679 0.0821 0.0964 N@10↑ 0.0187 0.0398 0.0361 0.0085 0.0035 0.0332 0.0384 0.0488 0.0492 ML-100K R@5↑ 0.0183 0.0459 0.0550 0.0092 0.0002 0.0001 0.0183 0.0183 0.0642 N@5↑ 0.0085 0.0327 0.0402 0.0035 0.0001 0.0001 0.0150 0.0075 0.0362 R@10↑ 0.0367 0.1101 0.1009 0.0092 0.0002 0.0091 0.0183 0.0459 0.1468 N@10↑ 0.0145 0.0538 0.0550 0.0035 0.0001 0.0031 0.0150