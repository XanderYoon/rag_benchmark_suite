query formulation methods We study implicit query formation by masking and explicit query formulation through question generation. In Table 5, we compare the performance of FLARE with different masking β EM F 1 Prec. Rec. 0.0 0.488 0.576 0.571 0.605 0.2 0.498 0.588 0.582 0.616 0.4 0.510 0.597 0.591 0.627 0.6 0.506 0.593 0.586 0.622 Table 5: Performance of FLARE with respect to the masking threshold β on 2WikiMultihopQA. ASQA-hint WikiAsp EM D-F 1 R-L DR UniEval E-F 1 R-L Implicit 45.7 36.9 37.7 37.3 53.4 18.8 27.7 Explicit 46.2 36.7 37.7 37.2 53.4 18.9 27.6 Table 6: A comparison between implicit and explicit query formulation methods in FLARE. thresholds β. Retrieving directly with the complete sentence (β = 0 ) is worse than masking tokens with low probabilities, confirming our hypothesis that low-confidence erroneous tokens can distract retrievers. We compare implicit and explicit query formulation methods in Table 6. Performances of both methods are similar, indicating that both meth- ods can effectively reflect information needs. 7 Related Work We refer to subsection 2.2 and section 4 for ex- tensively discussion on single-time and multi-time retrieval augmented LMs, which is the most rele- vant area to this paper. Iterative and adaptive retrieval Iterative re- trieval and refinement has been studied in both text and code generation tasks (Peng et al., 2023; Zhang et al., 2023; Zemlyanskiy et al., 2022; Yu et al., 2023). FLARE differs from these methods in the granularity of generation and retrieval strategies. Adaptive retrieval has been studied in single-time retrieval scenarios based on either question pop- ularity or generation probabilities (Mallen et al., 2022; Li et al., 2023), while we focus on long-form generation requiring active information access. Browser-enhanced LMs WebGPT (Nakano et al., 2021) and WebCPM (Qin et al., 2023) train LMs to interact with