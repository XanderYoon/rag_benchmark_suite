categories based on when and what to retrieve. These baselines are not exact reproductions of the corresponding paper because many design choices differ which makes direct comparisons impossible. We implemented them using the same settings, with the only variation being when and what to retrieve. Previous-window approaches trigger retrieval every l tokens, where l represents the window size. Generated tokens from the previous window are used as the query: qt = yt−1 (t ≥ 2), yt = [w(t−1)l+1, ..., wtl]. Some existing methods in this category are RETRO (Borgeaud et al., 2022), IC-RALM (Ram et al., 2https://api.openai.com/v1/completions April 23. 3https://www.microsoft.com/en-us/bing/apis/ bing-web-search-api 2023), which retrieve every few tokens, and KNN- LM (Khandelwal et al., 2020), which retrieves ev- ery token.4 We follow Ram et al. (2023) to use a window size of l = 16. Previous-sentence approaches trigger retrieval every sentence and use the previous sentence as the query, and IRCoT (Trivedi et al., 2022) belongs to this category: qt = yt−1 (t ≥ 2), yt = st. Question decomposition approaches manually annotated task-specific exemplars to guide LMs to generate decomposed sub-questions while pro- ducing outputs. For example, self-ask (Press et al., 2022), a method in this category, manually inserts sub-questions in exemplars using Prompt D.2. For the test case, retrieval is triggered dynamically whenever the model generates a sub-question. The aforementioned approaches can retrieve ad- ditional information while generating. However, they have notable drawbacks: (1) Using previously generated tokens as queries might not reflect what LMs intend to generate in the future. (2) Retriev- ing information at a fixed interval can be inefficient because it might occur at inappropriate points. (3) Question decomposition approaches require task- specific prompt engineering, which restricts their generalizability in new tasks. 5 Experimental Setup We evaluate the effectiveness of FLARE on 4 di- verse knowledge-intensive