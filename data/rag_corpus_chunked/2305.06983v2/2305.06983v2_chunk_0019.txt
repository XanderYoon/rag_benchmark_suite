37.5 36.6 51.8 18.1 27.3 Previous-sentence 71.0 39.9 27.9 34.3 30.9 44.7 35.9 37.5 36.7 52.6 17.8 27.2 FLARE (ours) 77.3 41.3 28.2 34.3 31.1 46.2 36.7 37.7 37.2 53.4 18.9 27.6 Table 2: Comparison between FLARE and baselines on StrategyQA, ASQA, ASQA-hint, and WikiAsp. D-F1 is Disambig-F1, R-L is ROUGE-L, and E-F1 is named entity-based F1. 2WikiMultihopQA ASQA-hint EM F 1 Prec. Rec. EM D-F 1 R-L DR Previous 39.0 49.2 48.9 51.8 42.5 34.1 36.9 35.5 Next 48.8 57.6 57.1 60.5 45.9 35.7 37.5 36.6 Table 3: A head-to-head comparison between using the previous sentence and the next sentence for retrieval. #Tokens EM F 1 Prec. Rec. 16 43.2 52.3 51.7 54.5 32 43.6 52.4 52.0 55.0 48 40.0 49.3 49.0 52.0 All 39.0 48.5 48.2 51.1 Table 4: Previous-window approaches using different numbers of tokens as queries. ous window underperforms single-time retrieval on ASQA, which we hypothesize is because the previous window does not accurately reflect future intent. Since we focus on evaluating factuality, met- rics with an emphasis on factual content (such as EM, Disambig-F1, UniEval) are more reliable than metrics computed over all tokens (ROUGE-L). 6.2 Ablation Study Importance of forward-looking retrieval. We first validate that forward-looking retrieval is more effective than past-context-based retrieval. We run ablation experiments on 2WikiMultihopQA and ASQA-hint comparing retrieval using the previ- ous versus the next sentence. Specifically, both methods retrieve every sentence and directly use the complete previous/next sentence as queries. As shown in Table 3, using the next sentence to retrieve is clearly better than using the previous sentence, confirming our hypothesis. We also run previous-window approaches using different numbers of past tokens as queries. As shown in Table 4, using too many tokens (> 32) in %steps/sentences with retrieval 0.0 20.0 40.0 60.0 80.0 0.0 25.0 50.0