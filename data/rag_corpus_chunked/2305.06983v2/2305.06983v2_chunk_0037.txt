in Prompt D.1. We found increasing the number of retrieval documents often increases per- formance. Therefore, we use the maximum number of documents that can fit within the input length limit of text-davinci-003, which is 2 for 2Wiki- MultihopQA. Commonsense Reasoning For “Would a pear sink in water?”, the output we aim to generate is “The density of a pear is about 0.6g/cm3, which is less than water. Objects less dense than water float. Thus, a pear would float. So the final answer is no.” We use 6 exemplars from Wei et al. (2022) listed in Prompt D.5, BM25 on the Wikipedia corpus, and 3 retrieved documents to run experiments. Long-form QA For “Where do the Philadelphia Eagles play their home games?”, the output we aim to generate is “We need to consider the dif- ferent possible locations or venues that could be considered the home field of the Philadelphia Ea- gles. These include the city, the sports complex, or the stadium. Therefore, this question has 3 in- terpretations and the answers are: (1) The city is Philadelphia. (2) The sports complex is the South Philadelphia Sports Complex. (3) The stadium is the Lincoln Financial Field stadium.” For both the original setting (ASQA) and the setting with hints (ASQA-hint), we manually annotate 8 exemplars (Prompt D.6 and D.8), use BM25 on the Wikipedia corpus, and 3 retrieved documents to run experi- ments. Open-domain Summarization The original WikiAsp dataset is designed for multi-document summarization and provides a list of references to systems. We converted it into the open-domain setting by removing the associated references and instead gathering information from the open web. For “Generate a summary about Echo School (Ore- gon) including the following aspects: academics, history.”, the output we aim to generate is “# Aca- demics. In 2008, 91% of