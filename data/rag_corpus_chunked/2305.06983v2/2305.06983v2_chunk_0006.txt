we focus on examining various methods of determin- ing when and what to retrieve, we follow exist- ing methods (Ram et al., 2023; Trivedi et al., 2022) to prepend the retrieved documents before the user input to aid future generation for both baselines and our method for fair comparisons: y = LM([Dq, x]), where [·, ·] is concatenation fol- lowing the specified order. 2.2 Single-time Retrieval Augmented Generation The most common choice is to directly use the user input as the query for retrieval and generate the complete answer at once y = LM([Dx, x]). 2.3 Active Retrieval Augmented Generation To aid long-form generation with retrieval, we pro- pose active retrieval augmented generation. It is a generic framework that actively decides when and what to retrieve through the generation process, resulting in the interleaving of retrieval and genera- tion. Formally, at step t(t ≥ 1), the retrieval query qt is formulated based on both the user input x and previously generated output y<t = [y0, ..., yt−1]: qt = qry(x, y<t), where qry(·) is the query formulation function. At the beginning (t = 1 ), the previous generation is empty (y<1 = ∅), and the user input is used as the initial query (q1 = x). Given retrieved documents Dqt, LMs continually generate the answer until the next retrieval is triggered or reaches the end: yt = LM([Dqt, x, y<t]), where yt represents the generated tokens at the cur- rent step t, and the input to LMs is the concatena- tion of the retrieved documents Dqt, the user input x, and the previous generation y<t. We discard previously retrieved documents ∪t′<tDqt′ and only use the retrieved documents from the current step to condition the next generation to prevent reaching the input length limit of LMs. 3 FLARE: Forward-Looking Active REtrieval