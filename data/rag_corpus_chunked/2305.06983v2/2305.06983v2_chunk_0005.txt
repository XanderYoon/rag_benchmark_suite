contains low-probability tokens and regenerate the next sentence until reaches the end. FLARE is applicable to any existing LMs at inference time without additional training. Con- sidering the impressive performance achieved by GPT-3.5 (Ouyang et al., 2022) on a variety of tasks, we examine the effectiveness of our meth- ods on text-davinci-003. We evaluate FLARE on 4 diverse tasks/datasets involving generating long outputs, including multihop QA (2WikiMul- tihopQA), commonsense reasoning (StrategyQA), long-form QA (ASQA), and open-domain summa- rization (WikiAsp) (Ho et al., 2020; Geva et al., 2021; Stelmakh et al., 2022; Hayashi et al., 2021). Over all tasks, FLARE achieves superior or com- petitive performance compared to single-time and multi-time retrieval baselines, demonstrating the effectiveness and generalizability of our method. 2 Retrieval Augmented Generation We formally define single-time retrieval augmented generation and propose the framework of active retrieval augmented generation. 2.1 Notations and Definitions Given a user input x and a document corpus D = {di}|D| i=1 (such as all Wikipedia articles), the goal of retrieval augmented LMs is to generate the answer y = [s1, s2, ..., sm] = [ w1, w2, ..., wn] containing m sentences or n tokens leveraging information retrieved from the corpus. In retrieval augmented LM, the LM typically pairs with a retriever that can retrieve a list of documents Dq = ret(q) for a query q; the LM conditions on both the user input x and retrieved documents Dq to generate the answer. Since we focus on examining various methods of determin- ing when and what to retrieve, we follow exist- ing methods (Ram et al., 2023; Trivedi et al., 2022) to prepend the retrieved documents before the user input to aid future generation for both baselines and our method for fair comparisons: y = LM([Dq, x]), where [·, ·] is concatenation fol- lowing