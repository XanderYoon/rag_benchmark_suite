2023; Chowd- hery et al., 2022; Zhang et al., 2022; Touvron et al., 2023; Zhao et al., 2023) have become a founda- tional component in natural language processing (NLP) systems with their remarkable abilities. Al- though LMs have memorized some world knowl- edge during training (Petroni et al., 2019; Roberts et al., 2020; Jiang et al., 2020), they still tend to ∗Lead contributors. 1Code and datasets are available athttps://github.com/ jzbjyb/FLARE. hallucinate and create imaginary content (Maynez et al., 2020; Zhou et al., 2021). Augmenting LMs with retrieval components that look up relevant in- formation from external knowledge resources is a promising direction to address hallucination (Khan- delwal et al., 2020; Izacard et al., 2022). Retrieval augmented LMs commonly use a retrieve-and-generate setup where they retrieve doc- uments based on the user’s input, and then generate a complete answer conditioning on the retrieved documents (Chen et al., 2017; Guu et al., 2020; Lewis et al., 2020; Izacard and Grave, 2021; Sachan et al., 2021; Lee et al., 2021; Jiang et al., 2022; Izacard et al., 2022; Nakano et al., 2021; Qian et al., 2023; Lazaridou et al., 2022; Shi et al., 2023). These single-time retrieval augmented LMs outper- form purely parametric LMs, particularly for short- form knowledge-intensive generation tasks such as factoid question answering (QA) (Kwiatkowski et al., 2019; Joshi et al., 2017), where the informa- tion needs are clear in the user’s input, and it is sufficient to retrieve relevant knowledge once solely based on the input. Increasingly powerful large LMs have also demonstrated abilities in more complex tasks that involve generating long-form output, such as long- form QA (Fan et al., 2019; Stelmakh et al., 2022), open-domain summarization (Cohen et al., 2021; Hayashi et al., 2021; Giorgi et al., 2022), and (chain-of-thought; CoT) reasoning (Wei et al., 2022; Ho