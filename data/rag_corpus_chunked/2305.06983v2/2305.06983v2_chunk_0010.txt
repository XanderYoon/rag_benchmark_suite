we actively trigger retrieval if any token of ˆst has a probability lower than a threshold θ ∈ [0, 1]. θ = 0 means retrieval is never triggered, while θ = 1 triggers retrieval every sentence. yt = ( ˆst if all tokens of ˆst have probs ≥ θ st = LM([Dqt, x, y<t]) otherwise where the query qt is formulated based on ˆst. 3.2.2 Confidence-based Query Formulation One way to perform retrieval is to directly use the next sentence ˆst as the query qt. This shares a sim- ilar spirit with methods that use generated hypo- thetical titles or paragraphs from LMs as retrieval queries or evidences (Gao et al., 2022; Sun et al., 2022; Yu et al., 2022; Mao et al., 2021). We gen- eralize such techniques to long-form generation where active information access is essential. We found retrieving with the next sentence achieves significantly better results than with the previous context, as shown later in subsection 6.2. However, it has a risk of perpetuating errors con- tained in it. For example, if the LM produces the sentence “Joe Biden attended the University of Pennsylvania” instead of the correct fact that he attended the University of Delaware, using this er- roneous sentence as a query might retrieve mislead- Joe Biden attended the University of Pennsylvania, where he earned a law degree. Ask a question to which the answer is “the University of Pennsylvania”Ask a question to which the answer is “a law degree” What university did Joe Biden attend?What degree did Joe Biden earn? implicit query by maskingexplicit query by question generationJoe Biden attended , where he earned . LM such as ChatGPT Figure 3: Implicit and explicit query formulation. To- kens with low probabilities are marked with underlines. ing information. We propose two simple methods to overcome