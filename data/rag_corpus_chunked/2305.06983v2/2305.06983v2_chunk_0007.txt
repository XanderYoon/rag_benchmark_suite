step t, and the input to LMs is the concatena- tion of the retrieved documents Dqt, the user input x, and the previous generation y<t. We discard previously retrieved documents ∪t′<tDqt′ and only use the retrieved documents from the current step to condition the next generation to prevent reaching the input length limit of LMs. 3 FLARE: Forward-Looking Active REtrieval Augmented Generation Our intuition is that (1) LMs should only retrieve information when they do not have the necessary knowledge to avoid unnecessary or inappropriate retrieval, and (2) the retrieval queries should reflect the intents of future generations. We propose two forward-looking active retrieval augmented gener- ation (FLARE) methods to implement the active retrieval augmented generation framework. The first method prompts the LM to generate retrieval queries when necessary while generating the an- swer using retrieval-encouraging instructions, de- noted as FLAREinstruct. The second method directly uses the LM’s generation as search queries, denoted as FLAREdirect, which iteratively generates the next sentence to gain insight into the future topic, and if uncertain tokens are present, retrieves relevant documents to regenerate the next sentence. 3.1 FLARE with Retrieval Instructions Inspired by Toolformer (Schick et al., 2023), a straightforward way of expressing information needs for retrieval is to generate “[Search(query)]” when additional information is needed (Schick et al., 2023), e.g., “The colors on the flag of Ghana have the following meanings. Red is for [Search(Ghana flag red meaning)] the blood of mar- tyrs, ...” When working with GPT-3.5 models that Search results: !![1]: …[2]: … Joe Biden attended Search results: !"![1]: …[2]: …Search results: !""[1]: …[2]: … [Search(Joe Biden University)] [Search(Joe Biden degree)]the University of Pennsylvania, where he earned a law degree. Generate a summary about Joe Biden.Input$ &$ &#%$ &%%%Generation Retriever $ %$ %% Figure 2: An illustration of forward-looking active re-