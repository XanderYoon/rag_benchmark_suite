robustness of HPO over diverse domains and evaluation metrics. Also evident is that the difficulty of the optimization prob- lem varies between datasets. For instance, in ClapNQ con- vergence is rather slow. For MiniWiki, which is rich in good performing configurations (see Figure 2), finding a top con- figuration is easier, with an effective HPO algorithm such as Greedy-M, as few as three iterations can yield a top RAG configuration (by selecting the optimal generative model early). In contrast, even in this easy scenario, a method like Greedy-R-CC converges slower then the alternatives. This underscores the importance of the HPO algorithm choice. Among greedy methods, the order of parameter optimiza- tion is critical. The results show that algorithms starting with optimizing retrieval-related parameters first (Greedy-R and Greedy-R-CC) require more iterations to find good configu- rations. Interestingly, the naive option of random sampling also finds a good RAG configuration after a small number of it- erations. That is likely due to the large impact of the gener- ative model choice on performance, as reflected by the fast convergence achieved by the Greedy-M approach. The complex TPE algorithm was found to be roughly equivalent in quality to random choice. In larger or continu- ous spaces, TPE may offer greater advantages. Impact of Metric Choice The results of Greedy-M in Figure 3 show performance is boosted significantly when the generative model parameter is optimized first, suggesting its importance. We therefore further investigate the best performing model in each setup. 15Answer faithfulness follow similar trends, see Appendix D. 1 2 3 4 5 6 7 8 9 10 # Iterations 0.5 0.6RAGAS AC AIArxiv 1 2 3 4 5 6 7 8 9 10 # Iterations 0.500 0.525 0.550 0.575RAGAS AC BioASQ 1 2 3 4 5 6 7 8 9 10 # Iterations