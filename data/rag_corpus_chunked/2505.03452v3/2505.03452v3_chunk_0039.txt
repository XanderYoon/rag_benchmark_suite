Figure 12: Examples of benchmark entries in WatsonxQA. Given the next[document], create a[question]and[answer]pair that are grounded in the main point of the document, don’t add any additional information that is not in the document. The[question]is by an information-seeking User and the [answer]is provided by a helping AI Agent. [document]: [A WatsonxQA document example] # Response: [question]: What is a token limit? [answer]: Every model has an upper limit to the number of tokens in the input prompt plus the number of tokens in the generated output from the model (sometimes called context window length, context window, context length, or maximum sequence length.) ... [document]: Figure 13: The prompt used for synthetic data generation. The prompt consists of instruction followed byK= 3examples of document and generated QA. Table 11: Results of a likelihood ratio test for the grid-search results of the AIArxiv dataset (Lexical-AC metric) Main effect/Interactionχ 2 degrees of freedom p-value Generative model 1918 10≈0Embedding model 143 109.5×10 −26 Chunk size 68 81.4×10 −11 Chunk overlap 1.6 3 0.66K 90 63.7×10 −17 Generative model * Embedding model 6.6 4 0.16Embedding model * Chunk size 53 47.1×10 −11 Chunk size * Chunk overlap 0.27 2 0.87Generative model * K 26 42.8×10 −5 Table 12: Results of a likelihood ratio test for the grid-search results of the BioASQ dataset (Lexical-AC metric) Main effect/Interactionχ 2 degrees of freedom p-value Generative model 10487 10≈0Embedding model 610 101.3×10 −124 Chunk size 126 81.6×10 −23 Chunk overlap 3.3 3 0.35K 632 62.6×10 −133 Generative model * Embedding model 24 48.2×10 −5 Embedding model * Chunk size 58 47.9×10 −12 Chunk size * Chunk overlap 3.2 2 0.2Generative model * K 313 42.0×10 −66 Table 13: Results of a likelihood ratio test for the grid-search results of the ClapNQ dataset (Lexical-AC metric) Main effect/Interactionχ 2 degrees of