N.; Toledo, A.; Shnarch, E.; and Choshen, L. 2024. Ge- nie: Achieving Human Parity in Content-Grounded Datasets Generation. arXiv:2401.14367. Zhu, K.; Luo, Y .; Xu, D.; Wang, R.; Yu, S.; Wang, S.; Yan, Y .; Liu, Z.; Han, X.; Liu, Z.; and Sun, M. 2024. RAGEval: Scenario Specific RAG Evaluation Dataset Gen- eration Framework. arXiv:2408.01262. A WatsonxQA additional details As stated in the body of the paper, the WatsonxQA bench- mark includes75QA pairs and gold document labels, of which50were generated synthetically. The benchmark con- tains five fields: a question, a gold answer and, for comput- ing context relevance metrics, the gold passage id and its content. Some example benchmark entries are given in Fig- ure 12. Synthetic generation was operated using falcon-180b model, and then manually filtered and reviewed for quality - the methodology we used is detailed in Yehudai et al. (2024). The prompt used for the synthetic generation is detailed in Figure 13. B Search Space Selection The search space values for the parameters Chunk Size, Chunk Overlap and Top-K were chosen based on previous works: Chunk sizeWang et al. (2024c) used the values {128,256,512,1024,2048}. They reported that the values 256and512performed well (see Table 3 in Wang et al. (2024c)) in terms of faithfulness and relevancy. Lyu et al. (2024) used{64,128,256,512}. We chose three values {256,384,512}. Top-KFu et al. (2024) experimented with{1,3,5,7,9}, and Lyu et al. (2024) with{2,4,6,8,10}. We chose to use {3,5,10}. Chunk OverlapLyu et al. (2024) used {0%,10%,30%,50%,70%}. Others have not consid- ered this parameter. We used{0%,25%}. C Impact of specific parameters To test the impact of the different RAG pipeline parameter choices, we conduct statistical analyses over the grid-search results for each dataset. Specifically, we fit a linear mixed-effects model on the dataset results, where the per-example answer correctness is the dependent variable, the choice