gains of up to20% (see Figure 3, comparing the perfor- mance at the first and last iterations). While our experiments focus on core RAG components, the potential impact on more complex systems parametrized by larger search spaces is likely even greater. For example, exploring HPO in the context of multi-modal or agentic RAG pipelines seems a promising direction for future work. We showed that RAG HPO can be performed efficiently. Even without prior knowledge of the RAG pipeline param- eters, exploring a small subset of the configuration space is often sufficient. Simple strategies such as random sampling perform surprisingly well, while a greedy approach that pri- oritizes model selection outperforms the common practice of sequential optimization by pipeline order. Our results highlight the importance of the optimization objective choice, as different objective choices lead to differ- ent optimal RAG configurations. We further show that devel- opment set sampling can reduce the costs of HPO for RAG by orders of magnitude. With the use of the Greedy-M algo- rithm, the saved compute, at the mild cost of performance, may be attractive for many users. For practitioners interested in boosting the performance of their RAG pipelines, we strongly suggest the use of HPO, and offer the following recommendations. Carefully choose an optimization metric that reflects the goals of the appli- cation. With that, evaluate multiple configurations with ran- domly picked parameter values, this initial quick exploration is likely to give valuable gains. Next, improve efficiency by using a greedy HPO algorithm that optimizes model choices first, that will provide faster convergence. For large datasets, combine that algorithm with development set sampling to efficiently find a top-performing RAG configuration. Finally, we open-source our complete grid search results over the development and test sets for all datasets. 17 To our knowledge, we are the