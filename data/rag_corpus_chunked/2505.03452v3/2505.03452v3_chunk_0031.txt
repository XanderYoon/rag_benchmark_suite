used {0%,10%,30%,50%,70%}. Others have not consid- ered this parameter. We used{0%,25%}. C Impact of specific parameters To test the impact of the different RAG pipeline parameter choices, we conduct statistical analyses over the grid-search results for each dataset. Specifically, we fit a linear mixed-effects model on the dataset results, where the per-example answer correctness is the dependent variable, the choice of generative model, em- bedding model, chunk size, chunk overlap and retrieved K are the fixed effects we test for, and the individual examples are modeled as a random effect. In addition to the main ef- fects, we include in our model possibleinteractioneffects: between the embedding model and the generative model, be- tween the embedding model and the chunk size, between the chunk size and chunk overlap, and between the generative model and the retrieved K. To assess the significance of each of the tested main ef- fects and interactions, we performed likelihood ratio tests, comparing the full mixed-effects model to a reduced model that excludes a specific main effect or interaction. We report the resulting test statisticsÏ‡ 2 and significance valuespfor each dataset in Tables 6-15. As can be seen in the tables, most of the effects and interactions are statistically signifi- cant (p < .05), indicating that these choices do indeed affect the pipeline result. Consistently, the choice of the generative model has a particularly large effect, explaining much of the variance of the statistical model. In addition, for each dataset and metric we report the marginal means for each chosen pipeline parameter, and their delta from the overall mean metric result. As can be seen in Tables 16-20, the largest differences in the metric scores relate to the choice of generative model. In addition, the relative success of the different generative models de- pends on the chosen