number of iterations and returns the best performing configuration. An efficient HPO algorithm identifies a top- performing configuration with minimal iterations. We examine two categories of HPO algorithms: (i) stan- dard HPO algorithms that are not specifically tailored to RAG; (ii) RAG-aware greedy algorithms that leverage some knowledge of the components within the optimized RAG pipeline. All algorithms optimize answer correctness unless explicitly noted otherwise. Standard algorithmsOur first standard HPO algorithm isTPE, using an implementation from hyperopt (Bergstra, Yamins, and Cox 2013), with five random initialization iter- ations, and otherwise the default settings. The second algo- rithm (Random) disregards results from prior iterations and uniformly selects an unexplored RAG configuration. RAG-Aware greedy algorithmsThe second category of algorithms assumes an ordered list of search space param- eters ranked by their presumed impact on RAG perfor- mance. These algorithms take a greedy approach: they it- erate through the parameters list, optimizing one parame- ter at a time, assuming that optimizing high impact param- eters first accelerates convergence to a strong configuration. When optimizing a parameterp, the algorithm uses fixed values for all preceding parameters and evaluates all possi- ble values pfp, with random values assigned to all following parameters. The value ofpyielding the best objective score is picked, and the algorithm continues to the next parameter. The greedy algorithms differ solely in their parame- ter ordering.Model-first ordering(Greedy-M) optimizes the generative and embedding models first, assuming they are more important: Generative Model, Embedding Model, Chunk Size, Chunk Overlap, Top-K.Retrieval- first(Greedy-R) is a prevalent option following the RAG pipeline structure, starting with retrieval optimization (still with model first), then generation: Embedding Model, Chunk Size, Chunk Overlap, Generative Model and Top- K.Retrieval-first with context correctness(Greedy-R-CC) uses the same order, yet optimizes the retrieval-related pa- rameters with a context correctness metric evaluated solely on the retrieval