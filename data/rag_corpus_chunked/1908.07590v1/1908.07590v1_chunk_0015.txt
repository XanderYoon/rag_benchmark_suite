that it is important to study the signals contained in a larger range than one single sentence. One promising way is to apply the neural network to exploit the information on the sentence level and circumvent onerous feature engineering work if more data is available. REFERENCES [1] Yue Cao, Mingsheng Long, Jianmin Wang, and Shichen Liu. 2017. Collective Deep Quantization for Efficient Cross-Modal Retrieval.. In AAAI, Vol. 1. 5. [2] Gal Chechik, Eugene Ie, Martin Rehn, Samy Bengio, and Dick Lyon. 2008. Large- scale content-based audio retrieval from text queries. In Proceedings of the 1st ACM international conference on Multimedia information retrieval. ACM, 105–112. [3] David Doukhan, Albert Rilliard, Sophie Rosset, Martine Adda-Decker, and Christophe d’Alessandro. 2011. Prosodic analysis of a corpus of tales. In Twelfth Annual Conference of the International Speech Communication Association . [4] Cuicui Kang, Shiming Xiang, Shengcai Liao, Changsheng Xu, and Chunhong Pan. 2015. Learning consistent feature representation for cross-modal multimedia retrieval. IEEE Transactions on Multimedia 17, 3 (2015), 370–381. [5] Richard F Lyon, Martin Rehn, Samy Bengio, Thomas C Walters, and Gal Chechik. 2010. Sound retrieval and ranking using sparse auditory representations. Neural computation 22, 9 (2010), 2390–2416. [6] Raúl Montaño and Francesc Alías. 2016. The role of prosody and voice quality in indirect storytelling speech: Annotation methodology and expressive categories. Speech Communication 85 (2016), 8–18. [7] Raúl Montaño, Francesc Alías, and Josep Ferrer. 2013. Prosodic analysis of storytelling discourse modes and narrative situations oriented to Text-to-Speech synthesis. In Eighth ISCA Workshop on Speech Synthesis . [8] Stephen Robertson, Hugo Zaragoza, et al . 2009. The probabilistic relevance framework: BM25 and beyond. FTIR 3, 4 (2009), 333–389. [9] Emma Rodero. 2012. See it on a radio story: Sound Effects and Shots to Evoked Imagery and Attention on Audio Fiction. Communication research 39, 4 (2012). [10]