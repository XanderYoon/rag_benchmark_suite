the confidence of the connections, there are on average 4.61 candidate triggers labeled with confidence larger than 0, which implies that 1.64 candidate triggers in each story do not indicate real sound effects on the semantic level. Continuing our analysis, we divide text-triggered sound effects into four categories: action- triggered sound, scene-triggered sound, character-triggered sound, and onomatopoeia-triggered sound. As expected, the onomatopoeia- triggered sound has the highest confidence of 91.2%, which sug- gests that most of the retrieved results are correct. However, when it comes to scene-triggered sound, only 57.9% of the candidate triggers are labeled confident to represent a sound effect. Many non-ideal situations could happen, such as those listed in Table 1. Preliminary results of keyword-based retrieval reveal that a great coverage rate can be achieved with the tag-sound database. Then the remaining question is that relying on the retrieval results will give rise to low precision. The cause behind this is that machines do not understand whether the scenes indicated by the words are truly happening in the story world. Suppose that we have a sentence W1:n and a known candidate trigger Wi:j given by the retrieval model where 1 ≤ i ≤ j ≤ n, our task is to determine whetherWi:j is referring to an effective sound effect on the semantic level based on the context W1:n. In our experiments, we will focus on the Wi:j in scene-triggered sound effects, since it is the most difficult category. 3 SEMANTIC INFERENCE MODEL Based on the previous discussions, retrieving sound effects using only keywords is not sufficient to guarantee the robustness of re- sults. Instead, the whole context should be considered when adding the sound effects to a story. In this section, we introduce a model with fine-designed features that can make inference about the ne- cessity of