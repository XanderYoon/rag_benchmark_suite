Yu. 2024. Towards Weakly Supervised Text-to-Audio Grounding. arXiv preprint arXiv:2401.02584 (2024). [40] Xuenan Xu, Mengyue Wu, and Kai Yu. 2023. Investigating Pooling Strategies and Loss Functions for Weakly-Supervised Text-to-Audio Grounding via Contrastive Learning. In International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW). [41] Xuenan Xu, Xiaohang Xu, Zeyu Xie, Pingyue Zhang, Mengyue Wu, and Kai Yu. 2024. A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). [42] Dongchao Yang, Jianwei Yu, Helin Wang, Wen Wang, Chao Weng, Yuexian Zou, and Dong Yu. 2023. Diffsound: Discrete Diffusion Model for Text-to-Sound Generation. IEEE/ACM Transactions on Audio, Speech, and Language Processing 31 (2023). [43] Ching-Feng Yeh, Po-Yao Huang, Vasu Sharma, Shang-Wen Li, and Gargi Gosh. 2023. Flap: Fast Language-Audio Pre-Training. In Automatic Speech Recognition and Understanding Workshop (ASRU).