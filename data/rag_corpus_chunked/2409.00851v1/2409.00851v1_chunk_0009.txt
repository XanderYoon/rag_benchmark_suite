the five text descriptions matches the audio clip, it counts as 100% retrieval accuracy. Figure 2: Distribution of temporal conjunctions and prepo- sitions in the full AudioCaps [ 16] dataset. Most temporal sentences contain future temporal cues, such as ‘Followed by’. There is only a small proportion ofpast cues, e.g. ‘Before’. Figure 3: Distribution of temporal conjunctions and preposi- tions in the full Clotho [ 9] dataset. Most temporal sentences contain joint cues (e.g. ‘As’, ‘While’), followed byfuture ones (e.g. ‘Then’). Fewer sentences containpast cues (e.g. ‘Before’). The AudioCaps dataset is employed in all related text-to-audio retrieval works for training and evaluation. We want to understand the temporal characteristics of the AudioCaps dataset to gauge if the data available for training text-to-audio retrieval models is a part of the problem of models not understanding temporal cues [34]. First, we analyse the distribution of temporal conjunctions and prepositions in all the audio captions in the AudioCaps dataset in Fig. 2. We observe that most conjunctions and temporal preposi- tions suggest future events, i.e. ‘Followed by’, ‘Then’. This is closely followed by the joint occurrence of audio events, i.e. ‘As’ and ‘While’. However, almost no examples contain the temporal prepositions ‘Before’ or ‘Preceded by’ which is reasonable as humans would not naturally describe events in that order. A similar analysis is per- formed by [34], providing the distribution for ‘Followed by’, ‘Then’, MM ’24, October 28-November 1, 2024, Melbourne, VIC, Australia Oncescu, et al. ‘Before’ and ‘After’. However, in [34], this distribution describes their training and test data which combines multiple datasets in- cluding AudioCaps [16] and Clotho [9]. Here, we consider all words in the AudioCaps descriptions that represent temporal ordering. Given the distribution in Fig. 2, expecting a model trained on this data to understand the meaning of reverse temporal