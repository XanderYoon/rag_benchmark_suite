48.04 61.74 TempTestğ‘Ÿğ‘’ğ‘£ 47.29 62.29 TempTestğ‘Ÿğ‘’ğ‘ 47.24 62.23 only difference is that for the former, the actual positional text loca- tions of the sounds are swapped, whilst for the latter the meaning is reversed by changing the temporal connector. This leads us to believe that at best, the model learns text location-based ordering rather than the ordering given by the text connector. In the left- hand side of Tab.4 we observe a similar behaviour for the Clotho temporal test sets, with the model performing similarly well on TempTestğ‘Ÿğ‘’ğ‘ and a bit worse on TempTestğ‘Ÿğ‘’ğ‘£ . This indicates that the model at best learns the text location-based ordering, but does not really understand temporal cues. We do the same experiments on the test sets of AudioCapsğ‘¢ğ‘›ğ‘– and find that the model is unable to identify the text-based order of sound events, with results on â€˜correctâ€™ (TempTest) and â€˜wrongâ€™ (TempTestğ‘Ÿğ‘’ğ‘£ and TempTestğ‘Ÿğ‘’ğ‘ ) splits being comparable. This is due to the test set not being biased anymore towards future events. Next, we examine whether the modelâ€™s understanding of tem- poral ordering is limited due to a lack of variety in the training examples. We take the same pre-trained model as before [24], and finetune it on the ğ´ğ‘¢ğ‘‘ğ‘–ğ‘œğ¶ğ‘ğ‘ğ‘  ğ‘¢ğ‘›ğ‘– ğ‘‡ ğ‘Ÿğ‘ğ‘–ğ‘›ğ‘¢ğ‘›ğ‘– set. We notice that the overall performance on the ğ´ğ‘¢ğ‘‘ğ‘–ğ‘œğ¶ğ‘ğ‘ğ‘  ğ‘¢ğ‘›ğ‘– test sets and the corre- sponding temporal subsets is higher when finetuning on a more uniform distribution of temporal cues (left half of Tab. 5) than when finetuning on the original training data (bottom of Tab. 3). Thus, the lack of understanding temporal ordering is in part due to the train- ing data not containing examples of past temporal cues. We also notice some signs of better temporal understanding, with a slightly bigger drop in performance on the TempTestğ‘Ÿğ‘’ğ‘£ and