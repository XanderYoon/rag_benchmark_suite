whilst preserving the content (AudioCapsğ‘¢ğ‘›ğ‘– ). Furthermore, we investigate the impact of more uniform training data on the text-to-audio retrieval performance, reporting results on the original test data and on rephrased test data (TempTestğ‘Ÿğ‘’ğ‘£ and TempTestğ‘Ÿğ‘’ğ‘ ). The rephrasing of text descriptions is illustrated in Fig. 1. Furthermore, we present an empirical evaluation of the correct- ness and completeness of AudioCaps descriptions by leveraging a Large Language Model (LLM). More specifically, we provide an LLM with (a subset of) AudioCaps descriptions and the start and end times of the sounds that make up the audio files (provided by [38]). We ask the LLM to classify the sentences into correct â€“ if the descrip- tion contains all the sounds and the correct ordering, incomplete â€“ if the description is missing sounds or is missing temporal con- text, and incorrect â€“ if the description contradicts the provided grounded sounds. We observe that about 23% of the descriptions arXiv:2409.00851v1 [cs.IR] 1 Sep 2024 MM â€™24, October 28-November 1, 2024, Melbourne, VIC, Australia Oncescu, et al. Figure 1: Analysing and improving the understanding of temporal cues in text-to-audio retrieval model. Top left: AudioCaps ğ‘¢ğ‘›ğ‘– is a variant of the AudioCaps dataset with modified descriptions that have a more uniform distribution of textual temporal cues. Additionally (bottom left), we generate test sets with reversed temporal ordering or replaced temporal conjunctions (TempTestğ‘Ÿğ‘’ğ‘£ and TempTestğ‘Ÿğ‘’ğ‘ ). Middle: Generation of audio-text pairs in the SynCaps dataset that provides a controlled evaluation setting. Right: Our text-text contrastive loss improves temporal understanding using positive descriptions (green) for the same sound ordering and negative examples (red) for the opposite temporal meaning. are incomplete or incorrect. This can contribute to models trained on AudioCaps not being able to understand temporal ordering. To gain further insights into the temporal understanding capa- bilities, we