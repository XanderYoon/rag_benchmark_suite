additionally consider rev and rep subsets of the temporal subset TempTest. In Tab. 3, we take the checkpoint provided by [24] which was pre-trained on the WavCaps [24], AudioCaps [16], and Clotho [9], and finetune it on the original AudioCaps dataset (similar to [24]). We notice that on the reversed TempTestğ‘Ÿğ‘’ğ‘£ set the model per- forms worse, indicating that the model understands temporal or- dering. However, on TempTestğ‘Ÿğ‘’ğ‘ which contains the replacement of temporal cues, the model performs similarly to onTempTest. This is interesting, as the temporal ordering of both ğ‘‡ ğ‘’ğ‘šğ‘ğ‘‡ ğ‘’ğ‘ ğ‘¡ğ‘Ÿğ‘’ğ‘£ and TempTestğ‘Ÿğ‘’ğ‘ is reversed and wrong as compared to TempTest. The Dissecting Temporal Understanding in Text-to-Audio Retrieval MM â€™24, October 28-November 1, 2024, Melbourne, VIC, Australia Table 3: Text-to-audio retrieval and audio-to-text retrieval on the AudioCaps and AudioCaps ğ‘¢ğ‘›ğ‘– datasets for the model fine-tuned on AudioCaps (Train). We report retrieval accu- racies R@1. Reversing the order of events ( rev, rep) does not generally result in a drop in performance, showing that the model does not understand temporal ordering. Lower per- formance on TempTestğ‘Ÿğ‘’ğ‘£ might be due to the bias induced by data being described in a future fashion. When this bias is removed from the test set in AudioCaps ğ‘¢ğ‘›ğ‘– , reversing the order of events does not change performance. Eval Dataset Subset Tâ†’A A â†’T R@1 R@1 AudioCaps Test 43.71 55.44 TempTest 50.06 62.95 TempTestğ‘Ÿğ‘’ğ‘£ 44.11 57.27 TempTestğ‘Ÿğ‘’ğ‘ 49.12 63.12 AudioCapsğ‘¢ğ‘›ğ‘– Test 41.61 53.80 TempTest 48.04 61.74 TempTestğ‘Ÿğ‘’ğ‘£ 47.29 62.29 TempTestğ‘Ÿğ‘’ğ‘ 47.24 62.23 only difference is that for the former, the actual positional text loca- tions of the sounds are swapped, whilst for the latter the meaning is reversed by changing the temporal connector. This leads us to believe that at best, the model learns text location-based ordering rather than the ordering given by the