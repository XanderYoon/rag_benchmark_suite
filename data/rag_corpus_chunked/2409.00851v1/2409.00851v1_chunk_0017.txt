temporal cues of interest. We call this subset TempTest. MM â€™24, October 28-November 1, 2024, Melbourne, VIC, Australia Oncescu, et al. Figure 4: Distribution of temporal conjunctions and preposi- tions in the AudioCaps training data. We compare the propor- tion of temporal textual cues in the original training dataset (Train) and our proposed variant with a more uniform distri- bution of temporal textual cues ( ğ‘‡ ğ‘Ÿğ‘ğ‘–ğ‘›ğ‘¢ğ‘›ğ‘– ). Figure 5: Distribution of temporal conjunctions and preposi- tions in the AudioCaps [16] validation dataset (Val) compared to our proposed variant with a more uniform distribution of temporal textual cues (ğ‘‰ ğ‘ğ‘™ğ‘¢ğ‘›ğ‘– ). For Clotho, we use its original data in our experiments. Differ- ently from our AudioCaps experiments, we do not create a dataset variant with more uniformly distributed temporal conjunctions, since the â€˜futureâ€™ and â€˜pastâ€™ cues only account for less than 15% of the Clotho data. However, as for AudioCaps, we evaluate the model on multiple test subsets that allow us to analyse the temporal understanding capabilities. 3.3.5 Experiments. We consider three main experiments. First, we conduct the standard evaluation for text-to-audio retrieval on the AudioCaps and Clotho test sets. The performance on the standard Figure 6: Distribution of temporal conjunctions and preposi- tions in the AudioCaps [ 16] test dataset (Test) compared to our proposed variant with a more uniform distribution of temporal textual cues (ğ‘‡ ğ‘’ğ‘ ğ‘¡ğ‘¢ğ‘›ğ‘– ). test set serves as a point of reference for the training and evaluation on different variants of the data. The second experiment involves reversing the ordering of sounds in the text queries of the test set. We refer to this asğ‘‡ ğ‘’ğ‘ ğ‘¡ğ‘Ÿğ‘’ğ‘£ . The purpose of this experiment is to see what happens if the temporal text descriptions keep the same temporal preposition or conjunction but the sound sources are reversed,