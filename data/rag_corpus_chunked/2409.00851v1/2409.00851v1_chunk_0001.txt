VIC, Australia. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3664647.3681690 1 Introduction The continued improvement of models and the increase in data available have led to impressive advances on various text-video tasks [1, 2, 13, 15, 17, 20, 21] and text-audio tasks [10], including text- to-audio retrieval [5, 18, 24, 26, 31, 35, 43], audio captioning [8, 9, 22] and recently, text-to-audio generation [14, 19, 42]. Understanding details, such as the temporal ordering of events, is important if we want our systems to give the best search results or generate reliable content for a text query. Recently, [ 34] showed that text-audio models do not use temporal cues available in text-audio datasets. This work is licensed under a Creative Commons Attribution- NonCommercial International 4.0 License. MM ’24, October 28-November 1, 2024, Melbourne, VIC, Australia © 2024 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-0686-8/24/10 https://doi.org/10.1145/3664647.3681690 In this work, we build on [ 34] and examine the limitations of current state-of-the-art text-audio models, particularly in their use of temporal information. Different from [ 34] that considers a text-audio model containing a CNN-based audio encoder, our analysis uses the recent transformer-based audio encoder HTS- AT [4] that serves as a component of state-of-the-art text-to-audio retrieval models [24, 35]. We assess whether the model contain- ing a transformer-based audio encoder results in better temporal understanding abilities than a CNN-based one. Additionally, we investigate the experimental designs and datasets used to determine if poor temporal understanding in current state-of-the-art models is caused by the training data or by the model architecture. To determine whether commonly used text-audio datasets, such as AudioCaps [16] and Clotho [ 9], are suitable for training and evaluating the ability of current models to comprehend time, we examine the relative distribution of audio descriptions that con- tain temporal cues. In