and RS models are α = 10 −4. C. Relevance Score (RS) Performance To evaluate our RS score, we use test data to determine how accurately the RS model can detect samples with relevant text to a given image. Fig. 7 shows the score histogram of 2,000 test samples for either of positive and negative statements. The RS score is a number in interval [0, 1] and it is not straightforward to evaluate it with respect to an image and query since the dataset entries are only labeled as ‘relevant’ or ‘irrelevant’. Instead, we can form aRS-labeler by using a threshold 0 ≤ η ≤ 1 to make a hard decision as ‘relevant/irrelevant’ in order to evaluate its performance based on the evaluation dataset entries. One may also use the original LLaV A model with the same prompt used by RS model to form LLaVA-labeler. Table I displays the values for true detection (TD) of relevant samples (denoted as true0) and irrelevant samples (denoted as true1), as well as overall accuracy of the labeling for both RS-labeler with optimized threshold η = 0 .7 and LLaV A-labeler. Table I indicates that our model compared to the original LLaV A has greater confidence in determining the relevance of the image to the query as the probability of true detection for both relevant (true0) and irrelevant (true1) Fig. 7. RS model performance on test data. samples and hence the overall accuracy for RS-labeler is higher. TABLE I PERFORMANCE EVALUATION OF SCORING MODELS . Model Accuracy true0 true1 LLaV A 0.724 0.695 0.746 RS model 0.865 0.909 0.831 VILA 0.732 0.710 0.734 CS model 0.875 0.940 0.806 Fig. 8 illustrates the effect of changing the threshold on true0, true1, and accuracy. As shown, there is a trade-off: for example, if the threshold is