the range of [0, 1] for any given statement and image, we modify the RLHF loss function as follows: L = − log (σ (y−1(I, sp)) − σ (y−1(I, sn))) , (1) where σ is our softmax operator. During the inference, given a pair of (I, q), we can obtain the RS as: RS = σ (y−1(I, q)) . (2) C. Correctness Score (CS) Model When the RAG response is generated, we apply the partition mechanism above to break the entire generated response r into the spans, in here atomic statements {si}L i−1 where L is the number of spans. For each of the atomic statements, we use the categorization algorithms mentioned above and mark the statements as subjective or objective. For objective statements, we use CS models to obtain its correctness score. For each atomic statement, the CS model has access to all retrieved images along with the statement for the correctness measure evaluation. In terms of structure, the difference between the CS model and the RS model is its ability to work with multiple images rather than a single image. Hence, we exploit VILA instead of the LLaV A model and to simplify training, we adopt the weight from the VILA model in Fig. 5 for the CS model. The reason for this is that LLaV A is not originally trained on multiple images, which limits its performance when it makes inferences on multiple images. This in turn affects the performance of the CS score which is the fine-tuned model with a dedicated LM head. In contrast, VILA has a similar structure to the LLaV A model but is trained specifically for multi-image inference. The training process for the dedicated LM head in our CS model is similar to that of the RS model. The template that we