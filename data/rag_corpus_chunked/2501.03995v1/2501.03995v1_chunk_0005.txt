a RAG system and producing a relevancy score (RS) between each selected piece and the query. For example, when an image (or text) is selected, RS evaluates how relevant the retrieved image (or text) is to the user query. By assigning a relevancy score to each image, we can determine how well the visual data aligns with the user’s intent and the specific information requested. (ii) Second, we design an algorithm to partition the output response by the RAG into segments, namely spans, and categorize each span. The span may be defined as statements, phrases, etc. Some spans may not be scorable, e.g., if it is based on personal opinions or feelings rather than on facts. Alternatively, a span is not scorable if it states an analysis say in a conditional statement, or expresses the uncertainty such as the possibility or probability of something being true. We label such statements as “subjective” which have been also referred to as “analysis” statement type in the prior-art [12]. A span that is not “subjective”, i.e., it is scorable, is labeled as “objective”. (iii) Third, we design and train a neural network structure which assesses the correctness of each objective span in the view of the raw context defined as the selected pieces of the data by the RAG. We note that in multi-modal RAG, the raw context may be first converted to text-based context, e.g., by using VLM for the images, and then text-based context will be used by an LLM to generate the response based on the query. Alternatively, the raw context may be directly fed to a MLLM to generate the response based on the query. Irrespective of the internal structure of the RAG system, the CS assesses the accuracy of each span of the generated text with the raw