in NIPS, 2024. [4] W. Dai, J. Li, D. LI, A. Tiong, J. Zhao, W. Wang, B. Li, P. N Fung, and S. Hoi. Instructblip: Towards general-purpose vision-language models with instruction tuning. In Advances in NIPS , 2023. [5] J. Lin, H. Yin, W. Ping, P. Molchanov, M. Shoeybi, and S. Han. Vila: On pre-training for visual language models. In CVPR, 2024. [6] G. Team, R. Anil, S. Borgeaud, Y . Wu, J. B. Alayrac, J. Yu, R. Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. [7] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal, H. K¨uttler, M. Lewis, W. Yih, T. Rockt¨aschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in NIPS , 2020. [8] S. Min, K. Krishna, X. Lyu, M. Lewis, W. Yih, P. W. Koh, M. Iyyer, L. Zettlemoyer, and H. Hajishirzi. Factscore: Fine-grained atomic evaluation of factual precision in long form text generation. arXiv preprint arXiv:2305.14251, 2023. [9] Y . S. Chuang, L. Qiu, C. Y . Hsieh, R. Krishna, Y . Kim, and J. Glass. Lookback lens: Detecting and mitigating contextual hallucinations in large language models using only attention maps. arXiv preprint arXiv:2407.07071, 2024. [10] Y . F. Bakman, D. N. Yaldiz, B. Buyukates, C. Tao, D. Dimitriadis, and S. Avestimehr. Mars: Meaning-aware response scoring for uncertainty estimation in generative llms. arXiv preprint arXiv:2402.11756 , 2024. [11] S. Es, J. James, L. Espinosa-Anke, and S. Schockaert. Ragas: Au- tomated evaluation of retrieval augmented generation. arXiv preprint arXiv:2309.15217, 2023. [12] A. Gunjal, J. Yin, and E. Bas. Detecting and preventing hallucinations in large vision language models. In AAAI, 2024. [13] L. Jing, R. Li, Y . Chen, M. Jia, and X. Du. Faithscore: Evaluat- ing