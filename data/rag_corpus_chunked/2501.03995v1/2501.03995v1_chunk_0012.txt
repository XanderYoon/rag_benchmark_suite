RAG by focusing on the similarity between different data modalities. Specifically, we focus on text-based queries and enterprise data which consists of images. We aim to obtain the RS between the query and each of the raw context (image) from the enterprise database separately. Therefore, we design and train a model that receives an image and query as an input and returns a score as a measure of the relevancy between an image and the query. Even though the relevancy is measured by cosine similarity between the embeddings in RAG, this approach is arguably not optimal. Based on the current state-of-the-art, relevancy can be better examined by performing cross-attention between the query and the image in a transformer as in Fig. 4. Successive cross-attention units in the transformer integrate the query with the information from the image patches, and through training, such structure can outperform the use of cosine similarity between the embeddings of the query and image. Nonetheless, this approach incurs significant complexity, e.g., the calculation of RS in our design using the same GPU machine is 35 times slower than the computation of the cosine similarity. This is the primary reason that the RAG system relies on cosine similarity to search the enterprise data (through stored embedding in a vector database that is produced in a preprocessing stage). Once the transformer module is designed properly, its output contains valuable information about the relevancy between Fig. 4. General structure to quantify relevancy of image to query. the query and the image. At this point, a neural network head is trained to extract this information out of the produced embedding by the cross-attention module in the form of a single real number between zero (representing no relevance) and one (representing complete relevance). Fig. 5. RS model structure. Hence, to train