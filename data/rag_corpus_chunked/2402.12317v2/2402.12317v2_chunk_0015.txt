evolve neither of them (skip line 7, 13-20 in Algorithm 1, and terminate in a single iteration). We adopt the default setting in §3.2 except the specified changed in the algorithm. Table 3 shows evolving either queries or knowledge significantly enhances the results, highlighting that knowledge evolution also contributes to improving RACG in addition to the query rewriting. By ap- plying the synchronous evolution of both queries and knowledge, EVOR consistently outperforms evolving either of them by large margins across all datasets in EVOR-BENCH . This suggests the com- plementary strength of synchronous evolution for eliciting the best performance of LLMs in RACG. 4.2 Diverse Knowledge To understand the influence of diverse knowledge sources on EVOR, we conduct an ablation study by constraining the types of knowledge in the retrieval pool. Specifically, we construct the knowledge soup K with only one of web search, execution feedback, code snippets and documentation. We also consider the pairwise combination of execu- tion feedback, code snippets and documentation, evolution (→) w/o evolution w/ evolution Knowledge (↓) ChatGPT CodeLlama ChatGPT CodeLlama None 8.6 7.3 - - Single Source Retrieval Web 9.7 7.5 10.6 8.2 Exec 11.7 7.4 13.8 9.1 Code 15.6 16.2 23.5 24.8 Doc 19.2 16.0 28.9 20.5 Knowledge Soup Retrieval Exec + Code 18.3 15.9 27.8 25.3 Exec + Doc 20.7 17.2 32.4 23.0 Code + Doc 21.8 19.6 33.5 31.2 Exec + Code + Doc 22.4 20.4 35.3 32.2 Table 4: The average performance of ChatGPT and CodeLlama with different knowledge sources. Web refers to web search, Exec refers to execution feedback, Code refers to code snippets and Doc refers to documen- tation. The results show that diverse types of knowledge enhance RACG performance, where the improvement is larger under the setting with evolution. and the setting where all of them are