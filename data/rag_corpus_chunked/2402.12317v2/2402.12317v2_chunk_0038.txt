length of 300 to them, as they are usually short; (4). For documenta- tion, always include other types of knowledge first, and include documentation to fill in the rest length. For example, if we want to include both documen- tation and code snippets as the knowledge source and the maximum context length is 4,096, we will allocate a maximum length of 300 to code snippets and a maximum length of 4,096-300-400=3,396 to the documentation. G Web Search As the artificially modified libraries are not avail- able online, we replace the documentation returned by web search with our modified version. In ad- dition, we heuristically update the content from web search based on our modifications, e.g., map keywords to the synonyms we use. In Figure 4, we present an example of the top-3 web search results returned by Google search to the query "In the programming language Pony, checks if the current element is less than the previous el- ement in the nums array". Due to the infrequent usage of the programming language Pony, there is little available resource online. The web search fails to identify the relevant knowledge piece. Even the specific instruction "programming language Pony" is given in the query, a guidance to solve the problem in C++ is included. In addition, the returned texts are long, complex, and diverse, mix- ing various types of knowledge sources including tutorials, blogs, and community Q&A discussions. LLMs may find it challenging to process and effec- tively utilize all of the information simultaneously. Finally, although we empirically remove some un- related information, e.g., remove the line that starts with âˆ— that is likely to be an irrelevant item list- ing, there is more that is hard to remove with just heuristics. This poses a great challenge to LLMs as they are burdened