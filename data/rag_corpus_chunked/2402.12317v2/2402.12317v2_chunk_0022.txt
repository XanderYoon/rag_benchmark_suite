the code. In this work, we utilize the executor to provide feedback and check code out- puts on syntax errors, which contributes to evolve both queries and knowledge in RACG. 6 Conclusion Much recent work illustrated the ability of LLMs to incorporate external knowledge with retrieval- augmented generation. We propose a novel pipeline, EVOR, which achieves two to four times execution accuracy compared to existing code gen- eration methods. Extensive experiments demon- strate that EVOR can be easily combined with them to provide further improvements, including the agent-based ones to solve challenging tasks such as repo-level code generation. Through an in- depth analysis, we further show the complementary strength of synchronous evolution of queries and documents in RACG, which enhances the model performance by larger margins with more diverse knowledge sources. We hope that our findings will inspire researchers and practitioners to develop ef- ficient and effective strategies in their customized code-generation tasks with LLMs. 7 Limitations Despite the effectiveness of EVOR in RACG, one limitation is that it requires multiple rounds of in- teractions among retrievers, LLMs, and executors to output the code answer. This iterative process can lead to longer latency and increased energy consumption, which are critical concerns in real- time applications and energy-constrained environ- ments. We hope that future work will design more efficient architectures or approaches to integrate LLMs seamlessly while maintaining or improving performance in RACG. Such advancements could significantly enhance the practicality and scalabil- ity of LLMs in realistic scenarios. 8 Potential Risk The use of retrieval-augmented code generation with large language models introduces several po- tential risks, primarily centered around the quality and relevance of the retrieved code snippets. There is a risk of biased or incorrect information being re- trieved, which could propagate errors or introduce vulnerabilities into generated code. Additionally,