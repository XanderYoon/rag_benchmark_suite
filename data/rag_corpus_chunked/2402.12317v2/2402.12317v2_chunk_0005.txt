2 , ..., f0 n]. Based on n, p0, I, and F 0, we prompt an LLM Mq to write a new query q1 on what knowledge is currently required. In general, given n, pi, I, and F i in the iteration i, Mq writes qi+1, which is used for retrieval in the iteration i + 1. 2.2 Knowledge Soup In this section, we first introduce the four compo- nents included in the construction of the knowledge soup K and then describe the process of its evolu- tion. 2.2.1 Construction We consider four types of knowledge as follows: Web search is a general and popular resource applied in traditional RAG applications. Human programmers frequently refer to it when they try to understand some syntax or fix a bug. It con- tains diverse information including blogs, tutori- als, and community Q&A discussions relevant to solving coding problems. Intuitively, it is valuable as human programmers frequently rely on search engines to seek assistance when struggling with coding challenges. Previous work (Nakano et al., 2021) has fine-tuned GPT-3 (Brown et al., 2020) to answer long-form questions using a text-based web-browsing environment. In this study, we inves- tigate the efficacy of LLMs in utilizing web search content to solve unfamiliar coding problems with- out further training. We use the Python API of Google search 1 to retrieve top-ranking websites and further convert the HTML page to markdown using the package html2text 2. In Appendix G, we include more discussions about the content in the web search. Documentation is commonly accessible upon the release of a new programming language or an updated library version. Official documentation serves to thoroughly elucidate the essential syn- tax and grammar required for coding. Zhou et al. (2022) demonstrated that language models can ef- fectively leverage code documentation after fine-