conduct extensive analyses and find that EVOR can be easily combined with existing code generation approaches including agent- based ones to provide further improvements. 2 Evolving Retrieval Given a question n in natural language, the ob- jective of retrieval-augmented code generation is to first retrieve relevant information K+ from ex- ternal knowledge K and then augment large lan- guage models to generate a program p in the tar- get library/programming language, which LLM M is not familiar with. Distinct from the clas- sical retrieval-augmented generation, which usu- ally focuses on static knowledge bases, we pro- pose synchronous evolution of both queries and diverse knowledge bases. Intuitively, this helps the retrieval model identify more relevant information and thus improves the quality of LLM generation (Shao et al., 2023). In this section, we present the process of query evolution (ยง2.1), the knowledge base construction and evolution (ยง2.2), the EVOR pipeline (ยง2.3) and the collection of EVOR-BENCH (ยง2.4). 2.1 Query evolution Starting from the given question n, we first go through a warmup iteration i0 where q0 = n is used as the query in retrieval. Conditioned on both n and the retrieved knowledge Kr, LLM M then generates a draft program p0. We apply the a compiler or interpreter to execute p0 on LLM- generated inputs I = [ i1, i2, ..., in] (more details on Appendix C), which provides execution feed- back F 0 = [f 0 1 , f 0 2 , ..., f0 n]. Based on n, p0, I, and F 0, we prompt an LLM Mq to write a new query q1 on what knowledge is currently required. In general, given n, pi, I, and F i in the iteration i, Mq writes qi+1, which is used for retrieval in the iteration i + 1. 2.2 Knowledge Soup