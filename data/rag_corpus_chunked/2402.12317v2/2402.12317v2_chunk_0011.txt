n without aug- menting external knowledge. MPSC: Huang et al. (2023) proposed Multi- Perspective Self-Consistency (MPSC) incorporat- ing both inter- and intra consistency. Following the original implementation, we prompt LLMs to generate diverse outputs from three perspectives: Solution, Specification and Test case, construct the 3-partite graph, and pick the optimal choice of so- lutions based on confidence scores. ExeDec: Shi et al. (2023a) introduced a decomposition-based synthesis strategy, where they employ a subgoal model to predict the subgoal of the desired program state for the next part of the program and use another synthesizer model to gen- erate the corresponding subprogram to achieve that 5https://platform.openai.com/docs/models/gpt-3-5-turbo 6https://huggingface.co/codellama/CodeLlama-34b- Instruct-hf Method Model: ChatGPT Model: CodeLlama Scipy-M Tensor-M Ring Pony Avg. Scipy-M Tensor-M Ring Pony Avg. Baseline Vanilla 17.6 11.1 3.7 1.8 8.6 11.3 17.8 0.0 0.0 7.3 MPSC 18.3 11.1 4.1 1.8 8.8 11.6 17.8 0.0 0.0 7.4 ExeDec 22.5 17.8 4.5 3.6 12.1 13.2 17.8 0.0 0.0 7.8 Reflexion 23.2 22.2 5.3 4.7 13.9 14.5 20.0 0.0 0.9 8.9 DocPrompting 32.4 33.3 8.4 2.7 19.2 16.9 37.8 4.7 4.4 16.0 Ours EVOR 37.9 53.3 36.6 13.5 35.3 31.2 53.3 26.7 17.4 32.2 EVOR + MPSC 38.6 55.6 37.8 15.6 36.9 33.6 55.6 27.3 18.4 33.7 EVOR + ExeDec 39.2 55.6 40.0 16.3 37.8 34.1 57.8 27.9 19.1 34.7 EVOR + Reflexion 39.4 55.6 39.2 17.3 37.9 35.3 55.6 28.6 18.8 34.6 Table 2: The performance of baseline methods,EVOR and their combinations inEVOR- BENCH . EVOR demonstrates significantly superior results, with further improvement when combined with other baseline methods. subgoal. Subprograms are finally combined as the output answer to solve the original coding problem. In experiments, we use ChatGPT as the subgoal model and compare LLMs to synthesize programs following the subgoal predictions. Reflexion: Shinn et al. (2024) uses a framework to reinforce