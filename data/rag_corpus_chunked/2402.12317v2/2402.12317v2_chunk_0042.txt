2022). As shown in Figure 5, across four datasets, when utilizing dense retrievers, ChatGPT signif- icantly enhances the performance achieved with a sparse retriever. Aligned with the results in the re- trieval benchmark (MTEB), ChatGPT consistently achieves the best performance when using SFR- Embedding-Mistral as the retrieval model. How- 8https://platform.openai.com/docs/guides/embeddings P 2k 4k 8k 12k 16k Context length 0 10 20 30 40 50Performance Scipy-M T ensorflow-M Ring Pony Figure 6: ChatGPT performance with various maxi- mum allowed context lengths. P refers to the baseline where no external knowledge is included. Although the model supports the context length up to 16k, the results reveal that the execution accuracy ceases to enhance when the context window is expanded from 4k to 16k. This suggests that augmenting ChatGPT with external knowledge beyond the 4k context does not yield further improvement in the generalization performance. ever, the gap between different dense retrievers is not significant. After considering both the perfor- mance and the cost, we opt for INSTRUCTOR- xl for efficient and cost-effective development of EVOR. I Long-context Model Besides the retrieval-based pipelines, long-context models are another alternative for LLMs to incor- porate massive external knowledge. The context window of Claude 2.19 and GPT-410 have reached 200k and 128k tokens respectively, which ques- 9https://www.anthropic.com/news/claude-2-1 10https://platform.openai.com/docs/models/gpt-4-and-gpt- 4-turbo tions the necessity to adopt RACG, where only a small portion of knowledge is retrieved and ex- posed to LLMs. Intuitively, LLMs benefit from larger context windows, as they can utilize more external knowledge to enhance their coding. How- ever, our experiments do not imply the case. We adopt the default setting of EVOR, but only change the maximum context length of LLMs to 2k, 4k, 8k, 12k, and 16k tokens. Figure 6 indi- cates that ChatGPT achieves the best performance when only using external knowledge of