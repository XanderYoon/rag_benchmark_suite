results when more types of knowledge are integrated. For example, with- out queries and knowledge evolution, ChatGPT archives 6.2% higher average performance by us- ing both code snippets and documentation as the knowledge sources, compared to only employing the code snippets. This indicates the advantage of diverse knowledge soup in enhancing the RACG performance of LLMs. On the other hand, by evolving both queries and knowledge or only evolving queries, both Chat- GPT and CodeLlama achieve significantly larger improvements when the knowledge soup becomes more diverse. For example, when the documen- tation is further included in the knowledge soup on top of the execution feedback and the code snippets, CodeLlama enhances the average result from 15.9% to 20.4% (+4.5%) in the setting where queries and knowledge are not evolved, but en- hances from 25.3% to 32.2% (+6.9%) when both are evolved. This suggests that synchronous evolu- tion is critical to fully exploit the advantage of di- verse knowledge soup in adapting LLMs in RACG. 4.3 Repo-level Code Generation Apart from updated libraries and long-tail program- ming languages, repo-level code generation is also a natural and realistic scenario for RACG, where LLMs are instructed to solve issues with refer- ence to the Github repository code. Different from the documentation in EVOR-BENCH , the reposi- tory code could be much more complex with inter- twined variable dependencies, customized function calls, etc. To solve an issue, the LLM usually needs to act as an agent to explore directories, use tools, make decisions, and more. Recent efforts have demonstrated the success of such agent-based meth- ods (OpenDevin Team, 2024; Yang et al., 2024). We explore the applicability of EVOR in this challenging setting. Specifically, we employ the popular SWE-bench-Lite (Jimenez et al., 2023) as the testbed, use all the repository content as the documentation,