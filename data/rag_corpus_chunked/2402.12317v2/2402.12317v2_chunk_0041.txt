386 DocPrompting 16.9 3923 37.8 4012 4.7 4050 4.4 3978 16.0 3991 RK 23.9 5124 42.2 5023 8.2 4987 7.3 4823 20.4 4989 EVOR 31.2 14564 53.3 12323 26.7 29384 17.4 14592 32.2 17716 Table 7: The comparison of LLM performance and consumed tokens per example without retrieval (Vanilla), retrieval without evolution from only documentation (DocPrompting), retrieval without evolution from knowledge soup (RK) and EVOR retrieval. By default, we use INSTRUCTOR-xl as the embedding model. The results in the table demonstrate the association between superior results and the massively processed tokens, which implies the trade-off between the performance and the cost. Scipy-M T ensorflow-M Ring Pony Benchmarks 0 10 20 30 40 50Performance None BM25 INSTRUCTOR text-embedding-3-large SFR-Embedding-Mistral Figure 5: Comparison of ChatGPT generalization performance when the sparse retriever (BM25), or the dense retriever (INSTRUCTOR, text-embedding- 3-large, SFR-Embedding-Mistral) is employed. The re- sults show that dense retrievers significantly outperform their sparse counterpart, BM25. In general, ChatGPT achieves the best performance when SFR-Embedding- Mistral is used as the retrieval model. trievers using the default setting of EVOR, except for changing the retrieval model. INSTRUCTOR- xl (Su et al., 2023) is an 1.3B embedding model fine-tuned to follow instructions for efficient adap- tation. text-embedding-3-large 8 is OpenAIâ€™s lat- est embedding model, showcasing competitive per- formance. SFR-Embedding-Mistral is trained on top of E5-mistral-7b-instruct (Wang et al., 2023a) and Mistral-7B-v0.1 (Jiang et al., 2023a) and achieves state-of-the-art performance in MTEB leaderboard (Muennighoff et al., 2022). As shown in Figure 5, across four datasets, when utilizing dense retrievers, ChatGPT signif- icantly enhances the performance achieved with a sparse retriever. Aligned with the results in the re- trieval benchmark (MTEB), ChatGPT consistently achieves the best performance when using SFR- Embedding-Mistral as the retrieval model. How- 8https://platform.openai.com/docs/guides/embeddings P 2k 4k 8k 12k 16k Context length 0 10