framework (e.g., concept extraction, answer generation), and the experimental environment setup are all detailed in the Appendix A for repro- ducibility. The core parameters of MetaKGRAG will be analyzed in detail in the subsequent analysis section. 4.2 Results and Analysis 4.2.1 Main Results. The main experimental results are presented in Tab. 2, 3, 4, and 5. The results across all five datasets validate the effectiveness of our framework. We highlight three key findings. (1) Our framework consistently outperforms all baselines, achiev- ing 91.70% on ExplainCPE (+9.88% over best LLM), 92.11% on Com- monsenseQA (+10.35%), and 88.49% on JEC-QA (+8.36%). These improvements across medical, commonsense, and legal domains demonstrate the effectiveness of our metacognitive approach. Re- garding to the ROUGE-L and G-Eval results of webMedQA and ExplainCPE, please refer to the Appendix C. As shown in Tab. 9, our MetaKGRAG method also achieved scores that surpass other baselines. The results demonstrate that our method not only im- proves the accuracy of multiple-choice question answering, but also excels in explanatory answer generation capabilities. (2) A critical finding is that simply stacking existing refinement methods on KG-RAG yields only marginal improvements. Methods like FLARE, ReAct, and Meta RAG. When combined with KG-RAG, improve performance by merely 1-3%. In stark contrast, MetaK- GRAG achieves 5-10% improvements over basic KG-RAG methods. Table 3: Performance Comparison on webMedQA. Prec. and Rec. represent Precision and Recall, respectively. Type Method Prec. Rec. F1 Without Retrieval LLM Only Qwen2.5-7B 66.68 71.14 68.85 Qwen2.5-72B 70.12 73.58 71.81 GPT4o 72.53 75.11 73.80 o1-mini 68.24 72.05 70.09 Claude3.5-Sonnet 71.89 74.32 73.09 Gemini1.5-Pro 72.01 74.88 73.42 Self-Refine Chain-of-Thought 71.21 74.63 72.88 Meta Prompting 71.85 75.01 73.40 With Retrieval KG-RAG KGRAG 73.15 76.02 74.56 ToG 73.89 76.55 75.19 MindMap 72.93 75.81 74.34 KGGPT 73.51 76.23 74.85 Self-Refine FLARE 74.22 76.91 75.54 ReAct 74.98 77.53