our custom dataset, Univer- sityQuestionBench (UQB). Our pipeline demonstrated strong performance across three key metrics: faithfulness, answer relevance, and context relevance. The quantitative results were complemented by a qualitative assessment, which confirmed the high acceptability and consistency of the generated an- swers from a human perspective. The findings underscore the efficacy of our RAG-based approach in addressing university-level questions, highlighting the potential of fine-tuned language models with context retrieval pipeline and custom datasets in enhancing educational tools. VIII. F UTURE DIRECTIONS Several future contributions are envisioned to further en- hance the proposed pipeline’s performance and scope, includ- ing improvements to the model and dataset. These contribu- tions aim to expand the dataset’s diversity, incorporate data from various universities, and establish real-time connectivity with course selection departments for more accurate and up- to-date information. Below are the key future contributions: A. Contribution 1: Expanding Dataset Diversity The first improvement involves expanding the dataset to include more diverse questions and answers, which can in- crease the robustness of the model across a wider array of academic subjects and contexts. This can be achieved by crowdsourcing data contributions from a broader range of stu- dents and institutions, ensuring the dataset contains both valid and new question-answer pairs. By increasing the diversity of the dataset, the model’s generalizability and effectiveness in handling various academic queries are expected to improve significantly. B. Contribution 2: Incorporating Multi-University Data To enhance the generalization and versatility of the dataset, it is proposed that question-answer data from multiple uni- versities be incorporated. Each university can have its unique structure, curriculum, and question patterns, which, when combined, create a more generalized dataset suitable for a wide range of academic scenarios. By pooling datasets from multiple institutions, the model will gain exposure to a wider variety of scholarly discourse, which can