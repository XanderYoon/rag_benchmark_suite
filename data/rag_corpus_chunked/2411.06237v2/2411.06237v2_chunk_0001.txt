OpenAI GPTs and Google Gemini models, often face significant challenges when it comes to extracting and utilizing local data, particularly from specialized datasets such as universities archives. These models are typically trained on broad, diverse datasets, which can result in a lack of specificity and accuracy when applied to niche domains. The challenges include the inability to access and process localized data ef- fectively, leading to issues like hallucinations and inaccuracies in generated content. Additionally, the models’ reliance on pre-existing knowledge limits their capability to incorporate newly acquired, domain-specific information without extensive retraining [1], [2]. We extend our gratitude to our fellow group members within the UIAI Com- munity at the University of Isfahan—Kiana Fakhrian, Amirhossein Moalemi, Amirhossein Ala, and Zahra Mortazavi—for their dedicated efforts in inte- grating our dataset and diligently scraping documents from the University of Isfahan website. Their contributions were instrumental to the progress of this work. 1Dataset is publicly available at https://huggingface.co/datasets/UIAIC/ UQB Retrieval-Augmented Generation (RAG) offers a robust solution to the challenges faced by LLMs in processing local documents. By integrating retrieval mechanisms with genera- tion capabilities, RAG pipelines enable models to access and utilize specific, relevant information from extensive datasets. Our proposed pipeline leverages a two-stage RAG approach combined with a Persian Large Language Model (PLM) and advanced prompt engineering techniques. Initially, queries are categorized to identify the most relevant documents, after which the appropriate LLM is engaged to generate accurate and contextually relevant responses. This method significantly enhances the precision and utility of LLMs in handling local- ized, domain-specific queries [3], [4]. We developed the ”UniversityQuestionBench” dataset, cre- ated from the most frequently asked questions by students across various disciplines. This dataset is designed to evaluate the performance of Persian LLMs integrated with RAG using the RAGAS evaluation metrics, which includes three key