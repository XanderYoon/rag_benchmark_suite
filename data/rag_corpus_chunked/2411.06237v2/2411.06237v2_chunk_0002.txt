responses. This method significantly enhances the precision and utility of LLMs in handling local- ized, domain-specific queries [3], [4]. We developed the ”UniversityQuestionBench” dataset, cre- ated from the most frequently asked questions by students across various disciplines. This dataset is designed to evaluate the performance of Persian LLMs integrated with RAG using the RAGAS evaluation metrics, which includes three key mea- sures: Faithfulness, Answer Relevance and Context Relevance. By employing these metrics, we ensure that the model provides accurate, relevant, and contextually appropriate responses. The dataset and evaluation processes aim to benchmark the effectiveness of our pipeline in addressing the specific needs of universities students [5], [6], [7]. Our contributions to this paper are as follows: • Development of a two-stage RAG pipeline integrated with Persian LLMs for handling localized queries. • Creation of the UniversityQuestionBench dataset, tailored to the most common queries from university students. • Leveraging the RAGAS evaluation metrics to rigorously assess the performance of our models. • Demonstration of significant improvements in Faithful- ness, Answer Relevance and Context Relevance of Re- sponses generated by our pipeline. II. R ELATED WORK A. Introduction to Retrieval-Augmented Generation Retrieval-Augmented Generation (RAG) is a novel paradigm that enhances the performance of large language models by incorporating information retrieval processes into the generation mechanism. This approach aims to arXiv:2411.06237v2 [cs.IR] 1 Dec 2024 Fig. 1. Our Proposed Pipeline improve the accuracy and robustness of generated content by utilizing relevant external data sources. Recent studies have demonstrated the effectiveness of RAG frameworks in various applications in AI and machine learning [1], [8]. B. Recent Advances and Techniques in RAG Recent advancements in RAG have focused on innovative techniques and methodologies to optimize retrieval and gener- ation processes. Lewis et al. (2020) highlight the power of RAG in knowledge-intensive NLP tasks, demonstrating its