Embeddings delivers the best performance in faithfulness, reflecting the general applicability and robustness of these embed- dings across various datasets. – Conversely, Dorna with Dorna Embeddings ex- hibits superior performance in answer relevancy, em- phasizing the importance of leveraging embeddings specifically designed for Persian text in achieving domain-specific objectives. • Performance Variability of Persian-Specific Embed- dings: While Persian-Sentence-Embedding-V3 demon- strates strengths in context relevancy, its relatively lower performance in faithfulness and answer relevancy indi- cates the need for further optimization and training on diverse Persian datasets to improve its applicability for information retrieval tasks. B. Quality of Outputs To assess the acceptability of the pipeline outputs from a human perspective, we conducted a qualitative evaluation involving 10 reviewers, including members of the University of Isfahan Artificial Intelligence Community and university students. The evaluators rated the generated answers based on clarity, coherence, and overall satisfaction. Feedback indicated that the majority of the answers were clear, well-structured, and effectively addressed the questions, demonstrating high acceptability. Moreover, the consistency of the answers was noted, with evaluators observing a uniform level of quality across different questions. This consistency highlights the robustness of our pipeline, confirming its ability to produce reliable and high- quality answers suitable for practical use in a university setting. VII. C ONCLUSION In this study, we developed a question-answering pipeline based on Retrieval-Augmented Generation (RAG) using a quantized version of Dorna model, a fine-tuned version of LLaMA-3 on Persian data, and our custom dataset, Univer- sityQuestionBench (UQB). Our pipeline demonstrated strong performance across three key metrics: faithfulness, answer relevance, and context relevance. The quantitative results were complemented by a qualitative assessment, which confirmed the high acceptability and consistency of the generated an- swers from a human perspective. The findings underscore the efficacy of our RAG-based approach in addressing university-level questions, highlighting