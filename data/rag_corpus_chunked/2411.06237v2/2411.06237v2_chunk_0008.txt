and Human Questions.Additionally, answerj corresponds to the manually validated answer for question j. The final dataset comprises over 500 documents, encom- passing a wide range of contexts to ensure comprehensive coverage. These documents include detailed information about the academic groups and sections of each department, pro- fessors along with their contact emails, and various aspects of the university, such as administrative procedures, facilities, and other relevant resources. This extensive collection ensures that the dataset accurately represents the diverse informational needs of students across the university. We illustrate the process of the Dataset Generation in the figure 2. Fig. 2. Data Generation Procedure - In this figure we has shown the question and answer generation. IV. P IPELINE GENERATION A. Pipeline Setting As previously discussed, large language models (LLMs) encounter challenges when responding to queries that they were not well-trained on, particularly due to the absence of specific training data related to those queries. Additionally, some queries directly pertain to local or private datasets. The retrieval-augmented generation (RAG) pipeline offers a solution to this issue without requiring extensive fine-tuning of the entire model on the specific dataset . Our pipeline is constructed based on the following steps: Step 1: Pass the crawled data, D, through the model, regardless of whether the data exists in the question or not. This is represented in the Equation 6: D = {datai}N i=1, (6) where datai represents individual pieces of information and N is the total number of data items extracted. Step 2: Identify the type of question and determine the relevant department using the DORNA Model, which is a fine-tuned version of Llama-3 on Presian data [25], [26]. Specifically, we employed the 8-bit quantized version of Dorna utilizing QLoRA [27]. This approach enables us to load our base model with significantly reduced memory requirements.