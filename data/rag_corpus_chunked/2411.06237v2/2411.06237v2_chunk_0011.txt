Relevancy GPT 4o OpenAI Embeddings 0.6333 0.6395 0.1154 GPT 3.5-turbo OpenAI Embeddings 0.8497 0.5604 0.1849 GPT 3.5-turbo Persin-Sentence-Embedding-V3 0.8113 0.493 0.223 GPT 4o Persin-Sentence-Embedding-V3 0.6578 0.6564 0.1848 Dorna (Persian version of Llama3) Dorna Embeddings 0.839 0.823 0.216 • R(qi) is the set of documents retrieved for query qi. • Faithfulness(Ai, R(qi)) measures the relevancy of Ai against the information in R(qi). The faithfulness function can be further defined in the equation 13: Faithfulness(Ai, R(qi)) = P|A(i)| j=1 Rel(Aij, R(qi)) |A(i)| (13) where Ai is the set of statements in the answer and Rel(Aij, R(qi)) determines that the statement Aij from an- swer Ai is supported by the document R(qi) or not. B. Answer Relevance Answer relevance measures how well the generated answer addresses the query. This metric ensures that the answer is directly relevant to the question asked. We first initialize a set of questions q that can directly address from the Answer Ai. Let Rans denote answer relevance, calculated in the equation 14: Rans = 1 m mX j=1 Sim(Q, qj) (14) Where: • m is the number of questions in the set of questions q • Q is the users query which model generated Ai based on it. • Ai is the answer generated for users query Q. • Sim(Q, qi) calculates the similarity of Q and qj embed- ding vectors. In our study, we used cosine similarity to calculate the output of this function. C. Context Relevance Context relevance assesses how well the retrieved doc- uments match the query, ensuring that the documents are contextually appropriate and useful for generating an accurate answer. Let Rctx denote context relevance, calculated in the equation 15: Rctx = 1 N NX i=1 Relevance(R(qi), qi) (15) Where: • R(qi) is the set of documents retrieved for query qi. • Relevance(R(qi), qi)