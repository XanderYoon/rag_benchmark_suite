in the Equation 10: R(q) = TopK(FAISS(E(q), E(P)), 3), (10) where R(q) represents the set of top 3 retrieved paragraphs similar to the query q. Step 6: Create a prompt template and pass it to the LLMs. Our LLM, DORNA, is a fine-tuned version on Llama-3 of persian data. The prompt template T is designed to incorporate the retrieved paragraphs and the query. Step 7: Pass the generated prompt to the LLMs to produce the final answer. Let A denote the answer generated by DORNA in the Equation 11: A = DORNA(T (q, R(q))), (11) These steps constitute our pipeline, leveraging RAG and advanced embedding techniques to ensure accurate and rele- vant responses from localized data sources. We illustrate our Pipeline schema in figure 1. V. E XPERIMENTS To comprehensively assess the effectiveness of our RAG pipeline and LLMs, we utilize three key metrics as defined in the RAGAS paper: Faithfulness, Answer Relevance and Context Relevance. Each metric is described in detail below. A. Faithfulness Faithfulness evaluates how accurately the generated answer reflects the content of the retrieved documents. This metric is crucial to ensure that the model does not introduce hal- lucinations or incorrect information. Let F denote pipeline faithfulness, calculated in the equation 12: F = 1 N NX i=1 Faithfulness(Ai, R(qi)), (12) Where: • Ai is the answer generated for query qi. TABLE I EVALUATION METRICS FOR DIFFERENT MODELS AND EMBEDDINGS Model Embedding Faithfulness Answer Relevancy Context Relevancy GPT 4o OpenAI Embeddings 0.6333 0.6395 0.1154 GPT 3.5-turbo OpenAI Embeddings 0.8497 0.5604 0.1849 GPT 3.5-turbo Persin-Sentence-Embedding-V3 0.8113 0.493 0.223 GPT 4o Persin-Sentence-Embedding-V3 0.6578 0.6564 0.1848 Dorna (Persian version of Llama3) Dorna Embeddings 0.839 0.823 0.216 • R(qi) is the set of documents retrieved for query qi. • Faithfulness(Ai, R(qi)) measures the relevancy of Ai against the information in