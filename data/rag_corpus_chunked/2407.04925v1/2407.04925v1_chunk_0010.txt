it takes to generate a response) of the LLM- based recommender system compared to non-LLM course recommender systems (e.g., course recommender system us- ing collaborative filtering and content-based approaches), fo- cusing particularly on their ability to address the“cold start” problem. This problem occurs when the user lacks specific requirements on what skills they want to learn, and the sys- tem lacks data on the new user. LLM vs. LLM with RAG. We further examined the per- formance of a standard LLM recommender system (without RAG and without using a dataset as a knowledge base) ver- sus an RAG-enhanced LLM recommender system by testing different prompt templates for the retriever and various user queries for the generator to ascertain improvements in sys- tem performance and recommendation personalization. To explore the performance of our course recommender sys- tem, we focused on comparing the relevance of the recom- mended courses to different prompts by varying prompt tem- plates and user-specific requirements. 4. RESULTS 4.1 LLM vs. Non-LLM We compared RAMO with a traditional course recommenda- tion system built by the content-based and collaborative fil- Figure 3: Sample output for a cold-start question on LLM vs RAG-LLM system tering using the same dataset 2. During this comparison, we focused on the “cold start ” problem. The “cold start ” prob- lem is especially pertinent in the context of an e-learning platform for tutor training, such as tutor training platform [24]. When new tutors join the platform, they are encour- aged to complete various training courses to enhance their tutoring skills. Given the wide range of courses available, new tutors may feel overwhelmed when deciding where to begin their learning journey. In such scenarios, they may ask general questions such as, “What can I learn today since I am a new tutor onboarding to this