tokenize the course data and store the embeddings in vector store, considering its ad- vantage over BERT (Bidirectional Encoder Representations from Transformers) [7], while OpenAI embeddings [29] of- fer better generalization and contextual understanding [28], making them more suitable for diverse educational content. The generator is powered by LLMs, which generate the tex- tual contents based on the engineered prompts. To facilitate user’s interaction with the system, we make the recommen- dation process to be completed via conversational manner. The interface of our recommender system is shown in Figure 1, where we listed 5 default courses based on their ratings in the dataset on the web page to make it more user-friendly. As for the implementation of the system, we use GPT-3.5 Turbo, selected for its robust integration with theLangChain [32] framework—a platform designed to streamline the im- plementation of language models in application-specific con- texts. This setup allows the system to dynamically retrieve relevant documents and generate responses tailored to user inputs, as illustrated in the workflow in Figure 2. 3.2.3 Comparative Analysis To evaluate the performance of our system, we conducted a series of tests by providing different prompts representing various user needs to RAMO. This allowed us to explore its ability to deliver course recommendations based on the outputs generated in response to varied user prompts. LLM vs. Non-LLM. We explored both the relevance of the recommended courses to the user’s interests and responding time (the time it takes to generate a response) of the LLM- based recommender system compared to non-LLM course recommender systems (e.g., course recommender system us- ing collaborative filtering and content-based approaches), fo- cusing particularly on their ability to address the“cold start” problem. This problem occurs when the user lacks specific requirements on what skills they want to learn, and the sys- tem