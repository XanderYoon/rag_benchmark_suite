by the generated responses based on various user prompts, which are highly related to user’s needs and all came from the knowledge base. Additionally, our system supports conversational interaction with users, which could be seamlessly integrated into numerous online educational platforms. Our use of open-source LLMs (e.g. Llama 2 and Llama 3 [27]) has also been validated, proving to be a cost- effective approach for broader deployment. Limitations As this study is ongoing, we have not yet conducted com- prehensive evaluations of our recommender systems, includ- ing human evaluations or user studies. This is primarily due to the nascent stage of our research. Moreover, while many research projects on recommendation systems employ benchmarks to evaluate system adaptability, our study cur- rently lacks such benchmarks because we do not possess a test dataset. The Coursera dataset we utilized includes only course data, lacking user profiles which are essential for eval- uating the effectiveness of recommender systems across dif- ferent time periods. If we had access to user data, including users’ past course learning histories and their preferences, we could integrate this information with the course data to enhance our retrieval process. This integration would allow us to personalize recommendations more effectively, tailor- ing course suggestions to individual learning patterns and preferences. Incorporating detailed user data would enable RAMO to provide more accurate and relevant recommenda- tions, improving user satisfaction and engagement. It would also allow for longitudinal studies to track how users’ inter- actions with the system evolve over time and how well the recommendations align with their long-term learning goals. Future Work We plan to undertake several further steps to advance our research. Firstly, we aim to conduct thorough evaluations and tests to validate the efficacy and reliability of our recom- mender systems. This will involve integrating user studies and