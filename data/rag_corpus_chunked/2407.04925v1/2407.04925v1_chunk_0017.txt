metrics, user studies, and personalization improvements. Our experiment aims to assess both the relevancy of the recommendations and the satisfaction of the users with the recommended courses. We will utilize several quantitative metrics to evaluate the performance of the recommendation system. Key metrics in- clude post-test performance, measured by the improvement in students’ scores from pre-test to post-test after tutor- ing sessions, and course completion rate, which compares the rate of course completion between students who follow the system’s recommendations and those who do not. Ad- ditionally, engagement rate will be tracked by monitoring whether students continue engaging with the lesson without dropping out midway. User satisfaction will also be assessed through feedback collected after each lesson via a thumbs- up or thumbs-down system and detailed surveys. To gather qualitative insights into the system’s effectiveness and user experience, we will conduct user studies. These will involve satisfaction surveys completed by students following each lesson to gauge their satisfaction with the course content and the relevance of the recommendations, as well as focus group discussions to explore students’ experiences in more depth and gather suggestions for improvement. 6. ACKNOWLEDGMENTS We extend our sincere gratitude to Chenfei Lou, a current software engineer at X (former twitter), for his invaluable guidance in developing our demo. We also thank Sandy Zhao, a current master’s student in the CMU METALs pro- gram, for her excellent assistance in generating the wonder- ful diagram. Additionally, we appreciate Yuting Wang, an undergraduate student at CMU, for her help in refining the design in this paper. 7. REFERENCES [1] Maximum length - netdocuments, 2024. Accessed: 2024-07-05. [2] J. Basilico and T. Hofmann. Unifying collaborative and content-based filtering. In Proceedings of the twenty-first international conference on Machine learning, page 9, 2004. [3] M. H. Baturay. An overview of the world