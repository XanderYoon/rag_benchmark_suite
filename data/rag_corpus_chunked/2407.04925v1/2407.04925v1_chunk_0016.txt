users’ inter- actions with the system evolve over time and how well the recommendations align with their long-term learning goals. Future Work We plan to undertake several further steps to advance our research. Firstly, we aim to conduct thorough evaluations and tests to validate the efficacy and reliability of our recom- mender systems. This will involve integrating user studies and utilizing real user data once our systems are deployed on our e-learning platform. Such measures will enable us to robustly measure performance and refine our approach. Sec- ondly, we will focus on enhancing system performance, con- sidering scalability and the potential to expand our technol- ogy to encompass a broader range of educational tools and platforms. These efforts will ensure that our recommender systems not only meet current educational needs but also adapt to future demands and technological advancements. Thirdly, we could deploy RAMO on our own e-learning plat- form, and then have the opportunity to gather comprehen- sive user data and utilize our own course dataset rather than Coursera’s. This deployment would allow us to conduct ex- tensive testing and validation, further proving the eligibil- ity and effectiveness of the LLM for recommending courses. With access to real-time user data, we could continuously re- fine our algorithms, making the system more adaptive and responsive to users’ evolving needs. To evaluate the effectiveness of our LLM-based course rec- ommendation system, we plan to conduct a comprehensive experiment that includes quantitative metrics, user studies, and personalization improvements. Our experiment aims to assess both the relevancy of the recommendations and the satisfaction of the users with the recommended courses. We will utilize several quantitative metrics to evaluate the performance of the recommendation system. Key metrics in- clude post-test performance, measured by the improvement in students’ scores from pre-test to post-test after tutor-