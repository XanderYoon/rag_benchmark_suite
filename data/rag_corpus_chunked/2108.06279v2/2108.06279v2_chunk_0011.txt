classifi- cation, and compute for how many queries the effectiveness of ANCE and ColBERT is higher (denoted by W(in)) or lower (denoted with L(oss)) than BM25. For each partition, we also compute the average reward and risk associated with the W and L queries, following [17]. Table 3 reports the observed results. For the TREC 2019 queries, both ANCE and ColBERT exhibit approx. the same number of wins/losses for each query difficulty level. However, ANCE obtains higher rewards and higher risks on the class of easy queries than ColBERT (+0.1930 vs. +0.1827 and -0.1976 vs. -0.1380). On the medium difficulty class, the situation is reversed, and ColBERT obtains both higher rewards and higher risks than ANCE (+0.3053 vs. +02978 and -0.1521 vs. 0.1366). On the hard difficulty class, ColBERT is markedly superior to ANCE in terms of reward (+0.4114 vs. + 0.3750), and risk, even if such risk is computed over a single query. For the MSMARCO Dev queries, ColBERT is able to improve the MRR@10 of both easy and hard queries better than ANCE, and the losses are smaller for ColBERT than for ANCE. To conclude on RQ2, we have presented experimental evidence that both single and multiple representations are approximately as effective on easy queries. In contrast, for hard queries, the adoption of multiple embeddings helps w.r.t the usage of a single embedding. We explain this by noting that a single representation is learned to compress all semantic information and dependencies of the different tokens composing a query in a single embedding. On the other hand, multiple representations – using one embedding per query token together with additional masked tokens – can encode more diverse semantic information in the different embeddings, allowing to retrieve more relevant documents for queries that are hard to answer. Table 3 Comparative performances