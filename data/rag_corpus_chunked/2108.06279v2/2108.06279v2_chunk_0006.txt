there was not an effectiveness comparison with ColBERT in the ANCE paper [12]. ANCE embodies a recent single representation approach, where we have a single large embedding per query/document, which can be processed with exact similarity search in a single stage. In contrast, in the multiple representation approach (ColBERT), we have a smaller sized embedding for each term in the queries/documents, but due to the large number of embeddings, they must be processed using approximate similarity search. Thereafter the candidate set must be re-ranked to compute the exact similarity scores. The need for ColBERT to re-score all documents in the candidate set necessitates storing all document embeddings in memory. As noted by Lin et al. [2], this presents a significant storage overhead. This underlines the importance of an in-depth analysis 1Indeed, in [13] we show that these approximate scores can allow a high recall but low precision ranking to be obtained, which can be used to apply rank cutoffs to the the candidate set. of the pros and cons of both approaches, in particular: • RQ1. What is the effectiveness of single and multiple representations in dense retrieval, in terms of MAP, NDCG@10, MRR@10? • RQ2. What are the relative gains and losses of single and multiple representations w.r.t. a common baseline such as BM25? • RQ3. For which queries are single representations better than multiple representations, and vice-versa? In Section 3, we perform comparative experiments to address these research questions. 3. Experiments In the following, we report our experimental setup, followed by analyses for RQs 1-3. 3.1. Setup Our experiments use the MSMARCO passage ranking dataset, a dataset of 8.8M passages and build upon our PyTerrier IR experimentation platform [ 14, 15]. We adapt the ANCE implementation2 and the ColBERT implementation3 provided by their respective authors, using integrations with