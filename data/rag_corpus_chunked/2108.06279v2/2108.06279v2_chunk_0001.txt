as well as for definitional queries, and those with complex information needs. 1. Introduction Pre-trained contextualised language models such as BERT have been shown to greatly improve retrieval effectiveness over the previous state-of-the-art methods in many information retrieval (IR) tasks [1]. These contextualised language models are able to learn semantic representations called embeddings from the contexts of words and, therefore, better capture the relevance of a document w.r.t. a query, with substantial improvements over the classical approach in the rank- ing and re-ranking of documents [2]. Most BERT-based models are computationally expensive for estimating query-document similarities in ranking, due to the complexity of the underlying transformer neural network [3, 4, 5]. As such, BERT-based ranking models have been used as second-stage rankers in retrieval cascades, in particular to re-rank candidate documents generated by classical relevance models such as BM25 [6, 7, 8]. BERT-based models are also limited in the length of text that they can process, and hence are often applied on passages rather than full documents (which we focus on in this paper); entire document rankings can be obtained by estimating relevance at a passage level, then aggregating [9]. IIR 2021: The 11th Italian Information Retrieval Workshop, September 13–15, 2021, Bari, Italy © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings http://ceur-ws.org ISSN 1613-0073 CEUR Workshop Proceedings (CEUR-WS.org) arXiv:2108.06279v2 [cs.IR] 19 Aug 2021 Recently, several works have proposed investigating whether BERT-based systems are able to identify the relevant passages among all passages in a collection, rather than just among a query-dependent sample; these systems represent a new type of retrieval approaches called dense retrieval. In dense retrieval, passages are represented by real-valued vectors, while the query-document similarity is computed by deploying efficient nearest neighbour