[16] proposed Bnotehelper, which uses LLMs to rapidly generate note outlines from video content. However, this process neglected the importance of human-in-the-loop mechanisms. Yen et al. [ 15] tackle organizational challenges by transforming static LLM conversation histories into interactive object. LLMs should also assist people in naturally utilizing stored information during daily life. Zulfikar et al. [20] made progress by implementing LLMs that anticipate users’ memory needs through conversational context analysis, reducing retrieval effort. However, their framework focuses exclusively on textual information, neglecting the growing prevalence of visual data like images and videos in personal knowledge systems [9]. 3 Think-Aloud Study 3.1 Study Design To explore how users interact with and record information in a real-world context, we conducted a think-aloud study in an exhibition setting. Participants were tasked with exploring the exhibition, where they encountered various types of information, and were given the flexibility to define and experiment with any interaction mode they deemed suitable for capturing information. Throughout the process, we recorded their interactions via video, capturing what types of information they chose to record, the methods they employed for documentation, and their cognitive processes in interpreting the content. 3.1.1 Exhibition Setting. The study was conducted in the visitor center of our institution, an information-rich exhibition space designed to showcase the university’s research, academic achievements, and institutional history. The exhibition featured a diverse range of interaction channels, including virtual reality (VR), gesture-based interfaces, desktop- based interactions, museum-like installations, video and audio content, and immersive experiences. This multi-modal environment provided a complex, information-intensive setting where participants engaged with dense academic material through various sensory and interactive modalities. Participants were required to navigate, filter, and synthesize information across multiple formats, often switching between passive consumption (e.g., reading and watching videos) and active interaction (e.g., VR exploration and gesture-based engagement). Additionally,