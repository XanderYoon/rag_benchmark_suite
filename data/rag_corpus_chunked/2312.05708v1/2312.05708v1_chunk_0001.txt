and log- ical reasoning to program synthesis. One of the important active areas of LLM research is to uti- lize them as planning agents (Huang et al., 2022). Planning is an essential functionality for processing complex natural language instructions. A planner should possess the ability to select the appropriate tools to complete each sub-task. While LLMs ex- hibit exceptional generation capabilities, they have inherent limitations, such as lacking up-to-date in- formation and exhibiting a tendency to hallucinate tools. By providing LLMs with a relevant set of tools based on the given task (Schick et al., 2023; Lu et al., 2023), one can alleviate the issue of out- dated information. The set of methods to augment LLM input with retrieved information, such as rel- evant tools, is referred to as Retrieval Augmented Generation (RAG) (Guu et al., 2020; Lewis et al., 2020). RAG consists of three primary components: Tool Retrieval, Plan Generation, and Execution.1 In this study, we focus on enhancing tool retrieval, with the goal of achieving subsequent improve- ments in plan generation. Existing RAG methodologies rely heavily on se- mantic search for tool retrieval, but this approach has limitations, especially when queries lack speci- ficity or context. To this end, we present Context Tuning, a component in RAG that precedes tool retrieval, to provide contextual understanding and context seeking abilities to improve tool retrieval and plan generation. Our contribution can be sum- marized as follows: 1. We empirically show that traditional RAG is inadequate for implicit/context-seeking queries and present context tuning as a viable solution; 2. We provide a systematic comparison of vari- ous context retrieval methods applied on both lightweight models and LLMs; 3. We share empirically the insight that Chain of Thought (CoT) augmentation improves con- text retrieval when no fine-tuning is applied, whereas fine-tuning the retrieval