Evaluating Retrieval Quality in Retrieval-Augmented Generation Alireza Salemi University of Massachusetts Amherst Amherst, MA, United States asalemi@cs.umass.edu Hamed Zamani University of Massachusetts Amherst Amherst, MA, United States zamani@cs.umass.edu ABSTRACT Evaluating retrieval-augmented generation (RAG) presents chal- lenges, particularly for retrieval models within these systems. Tra- ditional end-to-end evaluation methods are computationally expen- sive. Furthermore, evaluation of the retrieval model‚Äôs performance based on query-document relevance labels shows a small correla- tion with the RAG system‚Äôs downstream performance. We propose a novel evaluation approach, eRAG, where each document in the retrieval list is individually utilized by the large language model within the RAG system. The output generated for each document is then evaluated based on the downstream task ground truth labels. In this manner, the downstream performance for each document serves as its relevance label. We employ various downstream task metrics to obtain document-level annotations and aggregate them using set-based or ranking metrics. Extensive experiments on a wide range of datasets demonstrate that eRAG achieves a higher correlation with downstream RAG performance compared to base- line methods, with improvements in Kendall‚Äôsùúè correlation ranging from 0.168 to 0.494. Additionally, eRAG offers significant compu- tational advantages, improving runtime and consuming up to 50 times less GPU memory than end-to-end evaluation. CCS CONCEPTS ‚Ä¢Computing methodologies ‚Üí Natural language generation; ‚Ä¢Information systems ‚Üí Evaluation of retrieval results . KEYWORDS Evaluation; Retrieval Quality; Retrieval-Augmented Generation ACM Reference Format: Alireza Salemi and Hamed Zamani. 2024. Evaluating Retrieval Quality in Retrieval-Augmented Generation. In Proceedings of the 47th Int‚Äôl ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ‚Äô24), July 14‚Äì18, 2024, Washington, DC, USA. ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 INTRODUCTION Retrieval-augmented generation (RAG) has emerged as a prominent approach in natural language processing, combining the strengths of retrieval and generation models [35], with use