observed with the SIGIR ’24, July 14–18, 2024, Washington, DC, USA. Alireza Salemi and Hamed Zamani Figure 2: The correlation between eRAG and the downstream performance of different LLM sizes. In this experiment, T5- small (60M parameters) and T5-base (220M parameters) with FiD are used. The documents are retrieved using BM25. Figure 3: The correlation between eRAG and the downstream performance of FiD and IPA LLMs. T5-small with 10 docu- ments retrieved by BM25 is used. The number of documents is chosen based on the limitations of the input size in IPA. larger model. Nonetheless, in none of the cases is there a significant difference between the correlations, suggesting that the proposed approach is effective regardless of the LLM size. How does different retrieval-augmentation approaches af- fect the correlation between eRAG and the downstream RAG performance? We applied eRAG to two LLMs. One LLM utilizes In-Prompt Augmentation (IPA), where the retrieved results are ap- pended to the input of the LLM. The other LLM employs Fusion-in- Decoder (FiD) [9], wherein each retrieved document is individually processed by the encoder, and subsequently, the representations for all documents are concatenated together and fed to the decoder. For the sake of space, we limit our experiments to NQ for question answering, FEVER for fact-checking, and WoW for long-text gen- eration. The correlation between eRAG and the outputs of each LLM is illustrated in Figure 3. Interestingly, the results suggest that although there is no significant difference between the correlation of eRAG with IPA and FiD LLMs, eRAG consistently exhibits a higher correlation with the FiD. This observation can be elucidated by considering the distinction between IPA and FiD methodologies. In IPA, all documents are concatenated together and then presented as a single input to the LLM. In contrast, FiD processes each docu- ment