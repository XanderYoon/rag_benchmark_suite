set of statements, S(as(q)). The aim of this step is to decompose longer sentences into shorter and more focused assertions. We use the following prompt for this step3: Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] answer: [answer] where [question] and [answer] refer to the given question and answer. For each statement si 2https://platform.openai.com 3To help clarify the task, we include a demonstration as part of the prompt. This demonstration is not explicitly shown in the listing of the prompts throughout this paper. in S, the LLM determines ifsi can be inferred from c(q) using a verification function v(si, c(q)). This verification step is carried out using the following prompt: Consider the given context and following statements, then determine whether they are supported by the information present in the context. Provide a brief explana- tion for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. statement: [statement 1] ... statement: [statement n] The final faithfulness score, F , is then computed as F = |V | |S| , where |V | is the number of statements that were supported according to the LLM and |S| is the total number of statements. Answer relevance We say that the answer as(q) is relevant if it directly addresses the question in an appropriate way. In particular, our assessment of answer relevance does not take into account fac- tuality, but penalises cases where the answer is incomplete or where it contains redundant informa- tion. To estimate answer relevance, for the given answer as(q), we prompt the LLM to generate n potential questions qi based on as(q), as follows: Generate a question