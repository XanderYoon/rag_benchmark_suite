the idea that the an- swer should be grounded in the given context. This is important to avoid hallucinations, and to ensure that the retrieved context can act as a justification for the generated answer. Indeed, RAG systems are often used in applications where the factual con- sistency of the generated text w.r.t. the grounded sources is highly important, e.g. in domains such as law, where information is constantly evolving. Sec- ond, Answer Relevance refers to the idea that the generated answer should address the actual ques- tion that was provided. Finally,Context Relevance refers to the idea that the retrieved context should be focused, containing as little irrelevant informa- tion as possible. This is important given the cost associated with feeding long context passages to LLMs. Moreover, when context passages are too long, LLMs are often less effective in exploiting that context, especially for information that is pro- vided in the middle of the context passage (Liu et al., 2023). We now explain how these three quality aspects can be measured in a fully automated way, by prompting an LLM. In our implementation and experiments, all prompts are evaluated using the gpt-3.5-turbo-16k model, which is available through the OpenAI API2. Faithfulness We say that the answer as(q) is faithful to the context c(q) if the claims that are made in the answer can be inferred from the con- text. To estimate faithfulness, we first use an LLM to extract a set of statements, S(as(q)). The aim of this step is to decompose longer sentences into shorter and more focused assertions. We use the following prompt for this step3: Given a question and answer, create one or more statements from each sentence in the given answer. question: [question] answer: [answer] where [question] and [answer] refer to the given question and answer.