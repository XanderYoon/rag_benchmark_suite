performance on multi-hop and long-context question answering. Our ablations further show that query formulation, node design, and balanced hyperparameter settings are critical to performance. 9 LIMITATIONS While QCG-RAG advances the state of graph-based retrieval-augmented generation, it still has several limitations. First, the framework depends on query generation quality; errors or biases in Doc2Query may propagate into graph construction and retrieval. Second, although query-centric graphs mitigate token overhead compared to entity-level graphs, constructing and maintaining large-scale QCGs remains computationally costly when applied to web-scale corpora. Third, our experiments are limited to English QA benchmarks; extending QCG-RAG to multi-lingual or domain-specific scenarios (e.g., legal or biomedical text) requires further validation. Finally, the current retrieval mechanism primarily focuses on structural and semantic similarity, but does not incorporate advanced reasoning strategies such as reinforcement learning or self-reflection, which may further enhance complex reasoning. We leave these directions for future work. ETHICSSTATEMENT This work builds on QA benchmarks (LiHuaWorld and MultiHop-RAG) that contain either synthetic or publicly available text, without involving private or sensitive user data. The proposed QCG-RAG framework aims to improve retrieval-augmented reasoning and does not introduce additional risks beyond those inherent to large language models, such as potential hallucinations or biases inherited from pre-trained models. We caution against deploying QCG-RAG in high-stakes domains (e.g., healthcare, law) without rigorous domain-specific validation, and emphasize that our contributions should be viewed as methodological advances in retrieval and reasoning. REPRODUCIBILITYSTATEMENT We have provided detailed descriptions of the QCG-RAG framework, including graph construction, retrieval mechanisms, and hyperparameter choices, in the main text and appendix. Dataset statistics, evaluation metrics, and experimental setups (embedding models, LLM configurations, and query generation methods) are reported in full. Hyperparameter ranges and default settings for both LiHuaWorld and MultiHop-RAG are explicitly specified, and all prompts used for query generation and evaluation are included