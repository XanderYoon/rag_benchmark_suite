Doc2Query and Doc2Query--, as the basis for introduc- ing our proposed Query-Centric Graph Retrieval Augmented Generation (QCG-RAG) framework. 3.2 FRAMEWORKOVERVIEW Prior graph-based RAG approaches exhibit inherent limitations in granularity: either too fine- grained with entity-level graphs or too coarse-grained with document-level graphs. To address this granularity dilemma, we proposeQuery-Centric Graph Retrieval-Augmented Generation (QCG-RAG), a novel framework that integrates Query-Centric Graph (QCG) indexing and retrieval mechanisms to enhance response accuracy and interpretability. As illustrated in Figure 2, our framework consists of two major steps: Query-Centric Graph Construction and Query-Centric Graph Retrieval & Generation. Query-Centric Graph Construction.We first enrich the retrieval space by generating synthetic query–answer pairs from each text chunk using extended Doc2Query. Given a chunk ci, an LLM generates a set of queries {qj g,i} with corresponding answers {aj g,i} that faithfully represent the content of ci. To reduce noise, we apply extended Doc2Query--, which ranks the generated query- answer pairs by their semantic similarity to the source chunk and retains only the top α fraction. Note that, unlike the original Doc2Query and Doc2Query--, which leverage queries only, the extended methods incorporate query–answer pairs. The resulting high-quality queries serve as nodes in the Query-Centric Graph (QCG), where edges representchunk–querymembership andquery–query similarity relations. This process enables graph construction with controllable granularity while strengthening chunk–query associations and capturing richer semantic relations among queries. Query-Centric Graph Retrieval & Generation.Given a user query qu, retrieval proceeds in four steps: (1) retrieving semantically related queries from the graph (Query → Retrieved Queries); (2) expanding to neighboring queries to capture multi-hop relations (Retrieved Queries → Neighboring 4 Queries); (3) aggregating and ranking associated chunks linked to the retrieved query set (Query Set → Chunk Set); and (4) generating the final response by conditioning the LLM on the user query and the top-K retrieved chunks (Top-K Chunk