graphs using LLM-based extraction, cluster entities into communities, and generate community summaries for retrieval alongside original documents, thereby supporting cross-chunk association and multi-hop reasoning. This line of work has motivated both (1)simplified variants(e.g., Fast GraphRAG 2, LightRAG (Guo et al., 2024), LazyGraphRAG (Edge et al., 2024b), Triplex3, and E2GraphRAG (Zhao et al., 2025)) that reduce construction costs through model and pipeline optimization, and (2)structural extensions (e.g., KG-Retriever (Chen et al., 2024), Mixture-of-PageRanks (Alonso & Millidge, 2024)) that organize knowledge into hierarchical indexes to improve retrieval coverage, highlighting the persistent granularity trade-off in graph-based RAG. In particular, Fast GraphRAG simplifies this pipeline by eliminating community detection and summary generation to reduce LLM usage. LightRAG further streamlines the process by removing the community component entirely, making the system more lightweight. LazyGraphRAG replaces LLM-based extraction with small local models that capture noun co-occurrences, while generating community summaries dynamically at query time. Triplex leverages a fine-tuned lightweight LLM (Phi3-3.8B) and E2GraphRAG employs traditional NLP tools such as SpaCy (Honnibal et al., 2020) for graph extraction, significantly lowering construction costs. Beyond simplification, KG-Retriever constructs a hierarchical index that integrates an entity-level knowledge graph with a document-level layer, enhancing intra- and inter-document connectivity to support efficient cross-document retrieval and multi-granularity access. To address the granularity dilemma of graph-based RAG, we propose Query-Centric Graph RAG (QCG-RAG), which enables controllable query-centric graph construction to balance granularity and align retrieved evidence with user intent. Document Expansion with Doc2Query & Doc2Query--.Doc2Query (Nogueira et al., 2019) is a document expansion technique that trains sequence-to-sequence models (e.g., T5 (Raffel et al., 2020)) to generate queries likely associated with a given document, thereby improving retrieval by appending the generated queries to the document chunks. Doc2Query-- (Gospodinov et al., 2023) refines this approach by filtering out irrelevant or hallucinated queries based on their similarity