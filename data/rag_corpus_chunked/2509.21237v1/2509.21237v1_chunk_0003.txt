â€¢Comprehensive Evaluation.We conduct experiments demonstrating that QCG-RAG consistently outperforms prior chunk-based and graph-based RAG methods in question answering accuracy. 2 RELATEDWORK Chunk-based RAG.Conventional chunk-based RAG frameworks, such as Naive RAG (Gao et al., 2023), typically follow a four-step pipeline: (1) Chunking: documents are segmented into fixed-length units using sliding windows or semantic boundary detection to balance granularity and context; (2) Embedding: chunks are encoded into dense vectors with pretrained encoders (e.g., BGE-M3 (Multi-Granularity, 2024) and Sentence-BERT (Reimers & Gurevych, 2019)) and indexed in vector databases (e.g., FAISS (Douze et al., 2024), Milvus (Wang et al., 2021), and ElasticSearch1); (3) Retrieval: user queries are embedded and compared against chunk vectors via similarity metrics, optionally reranked with cross-encoders; and (4) Generation: top-k retrieved chunks are concatenated with the query and fed into LLMs (e.g., GPT-4 (Achiam et al., 2023), Qwen2.5 (Qwen et al., 2025), DeepSeek-R1 (Guo et al., 2025)) to produce responses. While effective for factual grounding, this pipeline often suffers from semantic misalignment between retrieval and generation, as well as insufficient coverage for multi-hop queries. These limitations motivate graph-based RAG approaches, which introduce structured semantic representations to better bridge the gap between queries and dispersed evidence. 1https://github.com/elastic/elasticsearch 2 Graph-based RAG.Graph-based RAG extends conventional chunk-based RAG by introducing structured knowledge graphs that capture entity-level relations, enabling retrieval not only by text similarity but also through graph-based reasoning (Peng et al., 2024). Typical implementations, such as GraphRAG (Edge et al., 2024a), construct entity-centric graphs using LLM-based extraction, cluster entities into communities, and generate community summaries for retrieval alongside original documents, thereby supporting cross-chunk association and multi-hop reasoning. This line of work has motivated both (1)simplified variants(e.g., Fast GraphRAG 2, LightRAG (Guo et al., 2024), LazyGraphRAG (Edge et al., 2024b), Triplex3, and E2GraphRAG (Zhao et al., 2025)) that reduce construction costs through model and