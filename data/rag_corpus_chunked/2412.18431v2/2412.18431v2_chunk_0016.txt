Hy- brid + SyncGE method achieves state-of-the-art single-step retrieval performance on both MuSiQue and HotpotQA datasets. We observe consistent improvements using NaiveGE and SyncGE, out- performing HippoRAG in many setups regardless of the base retriever (i.e. sparse, dense or hybrid). Most notably, Hybrid + SyncGE surpasses Hip- poRAG by up to 9.8% at R@15 on MuSiQue. Higher recall leads to higher QA performance Our analysis shows a positive correlation between recall and QA performance, aligning with the re- sults of prior works (Gutierrez et al., 2024). As shown in Table 3, GEAR achieves the highest EM and F1 scores. A closer examination reveals in- teresting insights. Taking MuSiQue as an exam- ple, GEAR shows a 21% relative improvement in R@15 compared to HippoRAG w/ IRCoT, while achieving a 37% relative improvement in both EM and F1 scores. Similarly to Table 2, SyncGE out- performs HippoRAG on MuSiQue and HotpotQA. Retriever MuSiQue 2Wiki HotpotQA EM F1 EM F1 EM F1 No Passages 2.6 12.5 17.2 27.9 19.5 34.3 Gold Passages 36.6 59.2 54.4 70.3 55.0 75.9 Hybrid + SyncGE 14.0 27 .1 38.0 50 .2 45 .0 63 .4 HippoRAG 8.2 18 .2 39 .8 51 .8 40 .1 57 .6 IRCoT (BM25) 7.6 15 .9 28 .8 38 .5 34 .3 50 .8 IRCoT (ColBERTv2) 12.2 24 .1 32 .4 43 .6 45 .2 63 .7 HippoRAG w/ IRCoT 14.2 25.9 45 .6 59.0 49.2 67.9 GEAR 19.0 35 .6 47 .4 62 .3 50 .4 69 .4 Table 3: End-to-end QA performance using the top- 5 retrieved passages. The best model is in bold and second best is underlined. The top part shows the lower and upper bounds of QA performance, while the middle and bottom sections display scores for single-step and multi-step retrievers, respectively. 8 Discussion 8.1 What