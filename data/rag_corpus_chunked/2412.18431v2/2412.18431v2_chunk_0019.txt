values are indicated by grey dots for each hop type. advantage becomes more pronounced with 3-hop questions, where GEAR’s entire interquartile range exceeds HippoRAG w / IRCoT’s median perfor- mance across both hop subdivisions. This demon- strates GEAR’s enhanced capability in handling moderately complex questions. In addition to MuSiQue, 2Wiki and HotpotQA, we test GEAR against the hand-picked case study data provided by Gutierrez et al.. These include four path-finding questions across four different domains. Our find- ings (Appendix I.3) indicate that GEAR’s perfor- mance is on par with HippoRAG w/ IRCoT, out- performing the competition in three out of the four cases, in terms of recall. GEAR’s performance remains consistent across chunks with varying numbers of triples Using MuSiQue, we group questions based on the average number of triples (i.e. triple density, ρt) associated with their golden passages, and evaluate R@15 across four ranges: (i) ρt < 9, (ii) 9 ≤ ρt < 11, (iii) 11 ≤ ρt < 13 and (iv) 13 ≤ ρt. Across all these ranges, the recall performance of both SyncGE and GeAR exhibits lower variation, with significantly smaller standard deviations of1.18 ≪ 2.04 and 2.08 ≪ 5.59, respectively, compared to NaiveGE and HippoRAG w/ IRCoT. Further de- tails are provided in Appendix H. 8.3 Is G EAR efficient? As observed in Figure 2, GEAR requires fewer iter- ations than the competition to reach its maximum recall performance. Furthermore, Figure 4 shows that GEAR can act as a more efficient alternative with respect to LLM token utilisation. We note that even for a single iteration, GEAR uses fewer tokens than HippoRAG w/ IRCoT. In contrast to ours, this trend exacerbates for the competition as the number of iterations increases. These findings also reiterate the value of SyncGE, which outper- forms a significantly more LLM-heavy solution