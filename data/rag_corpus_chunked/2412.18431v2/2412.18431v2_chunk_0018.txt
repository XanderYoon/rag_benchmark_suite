that GEAR achieves strong retrieval performance in a single iteration on MuSiQue. This differenti- ates it from IRCoT-oriented setups that require at least 2 iterations to reach maximum performance. This can be attributed to the fact that GEAR reads (Eq. 4) multi-hop contexts and associates proximal triples in gist memory with passages, establishing synergy between our graph retriever and the LLM. We believe this mirrors the hippocampal process of forming and resolving sparse representations, where gist memories are learned in a one or few- shot manner (Hanslmayr et al., 2016). The 10% performance gap between Hybrid + SyncGE and GEAR at n = 1 indicates that the LLM reading and linking processes effectively approximate the hippocampus’s role within our framework. 8.2 How robust is G EAR? GEAR excels at questions of low-to-moderate complexity Figure 3 presents a detailed break- down of retrieval performance across different hop types, including path-finding and path-following questions categorized by Gutierrez et al.. For 2- hop questions, while GEAR and HippoRAG w/ IRCoT achieve similar interquartile ranges, GEAR shows a higher mean recall, indicating superior performance on low-complexity questions. This 0.0 0.2 0.4 0.6 0.8 1.0 R@15 GeAR HippoRAG w/ IRCoT Mean Median 2 Hop 3 Hop Type 1 3 Hop Type 2 4 Hop Type 1 4 Hop Type 2 4 Hop Type 3 Figure 3: Analysis of R@15 performance divided by hop types on MuSiQue. The hop categorisation follows the MuSiQue documentation. Mean recall values are indicated by grey dots for each hop type. advantage becomes more pronounced with 3-hop questions, where GEAR’s entire interquartile range exceeds HippoRAG w / IRCoT’s median perfor- mance across both hop subdivisions. This demon- strates GEAR’s enhanced capability in handling moderately complex questions. In addition to MuSiQue, 2Wiki and HotpotQA, we test GEAR against the hand-picked case study