multi-hop QA benchmarks: MuSiQue, HotpotQA, and 2WikiMultihopQA. GEAR pushes the state of the art, achieving significant improve- ments in both single- and multi-step retrieval set- tings, with gains exceeding 10% on the most chal- lenging MuSiQue dataset. Furthermore, we demon- strate that our framework can address multi-hop questions in fewer iterations while consuming sig- nificantly fewer LLM tokens. Even with a single iteration, GEAR offers a more efficient alterna- tive to other iterative retrieval methods, such as HippoRAG w/ IRCoT. Our contributions can be summarised as follows: • We introduce a novel graph-based retriever, SyncGE, which leverages an LLM for locat- ing initial nodes for graph exploration and subsequently expands them by diversifying beams of triples that link multi-hop passages. • We incorporate this graph retrieval method within an LLM-based agent framework, ma- terialising GEAR, achieving state-of-the-art retrieval performance across three datasets. • We conduct comprehensive experiments show- casing the synergetic effects between our pro- posed graph-based retriever and the LLM within the GEAR framework. 2 Related Work Our work draws inspiration from two branches of research: (i) retrieval-augmented models for QA and (ii) multi-hop QA using combinations of LLMs with graphical structures. 2.1 Retrieval-augmented Models for QA Lewis et al. first showcased the benefits of augment- ing language models’ input context with relevant passages. Recent work by Wang et al. and Shen et al. explores query expansion approaches, gener- ating pseudo-documents from language models to expand the content of original queries. Subsequent frameworks, beginning with IRCoT, have investi- gated the interleaving of retrieval and prompting steps, allowing each step to iteratively guide and refine the other (Trivedi et al., 2023; Jiang et al., 2023; Su et al., 2024). 2.2 Multi-hop QA with LLMs and Graphs Several architectures have introduced an offline indexing phase to form hierarchical passage sum- maries