Our experiments reveal that this strategy improves over more naive implementations, demonstrating the LLM’s capability to guide the exploration of initial nodes for graph expansion. Furthermore, GEAR utilises multi-hop contexts returned by SyncGE and constructs a gist memory which is used for effec- tively summarising information across iterations. GEAR achieves superior performance compared to other multi-step retrieval methods while requiring fewer iterations and LLM tokens. Limitations The scope of this paper is limited to retrieval using a graph of triples that bridge corresponding pas- sages. While we demonstrate the effectiveness of our graph expansion approach and GEAR, several components could be further refined. More so- phisticated graph construction methods addressing challenges such as entity disambiguation (Dredze et al., 2010) and knowledge graph completion (Lin et al., 2015) may yield further improvements, as discussed in Appendix E. Similarly, our choice of a dense embedding model for the scoring function in the diverse triple beam search could be replaced by alternatives, such as formulating this as a natural language inference task (Wang et al., 2021). Beyond the core graph and scoring mecha- nisms, our design choices for other agent com- ponents—such as the gist memory, reasoner, and query rewriter—adopt commonly validated prac- tices from prior research (Trivedi et al., 2022; Li et al., 2024; Fang et al., 2024). While effective, exploring more sophisticated designs specifically tailored for these functions presents an opportunity for future performance gains. References Howard Chen, Ramakanth Pasunuru, Jason Weston, and Asli Celikyilmaz. 2023. Walking down the mem- ory maze: Beyond context limit through interactive reading. Preprint, arXiv:2310.05029. Gordon V . Cormack, Charles L A Clarke, and Stefan Buettcher. 2009. Reciprocal rank fusion outperforms condorcet and individual rank learning methods. In Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Infor- mation Retrieval, SIGIR ’09,