retrieved results (Fang et al., 2024). However, recursively prompting LLMs to traverse graphs remains computationally expensive, particularly as search spaces expand. In this paper, we present GEAR, a Graph- enhanced Agent for Retrieval-augmented gener- ation. During the offline stage, we align passages with their extracted triples to create interconnected indices. This alignment allows passages to be connected through graphs of triples. GEAR fea- tures a graph-based passage retrieval component called SyncGE. Unlike previous approaches that require expensive LLM calls for graph exploration, our method uses an LLM only to locate initial nodes (triples) and then employs a generic seman- tic model to expand the triple sub-graph by ex- ploring diverse triple beams. Additionally, GEAR uses multi-hop context retrieved by SyncGE to con- struct a memory that summarises information for multi-step retrieval. Our work refines the neurobiology-inspired paradigm proposed by Gutierrez et al. by modeling the communication between the hippocampus and neocortex during episodic memory formation. In our design, an array of proximal triples functions as a memory gist learned through the hippocam- pus within one or a few shots (iterations), which is then projected back to the neocortex for later re- call stages (Hanslmayr et al., 2016; Griffiths et al., 2019). We highlight the complementary potential between our graph retrieval approach and an LLM, which, within our system, emulates the synergy between the hippocampus and neocortex, offering insights from a biomimetic perspective. We evaluate the retrieval performance ofGEAR on three multi-hop QA benchmarks: MuSiQue, HotpotQA, and 2WikiMultihopQA. GEAR pushes the state of the art, achieving significant improve- ments in both single- and multi-step retrieval set- tings, with gains exceeding 10% on the most chal- lenging MuSiQue dataset. Furthermore, we demon- strate that our framework can address multi-hop questions in fewer iterations while consuming sig- nificantly fewer LLM tokens. Even with