original queries. Subsequent frameworks, beginning with IRCoT, have investi- gated the interleaving of retrieval and prompting steps, allowing each step to iteratively guide and refine the other (Trivedi et al., 2023; Jiang et al., 2023; Su et al., 2024). 2.2 Multi-hop QA with LLMs and Graphs Several architectures have introduced an offline indexing phase to form hierarchical passage sum- maries (Chen et al., 2023; Sarthi et al., 2024; Edge et al., 2024). However, summarisation must be repeated when adding new data, making knowl- edge base updates computationally expensive. Re- cent approaches have leveraged structured knowl- edge to address multi-hop QA challenges with LLMs (Park et al., 2023; Shen et al., 2024b; Li et al., 2024; Gutierrez et al., 2024; Liang et al., 2024; Wang et al., 2024). GraphReader, TRACE and HippoRAG propose offline methods for ex- tracting entities and atomic facts or semantic triples from passages (Li et al., 2024; Fang et al., 2024; Gutierrez et al., 2024). This allows chunks contain- ing the same or neighbouring entities to construct a graph of indexed passages. TRACE relies on an LLM to iteratively select triples for reasoning chains, which ground answer generation or filter retrieved results. However, its search space is lim- ited by pre-filtered candidate lists for each query. Li et al. employ an LLM agent that selects from a set of predefined actions to traverse knowledge graph nodes in real time given an input question. Liang et al. later introduced additional graph stan- dardisation, including instance-to-concept linking and semantic relation completion. However, this approach heavily depends on associating triples with pre-defined concepts for logical form-based retrieval. HippoRAG leverages an alignment of passages and extracted triples to retrieve passages based on the Personalized PageRank algorithm (Gutierrez et al., 2024). While achieving improvements for single- and multi-step retrieval (when coupled with