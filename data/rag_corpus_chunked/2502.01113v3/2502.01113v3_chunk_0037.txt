HotpotQA [ 72], MuSiQue [ 63], and 2WikiMultiHopQA (2Wiki) [20]. We provide a brief overview of these datasets below. 17 Table 6: Statistics of the datasets and constructed KG-indexes used for testing. Dataset Domain #Test #Document #Entity #Relation #Triple HotpotQA Multi-hop 1,000 9,221 87,768 45,112 279,112 MuSiQue Multi-hop 1,000 11,656 100,853 55,944 319,618 2Wiki Multi-hop 1,000 6,119 48,779 20,748 160,950 PubMedQA Biomedical 2,450 5,932 42,389 20,952 149,782 DelucionQA Customer Support 184 235 2,669 2,298 6,183 TechQA Customer Support 314 769 10,221 4,606 57,613 ExpertQA Customer Support 203 808 11,079 6,810 16,541 EManual Customer Support 132 102 695 586 1,329 MS Marco General Knowledge 423 3,481 24,740 17,042 63,995 HAGRID General Knowledge 1,318 1,975 23,484 18,653 48,969 • HotpotQA [72] is a multi-hop QA dataset that requires reasoning over multiple documents to answer questions. The dataset consists of 97k question-answer pairs, where each question is associated with up to 2 supporting and several distracting documents. The questions are designed to be answerable using multiple pieces of information from the supporting documents. • MuSiQue [63] is a challenging multi-hop QA dataset with 25k 2-4 hop questions. It requires coherent multi-step reasoning to answer questions that span multiple documents. • 2WikiMultiHopQA (2Wiki) [20] is a multi-hop QA dataset that requires reasoning over multiple Wikipedia articles to answer questions. The dataset consists of 192k questions, which are designed to be answerable using information from 2 or 4 articles. In experiments, we adhere to the official data split to obtain the training samples and follow existing methods [64, 16] to use the same 1,000 samples from each validation set to avoid data leakage. We merge the candidate passages as the document corpus for KG-index construction. The statistics of the training and test data are presented in Table 5 and Table 6, respectively. B.2 Domain-specific RAG