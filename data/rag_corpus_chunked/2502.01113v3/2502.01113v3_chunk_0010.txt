and KGs without further training. 3.2.1 Query-dependent GNN Conventional GNNs [14] follow the message passing paradigm, which iteratively aggregates informa- tion from neighbors to update entity representations. Such a paradigm is not suitable for the GFM retriever as it is graph-specific and neglects the relevance of queries. Recent query-dependent GNNs [78, 11] have shown promising results in capturing query-specific information and generalizability to unseen graphs, which is essential for the GFM retriever and can be formulated as: H L q =GNN q(q,G,H 0),(4) where H 0 ∈R |E|×d denotes initial entity features, and H L q denotes the updated entity representations conditioned on queryqafterLlayers of query-dependent message passing. The query-dependent GNN is theoretically proven to exhibit multi-hop logical reasoning ability [21, 73, 52] (detailed in Section A), which is selected as the backbone of our GFM retriever. It allows the GFM retriever to dynamically adjust the message passing process based on user queries and find the most relevant information on the graph with multi-hop reasoning. The path interpretation for this multi-hop reasoning process is shown in Section 4.8. Query Initialization.Given a query q, we first encode it into a query embedding with a sentence embedding model: q=SentenceEmb(q),q∈R d,(5) where d denotes the dimension of the query embedding. Then, for all the entities mentioned in the querye q ∈ E q ⊆ E, we initialize their entity features asqwhile others as zero vectors: H 0 = q,e∈ E q, 0,otherwise. (6) Query-dependent Message Passing.The query-dependent message passing will propagate the information from the question entities to other entities in the KG to capture their relevance to the query. The message passing process can be formulated as: Triple-level: h0 r =SentenceEmb(r),h 0 r ∈R d,(7) ml+1 e =Msg(h l e,g l+1(hl r),h l e′), (e,r,e ′)∈ G,(8) Entity-level: hl+1 e =Update(h l