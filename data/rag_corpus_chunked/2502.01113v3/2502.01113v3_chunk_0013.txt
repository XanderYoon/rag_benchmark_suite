Aq ={e}or{e ′}. The GFM retriever is then trained to predict the masked entity using both the query and the KG, as outlined in equation 13. Supervised Document Retrieval Fine-tuning.After self-supervised pre-training, we supervised fine-tune the GFM retriever on a labeled document retrieval task. In this task, queries q are natural language questions, and target entities Aq are extracted from labeled supporting documents Dq. The GFM retriever is trained to retrieve relevant entities from the KG index using the same training objective as in equation 13. 3.3 Documents Ranking and Answer Generation Given the entity relevance scores Pq ∈R |E|×1 predicted by the GFM retriever, we first retrieve the top-TentitiesE T q with the highest relevance scores as: E T q = argtop-T(P q),E T q ={e 1,. . .,e T }.(14) These retrieved entities are then used by the document ranker to obtain the final documents. To diminish the influence of popular entities, we weight the entities by the inverse of their frequency as entities mentioned in the document inverted index M∈ {0, 1} |E|×|D| and calculate the final document relevance scores by summing the weights of entity mentioned in documents: Fe = ( 1P d∈D M[e,d] ,e∈ E T q , 0,otherwise, (15) Pd =M ⊤Fe,P d ∈R |D|×1.(16) The top-K documents are retrieved based on the document relevance scores Pd and fed into the context of LLMs, with a retrieval augmented generation manner, to generate the final answer: DK = argtop-K(P d),D K ={D 1,. . .,D K},(17) a=LLM(q,D K).(18) 6 4 Experiment In experiments, we aim to address the following research questions: (1) How doesGFM-RAG perform in multi-hop retrieval and QA tasks? (Sections 4.2 and 4.3); (2) What are the efficiency and effectiveness of GFM-RAG in multi-hop retrieval? (Section 4.4); (3) How well does GFM-RAG generalize