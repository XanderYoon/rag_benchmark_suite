hop QA tasks as its retriever is designed for summarization and lacks multi-hop reasoning capability. With the help of LLMs, the multi-step retrieval pipeline IRCoT improves the performance of all single-step methods through iterative reasoning and retrieval. However,GFM-RAG still outperforms the multi-step methods by a large margin even with a single-step retrieval. This indicates that the GFM-RAG can effectively conduct the multi-hop reasoning in a single step (detailed in Section 4.8 and Section E.8), which is more efficient and effective than the multi-step retrieval pipeline (detailed in Section 4.4). 4.3 Question Answering Performance We then evaluate the QA performance ofGFM-RAG, as it is directly influenced by retrieval quality. We adopt the GPT-4o-mini [47] as LLM and use the top-5 retrieved documents for generating answers. From the results shown in Table 2, the single-step GFM-RAG has already achieved state-of-the-art 7 Table 1: Retrieval performance comparison. Category Method HotpotQA MuSiQue 2Wiki R@2 R@5 R@2 R@5 R@2 R@5 Single-step BM25 55.4 72.2 32.3 41.2 51.8 61.9 Contriever 57.2 75.5 34.8 46.6 46.6 57.5 GTR 59.4 73.3 37.4 49.1 60.2 67.9 ColBERTv2 64.7 79.3 37.9 49.2 59.2 68.2 RAPTOR 58.1 71.2 35.7 45.3 46.3 53.8 Proposition 58.7 71.1 37.6 49.3 56.4 63.1 GraphRAG (MS) 58.3 76.6 35.4 49.3 61.6 77.3 LightRAG 38.8 54.7 24.8 34.7 45.1 59.1 HippoRAG (Contriever) 59.0 76.2 41.0 52.1 71.5 89.5 HippoRAG (ColBERTv2) 60.5 77.7 40.9 51.9 70.7 89.1 SubgraphRAG 61.5 73.0 42.1 49.3 70.7 85.5 G-retriever 53.3 65.5 38.8 45.1 60.8 67.8 Multi-step Adaptive-RAG 61.0 76.4 35.1 44.7 44.7 61.4 FLARE 73.1 81.3 44.3 55.1 67.1 73.1 IRCoT + BM25 65.6 79.0 34.2 44.7 61.2 75.6 IRCoT + Contriever 65.9 81.6 39.1 52.2 51.6 63.8 IRCoT + ColBERTv2 67.9 82.0 41.7 53.7 64.1 74.4 IRCoT + HippoRAG (Contriever) 65.8 82.3 43.9 56.6 75.3 93.4 IRCoT + HippoRAG (ColBERTv2)67.0 83.0