in large language models (LLMs) [ 47, 42, 70] have greatly propelled the evolution of natural language processing, positioning them as foundational models for artificial general intelligence (AGI). Despite the remarkable reasoning ability [ 48], LLMs are still limited in accessing real-time information and lack of domain-specific knowledge, which is outside the pre-training corpus. To address these limitations, retrieval-augmented generation (RAG) [12] has become a popular paradigm in adding new knowledge to the static LLMs by retrieving relevant documents into the context of LLM generation. Existing RAG methods typically retrieve documents independently, making it difficult to capture com- plex relationships between pieces of knowledge [30, 5, 43]. This limitation hampers the performance of LLMs in integrating knowledge across document boundaries, particularly in multi-hop reasoning tasks [72, 63] and real-world applications like legal judgment [28] and medical diagnoses [25], which require reasoning over multiple sources. Although recent methods have expanded the retrieval process ∗Equal Contribution. †Corresponding author. 39th Conference on Neural Information Processing Systems (NeurIPS 2025). arXiv:2502.01113v3 [cs.IR] 11 Dec 2025 into multiple steps and incorporate LLM reasoning, they still encounter high computational costs due to iterative retrieval and reasoning with LLMs [64, 59, 26]. Recently, graph-enhanced retrieval augmented generation (GraphRAG) [51, 17] has emerged as a novel solution that builds a graph structure to explicitly model the intricate relationships between knowledge. This enables the development of a graph-enhanced retriever to identify relevant infor- mation using graphs. The structural nature of graphs allows GraphRAG to capture global context and dependencies among documents, significantly improving reasoning across multiple sources [9]. Methods like HippoRAG [16] enhance retrieval by employing a personalized PageRank algorithm to locate relevant knowledge with graphs. However, these algorithms rely solely on the graph structure, which is often noisy or incomplete, limiting their overall performance. Alternative methods [41, 18] incorporate