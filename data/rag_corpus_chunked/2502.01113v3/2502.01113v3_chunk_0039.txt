each question is related with up to 3 context documents. • MS Marco [45] is an open-domain question-answering dataset sourced from Bing search engine user query logs. Each question is associated with 10 context passages retrieved via Bing web search. • HAGRID [27] is a multi-lingual information retrieval dataset with questions and passages from MIRACL [75]. 18 In experiments, we use test sets constructed by RAGBench [10] and merge all the candidate passages as document corpus for KG-index construction. The statistics of the test dataset are detailed in Table 6. C Baselines In experiments, we compare with several widely used retrieval methods under three categories: (1) single-step naive methods: BM25 [53], Contriever [22], GTR [46], ColBERTv2 [55], RAPTOR [56], Proposition [6]; (2)graph-enhanced methods: GraphRAG (MS) [ 9], LightRAG [15], HippoRAG [16]; (3)multi-step methods: Adaptive-RAG [ 23], FLARE [ 24], and IRCoT [ 64]. The detailed introduction of the baselines is as follows. Single-step Naive Methodsare widely adopted in real-world applications due to their great efficiency and generalizability. • BM25 [53] is a classic information retrieval method based on the probabilistic model that ranks a set of documents based on the query terms frequency appearing in each document. • Contriever [22] trains a dense retriever with contrastive learning on a large-scale corpus to retrieve relevant documents for a given query. • GTR [46] develops a scale-up T5-based dense retriever that could generalize across different datasets and domains. • ColBERTv2 [55] is a state-of-the-art dense retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the retrieval quality. • RAPTOR [56] is an LLM-augmented retriever that recursively embeds, clusters, and sum- marizes chunks of text, constructing a tree with differing levels of summarization to enable accurate retrieval. • Proposition [6] enhances the performance of dense retrievers