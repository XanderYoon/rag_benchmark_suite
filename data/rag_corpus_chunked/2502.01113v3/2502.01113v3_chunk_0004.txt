retrieval augmented generation ( GFM-RAG), powered by a novel query-dependent GNN to enable efficient multi-hop retrieval within a single step. • We train a large-scale model with 8M parameters, marking the first graph foundation model (GFM) that can be applied directly to various unseen datasets for retrieval augmented generation. • We evaluate GFM-RAG on three multi-hop QA datasets and seven domain-specific RAG datasets, achieving state-of-the-art performance across all, demonstrating its effectiveness, efficiency, generalizability, and potential as a foundational model for further enhancement. 2 2 Related Work Retrieval-augmented generation (RAG)[ 12] provides an effective way to integrate external knowl- edge into large language models (LLMs) by retrieving relevant documents to facilitate LLM genera- tion. Early works adopt the pre-trained dense embedding model to encode documents as separate vectors [30, 5, 34, 43], which are then retrieved by calculating the similarity to the query. Despite efficiency and generalizability, these methods struggle to capture complex document relationships. Subsequent studies have explored multi-step retrieval, where LLMs guide an iterative process to retrieve and reason over multiple documents [64, 24, 58]. However, this approach is computationally expensive. Graph-enhanced retrieval augmented generation (GraphRAG)[ 51, 17] is a novel approach that builds graphs to explicitly model the complex relationships between knowledge, facilitating comprehensive retrieval and reasoning. Early research focuses on retrieving information from existing knowledge graphs (KGs), such as WikiData [65] and Freebase [3], by identifying relevant facts or reasoning paths [33, 38, 50]. Recent studies have integrated documents with KGs to improve knowledge coverage and retrieval [9, 35]. A graph structure is built from these documents to aid in identifying relevant content for LLM generation [8]. Based on graphs, LightRAG [15] incorporates graph structures into text indexing and retrieval, enabling efficient retrieval of entities and their relationships. HippoRAG [ 16] enhances multi-hop retrieval by using a