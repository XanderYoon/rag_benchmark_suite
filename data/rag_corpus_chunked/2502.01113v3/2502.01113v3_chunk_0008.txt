retriever), which is pre-trained on large-scale datasets and could retrieve documents based on any user query and KG-index ( 2 3 ); and C.documents ranking and answer generation, which ranks retrieved documents and generates final answer ( 4 5 ). 3.1 KG-index Construction Conventional embedding-based index methods encode documents as separate vectors [ 30, 5, 43], which are limited in modeling the relationships between them. Knowledge graphs (KGs), on the other hand, explicitly capturing the relationships between millions of facts, can provide a structural index of knowledge across multiple documents [9, 16]. The structural nature of the KG-index aligns well with the human hippocampal memory indexing theory [62], where the KG-index functions like an artificial hippocampus to store associations between knowledge memories, enhancing the integration of diverse knowledge for complex reasoning tasks [16]. To construct the KG-index, given a set of documents D, we first extract entities E and relations R to form triples T from documents. Then, the entity to document inverted index M∈ {0, 1} |E|×|D| is constructed to record the entities mentioned in each document. Such a process can be achieved by existing open information extraction (OpenIE) tools [1, 77, 49]. To better capture the connection between knowledge, we further conduct the entity resolution [ 13, 74] to add additional edges T + between entities with similar semantics, e.g., (USA, equivalent, United States of America ). Therefore, the final KG-index G is constructed as G={(e,r,e ′)∈ T ∪ T +}. In implementation, we leverage an LLM [47] as the OpenIE tool (prompts are shown in Table 22) and a pre-trained dense embedding model [55] for entity resolution. Details can be found in Section D.1. 3.2 Graph Foundation Model (GFM) Retriever The GFM retriever is designed to retrieve relevant documents based on any user query and the constructed