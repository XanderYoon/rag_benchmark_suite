graphs allows GraphRAG to capture global context and dependencies among documents, significantly improving reasoning across multiple sources [9]. Methods like HippoRAG [16] enhance retrieval by employing a personalized PageRank algorithm to locate relevant knowledge with graphs. However, these algorithms rely solely on the graph structure, which is often noisy or incomplete, limiting their overall performance. Alternative methods [41, 18] incorporate graph neural networks (GNNs) into the retrieval process. These methods have shown impressive performance due to GNNs’ powerful multi-hop reasoning capabilities on graphs [ 73]. Nevertheless, they still face limitations in generalizability since they require training from scratch on new datasets. Nowadays, the search for a foundation GNN model that can transfer and generalize across different datasets has been an active research topic. Ideally, a foundation GNN or graph foundation model (GFM) can benefit from large-scale training and generalize across diverse graphs [40, 37]. Efforts have been made to identify transferable graph tokens (e.g., motifs, sub-trees, and relation graphs) [11, 66, 68] that can be shared among different graphs for GFM design. However, these methods primarily focus on graph-related tasks (e.g., node classification and link prediction), leaving the design of a GFM to enhance LLMs’ reasoning ability unexplored. Documents KG-index Q GFM Retriever Retrieved Docs. Doc. Ranker Q LLM A Query Answer Figure 1: The overview framework ofGFM-RAG. To bridge the gap, in this paper, we propose an effective, efficient, and general graph founda- tion model for retrieval augmented generation (GFM-RAG), thereby enhancing LLMs’ reason- ing ability. As shown in Figure 1, we create a knowledge graph index(KG-index) from doc- uments in each dataset. The KG-index con- sists of interconnected factual triples pointing to the original documents, which serves as a structural knowledge index across multiple sources, enhancing the integration of diverse knowledge for complex reasoning tasks [ 16]. Then,