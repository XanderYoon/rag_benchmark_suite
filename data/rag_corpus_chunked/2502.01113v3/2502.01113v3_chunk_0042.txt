use the GPT-4o-mini [ 47] with the OpenIE prompts described in HippoRAG [16] to extract the entities, relations, and triples from the document corpus. Then, we use the ColBERTv2 [55] to conduct the entity resolution by computing the similarity between entities as s(ei,e j) =Emb.(e i)⊤Emb.(ej),(21) where a new triple (ei,equivalent,e j) is generated if s(ei,e j)> τ and ei ̸=e j. We set the threshold τ as 0.8 in our experiments. We divide the samples into groups of approximately 1k questions and 10k documents each to control the constructed KG-index size. In the end, we obtain 60 different KG-indexes and associated question-document pairs for model training. D.2 Model Settings In GFM-RAG, the GFM is implemented as a 6-layer query-dependent GNN with the hidden dimension of 512, DistMult message function, and sum aggregation. The relation update function gl(·) is implemented as a 2-layer MLP. We use the all-mpnet-v2 as the sentence embedding model with a dimension of 768. The total training parameters of the GFM is 8M. In the retrieval stage, we select topT= 20entities for the document ranker. D.3 Training Settings In KG completion pre-training, we randomly sample triples (e,r,t) from knowledge graphs and mask out either the head or the tail entity to create a synthetic queryq= (e,r, ?) and answer a={e} in a self-supervised manner. For example, given a triple (Barack Obama , born_in, Honolulu), we 20 Table 8: Comparison of different sentence embedding models used inGFM-RAG. Sentence Embedding Model HotpotQA MuSique 2Wiki R@2 R@5 R@2 R@5 R@2 R@5 sentence-transformers/all-mpnet-base-v2 70.2 82.1 46.0 55.1 81.185.6 BAAI/bge-large-en 68.1 81.1 45.955.9 80.786.3 Alibaba-NLP/gte-Qwen2-1.5B-instruct 69.9 81.5 46.0 55.0 79.8 86.2 Alibaba-NLP/gte-Qwen2-7B-instruct 68.5 81.5 45.5 55.1 80.8 85.6 nvidia/NV-Embed-v2 69.2 81.4 46.354.9 80.3 85.5 Table 9: Comparison ofGFM-RAGwith pre-trained and fine-tuned sentence embedding models. Method HotpotQA MuSiQue 2Wiki R@2 R@5 R@2