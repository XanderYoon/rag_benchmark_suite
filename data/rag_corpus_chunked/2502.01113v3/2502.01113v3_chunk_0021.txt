of GFM-RAG for multi-hop reasoning in Table 4. Inspired by NBFNet [78], the paths’ importance to the final prediction can be quantified by the partial derivative of the prediction score with respect to the triples at each layer (hop), defined as: s1,s 2,. . .,s L = argtop-k ∂pe(q) ∂sl .(19) The top-k path interpretations can be obtained by the top- k longest paths with beam search. We illustrate the path interpretations in Table 4. In the first example, GFM-RAG successfully deduces that the singer of the song has a football club named after him and that he owned it. In the second example, GFM-RAG identifies two paths related to the murder case and the judge presiding over the trial. These interpretations show that GFM-RAG exhibits the ability of multi-hop reasoning within single-step retrieval. We also illustrate the distribution the multi-hop prediction in Section E.8. 5 Conclusion In this paper, we introduce the first graph foundation model for retrieval augmented generation. By leveraging the knowledge graph index,GFM-RAG explicitly models the complex relationships between knowledge and documents, facilitating a more effective and efficient retrieval process. Powered by a query-dependent GNN pre-trained on large-scale datasets,GFM-RAG can effectively perform multi-hop reasoning over the graph structure to find relevant knowledge in a single step. Extensive experiments across three benchmark datasets and seven domain-specific datasets demonstrate that GFM-RAG significantly outperforms state-of-the-art methods in effectiveness, efficiency, and generalizability. Its alignment with scaling laws also suggests the potential for scaling to even larger datasets. In the future, we plan to conduct larger-scale training and further explore GFM-RAG’s capabilities in other challenging scenarios such as knowledge graph completion and question answering. 10 Acknowledgments G Haffari is partly supported by the ARC Future Fellowship FT190100039 and DARPA Assured Neuro Symbolic Learning and Reasoning (ANSR) program under award number FA8750-23-2-1016.