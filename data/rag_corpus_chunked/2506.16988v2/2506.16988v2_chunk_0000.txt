RAGentA: Multi-Agent Retrieval-Augmented Generation for Attributed Question Answering Ines Besrour∗ ines.besrour@mailbox.tu-dresden.de TU Dresden & ScaDS.AI Dresden/Leipzig Dresden, Germany Jingbo He∗ jingbo.he@mailbox.tu-dresden.de TU Dresden & ScaDS.AI Dresden/Leipzig Dresden, Germany Tobias Schreieder tobias.schreieder@tu-dresden.de TU Dresden & ScaDS.AI Dresden/Leipzig Dresden, Germany Michael Färber michael.faerber@tu-dresden.de TU Dresden & ScaDS.AI Dresden/Leipzig Dresden, Germany Abstract We present RAGentA, a multi-agent retrieval-augmented genera- tion (RAG) framework for attributed question answering (QA) with large language models (LLMs). With the goal of trustworthy answer generation, RAGentA focuses on optimizing answer correctness, defined by coverage and relevance to the question and faithfulness, which measures the extent to which answers are grounded in re- trieved documents. RAGentA uses a multi-agent architecture that iteratively filters retrieved documents, generates attributed answers with in-line citations, and verifies completeness through dynamic refinement. Central to the framework is a hybrid retrieval strategy that combines sparse and dense methods, improving Recall@20 by 12.5% compared to the best single retrieval model, resulting in more correct and well-supported answers. Evaluated on a synthetic QA dataset derived from the FineWeb index, RAGentA outperforms standard RAG baselines, achieving gains of 1.09% in correctness and 10.72% in faithfulness. These results demonstrate the effectiveness of our multi-agent RAG architecture and hybrid retrieval strategy in advancing trustworthy QA with LLMs. CCS Concepts • Information systems → Question answering ; • Comput- ing methodologies → Multi-agent systems; Natural language generation. Keywords Retrieval-Augmented Generation, Multi-Agent System, Attributed Question Answering, Large Language Model ACM Reference Format: Ines Besrour, Jingbo He, Tobias Schreieder, and Michael Färber. 2025. RA- GentA: Multi-Agent Retrieval-Augmented Generation for Attributed Ques- tion Answering. In SIGIR 2025 LiveRAG Challenge, held in conjunction with the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2025), July 13–17, 2025, Padua, Italy. ∗Both authors contributed equally to this research. This work is licensed under