difference be- tween logarithmic probabilities: score = log ğ‘ (â€œYesâ€) âˆ’ log ğ‘ (â€œNoâ€). After scoring all documents, the system computes the mean score (ğœğ‘) and standard deviation (ğœ), establishing a dynamic threshold as adjusted_ğœğ‘ = ğœğ‘ âˆ’ ğ‘› Â·ğœ, where ğ‘› is a hyperparameter control- ling filtering stringency. According to empirical analyses from the MAIN-RAG study, optimal performance is achieved at ğ‘› = 0.5. Uti- lizing this dynamic threshold, the system retains documents where score â‰¥ adjusted_ğœğ‘ and filters those where score < adjusted_ğœğ‘. 4.2.3 Agent-3: Final-Predictor. Following the filtering of irrelevant documents, Agent-3 synthesizes a comprehensive answer using the remaining, relevant documents. The principal modification to Agent-3, relative to MAIN-RAG, is the generation of explicit in-line citations. Specifically, Agent-3 is instructed to generate citations in the standardized [ğ‘‹ ] format (where ğ‘‹ denotes the corresponding document identifier) using few-shot citation examples immediately after each factual assertion. As a result, each statement is treated as a discrete "claim", paired with its supporting citation(s), and extracted in a structured format. 4.2.4 Agent-4: Reviser. Agent-4 constitutes our most significant extension to the MAIN-RAG framework, conducting sophisticated multi-stage analysis to determine whether the query has been com- prehensively answered. The reviser operates through a systematic pipeline that begins by decomposing complex queries (containing multiple sub-questions) into constituent components and mapping each generated claim to specific aspects of the original question. This process evaluates whether claims effectively address corre- sponding question components while filtering irrelevant ones. Fol- lowing the initial mapping, Agent-4 employs regular expression functions to parse structured output and assess answer complete- ness by categorizing each component as â€œfully answered, â€ â€œpartially answered, â€ or â€œnot answered. â€ When gaps are identified, Agent-4 initiates a targeted follow-up process: it generates questions to address these gaps and uses the hybrid retrieval system