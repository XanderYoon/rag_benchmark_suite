by incorporating these two topolog- ical knowledge. Our empirical analysis reveals that LLMs benefit from additional texts that are similar to the target text. Moreover, by analyzing a wide range of text-attributed networks from diverse domains, we empirically verify the noticeable positive correlation between textual and proximity/role-based similarity. These findings have inspired us to develop Topology-aware Retrieval-Augmented Generation (Topo-RAG), a framework that enhances text genera- tion by retrieving texts based on their topological similarities to the target text. We conduct comprehensive experiments to validate the effectiveness of Topo-RAG in text generation. Moreover, we take the initiative in utilizing node classification and link prediction to quantify the quality of the generated texts in a novel task-oriented manner. Additionally, we showcase an application of Topo-RAG in addressing missing feature issues in graph machine learning tasks. Recognizing the importance of not only considering the quantity but also the structure of input knowledge in text generation [67], future work will focus on optimizing input formats by leverag- ing topological signals for question-answering and text-generation tasks. Moreover, we plan to assess the robustness of the TopoRAG framework by exploring the potential of attacking/defending over graphs to compromise/strengthen the capability of LLMs in com- pleting downstream tasks. A APPENDIX In this section, we present supplementary findings that enhance the analysis from our primary study and further validate the gener- alizability of the observed phenomenon. A.1 Textual Similarity over Sent Emails on Eron-Email Dataset Following the same setting used for Figure 2(c), we visualize the textual similarity of emails sent by any pair of employees and fur- ther group them based on their job titles. Similar to the observation in Figure 2(c), we can see that people sharing the same job titles have similar textual patterns in their sent emails. A.2 Additional Correlation Analysis Here we conduct