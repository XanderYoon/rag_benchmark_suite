ğ¾ ğœ™Topo(ğ‘£ğ‘–, ğ‘£ ğ‘— ), (7) After that, we formulate the texts of nodes in Tğ‘– along with the partially observed text ğ‘‹ğ‘– of target node ğ‘£ğ‘– into the prompt trigger- ing LLM for text generation. Compared with conventional retrievals that only consider textual relations, the Topo-RAG framework con- siders topological relations. To implement this, itâ€™s necessary to pre-calculate the topological relations between every pair of nodes, a process requiring O (|V |2) in both space and time complexity. To manage space constraints, we apply a top-k thresholding, reducing the space requirement significantly to O (|V |ğ¾). These computa- tions are done in advance during an offline phase. Consequently, when a text generation request for a specific target node is made, we can retrieve the necessary information instantaneously from the pre-computed dictionary, maintaining a time complexity of O (1). Note that prompting LLMs with the retrieved nodes of very long texts could exceed the input limits. Since this is a common issue for any RAG framework, one can equip our Topo-RAG framework with the existing strategies [30, 63] that handle this long-context issue. Here, we exclude instances where the context limit is ex- ceeded. The length distribution analysis in Figure 7(b) reveals that the textual length of most nodes remains within acceptable limits, ensuring that our results and insights are still applicable to the original dataset even after the exclusion. 6 EXPERIMENTS Table 1: Statistics of Datasets. SFull denote nodes with fully available textual information while SPartial denote nodes with partially observable text. Domain Dataset # Nodes # Edges # Instances (SFull/S Partial) Splitting Citation Cora [6, 70] 2,708 5,429 2,522/186 Random Pubmed [6, 70] 19,717 44,335 17,786/1,931 Random Arxiv [6, 25] 16,316 53,519 14,791/1,525 Time E-commerce Product [6, 25] 16,475 60,015 15,790/685 Random Book [45] 7,252 203,438 6,526/726 Time