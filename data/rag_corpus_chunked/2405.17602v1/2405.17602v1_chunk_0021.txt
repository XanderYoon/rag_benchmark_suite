the sender and receiver of the target email to be generated and then collect emails from the two employees with the highest topological similarity to that sender and receiver. Furthermore, we select the Top-3 emails from those collected emails based on their textual similarity to the partially observed target text. For most of the hyperparameters used for eval- uation with node classification and link prediction, we follow the same setting as [65] and [78]. In node classification, the hyperpa- rameters are: training epoch is 1000, learning rate 0.01, weight decay 0.0005, early stopping 100, 2 layer graph convolution layer/MLP, dropout 0.5, number of hidden layers 64. In link prediction, the hy- perparameters are: encoder learning rate 0.001, predictor learning rate 0.001, number of hidden layers 256, and dropout 0. Augmenting Textual Generation via Topology Aware Retrieval Conferenceâ€™17, July 2017, Washington, DC, USA Table 2: Performance comparison of TopoRAG with baselines. The best results are in bold. BLEU is BLEU-4, ROUGE is ROUGE-L. Our TopoRAG almost achieves the best performance across all baselines on all datasets. "Average" is computed by averaging each metric across 9 datasets. "Boost" is computed by the relative performance gain from the second-to-best "Text" to the best "TopoRAG". LLM Retriever Cora Pubmed Arxiv Product Book BLEU ROUGE Bert-F1 BLEU ROUGE Bert-F1 BLEU ROUGE Bert-F1 BLEU ROUGE Bert-F1 BLEU ROUGE Bert-F1 GPT 3.5 None 1.46 15.90 82.15 1.52 14.63 80.28 1.22 15.25 81.87 1.57 15.09 81.98 1.05 14.75 80.98 RD 1.78 16.42 83.10 2.38 15.83 81.32 2.64 16.22 83.03 1.65 14.90 82.09 1.34 14.77 82.30 Text 1.77 16.43 83.05 2.27 15.49 81.37 2.23 15.89 82.96 2.44 15.50 82.16 1.77 15.30 82.53 TopoRAG 3.49 17.58 83.86 3.97 17.54 82.97 3.66 17.49 84.10 3.65 16.85 83.17 2.55 16.14 83.15 Boost 97.18% 7.00% 0.98% 74.89% 13.23% 1.97% 64.13% 10.07% 1.37% 49.59%