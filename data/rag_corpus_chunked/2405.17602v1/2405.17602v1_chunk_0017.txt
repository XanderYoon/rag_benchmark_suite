with fully available textual information while SPartial denote nodes with partially observable text. Domain Dataset # Nodes # Edges # Instances (SFull/S Partial) Splitting Citation Cora [6, 70] 2,708 5,429 2,522/186 Random Pubmed [6, 70] 19,717 44,335 17,786/1,931 Random Arxiv [6, 25] 16,316 53,519 14,791/1,525 Time E-commerce Product [6, 25] 16,475 60,015 15,790/685 Random Book [45] 7,252 203,438 6,526/726 Time Epinion [4, 79] 4,976 15,613 4,477/499 Time Music [45] 10,341 447,250 9,306/1,035 Time Pantry [45] 4,650 43,970 4,184/466 Time Social Eron-Email [58] 18,055 123,208 182,265/46,990 Random Conference’17, July 2017, Washington, DC, USA 6.1 Experimental Settings 6.1.1 Datasets. Although previous works [26, 35] borrow knowl- edge graphs to enhance text generation, the improvement mainly comes from the complex logical pattern encoded in the knowl- edge graph rather than proximity/structure topological patterns discussed in this paper. Therefore, we collect additional datasets to demonstrate the effectiveness of considering these two patterns in text generation, the details of which are discussed next: • Cora, Pubmed, Arxiv [6, 25, 70]: Citation networks where nodes represent papers with abstracts as textual information, and edges signify reference relations. We divide nodes into fully- observed/partially-observed sets in a 90%/10% ratio and further remove nodes whose abstracts are less than 100 words. Then, we create the induced subgraph and remove edges connecting two nodes in the testing set to avoid information leakage. For the larger Arxiv network, due to resource constraints, we randomly select 2% nodes as seeds and apply the GraphSAGE sampling with the number of neighbors [2, 2] across two layers. Since Arxiv provides the publication time of each paper [25], we use the same preprocessing as Cora/Pubmed but follow the chrono- logical order, imitating the real scenarios where users are writing papers with references to historical papers. • Book, Epinion, Music, Pantry [4, 6, 25, 45,