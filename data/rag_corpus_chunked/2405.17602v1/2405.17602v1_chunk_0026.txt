the po- tential of incorporating texts of non-neighboring nodes while the message-passing of GCN/SAGE only considers neighboring texts. In addition, we can see the additional benefit of TopoRAG on Cora is more than the one on Pubmed. We hypothesize that this is due to the higher correlation between textual similarity and topological similarity of Cora (0.2099) than the one of Pubmed (0.1039) in Fig- ure 8. Notably, the superiority of our method is more pronounced in the results shown in Table 3 compared to "ROUGE" and "Bert-F1" in Table 2. This suggests that employing complex, task-oriented evaluation metrics can reveal subtle distinctions in the quality of generated texts. Such an approach is particularly valuable in the current landscape of Large Language Models (LLMs), providing a nuanced means to quantify the effectiveness of text generation. 6.3 Impact of Starting Words We explore the impact of increasing the number of starting words, ranging from 0 to 100, on the performance of text generation for the Cora/Book datasets. Our findings reveal that TopoRAG consistently outperforms other methods. This advantage becomes even more obvious when the number of initial words becomes less. This trend suggests that a reduced count of starting words offers less contex- tual information, thereby heightening the need for the additional information provided by the TopoRAG. Moreover, we observe an interesting trend with BLEU scores initially increasing and then de- creasing on Cora, whereas BertScore-F1 shows a consistent upward trajectory. This pattern can be attributed to the inherent charac- teristics of these evaluation metrics. The BLEU score focuses on the overlap of exact words. As we provide more starting words, the length of the remaining part of the target sentence decreases. Figure 6: As the number of beginning words increases, the BLEU score first increases and then decreases on Cora while