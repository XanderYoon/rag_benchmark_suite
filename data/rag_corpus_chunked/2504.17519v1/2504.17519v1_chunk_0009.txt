how well the model retrieves queries associated with incrementally added documents: Definition 2 (Generalization Performance ğºğ´ğ‘›). ğºğ´ğ‘› = 1 ğ‘› ğ‘›âˆ‘ï¸ ğ‘œ=1 ğ‘ƒğ‘œ,ğ‘œ (5) where ğ‘ƒğ‘œ,ğ‘œ represents the retrieval performance on queries targeting Dğ‘œ after indexing corpus Dğ‘œ . 3 Experimental Setup 3.1 Datasets We conduct our experiments on two widely used datasets: Natural Questions (NQ) [13] and MS-MARCO [1]. We appropriately par- tition the document sets within the datasets to simulate dynamic corpora scenarios. To simulate the task of dynamic corpora, we partition the docu- ments sets in MS-MARCO and NQ through a two-phase process: (i) Initial corpus construction: Collect all documents and ran- domly select 50% as the initial corpus D0. Extract query-document pairs associated with D0 and split them into a training set P0 and an initial test set Q0. All models are fully trained on P0, simulating initialization on the base corpus. (ii)Incremental document addi- tions: Partition the remaining 50% of documents into five equally sized subsets, each comprising 10% of the original corpus (D1 to D5). For each Dğ‘– (1 â‰¤ ğ‘– â‰¤ 5), extract its associated query-docu- ment pairs to form incremental test sets Q1 to Q5. No additional training is performed for these document setsâ€”models only index new documents upon each addition. 3.2 Retrieval approaches To compare the performance of GR approaches with previous re- trieval methods on dynamic corpora, we selected three types of retrieval approaches: sparse retrieval approaches, dense retrieval approaches, and generative retrieval approaches. Sparse retrieval. (i) BM25 [26], a traditional retrieval approach that ranks documents according to the frequency of the term and the normalization of the length of the document. We re-index the entire corpora when the corpora is updated. Dense retrieval. (i) DPR [10], a neural retrieval method that uses dual encoders to map queries and documents