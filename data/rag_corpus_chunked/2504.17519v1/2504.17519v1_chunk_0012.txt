tasks. (vi) SEAL [2] uses arbitrary n-grams from documents as docids and generates a series of n-grams under the constraints of the FM-index to retrieve the corresponding documents. (vii) MIN- DER [15] adopts multiple text types to represent docids, such as titles, URLs, and n-grams. Different types of scores are generated at the same time and documents are retrieved based on these scores. (viii) LTRGR [16] also adopts the multiple text docid design, and in- troduces an additional learn-to-rank task and rank loss to optimize the retrieval model. To enable GR approaches to handle dynamic corpora, we adopt the following design strategies for docid assignment: (i) For nu- meric-based docids: These approaches rely on structured numeri- cal representations (e.g., k-means centroids, product quantization codebooks). We preserve the original document encoder’s state (k-means cluster centroids or vector quantization codebooks) to encode new documents, maintaining identifier consistency with initial documents. (ii) For text-based docids: These approaches leverage document-induced textual patterns (e.g., Title, URLs). We leverage new documents’ inherent metadata and text structure to automatically assemble valid identifiers. 3.3 Implementation details We implement BM25 using the bm25s library.1 For dense retrieval models (DPR and DPR-HN), we employ the pyserini toolkit [18], using its built-in functionalities for indexing and retrieval. For GR approaches (DSI, ULtron variants, NCI, GenRET, SEAL, MINDER, and LTRGR), we adopt their official implementations and strictly follow the default hyperparameter configurations provided in the original works to ensure reproducibility. All models operate with a maximum input sequence length of 512 tokens. Experiments are conducted on 8 NVIDIA A100 GPUs, 1https://github.com/xhluca/bm25s with distributed training enabled for GR methods to accommodate their large parameter sizes. For DPR/DPR-HN, we initialize the document encoder with the checkpoint pre-trained on the initial documents and freeze its parameters during incremental phases. 3.4 Statistical Validation We verified the