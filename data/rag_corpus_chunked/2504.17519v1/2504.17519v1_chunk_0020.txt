/uni00000013/uni00000011/uni00000014 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000016 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000018/uni0000002c/uni00000027/uni00000025/uni0000002c /uni00000035/uni00000048/uni00000057/uni00000055/uni0000004c/uni00000048/uni00000059/uni00000044/uni0000004f/uni00000003/uni00000031/uni00000048/uni0000005a/uni0000004f/uni0000005c/uni00000003/uni00000024/uni00000047/uni00000047/uni00000048/uni00000047/uni00000003/uni00000027/uni00000052/uni00000046/uni00000058/uni00000050/uni00000048/uni00000051/uni00000057/uni00000056 /uni00000025/uni00000030/uni00000015/uni00000018 /uni00000027/uni00000033/uni00000035 /uni00000038/uni0000004f/uni00000057/uni00000055/uni00000052/uni00000051/uni00000010/uni00000033/uni00000034 /uni0000002a/uni00000048/uni00000051/uni00000035/uni00000028/uni00000037 /uni00000031/uni00000010/uni0000004a/uni00000055/uni00000044/uni00000050 /uni00000038/uni00000035/uni0000002f /uni00000037/uni0000004c/uni00000057/uni0000004f/uni00000048 /uni00000034/uni00000058/uni00000048/uni00000055/uni0000005c Figure 1: IDBI results for different retrieval methods on NQ dataset. Lower is better. To quantify the retrieval bias toward initial documents, we in- troduce the Initial Document Bias Index (IDBI) . Definition 3 (Initial Document Bias Index (IDBI)). The IDBI measures the discrepancy between the observed proportion of initial documents retrieved in the Top-ğ¾ results and their expected proportion under an unbiased distribution. It is defined as: IDBI = ğ‘…init âˆ’ ğ¸init ğ¾ âˆ’ ğ¸init , (7) where: ğ‘…init is the number of retrieved initial documents in the Top- ğ¾ results. ğ¸init = ğ¾ Ã— | D0 | | D0âˆªD new | is the expected count of initial documents under a uniform distribution. Remark. The IDBI assumes that initial documents D0 and new documents Dnew are drawn from the same latent query-document relevance distribution. The index is normalized within the range [0, 1], where: IDBI = 0 indicates no bias (i.e., retrieved documents are proportional to their corpus distribution). IDBI = 1 indicates complete bias toward initial documents. As shown in Figure 1, numeric-based docids (e.g., GenRET, Ultron- PQ) exhibit significant retrieval bias toward initial documents across both task settings. This aligns with our hypothesis that numeric- based representations introduce a semantic gap, making it harder for the model to associate new documents with their identifiers. While text-based docids (e.g., URL, title, query) demonstrate better Replication and Exploration of Generative Retrieval over Dynamic Corpora SIGIR â€™25, July 13â€“18, 2025, Padua, Italy Table 4: Comparison of retrieval performance (Hit@10) on the NQ dataset for initial and newly added documents across various text-type docid representations. Text Type NQ (Hit@10) D0 D1 D2 D3 D4 D5 Initial documents n-gram 0.753 0.712 0.688 0.666 0.642 0.626 url 0.759 0.757