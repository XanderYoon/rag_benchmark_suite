and generative retrieval approaches. Sparse retrieval. (i) BM25 [26], a traditional retrieval approach that ranks documents according to the frequency of the term and the normalization of the length of the document. We re-index the entire corpora when the corpora is updated. Dense retrieval. (i) DPR [10], a neural retrieval method that uses dual encoders to map queries and documents into a shared dense vector space for similarity computation. We use the document en- coder trained on D0 to re-encode the newly added documents for retrieval. (ii) DPR-HN [20, 25], an enhanced DPR variant that incor- porates hard negative sampling techniques. It integrates in-batch negatives, top-K retrieved negatives from dense retrievers, and BM25 hard negatives. Generative retrieval. (i) DSI-SE [30], which uses the hierarchical k-means clustering results of document embeddings as docids and trains the model to memorize the documents in parameters. (ii) Ul- tron-PQ [36] uses the product quantization results of document embeddings as docids and designs a three-stage training task to enable the model to memorize the documents. (iii) Ultron-URL [36], a variant of Ultron, uses the document URLs as docids. (iv) NCI [31] uses a prefix-aware weight-adaptive decoder and various query SIGIR â€™25, July 13â€“18, 2025, Padua, Italy Zhen Zhang et al. Table 1: Model performance on queries corresponding to the initial document set D0, where the document set size continuously expands as new documents are added. The best results are indicated in boldface. Method DocID Type NQ (Hit@10) MS-MARCO (Hit@10) D0 D1 D2 D3 D4 D5 ğ¹ğ‘› â†“ D 0 D1 D2 D3 D4 D5 ğ¹ğ‘› â†“ Sparse retrieval BM25 Term Weight 0.647 0.625 0.611 0.598 0.573 0.573 0.051 0.653 0.640 0.632 0.629 0.619 0.614 0.026 Dense retrieval DPR Dense Vector 0.725 0.704 0.696 0.686 0.670 0.660 0.042 0.683 0.681 0.668 0.656 0.651 0.648 0.022 DPR-HN