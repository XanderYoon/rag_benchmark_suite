the Introduction Section, retraining or continuing training the GR model would cost much more compu- tational overhead. Therefore, our work only focuses on the second paradigm, where the Retriever must leverage learned knowledge to handle novel documents through constrained decoding over the updated prefix tree T â€² D. This setting tests the modelâ€™s ability to generalize to unseen document representations without parameter updates. 2.3 Evaluation metrics Our evaluation primarily focuses on two aspects of model perfor- mance over dynamic corpora: (i) retrieve initial documents, which assesses the modelâ€™s ability to maintain performance on queries targeting original documents D0; and (ii) retrieve newly added doc- uments, which evaluates the modelâ€™s capacity to retrieve novel documents Dnew. We use Hit@10 as the primary metric in both settings and further introduce formal metrics to summarize the modelâ€™s performance as new documents are incrementally indexed. Retrieve initial documents. To assess the modelâ€™s forgetting be- havior when indexing new documents, we define the forgetting metric ğ¹ğ‘›, which quantifies the degradation in retrieval perfor- mance on queries targeting the original corpus D0 after indexing corpus D1 to Dğ‘›: Definition 1 (Forgetting Metric ğ¹ğ‘›). ğ¹ğ‘› = 1 ğ‘› ğ‘›âˆ‘ï¸ ğ‘œ=1 max ğ‘ƒ0,0 âˆ’ ğ‘ƒğ‘œ,0, 0 (4) where ğ‘ƒğ‘œ,0 represents the retrieval performance (e.g., Hit@10) of queries in D0 after indexing corpus Dğ‘œ . Retrieve newly added documents.To measure the modelâ€™s ability to generalize and retrieve newly indexed documents, we define the generalization performance metric ğºğ´ğ‘›, which captures how well the model retrieves queries associated with incrementally added documents: Definition 2 (Generalization Performance ğºğ´ğ‘›). ğºğ´ğ‘› = 1 ğ‘› ğ‘›âˆ‘ï¸ ğ‘œ=1 ğ‘ƒğ‘œ,ğ‘œ (5) where ğ‘ƒğ‘œ,ğ‘œ represents the retrieval performance on queries targeting Dğ‘œ after indexing corpus Dğ‘œ . 3 Experimental Setup 3.1 Datasets We conduct our experiments on two widely used datasets: Natural Questions (NQ) [13] and MS-MARCO [1].