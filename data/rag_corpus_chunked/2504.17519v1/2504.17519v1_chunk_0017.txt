for DSI. For instance, DSI++ improves Hits@10 for new documents on NQ from 0.205 to 0.644 on D5, demonstrating better generalization to unseen doc- uments. However, this comes at a cost: DSI++ exhibits noticeable forgetting on initial documents. For SEAL, incremental training yields only a slight improvement in both settings. This is because SEAL’s text-based docids inherently accommodate semantic varia- tions in new documents, reducing the need for extensive retraining. Further analysis in Table 3 suggests that while incremental train- ing provides modest benefits for text-based docid models, their robustness to dynamic corpora primarily stems from their ability to generalize via natural language patterns, rather than relying on explicit retraining. In conclusion, the performance of generative retrieval models in dynamic corpora reveals certain limitations, particularly when it comes to adapting to newly added documents. For retrieving initial documents, generative models perform acceptably, with only slight degradation as the corpus grows. Models like DSI-SE and NCI show only slight performance drops, similar to traditional methods SIGIR ’25, July 13–18, 2025, Padua, Italy Zhen Zhang et al. like BM25 and DPR. However, the challenge arises when retrieving newly added documents. Generative models that rely on numeric- based docids (e.g., DSI-SE and Ultron-PQ) struggle significantly, as they cannot adapt to new documents without retraining. In contrast, models using text-based docids, like SEAL and LTRGR, perform better, as text-based docids can generalize and adapt to new documents more effectively. While text-based docids show promise, not all text-based generative retrieval models perform equally well. For instance, models like SEAL demonstrate better performance compared to others like Ultron-URL. Further exploration is needed to determine which specific text features are most suitable for dynamic corpora scenario. 5 Analysis of Docid Design To understand the pros and cons of different docid designs for GR in dynamic corpus scenarios,