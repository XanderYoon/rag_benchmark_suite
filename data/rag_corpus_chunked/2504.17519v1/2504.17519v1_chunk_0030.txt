of docid size. Small docid sizes (64) lead to substantially degrade on newly added documents. Conversely, excessively large sizes (8192) create an over-discretized learning space where the model struggles to establish stable query-docid mappings. Table 7: Experiments about memory costs and efficiency. Method Memory Tok-K Latency DPR 980MB 100 152ms NCI 865MB 10 216ms 100 269ms SEAL 2200MB 10 619ms 100 778ms MDGR 886MB 10 241ms 100 320ms Table 7 shows MDGR achieves both effectiveness and system efficiency. This efficiency stems from combining number-type do- cids’ compact storage with number sequences, enabling dynamic adaptability without sacrificing speed – MDGR retrieves documents 3.6× faster than SEAL while outperforming other numeric-based docid methods (NCI) in dynamic corpora scenario. 7 Conclusion In this paper, we have conducted a systematic investigation into the capabilities and limitations of GR models in dynamic corpora sce- narios, where document collections expand continuously over time. Through comprehensive evaluations on realistic dynamic bench- marks derived from NQ and MS-MARCO datasets, we have revealed that certain GR methods, primarily those relying on numeric-based docids, face challenges in generalizing to unseen documents with- out additional training, while models utilizing text-based docids demonstrate stronger generalization capabilities in dynamic cor- pora. Our analysis has demonstrated that text-based docids in- herently address key limitations of numeric-based docids by mit- igating generation bias towards previously seen docids, enabling finer-grained document representation, and enhancing robustness against overfitting. Building on these insights, we have proposed a novel GR frame- work MDGR that combines the structured benefits of numeric- based docids with a revised design to avoid training-induced biases, achieving competitive performance in dynamic corpora scenario. Our findings not only highlight the critical role of docid semantics and representation in GR frameworks but also provide actionable guidelines for adapting generative retrieval to real-world dynamic environments. Future work may