the T5 model [41], appending them to the original document text. Dense retrieval. (i) DPR [22], which utilizes a BERT-based dual encoder to produce dense embeddings for queries and documents. PseudoQ [49] improves DPR by generating pseudo-queries using K-means clustering over document embeddings. (ii) ANCE [68], a RoBERTa-based dual encoder that incorporates hard negatives retrieved from an asynchronously updated approximate nearest neighbor (ANN) index. (iii) RepBERT [74], a BERT-based model that generates fixed-length contextualized embeddings, with queryâ€“ document relevance computed via inner product similarity. (iv)Sen- tence-T5 [36], which applies a T5-based architecture to gener- ate sentence embeddings using encoder-only and encoder-decoder models with contrastive learning. Generative retrieval. (i) DSI [60], which represents docids us- ing hierarchical k-means cluster IDs and trains with the DSI-Num objective. (ii) DSI-QG [80], which augments training data with synthetic queries generated using a query generation model [38] 4https://github.com/castorini/pyserini and represents documents with arbitrary unique numerical docids. (iii) NCI [64], which assigns semantically structured numeric do- cids paired with pseudo-queries. (iv) SEAL [16], which retrieves docids represented as arbitrary n-grams extracted from document text using an FM-index. (v) Ultron [79], which employs keyword and semantic-based docids, using a three-stage training approach: general pre-training, search-oriented pre-training, and supervised fine-tuning. (vi) ROGER [77], which transfers document relevance knowledge from a dense retriever to a generative retriever via knowledge distillation. (vii) MINDER [28], which assigns multi- ple identifiers, including titles, n-grams, and synthetic queries, to documents and pairs them for indexing. (viii) LTRGR [29], which trains on pairwise relevance objectives using margin-based rank- ing loss for optimization. (ix) GenRRL [76], which incorporates pointwise, pairwise, and listwise relevance optimization through reinforcement learning, using document summaries and URLs as docids. We exclude document summaries as docids due to their de- pendence on external summarization models, such as LLaMA-13b used in GenRRL.