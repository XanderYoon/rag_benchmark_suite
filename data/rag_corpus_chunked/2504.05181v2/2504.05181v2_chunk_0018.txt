79], we use a subset with 320k docu- ments and 360k query-document pairs for training. The NQ dataset, 2https://microsoft.github.io/msmarco/Datasets.html#document-ranking-dataset 3https://ai.google.com/research/NaturalQuestions/download SIGIR â€™25, July 13â€“18, 2025, Padua, Italy Kidist Amde Mekonnen et al. Figure 3: Architecture of the DDRO model, which fine-tunes the retrieval model through direct learning-to-rank (L2R) optimization using relevance feedback. Unlike GenRRL [ 76], DDRO directly optimizes with relevance judgment data, avoiding reinforcement learning, explicit reward modeling, and extensive hyperparameter tuning. For clarity, the model ğœ‹ ref ğœƒ from the SFT phase is referred to as ğœ‹ ref , with its param- eters frozen during this phase. introduced by Google, is a widely used benchmark in question- answering research. In this study, we use the NQ320k version, which includes 320k query-document pairs sourced from Wikipedia, with queries formulated in natural language. To ensure reliable evalua- tion and improve performance [26], we deduplicate documents by title and utilize the predefined training and validation splits. Evaluation metrics. Following [65, 76â€“79], we assess model per- formance using standard document retrieval metrics: Recall (R@1/5/ 10) and Mean Reciprocal Rank (MRR@10). Statistical significance is determined using paired t-tests with a threshold of ğ‘ < 0.05. 5.2 Baselines We evaluate our approach against three types of baseline: term- based retrieval, dense retrieval, and generative retrieval. Term-based retrieval. (i) BM25 [45], a probabilistic retrieval model commonly used as a standard baseline, implemented us- ing Pyserini.4 (ii) DocT5Query [38], which generates synthetic queries from documents using the T5 model [41], appending them to the original document text. Dense retrieval. (i) DPR [22], which utilizes a BERT-based dual encoder to produce dense embeddings for queries and documents. PseudoQ [49] improves DPR by generating pseudo-queries using K-means clustering over document embeddings. (ii) ANCE [68], a RoBERTa-based dual encoder that incorporates hard negatives retrieved from an asynchronously updated approximate