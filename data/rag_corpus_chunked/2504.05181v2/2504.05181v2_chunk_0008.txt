5ğœƒ (ğ‘ ğ‘— )), (2) where ğ· represents the document set, and ğ‘„ denotes the query set. This loss function enables parameter updates during both indexing and fine-tuning, enhancing the modelâ€™s ability to generate the most relevant docid for a given query or document. The retrieval phase employs a (constrained) beam search algorithm to decode the most probable docid, with their generation probabilities determining the final ranking [33, 60, 64, 70, 71, 80]. 3.2 Learning to Rank (L2R) L2R aims at training models to rank documents based on their relevance to a given query [ 6, 9, 63]. L2R methods can be classi- fied into point-wise, pair-wise, and list-wise approaches based on their learning objectives. (i) Point-wise methods [19] frame ranking as a classification problem by scoring individual documents in- dependently: ğ¿point = Ã ğ‘– L (Ë†ğ‘  (ğ‘‘ğ‘–, ğ‘), ğ‘ (ğ‘‘ğ‘–, ğ‘)), where Ë†ğ‘  (ğ‘‘ğ‘–, ğ‘) and ğ‘  (ğ‘‘ğ‘–, ğ‘) denote the predicted relevance score and ground truth relevance score, respectively. In GenIR, generated probabilities serve as relevance scores, aligning with this approach [ 60]. And the retrieval term in Eq. 2 belongs to this type. (ii) Pair-wise ap- proaches [6, 9, 15, 63] compare document pairs to determine relative preferences: ğ¿pair = Ã (ğ‘‘ğ‘–,ğ‘‘ğ‘— ) log 1 + exp âˆ’ Ë†ğ‘  (ğ‘‘ğ‘–, ğ‘) âˆ’ Ë†ğ‘  (ğ‘‘ ğ‘— , ğ‘) , where ğ‘‘ğ‘– and ğ‘‘ ğ‘— are used as pairs to compare. DDRO shares similari- ties with traditional pairwise L2R methods such as RankNet [5] and LambdaRank [7], in that it optimizes a margin between relevant and non-relevant documents. It differs in that the ranking signal is used to supervise the generation of structured docid sequences via a generative decoder. Unlike typical L2R approaches that score docu- ments retrieved by an external system, DDRO learns to produce do- cids directly, making