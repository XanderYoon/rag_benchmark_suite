is a critical factor influencing performance in GenIR, we further analyze the differences in performance among various de- signs within our proposedDDRO. Our analysis underscores the crit- ical impact of docid design on retrieval performance across datasets. DDRO (TU) excels on MS MARCO, where shorter, keyword-driven queries align well with title and URL-based docids that capture Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval SIGIR ‚Äô25, July 13‚Äì18, 2025, Padua, Italy Table 5: Comparison of retrieval model performance on the NQ320K dataset. The best-performing results are shown in bold. Statistical significance is determined using a paired t- test with a significance threshold of ùëù < 0.05, with a dagger symbol (‚Ä†) indicating statistical significance. Results for cited models are drawn from their respective original publications. Abbreviations used: SI ‚Äì Semantic ID; PQ ‚Äì Product Quanti- zation; NG ‚Äì N-grams; TU ‚Äì Title + URL. Model R@1 R@5 R@10 MRR@10 Term-based retrieval BM25 14.06 36.91 47.93 23.60 DocT5Query 19.07 43.88 55.83 29.55 Dense retrieval DPR 22.78 53.44 68.58 35.92 ANCE 24.54 54.21 69.08 36.88 RepBERT 22.57 52.20 65.65 35.13 Sentence-T5 22.51 52.00 65.12 34.95 Generative retrieval DSI (SI) 27.42 47.26 56.58 34.31 DSI-QG (SI) 30.17 53.20 66.37 38.85 NCI (SI) 32.69 55.82 69.20 42.84 SEAL (NG) 29.30 54.12 68.53 40.34 Ultron (TU) 33.78 54.20 67.05 42.51 Ultron (PQ) 25.64 53.09 65.75 37.12 ROGER-NCI (SI) [77] 33.20 56.34 69.80 43.45 ROGER-Ultron (TU) [77] 35.90 55.59 69.86 44.92 MINDER (SI) 31.00 55.50 65.79 43.50 LTRGR (SI) 32.80 56.20 68.74 44.80 Ours DDRO (TU) 40.86 53.12 55.98 45.99 DDRO (PQ) 48.92‚Ä† 64.10‚Ä† 67.31 55.51‚Ä† surface-level lexical features for efficient retrieval. In contrast,DDRO (PQ) performs better on NQ, which features longer, complex queries requiring deeper semantic understanding. PQ-based docids effec- tively capture latent relationships, making them well-suited for NQ‚Äôs informational queries. These findings