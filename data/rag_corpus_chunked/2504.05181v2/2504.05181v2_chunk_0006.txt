for a separate ranking step during inference. However, LTRGR focuses on optimizing passage ranking during the second phase, treating docid generation as a step toward this goal rather than fully integrating document-level relevance into the generative pro- cess. Consequently, the challenge of embedding document-level relevance directly into docid generation remains unaddressed. In contrast, DDRO integrates pairwise ranking directly into the gen- erative model’s optimization pipeline, ensuring docid generation inherently aligns with document-level relevance. Our approach. Building on the advancements of GenRRL, ROGER, and LTRGR, we propose a framework that combines SFT for do- cid generation with pairwise ranking optimization to better align GenIR objectives with ranking goals. DDRO addresses token-level misalignment by incorporating document-level relevance optimiza- tion into the training process, enhancing existing GenIR systems by enabling them to learn to rank more effectively. State-of-the-art baselines. SOTA baselines in GenIR, such as RIPOR [70] and PAG [ 71], employ multi-stage optimization ap- proaches. E.g., RIPOR refines relevance-based docids through itera- tive pre-training and fine-tuning, while PAG introduces a hybrid decoding strategy that combines simultaneous and sequential de- coding to enhance ranking efficiency. Both methods achieve strong results on the MS MARCO passage ranking dataset. Our work sim- plifies optimization with a single-framework approach, offering an alternative to multi-stage methods. A direct comparison with these baselines is deferred to future work to assess how DDRO can complement and extend these approaches while evaluating its scalability in large-scale retrieval tasks. Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval SIGIR ’25, July 13–18, 2025, Padua, Italy 3 Preliminaries and Motivations 3.1 Generative Information Retrieval (GenIR) GenIR models build on large pre-trained language models, such as T5 [41] and BART [27], and are designed to take a query string and generate a ranked list of document identifiers (docids) based on their generation