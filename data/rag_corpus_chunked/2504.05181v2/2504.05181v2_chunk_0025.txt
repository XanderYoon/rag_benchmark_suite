precision and broader recall. This underscores the importance of pairwise ranking in enhancing retrieval effectiveness at various ranking depths. These findings confirm that pairwise ranking optimization ef- fectively aligns model predictions with document relevance, con- tributing to improved performance across different ranking levels. Effect of KL Constraint Strength ğ›½. We evaluate the impact of the ğ›½ parameter, which controls the KL divergence constraint SIGIR â€™25, July 13â€“18, 2025, Padua, Italy Kidist Amde Mekonnen et al. Table 3: Comparison of retrieval model performance on the MS MARCO document ranking (MS300K) dataset. The best results are highlighted in bold. Statistical significance is as- sessed using a paired t-test with a ğ‘ < 0.05 threshold, where improvements are marked with the dagger symbol ( â€ ) to indicate statistical significance. The second-best values are underlined. Results for cited models are sourced from their original papers. Abbreviations: SI â€“ Semantic ID; PQ â€“ Prod- uct Quantization; NG â€“ N-grams; TU â€“ Title + URL. Model R@1 R@5 R@10 MRR@10 Term-based retrieval BM25 18.94 42.82 55.07 29.24 DocT5Query 23.27 49.38 63.61 34.81 Dense retrieval DPR 29.08 62.75 73.13 43.41 ANCE 29.65 63.43 74.28 44.09 RepBERT 25.25 58.41 69.18 38.48 Sentence-T5 27.27 58.91 72.15 40.69 Generative retrieval DSI (SI) 25.74 43.58 53.84 33.92 DSI-QG (SI) 28.82 50.74 62.26 38.45 NCI (SI) 29.54 57.99 67.28 40.46 SEAL (NG) 27.58 52.47 61.01 37.68 Ultron (TU) 29.82 60.39 68.31 42.53 Ultron (PQ) 31.55 63.98 73.14 45.35 ROGER-NCI (SI) [77] 30.61 59.02 68.78 42.02 ROGER-Ultron (TU) [77] 33.07 63.93 75.13 46.35 MINDER (SI) 29.98 58.37 71.92 42.51 LTRGR (SI) 32.69 64.37 72.43 47.85 Ours DDRO (PQ) 32.92 64.36 73.02 45.76 DDRO (TU) 38.24â€  66.46â€  74.01 50.07â€  between the DDRO policy ğœ‹ğœƒ and the reference policy ğœ‹ ref , on retrieval performance. Figure 4 shows results for different ğ›½ values on MS