for indexing. (viii) LTRGR [29], which trains on pairwise relevance objectives using margin-based rank- ing loss for optimization. (ix) GenRRL [76], which incorporates pointwise, pairwise, and listwise relevance optimization through reinforcement learning, using document summaries and URLs as docids. We exclude document summaries as docids due to their de- pendence on external summarization models, such as LLaMA-13b used in GenRRL. These models introduce preprocessing overhead and variability in identifier quality. Instead, DDRO employs product quantization (PQ) to generate compact, structured docids, ensuring consistency and scalability. Note on result sourcing. Baseline results for methods such as GenRRL [76] and ROGER [77] are taken from their original papers due to the unavailability of public code, ensuring consistency and avoiding potential reproducibility issues. Other results were repro- duced using publicly available code and the dataset configurations described in this work. 5.3 Implementation Details SFT. The SFT model is based on the T5-base pretrained model [41], trained with a learning rate of 1e-3 and a batch size of 128. All experiments involving various docid types were conducted on 8 NVIDIA RTX A6000 GPUs. Pseudo queries. The DocT5Query model [38], fine-tuned on the target dataset with document-query pairs, was used to generate 10 pseudo-queries per document. Contrastive data pair construction. Training triples were gener- ated using stratified sampling for diversity. Positive samples were selected based on qrels relevance judgments, while negatives were drawn from the top 1000 BM25-retrieved documents, stratified into top (1–100), mid (101–500), and lower (501–1000) ranks. Negatives were randomly sampled in roughly equal proportions, with 8 per query for NQ and 16 for MS MARCO. DDRO. The DDRO model was initialized with the pre-trained au- toregressive SFT model (see Section 4.2) and fine-tuned using the proposed direct learning-to-rank framework (see Section 4.3). Train- ing was performed using a modified Hugging Face TRLDPOTrainer