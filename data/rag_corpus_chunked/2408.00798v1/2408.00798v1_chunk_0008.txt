or Hynix NAND flash chip? PUC is an architecture defined as … NAND flash refers to … Augmented Question : existing solution : our design Sec. 3.2 Sec. 3.3 Sec. 3.4 Sec. 3.5 Sec. 3.6 Figure 2: Left: the workflow diagram of the online inference part of Golden-Retriever. Right: example interactions between the system and the LLM at the intermediate steps of the workflow. The system prompts LLM to generate intermediate responses, which are saved, accessed, and used for future steps in the workflow. Read the following technical document chunk, pay attention to the knowledge details and insights contained in the document. ### Document chunk starts here ### {{document_text_chunk}} ### Document chunk ends here ### This chunk is retrieved from the {{domain}} domain. Based on the above document, generate a summary from a domain expert’s perspective. Be as detailed as possible. Respond with the summary only, no title or anything else. Instructions Response Document Chunk This chunk discusses the difference between Periph… Instructions Text Corpus Document Chunk Original Document OCR Chunking Then for each chunk, prompt the LLM as follows: First convert documents to corpuses and split to chunks: Figure 3: Section 3.1. Illustration of document pre- processing and an example prompt implementation of the LLM-Driven Document Augmentation Process. We choose to use the LLM for this task because traditional string-exact-match methods are inade- quate. These methods may fail to detect jargons that are mistyped or not yet included in the dictio- nary, which could lead to misinterpretation in the following process. The LLM’s ability to adapt to new terms provides a more robust solution. This step is represented as a two-way branching node in the workflow, shown in Figure 2. If the result- ing list is empty, the main program proceeds along the "No" path; otherwise, it follows the