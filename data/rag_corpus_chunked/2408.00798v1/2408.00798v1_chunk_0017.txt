Dennis Assenmacher, Mattia Samory, Is- abelle Augenstein, Wil van der Aalst, and Claudia Wagne. 2023. People make better edits: measuring the efficacy of llm-generated counterfactually aug- mented data for harmful language detection. arXiv preprint arXiv:2311.01270. Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mah- davi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. 2023. Large language models encode clinical knowledge. Nature, 620(7972):172–180. Chenxi Whitehouse, Monojit Choudhury, and Al- ham Fikri Aji. 2023. Llm-powered data augmen- tation for enhanced cross-lingual performance. arXiv preprint arXiv:2305.14288. Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, and Zhen-Hua Ling. 2024. Corrective retrieval augmented generation. arXiv preprint arXiv:2401.15884. Yuexiang Zhai, Shengbang Tong, Xiao Li, Mu Cai, Qing Qu, Yong Jae Lee, and Yi Ma. 2024. Investigating the catastrophic forgetting in multimodal large language model fine-tuning. In Conference on Parsimony and Learning, pages 202–227. PMLR. 7 A Fine-tuning or Retrieval Augmented Generation? Knowledge injection via fine-tuning has several significant drawbacks. For instance, when fine-tuned on a knowledge statement like "A is B," the fine-tuned LLM can correctly answer "What is A?" but fails to answer "What is B?" with "A" for arbitrary A and B. This phenomenon is famously known as The Reversal Curse (Berglund et al., 2023). Although remedies such as generating reversed training data (Golovneva et al., 2024) have been proposed, they require higher training costs and do not guarantee that the tuned LLM will answer all possible forms of a query. Additionally, incorporating knowledge through fine-tuning necessitates a new fine-tuning job for each new piece of knowledge, which incurs computational costs and hinders efficient integration of new information. The amount of knowledge a model can effectively incorporate depends on the capacity of the fine-tuned model part (Roberts et al., 2020), while excessive fine-tuning may lead to catastrophic forgetting, where