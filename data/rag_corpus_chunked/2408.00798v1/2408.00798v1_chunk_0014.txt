100% 70% 80% Shisa 50% 80% 60% 80% 100% We compare our method with vanilla LLM (with- out RAG) and the vanilla RAG method. For each method, including ours, we test three state- of-the-art models: Meta-Llama-3-70B-Instruct (AI@Meta, 2024), Mixtral-8x22B-Instruct-v0.1, and Shisa-v1-Llama3-70b.2e5. 4.1.3 Result We list the scores of each method and LLM backbone in Table 1. Compared with Vanilla LLM and RAG, Golden-Retriever improves the total score of Meta-Llama-3-70B by 79.2% and 40.7%, respectively. Across all three LLMs tested, Golden-Retriever improves the scores by an aver- age of 57.3% over Vanilla LLM and 35.0% over RAG. This demonstrates that Golden-Retriever sig- nificantly enhances question-answering accuracy across multiple LLM backbones. 4.2 Abbreviation Identification Experiment 4.2.1 Dataset Preparation To test if LLMs can robustly identify unknown abbreviations (Section 3.2), we generated random abbreviations and inserted them into question tem- plates to create a synthetic dataset. For abbreviation generation, we computed the probability distribu- tion of each letter being the first letter in all words in an English dictionary, then sequentially sampled the letters by that distribution to form abbreviations. We manually prepared question templates. The question templates and generated abbreviations are shown in the random abbreviation generation code in Appendix C.1. 4.2.2 Experiment Setup The synthetic questions are integrated with the prompt template, as shown in the "Identify Jargon" step in Figure 2. We prompt the LLM, record the responses, and check if they contain all abbrevi- ations used in the questions. This experiment is conducted on the three aforementioned LLMs. 4.2.3 Result We list the accuracy of each LLM in identifying all abbreviations in questions with varying numbers of abbreviations in Table 2. The experiment shows that state-of-the-art models such as Llama3 and Mistral have high accuracy in identifying unknown abbreviations. We also observe different failure modes across the three LLMs,