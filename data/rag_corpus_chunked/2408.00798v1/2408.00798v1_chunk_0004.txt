Golden-Retriever includes both offline and on- line processes. The offline part involves a data pre- processing step where Optical Character Recogni- tion (OCR) is used to extract text from various doc- ument formats. This text is then summarized and contextualized by LLMs to enhance the document database, ensuring that documents are more likely to be relevant when queried. Unlike existing of- fline methods that use LLMs for model training or fine-tuning to improve cross-language performance or generate counterfactual data (Whitehouse et al., 2023; Sen et al., 2023), our approach focuses on augmenting the RAG document database directly. The online part is an interactive process that oc- curs each time a user asks a question. It starts with identifying jargons and context within the user’s query using LLMs. The identified jargons is then queried against a jargons dictionary to retrieve accu- rate definitions and descriptions. This information is used to augment the original question, providing clear context and resolving any ambiguities. The 2 augmented question is then used as input for the RAG framework, ensuring that the most relevant and accurate documents are retrieved. In summary, our contributions are as follows: • We identify the challenges of using LLMs for knowledge bases in real-world deployments. • We propose Golden-Retriever, an agentic derivative of RAG featuring reflection-based question augmentation before document re- trieval, enabling RAG to retrieve the most rel- evant documents despite ambiguous jargons and lack of context. • We evaluate Golden-Retriever with three open- source LLMs and compare its performance with baselines on a dedicated, domain-specific question-answer dataset. 2 Related Work Current RAG techniques often fall short of the ideal scenario for handling domain-specific queries in industrial knowledge bases. Vanilla RAG (Lewis et al., 2020), for instance, struggles with accurately interpreting domain- specific jargons. When asked, "What is the PUC