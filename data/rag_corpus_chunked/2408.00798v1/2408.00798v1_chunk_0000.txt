Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base Zhiyu Anσµ1 Xianzhong Dingγ Yen-Chun Fuµ Cheng-Chung Chuµ Yan Liµ Wan Duσ σ : University of California, Merced, CA, USA µ : Western Digital Corporation, CA, USA γ : Lawrence Berkeley National Laboratory, CA, USA {zan7, wdu3}@ucmerced.edu Abstract This paper introduces Golden-Retriever, de- signed to efficiently navigate vast industrial knowledge bases, overcoming challenges in traditional LLM fine-tuning and RAG frame- works with domain-specific jargon and context interpretation. Golden-Retriever incorporates a reflection-based question augmentation step before document retrieval, which involves iden- tifying jargon, clarifying its meaning based on context, and augmenting the question accord- ingly. Specifically, our method extracts and lists all jargon and abbreviations in the input question, determines the context against a pre- defined list, and queries a jargon dictionary for extended definitions and descriptions. This comprehensive augmentation ensures the RAG framework retrieves the most relevant docu- ments by providing clear context and resolving ambiguities, significantly improving retrieval accuracy. Evaluations using three open-source LLMs on a domain-specific question-answer dataset demonstrate Golden-Retriever’s supe- rior performance, providing a robust solution for efficiently integrating and querying indus- trial knowledge bases. 1 Introduction Technological companies maintain massive col- lections of proprietary documents generated over years, such as training materials, design documents, and research outputs. Engineers, especially new hires, are expected to quickly query these docu- ments or assimilate the new knowledge in these documents. However, navigating in the large num- ber of documents is challenging. These domain- specific documents normally have many abbrevia- tions and jargons unique to their technical commu- nity, further complicating the problem. Large Language Models (LLMs) offer excellent performance for general question-answering tasks 1Work conducted while interning at Western Digital Cor- poration. (Petroni et al., 2019; Hu et al., 2021). To make a pre-trained LLM incorporate a company’s domain-