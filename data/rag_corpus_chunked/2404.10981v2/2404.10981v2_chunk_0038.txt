or to adapt the generated response to meet the user’s preferences, context, or audience needs (contextual adaptation). In LAPDOG [52], customization is achieved primarily through content alignment by integrating persona profiles with external stories to enrich the context used for generation. The story retriever identifies relevant narratives based on the persona, expanding the limited profiles with additional information. The generator then combines this enriched knowledge with the dialogue history, ensuring that responses align closely with the persona’s traits and background. This approach allows for a nuanced understanding of the user’s personality, making the output more engaging and contextually appropriate. On the other hand, PersonaRAG [160] emphasizes real-time adaptation by customizing generated content based on dynamic user profiles, session behavior, and ongoing feedback. A multi-agent system continuously analyzes user interactions to refine responses, ensuring alignment with the user’s preferences and context. By integrating personalized insights at each step, the system can adjust its output to suit specific informational needs and situational contexts. This level of responsiveness allows the system to evolve in line with the user’s changing requirements, creating more relevant and targeted responses. ERAGent [123] also focuses on customization but through the use of a Personalized LLM Reader, which adapts responses using user-specific profiles. This module integrates rewritten questions, filtered knowledge, and user preferences to tailor responses according to both content relevance and user needs. For instance, it takes into account preferences like environmental consciousness or dietary restrictions, ensuring that the generated content is not only aligned with retrieved knowledge but also personalized to the user’s particular values and requirements. This deep level of customization ensures that the output is both relevant and personally meaningful, enhancing user engagement. ROPG [118] proposes a dynamic pre- and post-generation retriever selection model, enhancing personalization by aligning the retrieval process with both the input