need to be computed during retrieval can be limited to a local subgraph, thereby enhancing search speed. Several prominent methods and tools have been developed using this approach. For example, k-nearest neighbor language models kNN-LMs [72], as demonstrated by Khandelwal et al., integrate the kNN algorithm with pre-trained language models. This method employs a datastore created from collections of texts to dynamically retrieve contextually relevant examples, enhancing model performance without requiring additional training. FAISS [68], a tool widely adopted for indexing in many studies [72, 73, 83], integrates enhancements like the Hierarchical Navigable Small World (HNSW) approximation , Vol. 1, No. 1, Article . Publication date: August 2018. The Survey of Retrieval-Augmented Text Generation in Large Language Models 7 [97] to further speed up retrieval [83]. WebGPT [100] showcases another practical application by utilizing the Bing API3 for indexing based on actual user search histories, which illustrates the potential of integrating real-world user data into the retrieval process. Additionally, other methods like MEMWALKER [13] introduces innovative approaches to overcome limitations such as context window size in large language models. It creates a memory tree from input text, segmenting the text into smaller pieces and summarizing these segments into a hierarchical structure. Moreover, LRUS-CoverTree method [ 93] designed another tree structure for k-Maximum Inner-Product Search (k-MIPS) and achieves performance comparable with significantly lower index construction time. These techniques facilitate efficient indexing and management of large information volumes, demonstrating the versatility and effectiveness of graph-based approaches. Product Quantization. PQ is one of the most representative methods for handling large-scale data. It accelerates searches by segmenting vectors and then clustering each part for quantization. Unlike graph-based methods, which speed up searches by reducing the number of vectors for distance calculation, PQ achieves faster searches by reducing the time spent on calculating word distances.