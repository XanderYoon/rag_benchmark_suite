outcomes; for instance, excluding SPECTER in RRF-2 on Wikipedia yields better results than RRF-4, indicating that simply increasing the number of retrievers is not beneficial unless their strengths align with the retrieval task. Figure 5a illustrates how eRAG investigates the correlation between LLM performance and retrieval effectiveness on the NQ dataset using three retrievers with different characteristics: BM25 (lexical sparse), RetroMAE (dense) [143], and SPLADEv3 (learned sparse) [80]. The initial retrievals are re-ranked using a DeBERTa-v3 [79] cross-encoder. The analysis demonstrates that as retrieval quality improves, LLM performance increases significantly across various models. Notably, re- ranking with SPLADEv3 and DeBERTa-v3 consistently achieves the best results across datasets and metrics. This underscores the critical role that high-quality retrieval plays in determining overall RAG system effectiveness, suggesting that IR-focused LLMs could be a valuable asset in enhancing generation performance. Impact of the Generator. The BERGEN study [ 114] compares the performance of LLMs with gold passages (Oracle) against closed-book settings without retrieval, as shown in Figure 5b. Surprisingly, the experiments do not reveal a straightforward relationship between model size and the performance gains from retrieval. For instance, smaller models like LLaMA2-7B benefit more , Vol. 1, No. 1, Article . Publication date: August 2018. The Survey of Retrieval-Augmented Text Generation in Large Language Models 25 0.6 0.7 0.8 0.9 1.0 Retrieval Performance (Recall@5) 0.60 0.65 0.70 0.75 0.80 0.85RAG Performance (LLMeval) SPLADE-v3+RR BM25 SPLADE-v3 BM25+RR Oracle RetroMAE RetroMAE+RR (a) Impact of retrieval performance on RAG per- formance for SOLAR-10.7B [75] on NQ with dif- ferent ranking systems. RR means with additional re-ranking using DeBERTa-v3. TinyLlama-1.1B SOLAR-10.7B Mixtral-8x7B Llama3-8B Llama2-7B Llama2-70B LLM 0.0 0.2 0.4 0.6 0.8 1.0RAG Performance (LLMeval) +0.09 +0.03 +0.06 +0.15 +0.17 +0.15 Retriever Closed Book Oracle (b) Performance gains w/ and w/o oracle retrieval for LLMs with different sizes.