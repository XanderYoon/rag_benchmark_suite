it ideal for personalized search engines, adaptive learning systems, and real-time decision support. AAR [157] exemplifies adaptive retrieval by adjusting its strategy based on the prefer- ences of LLMs, learning from a small source model and generalizing to unseen tasks. FLARE [65] takes a similar adaptive approach but focuses on dynamically fetching additional information when model confidence is low, thereby improving the relevance of generated responses. SelfRAG [4] goes further by incorporating self-reflective processes, where the retrieval strategy evolves based on critiques of the generated content. CoK [86], on the other hand, implements a dynamic mechanism that adjusts retrieval strategies based on the evolving needs of the task. The retrieval process in CoK is not static but adapts according to the specific scenario and the nature of the , Vol. 1, No. 1, Article . Publication date: August 2018. 14 Huang et al. Algorithm 3 Conditional Retrieval Strategy in RAG Require: Query ğ‘, Documents ğ·, Maximum Iterations ğ‘ , Retriever ğ‘…, Generator ğº, Pre-retrieval Function ğ¹ğ‘ğ‘Ÿğ‘’ , Post-retrieval Function ğ¹ğ‘ğ‘œğ‘ ğ‘¡ , Condition Evaluation Function ğ¹ğ‘ğ‘œğ‘›ğ‘‘ Ensure: Final Output ğ‘¦ğ‘“ ğ‘–ğ‘›ğ‘ğ‘™ 1: Initialize ğ‘– â† 1 // Start iteration counter 2: ğ‘â€² â† ğ‘ // Initialize query 3: while ğ‘– â‰¤ ğ‘ do 4: Pre-retrieval Phase 5: ğ‘â€² â† ğ¹ğ‘ğ‘Ÿğ‘’ (ğ‘â€²) // Perform query manipulation and data modification 6: Retrieval Phase 7: ğ·ğ‘– â† ğ‘…(ğ‘â€², ğ·) // Retrieve documents based on the current query 8: Post-retrieval Phase 9: ğ· â€² ğ‘– â† ğ¹ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘â€², ğ·ğ‘– ) // Re-rank and filter documents based on conditions 10: Generation Phase 11: ğ‘¦ğ‘– â† ğº (ğ‘â€², ğ·â€² ğ‘– ) // Generate output using the refined documents 12: Conditional Branching 13: if ğ¹ğ‘ğ‘œğ‘›ğ‘‘ (ğ‘¦ğ‘–, ğ·â€² ğ‘– ) is Condition A then 14: Apply Strategy A // e.g., refine the query based on feedback 15: else if