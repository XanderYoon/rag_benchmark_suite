models and enhancing computational efficiency. In contrast, RECOMP [ 147] and CRAG [ 149] employ more external or structural strategies. RECOMP focuses on selective augmentation, where summaries generated from retrieved documents are selectively prepended to the input for the language model. If the retrieved documents are deemed irrelevant, the compressor can generate an empty summary, effectively filtering out unnecessary information. This method allows for a dynamic approach to filtering, where only helpful content is retained. CRAG, on the other hand, uses a decompose-then-recompose approach, where retrieved documents are split into finer knowledge strips. These strips are evaluated for relevance using a fine- tuned T5 model, and only the relevant strips are recomposed to form a refined set of information for the generation task. This granular filtering process ensures that the final document set is both relevant and concise, tailored specifically to the generation task. Dynamic filtering techniques are also employed in methods like FiD-TF [ 5] and CoK [ 86]. FiD-TF introduces Token Filtering during the decoding process, where less relevant tokens are dynamically filtered out based on cross-attention scores. This approach reduces the computational load by eliminating tokens deemed uninformative for generating the final answer, enhancing efficiency with minimal impact on performance. CoK employs a filtering technique based on self-consistency, identifying and processing only those questions with “uncertain” answers. This method works by sampling various reasoning paths and answers, preserving only predictions with high consistency. Questions that do not meet the specified consistency threshold undergo further processing, effectively preventing the propagation of errors in the generation process. Finally, FILCO [141] implements a comprehensive filtering approach using three distinct strate- gies: String Inclusion (STRINC) to match exact outputs, Lexical Overlap to measure word-level similarity, and Conditional Cross-Mutual Information (CXMI) to assess how much the context improves output likelihood. FILCO applies