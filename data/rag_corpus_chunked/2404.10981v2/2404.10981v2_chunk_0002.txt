be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference acronym ’XX, June 03–05, 2018, Woodstock, NY © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/18/06 https://doi.org/XXXXXXX.XXXXXXX , Vol. 1, No. 1, Article . Publication date: August 2018. arXiv:2404.10981v2 [cs.IR] 23 Aug 2024 2 Huang et al. Fig. 1. An example of RAG benefits ChatGPT resolves questions that cannot be answered beyond the scope of the training data and generates correct results. hinders LLMs’ ability to stay updated. Third, LLMs are susceptible to generating convincing yet inaccurate responses, known as “hallucinations”, which can mislead users. Addressing these challenges is crucial for LLMs to be effectively utilized across various domains. A promising solution is the integration of Retrieval-Augmented Generation (RAG) technology, which supplements models by fetching external data in response to queries, thus ensuring more accurate and current outputs. Figure 1 illustrates how RAG can enable ChatGPT to provide precise answers beyond its initial training data. Since its introduction by Lewis et al. [83] in 2020, RAG has seen rapid development, especially with the rise of models like ChatGPT. Despite these advancements, there remains a noticeable gap in the literature regarding a comprehensive analysis of the mechanisms underlying RAG and the progress achieved by subsequent studies. Moreover, the field suffers from fragmented research focuses and inconsistent terminology for similar methods, leading to confusion. This survey seeks to bridge this gap by offering a structured overview of RAG, categorizing various approaches, and providing an in-depth understanding of the current research landscape, with a focus on textual applications given their prominence in recent research. To provide clarity and structure, this paper is organized as