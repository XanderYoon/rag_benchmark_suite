[139] approach, which integrates both sparse and dense retrieval to capture relevant documents from both lexical and semantic perspectives. 9.3 Multimodal RAG The expansion of RAG systems to support multimodal data—encompassing text, images, and audio—presents new challenges. Integrating diverse modalities requires not only effective retrieval but also seamless alignment and generation across different data types. Cross-Modal Alignment. Aligning multimodal documents with text-based queries remains a core challenge. The complexity of mapping diverse data types into a unified retrieval framework necessitates improved cross-modal retrieval strategies capable of simultaneously handling text, image, and potentially video or audio data. Coherent Multimodal Generation. Generating responses that meaningfully integrate information from multiple modalities is another difficult task. Advanced generation models capable of reasoning across different modalities are required to produce outputs that are both contextually relevant and visually coherent. Recent advancements in multimodal RAG, such as MuRAG [17], REVEAL [49], and Re-ViLM [152], have shown potential in incorporating multimodal retrieval and generation into real-world applications like visual question answering [18], image captioning [120], and text-to-audio gen- eration [158]. Moving forward, research will likely focus on refining these techniques, especially in scaling multimodal retrieval to handle larger datasets and more complex queries. Extending retrieval capabilities to include more diverse media types, such as video and speech, also represents a promising direction for the continued evolution of RAG systems. 10 Conclusions In this paper, we have presented a comprehensive framework for understanding the RAG domain, highlighting its significance in enhancing the capabilities of LLMs. Through a structured overview of RAG, categorizing various methods, and an in-depth analysis of its core technologies and evaluation methods, this study illuminates the path for future research. It identifies crucial areas for improvement and outlines potential directions for advancing RAG applications, especially in textual contexts. This survey aims to elucidate the core