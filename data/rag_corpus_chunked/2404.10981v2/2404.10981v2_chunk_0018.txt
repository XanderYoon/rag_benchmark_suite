For instance, RECITE [125] utilizes a model’s internal memory to recite relevant information before generating responses, thus enhancing performance in tasks like closed-book question answering without external data. KnowledGPT [140] similarly refines the internal knowledge embedded within LLMs, optimizing its use during generation. GENREAD [156] further demonstrates how pre-existing knowledge within LLMs can be used to generate context that enhances task performance, bypassing the need for external sources. In another example, the Selfmem [21] framework allows the model to iteratively use its own outputs as memory in subsequent generation tasks. By selecting and utilizing the best internal outputs as memory, this approach boosts model performance without depending on external memory resources. External Data Enrichment. External Data Enrichment enhances document content by incorpo- rating new information from external sources, enriching the overall context and accuracy. This process can involve integrating facts, data, or contextual knowledge from external datasets or knowl- edge bases. For example, RA-DIT [89] augments input prompts during fine-tuning by leveraging large datasets like Wikipedia and CommonCrawl, enhancing the model’s capability in knowledge- intensive tasks. The dual instruction tuning technique optimizes both the language model and the retriever to more effectively incorporate retrieved information. UPRISE [20] demonstrates how retrieving prompts from diverse task datasets improves model generalization in zero-shot scenarios by enriching the context during inference. Additionally, RARG [ 159] exemplifies external data enrichment by integrating scientific evidence from academic databases to strengthen responses countering misinformation. This method involves a two-stage retrieval pipeline that identifies and ranks relevant documents, which are then used to support and enhance the factual accuracy of generated responses. 4 Retrieval 4.1 Search & Ranking The search and ranking process within RAG is crucial for improving the relevance and accuracy of generated outputs. Several methodologies have been developed to refine this process, each contributing unique