We delve into the core technologies that drive RAG, assessing their effectiveness in addressing retrieval and generation tasks. Additionally, this survey introduces the evaluation methods employed in RAG research, highlights current limitations, and proposes promising avenues for future exploration. , Vol. 1, No. 1, Article . Publication date: August 2018. The Survey of Retrieval-Augmented Text Generation in Large Language Models 3 Fig. 2. The unified RAG core concepts with basic workflow. 2 RAG Framework The hallucinations are largely attributed to LLMs’ inability to access up-to-date information. This limitation stems from the models’ reliance on their training datasets. RAG proposes a solution to this issue by supplementing the LLM’s training data with current information from external sources through a retrieval model, thereby enabling the generation of accurate responses. RAG presents a more cost-effective alternative to the extensive training and fine-tuning processes typically required for LLMs. It allows for the dynamic incorporation of fresh information via traditional retrieval methods or pre-trained LMs, without the need to directly integrate this new data into the LLM. This feature makes RAG both flexible and scalable, facilitating its application across different LLMs for various purposes. The information retrieved through RAG is derived from real-world data, authored by humans, which not only simplifies the generation process but also increases the reliability of the generated responses. Research by Khandelwal et al. [72] demonstrates that accessing relevant information from the training dataset itself can significantly improve LLM performance, highlighting the effectiveness of RAG. Over time, RAG has evolved from a means of providing supplementary information to enabling multiple interactions between the retrieval and generation components. This involves conducting several rounds of retrieval to refine the accuracy of the information retrieved and iteratively improve the quality of the generated output. Toolkits such as LangChain1 and LlamaIndex2 have modularized the RAG