effectively, using a cross-attention model trained on these additional examples to boost retrieval accuracy. 5.2 Filtering Filtering and re-ranking are distinct processes in the post-retrieval stage of RAG systems. Filtering focuses on eliminating irrelevant or low-quality documents from the retrieved set, thereby reducing the document set size and improving efficiency and effectiveness in subsequent processing. In contrast, re-ranking orders the remaining documents based on their relevance or utility for the task, often prioritizing those that enhance the quality of the generated output, especially in response- aware scenarios. Several filtering methods have been developed to refine document sets in RAG systems, each with unique mechanisms but sharing common goals of improving relevance and reducing compu- tational load. Self-RAG [4] employs a self-reflection mechanism, utilizing special “reflection tokens” , Vol. 1, No. 1, Article . Publication date: August 2018. The Survey of Retrieval-Augmented Text Generation in Large Language Models 17 generated by the model to evaluate the relevance and quality of retrieved passages and the model’s own generated outputs. This self-reflection ensures that only the most pertinent documents are retained, leveraging the model’s internal capabilities without relying on external models during inference. Similarly, BlendFilter [135] utilizes the LLM itself as the filter, assessing and removing irrelevant or less useful documents by applying filtering separately to knowledge retrieved from original, externally augmented, and internally augmented queries. Both Self-RAG and BlendFilter highlight the model’s intrinsic ability to perform filtering, reducing the need for additional models and enhancing computational efficiency. In contrast, RECOMP [ 147] and CRAG [ 149] employ more external or structural strategies. RECOMP focuses on selective augmentation, where summaries generated from retrieved documents are selectively prepended to the input for the language model. If the retrieved documents are deemed irrelevant, the compressor can generate an empty summary, effectively filtering out unnecessary information.