ğ¶ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡ ) // Generate output using the refined documents 12: Adaptive Adjustment 13: if ğ¹ğ‘“ ğ‘’ğ‘’ğ‘‘ğ‘ğ‘ğ‘ğ‘˜ (ğ‘¦ğ‘–, ğ·â€² ğ‘– ) is negative then 14: ğ‘â€², ğ¶ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡ â† ğ¹ğ‘ğ‘‘ğ‘ğ‘ğ‘¡ (ğ‘â€², ğ¶ğ‘œğ‘›ğ‘¡ğ‘’ğ‘¥ğ‘¡, ğ‘¦ ğ‘–, ğ·â€² ğ‘– ) // Dynamically adjust the query and context 15: end if 16: Feedback Integration 17: if ğ¹ğ‘“ ğ‘’ğ‘’ğ‘‘ğ‘ğ‘ğ‘ğ‘˜ (ğ‘¦ğ‘– ) is positive then 18: BREAK // Stop iterations if output is satisfactory 19: end if 20: ğ‘– â† ğ‘– + 1 // Increment iteration counter 21: end while 22: Final Synthesis 23: ğ‘¦ğ‘“ ğ‘–ğ‘›ğ‘ğ‘™ â† SynthesizeResults({ğ‘¦1, ğ‘¦2, . . . , ğ‘¦ğ‘– }) // Merge results 24: return ğ‘¦ğ‘“ ğ‘–ğ‘›ğ‘ğ‘™ selecting and combining these strategies, RAG systems can be tailored to effectively handle a wide range of information retrieval scenarios, leveraging the strengths of each approach to deliver robust and precise results. 5 Post-Retrieval 5.1 Re-Ranking As retrieval mechanisms often return a large number of potentially relevant documents, re-ranking methods are employed to reorder these documents, prioritizing those most likely to contribute meaningfully to the final output. By leveraging various strategies, including unsupervised tech- niques, supervised learning, and data augmentation, re-ranking aims to optimize the alignment between the retrieved content and the desired response, thereby improving the overall effectiveness of RAG systems [165]. Unsupervised Re-ranking. Unsupervised re-rankers do not rely on labeled data for training. They use strategies such as pointwise, listwise, or pairwise methods to rank documents based on LLM outputs without the need for supervised fine-tuning. For example, In-Context RALM [112] employs , Vol. 1, No. 1, Article . Publication date: August 2018. 16 Huang et al. a zero-shot approach where an off-the-shelf language model is used to re-rank the top-k documents retrieved by a BM25 retriever. This process involves selecting the document that maximizes the likelihood of the generated text, effectively using the