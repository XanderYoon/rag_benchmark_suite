is more diverse and natural in this early stage of a conversa- tion. This indicates that misusing external knowl- edge can lead to problematic system responses and a negative user experience. To address this, we investigate an adaptive retrieval-augmented generation solution for effec- tive conversational systems. In particular, moti- vated by the gate function in long-short term mem- ory models (Graves and Graves, 2012), which explicitly controls the use of input and memory, we propose a binary knowledge gate mechanism, called RAGate, to manipulate the use of external knowledge for a conversational system. To model the conversation context and accurately estimate the need for augmentation, we leverage the hu- man labels as ground truth and develop RAGate by exploring the use of recent advanced language models or constructing attention neural gate mod- els. To validate the effectiveness of RAGate, we conduct extensive experiments on an annotated Task-Oriented Dialogue (TOD) system dataset, KETOD, that builds upon the SGD dataset with TOD-spanning 16 domains, such as Restaurant and Weather. The experimental results show that RA- Gate enables conversational systems to efficiently use external knowledge at appropriate conversation turns, producing high-quality system responses. In particular, by modelling the uncertainty and confi- dence level of the system – which correlates with the likelihood of hallucinated output (Varshney et al., 2023) – we show that the "always" aug- mentation of external knowledge can significantly increase generation uncertainty and the risk of hal- lucination. After applying RAGate, we can effec- tively control the conversation system to make con- fident and informative responses. In addition, by varying the use of knowledge snippets in different relevance levels, we also observe the positive corre- lation between the calculated confidence score and the relevance of augmented knowledge, which can be valuable for many future studies. 2 Related Work In the