we explore the use of Llama-v2-7B and Llama-v2-13B to implement RAGate-prompt and fine-tune Llama-v2-7B for RAGate-PEFT. We im- plement QLoRA using the PEFT library (Man- grulkar et al., 2022) and set the lower rank to 16. As discussed in Section 3, we have various input fea- tures to be combined for performance optimisation. We begin with the use of context only, then concate- nate the context with the real response (contx-resp), with the synthetic response and recognised enti- ties (contx-syn-resp-ner) and further extend with the use of retrieved knowledge (contx-syn-resp-ner- know) or the source of knowledge (contx-syn-resp- ner-source). Specifically, we retrieve the relevant knowledge by exploring the use of TF-IDF and a learned BERT ranker. We evaluate their perfor- mance with the classic Recall@1 and Recall@3 on the test collection. We use a shallow cutoff because we only use top-relevant knowledge snippets for augmentation. Table 1 shows their retrieval per- formance. According to the leading performance of BERT-Ranker, we augment knowledge with its retrieved top 3 relevant knowledge snippets (i.e., k = 3). Regarding the development of RAGate- MHA, we explore the combinations of 2 to 8 layers, 2 or 4 heads and the embedding size in [64, 128, 256] for the best classification accuracy. We report the precision, recall, F1, Area Under Curve (AUC) and the False Discovery Rate (FDR) as the main measures to show the classification effectiveness. Next, we further deploy the best-performing RA- Gate gate function to update the KETOD dialogue system (Chen et al., 2022), which uses GPT-2 (Rad- ford et al., 2019) as the backbone model. To high- light the effect of various augmentation setups, we use the context with the gold action without extra prediction as input to KETOD. Then, we compare the resulting performance to the KETOD model without knowledge augmentation and