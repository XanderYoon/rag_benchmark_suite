the use of larger language models and the in-context learn- ing setup, which often result in improved perfor- mance (Arora et al., 2022), can not guarantee the enhancement of modelsâ€™ classification accuracy re- garding this classification task. Regarding the performance of RAGate-PEFT approaches, by first examining the effect of us- ing synthetic response and recognised name enti- ties, we observe significantly improved precision (0.5203 to 0.6818) but with the cost of lower recall (0.3359 to 0.2321). In addition, when we add the retrieved knowledge to the input features for pre- diction, we observe a significant performance drop across all evaluated aspects. This can be caused by the additional complexity introduced by the in- cluded retrieved knowledge snippets. Furthermore, we also explored the performance impact of nam- ing the source of the knowledge snippet. We use wikiHow1 in this study, which can provide rich task instructions for offering informative task-oriented system response (Sen et al., 2023). However, the fine-tuned model cannot reasonably connect the promised rich resource from the knowledge source and the prediction of augmentation necessity. RAGate Performance between fine-tuned LLM and MHA classifier. Next, by comparing the ex- perimental results of RAGate-MHA and RAGate- PEFT in Table 2, we observe a wide-margin re- call improvement using RAGate-MHA, reaching a minimum recall of 0.52, but with significantly lower precision accuracy. In Table 2, we also in- clude the use of both the context and the initial system responses (i.e., MHA([contx, resp])) for additional insights. We can observe that a higher precision can be achieved but the use of response does not improve the recall performance. These re- sults are consistent with the observed performance of RAGate-PEFT, which further encourages the use of a synthetic response due to the unavailability of a system response in a practical scenario. In addition, we