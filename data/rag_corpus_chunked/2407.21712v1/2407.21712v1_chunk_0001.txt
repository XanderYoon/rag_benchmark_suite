versational systems, enabling the generation of nat- ural and high-quality responses (Ni et al., 2023). Despite these advancements, recent studies have identified several limitations on the simple use of LLMs to address conversational tasks (Onoe et al., 2022; Huang et al., 2021; Ren et al., 2018). These limitations include the lack of up-to-date knowledge (Onoe et al., 2022), the generation of Can you find me some interesting things to do?Knowledge Cloud on earth, clouds are formed by the saturation of air in the homosphere. Cloud the Droplets or particles are suspended in the atmosphere above the surface of a planetary body. Sure! Here are a few interesting things you can do: 1.Explore the science of clouds.2.Virtual museum tours3.Online Courses4.Read a Book or listen to an audiobook. Sure! Here are a few suggestions based on different interests:1.Creative activities: painting, writing, DIY crafts2.Physical activities: exercise, outdoor walk and dancing3.Entertainment: movies, games, books Use Knowledge Not Use Knowledge Figure 1: Example conversation when generating a re- sponse with or without a knowledge snippet using a language model (GPT-4 in this example). non-factual or hallucinated content (Huang et al., 2021), and restricted domain adaptability (Ren et al., 2018). These issues can hinder the develop- ment of conversational agents with satisfactory user experience. To address these identified challenges, a common approach is to retrieve and augment LLMs with external knowledge to enhance the con- versational response, making them more accurate, reliable, and adaptable to different domains (Zhao et al., 2020; Lian et al., 2019; Ye et al., 2024). For example, Shuster et al. (2021) demonstrated that us- ing a dense retrieval model (DPR) (Karpukhin et al., 2020) to retrieve relevant knowledge for augmenta- tion can significantly reduce the hallucination rate, according to a corresponding human evaluation. Similarly, Yang et al. (2020) showed that leverag- ing