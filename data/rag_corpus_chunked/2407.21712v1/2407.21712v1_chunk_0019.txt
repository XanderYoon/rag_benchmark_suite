augmented conversational response gen- eration. Table 3 presents the results of applying RAGAte to the KETOD model for adaptive knowl- edge augmentation when evaluated on the KETOD dataset. We include four types of adaptive augmen- tation, namely the use of RAGate and comparison to the random selection with equal numbers of se- lections, human choice, and the commonly used "all" augmentation. In addition, to explore the ef- fect of varied quality of knowledge snippets, we also extend the evaluation of using the top-3 knowl- edge snippets ranked by different retrievers (i.e., BERT-ranker and TF-IDF) and the use of knowl- edge snippets at the 1st and 5th rank according to the BERT-ranker. Due to the space limit, we first present the results of using BERT-ranker retrieved and top-1 relevant knowledge and top-1 relevant in Table 3 and show the full results in the Appendix C. At first, without adaptive knowledge augmenta- tion, we compare the choice of response generation without augmentation and with "always" augmenta- tion (i.e., No-Aug versus Aug-All). In Table 3, we observe that by augmenting a total of 4,964 system responses in the test collection, the conversational model can generate more informative and effec- tive responses according to the reported scores of BLEU, ROUGE and BERTscore. This aligns with the reported effectiveness of RAG in many existing studies. However, we also identify a significant drop in the modelâ€™s generation confidence level. As denoted by Varshney et al. (2023), a lower con- fidence level can correlate with a higher chance of generating hallucinated responses, which could be caused by the unnecessary use of external knowl- edge. Hence, to investigate the effectiveness of adaptive knowledge augmentation, we examine the impact of using RAGate. According to the reported experimental results in Table 3, the adaptive aug- mented response generation with fewer