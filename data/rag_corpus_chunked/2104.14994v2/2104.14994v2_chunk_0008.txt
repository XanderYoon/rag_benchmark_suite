on a sample image. Once the user presses the search button, the provided image, the selected entity type, and the defined radius are sent to the backend. 3.2 Backend In the backend, the request is sent to a Python Flask application in JSON (JavaScript Object Notation) format. Then, the application forwards the request to an initialized instance of GeoWINE, which computes the results using the pipeline components specified in Section 2. Finally, the Flask application sends the computed results back to the frontend in JSON format. 4 DEMO W ALKTHROUGH In this section, we provide an example query in Figure 2 to guide the reader and user through the demo6. Users can upload an image or select from the provided list, spec- ify a radius in kilometers, and select entity types (explained in Section 2.2.1) from the drop-down list and then get the results as il- lustrated in the top left box. Given these inputs, the geocoordinates are predicted and pinpointed on the map (middle box). In addition to the predicted location (the green marker), the corresponding Wikidata entities are represented on the map within the selected radius (blue markers). For the pre-selected images the ground truth geocoordinates are available so that the user can compare the per- formance of the system. In this example, the location is predicted correctly, and the label is Notre-Dame Paris (top right box). In addition to the aforementioned outputs, a list of images is presented at the bottom. These images correspond to the retrieved entities on the map and they are ranked based on similarity to the input image. There are four different options here: similar ge- olocations/entities, similar places, overall similarity by ImageNet embeddings, and combined search. These four different ranked lists correspond to the four different visual representations: Geolocation, Place, Object and