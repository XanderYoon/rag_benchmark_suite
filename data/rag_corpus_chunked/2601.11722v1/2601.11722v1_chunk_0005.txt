[16]). These methods provide fine-grained judgments of factual align- ment on a continuous scale. In data-to-text generation, metrics such as PAR- ENT [5] evaluate whether candidate outputs faithfully express entities and rela- tions from structured inputs. By contrast, clarifying question generation has not been systematically assessed for faithfulness. Existing evaluations rely mainly on reference-based metrics (e.g., BLEU, METEOR) or indirect retrieval-based proxies [2,24], which do not directly measure factual consistency with the input context. In this work, we adapt entailment-based and data-grounding approaches from summarization and data-to-text to develop faithfulness evaluations tailored to clarifying question generation. 3 Methodology Our RAC framework follows a two-stage training pipeline as illustrated in Fig. 2. In the first stage, a large language modelpLM is fine-tuned on existing clarifi- cation datasets along two axes to generate: (1) factual questions conditioned by user queries and retrieved passagespθ0 and (2) less factual questions uncondi- tioned by passagespuncond. The two levels of question quality are then passed to a preference learning algorithm (contrastive) that encourages the model to rank faithful, evidence-grounded clarifications higher than unsupported or hal- lucinated alternatives. We formulate the task of generating clarifying questionsCqas a retrieval- augmented generation task. The initial user queryUq enables the retrieval of a set of relevant passagesD={d 1, . . . , dN }, which will be used as context for the generation. We assume all queries to be ambiguous, focusing on clarifying = {(Uq, D, Cq, Cq )} 2 + - Preference tuningFine-tuning on 1 p(Cq | Uq, D) Training Data-generation Fine-tuning on 1 p(Cq | Uq) p L M pθ pθ 0 * p u n c o n d Fig.2: Overview of our proposed training pipeline. Retrieval-Augmented Clarification for Faithful CS 5 question generation rather than clarification need prediction [17]. Each passage maycapturedifferentsemanticfacetsofthequery,butwerestricttoasingle-turn setup, generating one clarifying