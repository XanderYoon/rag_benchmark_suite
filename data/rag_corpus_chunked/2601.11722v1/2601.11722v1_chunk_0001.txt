in clarifying interac- tions [22]. Recent work has explored generating clarifying questions that are relevant, diverse, and human-plausible [8,28,30]. However, little attention has been given to whether these questions are grounded in the document corpus, even though unsupported clarifications may mislead users and harm retrieval effectiveness [10,18]. This is the author’s version of the work. It is posted here for your personal use. The definitive version is published in: Proc of the 48th European Conference on Information Retrieval (ECIR ’26), 29 March–2 April, 2026, Delft, Netherlands arXiv:2601.11722v1 [cs.CL] 16 Jan 2026 2 A-R Kebir et al. Retriever (BM25, dense vector) Top-k passages (a) passage retrieval (b) training pipeline > Ambiguous user query Faithful clarifying question Unfaithful clarifying question Preference Optimization (DPO) RACSFT Base Fig.1: Overview of RAC. Given an ambiguous user query, the system first re- trieves the top-kpassages ((a) passage retrieval). A mixture of the fine-tuned modelandthebasemodelisthenusedtogenerateunfaithfulclarifyingquestions. Both faithful and unfaithful clarifying questions are subsequently leveraged for preference optimization via the DPO algorithm ((b) training pipeline). During inference, the trained model directly generates faithful clarifying questions. Early approaches to clarifying question generation in conversational search largely relied on facet-based methods. These methods extracted candidate facets from the document collection to produce clarifying questions via templates or sequence-to-sequence models [1,2]. While this offered a basic form of corpus grounding, the reliance on coarse-grained facets proved reductive. The advent of large language models (LLMs) enabled more fluent generation, with systems either conditioning on extracted facets to produce natural clarifica- tions or directly deriving facets from queries before turning them into questions. Yet the task remains split into two stages—facet identification and question gen- eration—creating bottlenecks in facet extraction and risks of hallucination when clarifications introduce content unsupported by the corpus [27,28]. Inthiswork,webuildontheretrieval-augmentedgeneration(RAG)paradigm [12] to ground clarifications directly in the corpus, focusing