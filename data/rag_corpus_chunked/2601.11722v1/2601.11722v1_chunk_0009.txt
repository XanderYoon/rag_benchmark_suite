fine-tuning and preference optimization address complementary ob- jectives: supervised fine-tuning operates at the token level, teaching the model to produce clarifying questions, while preference optimization encourages it to prefer faithful outputs over unfaithful ones. To leverage both, we propose a com- bined training objective:LRAC(θ) =γ· L DPO(θ) + (1−γ)· L SFT(θ). 4 Experimental Setup 4.1 Datasets and Evaluation Datasets.We evaluate RAC on four datasets across conversational search and open-retrieval QA. For search, we use Qulac (derived from TREC Web Track Retrieval-Augmented Clarification for Faithful CS 7 2009–2012) [2] and the filtered version of ClariQ proposed by Sekulic et al. [27], which maps clarifying questions to facets. For QA, we use PaQa (AmbigNQ with GPT-3 clarifications) [8] and CambigNQ (AmbigNQ queries augmented with human-validated clarifications) [11]. Adapting Datasets for Retrieval-Augmented Clarification.Existing clarification datasets (Qulac, ClariQ) lack passage-level grounding, as their relevance labels are assigned at the document level and not explicitly tied to the clarifying ques- tion. To bridge this gap, we derive passage-level supervision through a three- stage pipeline: (i)Passage Indexing: we segment Clueweb09-124 into 250-token passages, following TREC CAsT [20], and index them with Pyserini [15]; (ii) Query Rewriting: for each ambiguous query–clarification pair(Uq, Cq), we gen- erate a facet-specific reformulationUr q by incorporatingCq using an LLM, yield- ing sharper retrieval intents thanUq alone; (iii)Pseudo-Relevance Retrieval: we employ BM25 [25] over the passage index to retrieve the top-kpassagesDfor U r q, treating them as pseudo-relevant evidence. This produces training tuples (Uq,D, C q)that support retrieval-conditioned clarification generation. Metrics.We employ both reference-based and reference-free metrics to evaluate the quality of generated clarifying questions. Reference-based metrics measure similarity to gold questions, while reference-free metrics assess faithfulness to the input query and associated passages. In addition, we use GPT-4 to assess faithfulness, serving as a model-based proxy for human judgment. Reference-based evaluation.We