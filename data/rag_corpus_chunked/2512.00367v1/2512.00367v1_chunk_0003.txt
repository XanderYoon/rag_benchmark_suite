calculating distance between sentence embed- dings, we train our models to be able to amplify the distances and give us scores which we then use to chunk. We train the chunkers using positive and negative samples created from the PQA-U dataset as described in Section 4.1. 3.1 Semantic Chunking The two methods that we introduce are distinctive in how they define the se- mantic boundaries of a chunk, ultimately determining the separation points be- tween two chunks. In both the methods, we employ a 1:1 negative sampling of data as mentioned in Section 4.1, to ensure that the learned representations and boundaries are robust. We choose simple light-weight approaches and models to ensure that performance is optimized for downstream tasks and the chunking it- self doesn’t take much time or compute. The shared methodology between both of our chunking strategies is explained below. Given a sentence pairS i andS j, we encode them using state-of-the-art sen- tence transformers [12]:all-MiniLM-L6-v2(MiniLM) [20],all-mpnet-base- v2(mpnet) [13], ande5-large-v2(e5) [19] to have a total of three chunking models per strategy. The resulting embeddingsE i andE j undergo a linear transformation. The training enables the model to specifically tune the embedding space for boundary detection. InProjected Similarity Chunking(PSC), the dot-product similarity be- tween embeddings is obtained and the resultant final scalar similarity score is used to determine the boundary InMetric F usion Chunking(MFC), we employ a combined metric of eval- uating similarity between two given embeddings. We employ an equally weighted combination of Dot Product Similarity, Euclidean Distance, and Manhattan Dis- tance which is passed through a single neural layer to obtain the final similarity score. The scalar similarity scoreSi,j is normalized into a probability range(0,1) using sigmoid. This value represents the model’s final prediction. If the output probability is greater than or equal to 0.5 (determined