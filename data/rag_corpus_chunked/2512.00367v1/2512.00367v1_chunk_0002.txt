chunking by employing embedding-based strategies. In such methods, candidate chunks are identified by measuring the cosine similarity between adja- cent sentences (or merged segments) and splitting when the similarity falls below a threshold, indicating a topic shift. However, cosine similarity has known short- comings for downstream tasks such as information retrieval [23] and often lacks robust, domain-specific performance, as our experiments demonstrate. The cost of use of the library implementation of semantic chunking was elaborated in [11] and concluded that the existing semantic chunker may not always be worth the computation cost. Additionally, recent research [22] has explored predicting op- timal chunk granularity, but to our knowledge, no recent work has proposed new semantic chunking algorithms or systematically examined their joint impact on retrieval and generation. We propose an approach that better aligns with human judgment than ex- isting baselines, particularly because the gold data used for evaluation, both for our models and the baselines, is human-authored. Our methods not only deliver higher retrieval and generation quality but also achieve measurable computa- tional efficiency gains compared to current chunking strategies. Breaking It Down 3 3 Methodology In this section, we detail the process of training and employing our semantic chunkers using domain-specific documents. The hypothesis behind our methods is that two sentences similar in ideas would occur together while two sentences with not so close ideas would occur in different paragraphs and thereby be in separate chunks. Instead of just calculating distance between sentence embed- dings, we train our models to be able to amplify the distances and give us scores which we then use to chunk. We train the chunkers using positive and negative samples created from the PQA-U dataset as described in Section 4.1. 3.1 Semantic Chunking The two methods that we introduce are distinctive in how they