between events, when the re- trieved documents contain the correct answer, the generator may still fail to follow the rules and then come up with an incorrect answer. Generally, the more documents in the top 10 retrieved information that are related to the correct answer, the higher the probability that the generator will answer correctly. The problem of attribution error occurs generally because there are only one to three supportive doc- uments in the retrieved information. K Prompt Templates There are mainly two kinds of prompts in our model: prompts for fine-tuning in Figure 2 and prompts for in-context learning of GPT in Table 4. As Figure 2 shows, Instruct prompts consist of five parts: Instruct, Retrieved documents, Rules, Query and Answer. The Instruct is fixed, the Retrieved documents are retrieved by our proposed RuleRAG according to Rules and Query, and the Answer is pre-defined. As Section 4 shows, we use 3-shot in-context learning for GPT to replace fine-tuning. In the following, we take RuleQA-I as an instance to show the RGFT instruct prompts (Table 9) and prompts for GPT-3.5-Turbo (Table 10). 18 Answer the Final Query by referring to the three cases below. Case 1: # Instruct: For the query in the form of “Time {time} what does {subject} {relation} ?”, we provide a collection of text consisting of multiple documents in the form of “Time {time} {subject} {relation} {object}.” Your response should directly generate the missing {object}. # Retrieved documents: Documents related to the Query. Time 2014-06-23 Abdullah Abdullah Expel or withdraw peace- keepers Election Commission (Afghanistan). Time 2014-02-20 Abdullah Abdullah Make a visit Afghanistan. · · · Time 2014-07-16 Abdullah Abdullah Make a visit Ashraf Ghani Ahmadzai. · · · Time 2014-09-20 Abdullah Abdullah Make a visit Foreign Affairs (United States). # Rules: Use the following Two