the robustness of our rule-guided approach RuleRAG to such queries, we first conduct the Standard RAG on them as a baseline and then test the performance of RuleRAG by adding our previously matched rules. Hence, the only difference in the input of LMs between the main experiment and this experiment is the queries. The others, including rules and answers, remain the same. The results are shown in Table 7. We find (1) In terms of absolute performance, compared Table 2, most of the results in Table 7 show a certain degree of degradation, which indicates that we successfully achieve interference with the methods. (2) Compared to the Standard RAG in Table 7, our proposed RuleRAG-ICL and RuleRAG-FT still achieve performance improve- ment over all the evaluation metrics, showing that our methods can overcome the interference of irrelevant rules. Fine-tuning based RuleRAG-FT is consistently better than RuleRAG-ICL, showing that our proposed RGFT is effective for these queries. Therefore, our methods are robust. To further improve the robustness of RuleRAG, in future work, we can use LLM to filter, sort, and evaluate rules or consider rules as interactable logi- cal units, and so on. For exceptions or anomalies, we can also introduce entity linking for unrecog- nized entities and semantic similarity checks for outliers in temporal data. In addition, the robust- ness of the LLM itself can also ensure performance. F The Choice of RuleRAG-ICL and RuleRAG-FT Our proposed RuleRAG includes two parts, RuleRAG-FT which requires training and RuleRAG-ICL which does not. They can also be used in combination with different LLMs: small-scale LLMs (6B, 7B, 13B in our paper) and a closed-source LLM (GPT-3.5-Turbo in our paper). For different usage scenarios and requirements, we are free to choose different combinations. Sum- marizing all the results shown in this paper, we give