37.563.2 44.2 45.083.9 23.9 38.288.5 35.1 27.0RG-Contriever RG-Mistral_7B_v0.245.5 15.4 24.555.2 40.8 39.863.2 46.3 45.883.9 26.1 39.888.5 39.8 31.9Standard RAG Contriever LLAMA2_13B41.2 22.1 39.552.7 40.8 44.262.2 49.2 52.480.6 42.4 51.487.6 50.2 57.4RuleRAG-ICLRG-Contriever LLAMA2_13B45.5 22.3 39.655.2 41.1 44.463.2 49.9 52.983.9 45.0 52.088.5 51.1 57.6RG-Contriever RG-LLAMA2_13B45.5 22.3 39.855.2 41.5 45.863.2 51.2 54.283.9 46.6 52.288.5 52.7 58.1Standard RAG Contriever GPT-3.5-Turbo41.2 19.1 27.752.7 38.1 44.262.2 46.5 43.780.6 56.3 39.187.6 30.7 59.9RuleRAG-ICLRG-Contriever GPT-3.5-Turbo45.5 19.7 30.155.2 41.0 49.963.2 49.4 65.883.9 56.5 50.388.5 32.6 64.6RG-Contriever RG-GPT-3.5-Turbo45.5 25.8 39.755.2 44.5 53.163.2 53.1 68.783.9 57.6 59.088.5 59.4 75.6 Table 4: The performance of RuleRAG-ICL with a powerful retriever, Contriever, under five LLMs. Architecture RuleQA-I RuleQA-Y RuleQA-W RuleQA-F RuleQA-NRetriever GeneratorEM T-F1EM T-F1EM T-F1EM T-F1EM T-F1Standard RAG DPR ChatGLM2_6B0.0 5.10.3 7.80.3 18.10.1 21.00.0 0.0RuleRAG-ICL RG-DPR RG-ChatGLM2_6B2.5 16.91.3 13.73.0 26.710.8 27.30.5 1.7RuleRAG-FT RGFT-DPR RGFT-ChatGLM2_6B7.3 21.242.2 35.223.5 30.519.2 29.825.6 25.6Standard RAG DPR Mistral_7B_v0.21.6 13.80.7 11.91.3 21.83.1 22.40.9 1.5RuleRAG-ICL RG-DPR RG-Mistral_7B_v0.23.1 20.04.5 23.434.2 40.76.4 28.64.2 16.6RuleRAG-FT RGFT-DPR RGFT-Mistral_7B_v0.222.6 34.949.2 47.335.5 45.253.7 48.950.9 62.6Standard RAG DPR LLAMA2_13B6.1 25.94.0 20.26.0 28.612.6 34.910.2 31.6RuleRAG-ICL RG-DPR RG-LLAMA2_13B10.0 30.06.5 23.714.1 43.420.5 36.918.2 36.1RuleRAG-FT RGFT-DPR RGFT-LLAMA2_13B22.0 39.846.6 47.942.3 48.145.6 49.642.1 55.6Standard RAG DPR GPT-3.5-Turbo9.0 29.14.8 25.96.9 31.525.7 24.516.0 43.3RuleRAG-ICL RG-DPR RG-GPT-3.5-Turbo12.2 30.39.9 28.116.4 33.737.9 32.127.5 50.6RuleRAG-FT RGFT-DPR RG-GPT-3.5-Turbo (3-shot)15.7 33.840.1 32.838.9 35.472.4 34.168.1 56.1 Table 5: The performance of RuleRAG-ICL and RuleRAG-FT with different LLMs as generators. The retriever is fixed as DPR. We omit R@10 since it has been given in detail in Table 2. We use 3-shot prompts for the closed-source GPT-3.5-Turbo to replace RGFT due to its unpublished parameters. D Implementation Details Generator fine-tuning. We fine-tune the ChatGLM2_6B, Mistral_7B_v0.2, LLAMA2_7B, LLAMA2_13B models using 2, 2, 4 and 8 V100 32G GPUs, respectively. We use LORA (Hu et al., 2022) with 4-bit, a parameter-efficient fine-tuning (PEFT) adaptation method, to deal with the enor- mous computation costs and hardware require-