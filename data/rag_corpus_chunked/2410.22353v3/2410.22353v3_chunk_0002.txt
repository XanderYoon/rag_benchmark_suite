rarely explicitly “pointed out” and “supervised” in the pre-training corpora of LLMs. Even if answered correctly, they still lead to implicit attribution processes that are difficult to explain and verify. Therefore, the cur- rent RAG is neither inherently trained to retrieve along reasonable retrieval directions nor organi- cally attribute retrieved content to answers. While answering knowledge-intensive queries, a priori rules instead of simply matching words can genuinely capture internal logical patterns among complicated knowledge. Some works incorporate rules into LLMs to handle the addition of num- bers (Hu et al., 2024) or industrial tasks (Zhang et al., 2024b), but there is currently no exploration of introducing rules into RAG for QA. As shown in Figure 1, the query is What is the trend in YSSTECH’s stock price going forward?. Current re- trievers recall many documents that contribute noth- ing to answering because of blind retrieval. By con- trast, financial KGs provide a rule that The merger of a company’s businesses with other influential companies leads to The increase in a company’s 1 arXiv:2410.22353v3 [cs.IR] 16 Feb 2025 Figure 1: (a) Without the help of rules, the current RAG can only retrieve documents about some keywords, rather than the overall semantics of the query, and thus get confused in answering. (b) Guided by the attributable rule r, our proposed RuleRAG retrieves logically supportive documents and then reasons the correct answer . stock price. Therefore, we can leverage this rule to conduct more targeted retrieval and offer docu- ments that can better support question answering. Upon the above motivation, we propose RuleRAG, Rule-guided Retrieval-Augmented Generation, which enables to both retrieve documents and reason answers with the guidance of rules. Compared to standard RAG, which relies on finding the precise statement of the query to be answered, training-free RuleRAG-ICL requires the introduction of