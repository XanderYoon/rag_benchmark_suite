10.4 17.3 6.8 8.3RuleRAG-FT 11.9 18.8 8.2 8.9Contriever + GPT-4o-miniCoK 27.9 11.6 36.8 31.4RuleRAG-CoK 40.0 16.2 38.6 35.4 Table 3: The results of Standard RAG and CoK on four RAG datasets before and after equipping RuleRAG. sistent performance gains with the help of the rules in our constructed RuleQA. Specifically, following the framework of RuleRAG, existing datasets can be adaptively equipped with rules in RuleQA by calculating the relevance between candidate rules and queries. If some rules are highly relevant, they are introduced, otherwise no rules are introduced. Table 3 also compares the performance changes of an advanced RAG model CoK without and with our proposed RuleRAG, indicating that when CoK replaces Standard RAG as the base method, the variant of RuleRAG, RuleRAG-CoK, still succeeds in introducing the guidance of rules. These results further confirm the effectiveness of our proposed rule-guided retrieval and generation in RAG for more comprehensive QA models and applications. 7 Conclusion and Future Works In this paper, we point out two high-level problems of current RAG and propose rule-guided retrieval- augmented generation (RuleRAG). RuleRAG-ICL intuitively shows RAG can directly benefit from prompting LLMs with rules by in-context learning. To further improve the QA performance, RuleRAG-FT retrofits retrievers to recall more supportive information by contrastive learning and updates generators through our designed RGFT. Experiments on our constructed five rule-aware QA benchmarks RuleQA show the strong performance of RuleRAG under multiple retrievers and gener- ators and the generalization of rules. Furthermore, the comparison results with and without rules in RuleQA for RuleRAG and CoK on existing RAG datasets also attest to the effectiveness of rules in broader scenarios. In the future, we will explore how to adapt rules in more complex RAG frame- works and use custom rules for more QA tasks. 8 Limitations Since existing RAG datasets