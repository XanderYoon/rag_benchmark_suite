fine-tuning or with SSFT/RGFT while recalling different numbers of top-scored documents. Before fine- tuning, the Recall@k and EM performance of the three retrievers are comparable and each has their own performance characteristic, with no obvious advantages or disadvantages. For instance, DPR has the best Recall@10 and SimCSE has the best EM under top-10 documents before fine-tuning. After fine-tuning, DPR consistently outperforms SimCSE and RGFT consistently outperforms SSFT. Specifically, under considering top-scored documents with the same k, for the two trainable dense retrievers, the RGFT version recalls more relevant information (R@k) than the SSFT version by a large margin, demonstrating the generality of the proposed RGFT across different retrievers. As a result, the EM scores of the generated answers are better when higher-quality documents from retriev- ers are provided. Moreover, when the retrievers and generators are applied with RGFT, RuleRAG- FT shows substantial performance gains, even with the retrieval number limited to top-1. For DPR and 6 SimCSE, as we include more documents, the Re- call@k and EM scores increasingly improve. This shows that leveraging rules to guide the retrieval and generation processes builds a bridge between queries and answers since rules provide retrieval directions and attributable mechanisms. For BM25, although Recall@k keeps increasing, EM experi- ences a drop, probably due to the retrieved noise. One additional finding is that even though the dif- ference in R@2 between the original DPR and Sim- CSE is not large (10.1% vs 10.2%), the EM of gen- erated answers can differ significantly (12.4% vs 9.1%). The reason may be that DPRâ€™s retrieved con- tent includes not only the correct answers but also other helpful information. RGFT further widens the gap of Reacll@k between DPR and SimCSE. Retrievers in RuleRAG-ICL Contriever (Izacard et al., 2022) is a powerful re- triever with strong unsupervised performance and