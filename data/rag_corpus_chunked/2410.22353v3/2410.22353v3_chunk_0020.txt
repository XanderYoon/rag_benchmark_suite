full set of rules in RuleQA. Therefore, it is important to verify its ability to generalize to unseen rules. RuleRAG-FT must capture transferable rule uti- lization capability, since RuleRAG-FT has no prior knowledge of the target rule bank and is forced to learn from the source rule bank. The results in Fig- ure 5, where Ri ∩ Rj = ∅ and |Ri| = |Rj| (i, j ∈ {1, 2, 3, 4}), show that (1) The diagonal ( Ri, Ri) has the highest performance gains and there are slight differences between various rule banks; (2) The results on two sides of the diagonal fluctua- tions within reasonable ranges and all show stable improvements over Standard RAG. This implies that RuleRAG-FT can take advantage of the ability to leverage the learned underlying rule patterns rather than being limited to concrete rule instances. Generalization on More Datasets To test RuleRAG’s performance on retrieving and reasoning using rules in a wider range of scenarios, we conduct assessments in four datasets: ASQA (Stelmakh et al., 2022), PopQA (Mallen et al., 2023), HotpotQA (Yang et al., 2018) and Natural Questions (NQ) (Kwiatkowski et al., 2019). Table 3 shows RuleRAG’s results on them. Even though these datasets were constructed without adapting rules, RuleRAG still achieves con- Datasets ASQA PopQA HotpotQA NQMethods EM EM EM EMContriever + LLAMA2_7BStandard RAG 8.6 14.3 4.4 7.6RuleRAG-ICL 10.0 15.3 5.4 7.8RuleRAG-FT 11.1 16.7 6.0 8.1Contriever + LLAMA2_13BStandard RAG 8.8 13.7 5.8 7.8RuleRAG-ICL 10.4 17.3 6.8 8.3RuleRAG-FT 11.9 18.8 8.2 8.9Contriever + GPT-4o-miniCoK 27.9 11.6 36.8 31.4RuleRAG-CoK 40.0 16.2 38.6 35.4 Table 3: The results of Standard RAG and CoK on four RAG datasets before and after equipping RuleRAG. sistent performance gains with the help of the rules in our constructed RuleQA. Specifically, following the framework of RuleRAG, existing datasets can be adaptively