20.5 11 12 13 14 15 16 17 18 19 20 21 22 EM(%) 8 9 10 11 12 13 14 15 16 17 18 19 20 EM(%) 8.9 9.1 13.8 13.9 10.8 12.7 14.8 15.1 14.6 15.2 18.2 18.7 6.5 7.0 7.5 8.0 8.5 9.0 9.5 10.0 10.5 11.0 EM(%) 7.9 8.7 8.1 7.9 10.1 Figure 3: The Reacll@k and EM performance of RuleRAG-FT in RuleQA-I with different numbers of retrieved documents and under multiple circumstances: three settings in DPR (DPR, SSFT-DPR and RGFT-DPR), three settings in SimCSE (SimCSE, SSFT-SimCSE and RGFT-SimCSE) and one setting in BM25. Horizontal numbers over the pillars represent EM for bar charts and slanted numbers around the lines represent Recall@k for line charts. ther improved under the guidance of rules from two perspectives: through in-context learning (ICL) in RuleRAG-ICL and through RGFT in RuleRAG-FT. For RuleRAG-ICL (RG-DPR + LLAMA2_7B), introducing rules in the retrieval stage alone en- hances DPR recall performance and improves the answer accuracy of the original LLAMA2_7B. RuleRAG-ICL (RG-DPR + RG-LLAMA2_7B) consistently surpasses Standard RAG across vari- ous metrics (+9.3 in R@10, +5.9 in EM and +3.2 in T-F1 on average absolute performance over all five benchmarks), achieving the improved performance. This confirms the sub-optimal ability of the current RAG and the effectiveness of our proposed dual rule-guided retriever and generator. For RuleRAG- FT, our proposed RGFT can amazingly improve performance by a significant margin (+45.7 in R@10, +24.2 in EM and +15.3 in T-F1 compared to the best performance of RuleRAG-ICL). In addi- tion to Standard RAG-based RuleRAG-ICL and RuleRAG-FT, RuleRAG can also be applied to many advanced RAG-based models. As a variant of RuleRAG, RuleRAG-CoK introduces the idea of rule-guided RAG into CoK. The performance improvement achieved is attributed to our proposal. To further corroborate that these gains are