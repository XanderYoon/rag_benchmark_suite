Standard RAG, RuleRAG-ICL and RuleRAG-FT with the 13B model always outperform their 7B counterparts, indicating that the introduced rules can provide better guidance when using larger models with the 1/8 2/8 3/8 4/8 5/8 6/8 7/8 1 Fine-tuning data ratio 50% 60% 70% 80% 90% 100%EM performance ratio RuleQA-I RuleQA-Y RuleQA-W RuleQA-F RuleQA-N Figure 4: The EM variation of RuleRAG-FT produces different characteristics due to the varying difficulty of the rules in our constructed five RuleQA benchmarks. same LLM architecture. Thirdly, the RuleRAG- ICL’s EM results of GPT-3.5-Turbo are better than LLAMA2_13B because of more massive model pa- rameters, however, the RuleRAG-FT’s EM results of LLAMA2_13B are better than GPT-3.5-Turbo in three of the five benchmarks. This phenomenon il- lustrates that RGFT is fairly effective and necessary for lightweight LLMs to overcome big LLMs, mak- ing RuleRAG-FT much cheaper than off-the-shelf big LLMs for LLM deployment and application. Impact of RGFT Data Volume In Figure 4, the x-axis is the ratio of fine-tuned data to the total amount of data in RGFT. The y-axis is the ratio of EM performance to the optimal one under DPR and LLAMA2_7B, with closer to 100% indicating stronger performance. Since the differ- ent properties of the rules in different benchmarks lead to different degrees of difficulty in learning, the growth of model performance under different benchmarks exhibits various characteristics. The performance in RuleQA-Y fluctuates mod- estly at a very low level throughout the first half of the RGFT process, and then sees a sudden surge in capability during the second half of the RGFT pro- cess. It is worth noting that the EM performance in RuleQA-I fluctuates more dramatically: While re- alizing substantial EM performance gains (ranking second in all the benchmarks), it undergoes several upward and downward drops before levelling off at the