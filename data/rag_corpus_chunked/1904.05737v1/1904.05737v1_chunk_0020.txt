Con- vKNRM+PACRR; the baseline chooses alpha less than or equal to 0.1 for 60% of total queries whereas the meta-learner chooses alpha between 0.2-0.5 for 75% of queries. It is not the case that the meta-learner simply favors the models that per- form better. For example, with PACRR+BM25, the baseline chooses a value of alpha greater than 0.6 about 50% of time (favors PACRR over BM25). This is in sharp contrast to the meta-learner, which prefers BM25 over PACRR (alpha less than 0.5) for about 64% of queries. The alpha weights can be used to dif- ferentiate meta-learners into two broad categories: the ﬁrst category consists of model combinations where both methods are given nearly equal weights 7, and the second category consists of combinations where the meta-learner often fa- vors one ranking method over the other 8. On average the meta-learners in the second category were more likely to perform better than the baseline than the meta-learners in the ﬁrst category. Additionally, oracle results for meta-learners in the former category are usually higher than for those in the latter category. 5 Conclusion In this work we investigated using a meta-learning method to improve retrieval performance by predicting how to combine the scores from two diﬀerent re- trieval models. Using an empirical evaluation on TREC Web Track data, we found that these meta-learning methods signiﬁcantly outperformed both base models for the majority of model combinations and metrics considered. In order to investigate the source of this improvement, we compared these meta-learners to baselines which used the same model weights for all queries, ﬁnding that our best-performing meta-learners also signiﬁcantly outperformed these “ﬁxed alpha” baselines. Finally, we consider a per-query oracle and ﬁnd that it sub- stantially improves over our meta-learning methods, demonstrating that there is room for improvement in future