calculated as the average percentage of query terms that occur in the top N documents for the query. It is closely related to TFC3 [6], which requires a retrieval method to give a higher score to a document with more distinct query terms. Bigram and trigram matches. These features are the average numbers of bigram matches and trigram matches in the top N documents (normalized by document length). They are related to the term proximity constraints that re- quire term proximity [31] to positively contribute to the retrieval score of docu- ment. Given that the retrieval models we consider commonly have a maximum kernel size of three, we do not consider larger n-gram sizes. Unordered matches. This feature is the average number of query term matches occurring within a 3 term window in the query’s top N documents (normalized by document length). As mentioned in [18], noncontiguous presence of query terms can provide evidence of a document’s relevance. 4 Evaluation Data. We evaluate our approach on the 2010–2014 TREC Web Track ad-hoc task benchmarks, which consist of 248 queries and approximately 89,700 judg- ments over about 88,500 documents from the ClueWeb09 and ClueWeb12 doc- ument collections. We preprocess the documents and perform stopword removal 4 Results from prior work [7] have suggested that neural IR models do not always beneﬁt from the presence of an explicit IDF signal (cf. TV vs. IDF in Table 2). 6 S. Arora and A. Yates using Terrier. [16] We instantiate our approach using every pair of the following models to serve as M1 and M2: BM25 [25], KNRM [34], PACRR [12], Deep- TileBar [30] and ConvKNRM [4] . These ﬁve models additionally serve as our baselines. We re-rank the TREC qrels (i.e., all judged documents) in order to remove the eﬀects of an initial