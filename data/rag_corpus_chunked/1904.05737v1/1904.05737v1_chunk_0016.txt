combining two n- gram models. For example, ConvKNRM+KNRM and ConvKNRM+BM25 per- form better than ConvKNRM+PACRR and ConvKNRM+DeepTileBar despite the fact that PACRR outperforms BM25. The ranking of the meta-learning methods is similar to the ranking of the oracles, suggesting that our meta- learner’s features are robust to the choice of models being combined. Feature PACCR PACCR BM25+ DTB+ PACCR +KNRM +BM25 KNRM BM25 +DTB Average query IDF 0.014 0.046 -0.048 0.029 -0.017 Max query IDF 0.000 -0.013 0.042 -0.026 0.037 Freq. of query term -0.018 -0.009 -0.045 0.010 -0.011 Freq. of max IDF query term -0.018 0.023 -0.022 0.020 -0.004 Document length -0.040 0.025 -0.034 0.010 0.002 Query coverage -0.009 -0.009 -0.008 -0.023 -0.010 Bigram match -0.009 -0.072 0.021 -0.003 -0.015 Trigram match 0.009 0.018 -0.011 0.012 -0.019 Unordered match -0.026 0.089 -0.017 0.028 0.010 Table 2: Feature weights from the meta-learners. Feature DTB+ DTB+ PACRR+ CKNRM CKNRM KNRM CKNRM CKNRM +KNRM +BM25 Average query IDF -0.011 0.008 -0.007 -0.027 -0.012 Max query IDF 0.011 -0.002 0.013 0.015 0.016 Freq. of query term -0.015 -0.004 -0.017 -0.006 -0.043 Freq. of max IDF query term 0.012 0.000 0.003 0.000 0.009 Document length -0.004 0.006 0.008 -0.014 -0.023 Query coverage 0.014 0.002 0.005 0.002 -0.019 Bigram match 0.034 -0.017 0.038 -0.000 -0.042 Trigram match 0.020 0.001 -0.002 0.034 0.002 Unordered match -0.061 0.030 -0.018 -0.056 0.035 Table 3: Feature weights from the meta-learners (continued). 10 S. Arora and A. Yates Analysis. In order to gain further insight about the meta-learning methods, we consider the weights they assign to features. In order to mitigate the impact of the features’ varying scales, we scale the feature values to zero mean and unit variance before training. These feature weights are shown in Table 2 and 3. Negative weights indicate that the meta-learner favors the second