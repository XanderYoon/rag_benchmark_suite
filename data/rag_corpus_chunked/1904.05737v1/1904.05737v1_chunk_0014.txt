meta-learners, we additionally report results using query-level oracle models. For each query in the test, we report the results using the optimal alpha. As before we vary α from [0, 1] in 0.1 intervals. Thus oracle results reveal the performance of a perfect meta learner. These results signify the improvements in retrieval that can be achieved by using query level statistics for combining two ranking models and provide motivation of our approach. 4.1 Results The results are shown in Table 1. All meta-learning methods signiﬁcantly out- perform the tuned BM25 baseline in terms of P@30 and usually also outperform BM25 in terms of nDCG and MAP. Furthermore, the meta-learners signiﬁcantly 8 S. Arora and A. Yates Model nDCG@20 MAP P@30 Single Models (Baselines) BM25 0.226 0.369 0.337 PACRR 0.232 0.367 0.350 KNRM 0.267 0.388 0.382 DeepTileBar 0.221 0.332 0.330 CoKNRM 0.291 0.396 0.411 Fixed Alpha (Baselines) KNRM+BM25 0.278 0.397 0.393 PACRR+BM25 0.246 0.379 0.362 PACRR+KNRM 0.271 0.392 0.388 DTB+BM25 0.259 0.366 0.373 DTB+PACRR 0.255 0.363 0.369 DTB+KNRM 0.278 0.381 0.389 CoKNRM+DTB 0.293 0.397 0.413 CoKNRM+PACRR 0.299 0.402 0.420 CoKNRM+KNRM 0.291 0.396 0.411 CoKNRM+BM25 0.294 0.398 0.414 Meta-learners KNRM+BM25 0.278 (KB) 0.396 (KB) 0.392 (KB) PACRR+BM25 0.248 (PB) 0.381 (FPB) 0.365 (PB) PACRR+KNRM 0.270 (PB) 0.392 (KPB) 0.389 (KPB) DTB+BM25 0.250 (DB) 0.359 (D) 0.366 (DB) DTB+PACRR 0.248 (PDb) 0.355 (D) 0.363 (pDB) DTB+KNRM 0.279 (KDB) 0.383 (FDb) 0.392 (KDB) CoKNRM+DTB 0.300 (fCDB) 0.397 (DB) 0.415 (DB) CoKNRM+PACRR 0.307 (CPB) 0.409 (FCPB) 0.425 (CPB) CoKNRM+KNRM 0.321 (FCKB) 0.420 (FCKB) 0.437 (FCKB) CoKNRM+BM25 0.324 (FCB) 0.423 (FCB) 0.439 (FCB) Oracle (Per-query) KNRM+BM25 0.338 0.418 0.427 PACRR+BM25 0.308 0.398 0.395 PACRR+KNRM 0.338 0.416 0.428 DTB+BM25 0.321 0.390 0.404 DTB+PACRR 0.324 0.385 0.406 DTB+KNRM 0.351 0.405 0.431 CoKNRM+DTB 0.369 0.414 0.450 CoKNRM+PACRR 0.392 0.441 0.470 CoKNRM+KNRM 0.398 0.444 0.474 CoKNRM+BM25 0.402 0.457 0.480 Table