Available:https://techcommunity.microsof t.com/t5/ai-azure-blog/raising-the-bar-for-rag-excellence-que ry-rewriting-and-new/ba-p/4045894 [50] Microsoft Learn Documentation, “Hybrid search scoring (RRF) – Azure AI Search,” Microsoft Learn, 2024. [Online]. Available:https://learn.mi crosoft.com/en-us/azure/search/hybrid-search-rrf [51] LangChain Documentation, “RAG-Fusion Template,” LangChain v0.2, 2024. [Online]. Available:https://docs.langchain.com/docs/use-cas es/retrieval/rag-fusion [52] LlamaIndex Blog, “Boosting RAG: Picking the Best Embedding & Reranker models,” LlamaIndex, 2024. [Online]. Available:https://bl og.llamaindex.ai/boosting-rag-picking-the-best-embedding-and-r eranker-models-8b4c2a0a7d9d [53] LlamaIndex Blog, “Improving Vector Search – Reranking with Post- gresML and LlamaIndex,” LlamaIndex, 2024. [Online]. Available:https: //blog.llamaindex.ai/improving-vector-search-reranking-with-p ostgresml-and-llamaindex-1a2c8d7c7f5d [54] Microsoft Learn, “Semantic ranking – Azure AI Search,” Microsoft Learn, 2024. [Online]. Available:https://learn.microsoft.com/en -us/azure/search/semantic-ranking [55] Cohere, “Rerank 3.5: Multilingual Reranking Model,” Cohere Docu- mentation, 2024. [Online]. Available:https://docs.cohere.com/docs/r erank-35 [56] Azure AI Search, “Semantic Ranking Overview,” Microsoft Learn, 2024. [Online]. Available:https://learn.microsoft.com/en-us/azure/sear ch/semantic-ranking-overview [57] Cohere Documentation, “Rerank 3.5 Performance Analysis,” Cohere AI, 2024. [Online]. Available:https://docs.cohere.com/docs/rerank-35-p erformance [58] NVIDIA, “NeMo Retriever Microservices,” NVIDIA Developer, 2024. [Online]. Available:https://docs.nvidia.com/deeplearning/nemo/us 69 er-guide/docs/en/stable/nlp/nemo_retriever_microservices.html [59] T. Sarthi et al., “RAPTOR: Recursive Abstractive Processing for Tree- Organized Retrieval,” inProc. ICLR, 2024, pp. 567–582. [60] Y. Tang and X. Yang, “MultiHop-RAG: Benchmarking Retrieval- AugmentedGenerationforMulti-HopQueries,” arXivpreprintarXiv:2401.15391, 2024. [Online]. Available:https://arxiv.org/abs/2401.15391 [61] L. Wang et al., “Reasoning RAG via System 1 or System 2: A Sur- vey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges,” arXiv preprint arXiv:2506.10408, 2025. [Online]. Available: https://arxiv.org/html/2506.10408v1 [62] Z. Wu et al., “HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation,” arXiv preprint arXiv:2502.12442, 2025. [Online]. Available:https://arxiv.org/html/2502.12442v1 [63] Microsoft Research, “Moving to GraphRAG 1.0 – Streamlining er- gonomics for developers and users,” Microsoft Research Blog, 2024. [On- line]. Available:https://www.microsoft.com/en-us/research/blog/mo ving-to-graphrag-1-0-streamlining-ergonomics-for-developers-a nd-users/ [64] Superlinked, “Optimizing RAG with Hybrid Search & Reranking,” Vec- torHub by Superlinked, 2024. [Online]. Available:https://www.superlin ked.com/blog/optimizing-rag-with-hybrid-search-and-reranking [65] Infiniflow, “Dense vector + Sparse vector + Full text search + Tensor reranker = Best retrieval for RAG?” Infinity Blog, 2024. [Online]. Available: https://infinitylabs.ai/blog/dense-sparse-fulltext-tensor-rag [66] Hugging Face, “BAAI/bge-m3,” Hugging Face Models, 2024. [Online]. Available:https://huggingface.co/BAAI/bge-m3 [67] M. Zhang et al., “Question Decomposition