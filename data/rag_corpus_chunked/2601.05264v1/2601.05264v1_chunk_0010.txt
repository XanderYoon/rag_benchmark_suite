fidelity of evidence, Two-stage reranking patterns such as RE-RAG formalize this design and report con- sistent gains on standard IR benchmarks [17], [18], [52], [53], [54]. The marginalization strategy further stabilizes evidence aggregation across pas- sagesinnoisy-retrievalsettings[39]. However, thisintroducescomputational complexity during inference [40]. Generation: Expressivity under Context Constraints T5 and BART function as high-capacity generators that leverage autoregres- sive decoding and bidirectional encoder states. Token limitations in these models can introduce truncation artifacts that particularly affect long-form reasoning tasks requiring extensive context integration [41]. 3.3 Empirical Characterization of the Canonical Pipeline Table 3.1: Canonical RAG Model Capabilities Model Architecture Key Strengths Primary Limitations DPR + BART Bi-encoder + Seq2Seq Fast retrieval, composable Limited citation control DPR + T5 Bi-encoder + Text-to-Text Strong generation capabilities Context length constraints FiD Passage-parallel decoding Enhanced evidence integration Computational overhead Atlas Pretrained retrieval + Generation End-to-end optimization Resource requirements WebGPT Citation-aware browsing Source attribution Latency considerations 3.4 Architectural Trade-offs and Design Implications Table 3.2: Design Dimensions in Canonical RAG 11 Dimension Canonical Choice Design Benefit Structural Limitation Retrieval DPR (bi-encoder) Sublinear retrieval at scale Reduced recall on lexical queries Fusion Concatenation Simplified interface Context length boundaries GenerationBART/T5 Pretrained fluency Hallucination susceptibility Grounding Implicit marginalization Unsupervised interpretability Limited traceability Adaptivity Static pipeline Predictable execution Inflexible under dynamic needs 3.5 Application Patterns and Domain Suitability Canonical RAG exhibits exceptional performance in tasks that necessitate the retrieval of empirical knowledge and the generation of concise responses. The architecture is particularly effective in the following applications: High-suitability domains: Question answering that is based on Wikipedia, in which the knowledge corpus is consistent with the training data and the queries adhere to predetermined patterns. The system's capacity to generate prompt, source-based responses is advantageous for customer support applications. Medium-suitability domains: The need for sophisticated evidence cal- ibration and domain-specific reasoning that