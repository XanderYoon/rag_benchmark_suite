J. Wei et al., “AlignRAG: An Adaptable Framework for Re- solving Misalignments in Retrieval-Aware Reasoning of RAG,” arXiv preprint arXiv:2504.14858, 2024. [Online]. Available:h t t p s : //arxiv.org/html/2504.14858v1 [147] J. Su et al., “Towards More Robust Retrieval-Augmented Genera- tion: EvaluatingRAGUnderAdversarialPoisoningAttacks,” arXivpreprint arXiv:2412.16708, 2024. [Online]. Available:https://arxiv.org/abs/24 12.16708 [148] “Enhancing AI Security in Production: Key Insights on LLMs & RAG,” J2 Interactive, 2024. [Online]. Available:https://www.j2inte ractive.com/blog/2024/07/global-summit-ai-security/ [149] “A Proactive Approach to RAG Application Security,” Akira AI, Mar. 11, 2025. [Online]. Available:https://www.akira.ai/blog/rag-applica tion-security 78 [150] “Red Teaming RAG Healthcare Chatbots,” iMerit, May 7, 2025. [On- line]. Available:https://imerit.net/blog/red-teaming-rag-healthc are-chatbots/ [151] “How to red team RAG applications,” Promptfoo, 2022. [Online]. Available:https://www.promptfoo.dev/docs/red-team/rag/ [152] T. Zhao et al., “RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation,” arXiv preprint arXiv:2507.08862, 2025. [Online]. Available:https://arxiv.org/abs/2507.08862 [153] H. Chaudhari et al., “Phantom: General Trigger Attacks on Retrieval Augmented Language Generation,” OpenReview, Feb. 4, 2025. [Online]. Available:https://openreview.net/forum?id=BHIsVV4G7q [154] “LLM Red Teaming: Complete guide [+expert tips],” Securaize, Jan. 15, 2025. [Online]. Available:https://securaize.substack.com/p/llm -red-teaming-complete-guide-expert [155] “Securing your RAG application: A comprehensive guide,” Pluralsight, Mar. 17, 2025. [Online]. Available:https://www.pluralsight.com/reso urces/blog/ai-and-data/how-to-secure-rag-applications-AI [156] “Implement human-in-the-loop confirmation with Amazon Bedrock Agents,” AWS Machine Learning Blog, Apr. 9, 2025. [Online]. Available: https://aws.amazon.com/blogs/machine-learning/implement-human -in-the-loop-confirmation-with-amazon-bedrock-agents/ [157] H. Zhou et al., “TrustRAG: Enhancing Robustness and Trustworthi- ness in RAG,” arXiv preprint arXiv:2501.00879, 2025. [Online]. Available: https://arxiv.org/html/2501.00879v1 [158] “TrustRAG: The RAG Framework within Reliable input, Trusted out- put,” GitHub, Feb. 4, 2024. [Online]. Available:https://github.com/g omate-community/TrustRAG [159] B. Zhang et al., “Benchmarking Poisoning Attacks against Retrieval- Augmented Generation,” arXiv preprint arXiv:2505.18543, 2025. [Online]. Available:https://arxiv.org/abs/2505.18543 [160] “LLM Red Teaming: The Complete Step-By-Step Guide To LLM Safety,” Confident AI, May 18, 2025. [Online]. Available:https://ww w.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide [161] “Red Teaming for Large Language Models: A Comprehensive Guide,” 79 Coralogix, Jun. 1, 2025. [Online]. Available:https://coralogix.com/ai -blog/red-teaming-for-large-language-models-a-comprehensive-g uide/ [162]K.Lietal., “ADMIT:Few-shotKnowledgePoisoningAttacksonRAG- based Fact Checking,” arXiv preprint arXiv:2510.13842, 2024. [Online].