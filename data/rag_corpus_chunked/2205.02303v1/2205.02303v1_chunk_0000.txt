Analysing the Robustness of Dual Encoders for Dense Retrieval Against Misspellings Georgios Sidiropoulos University of Amsterdam Amsterdam, The Netherlands g.sidiropoulos@uva.nl Evangelos Kanoulas University of Amsterdam Amsterdam, The Netherlands e.kanoulas@uva.nl ABSTRACT Dense retrieval is becoming one of the standard approaches for doc- ument and passage ranking. The dual-encoder architecture is widely adopted for scoring question-passage pairs due to its efficiency and high performance. Typically, dense retrieval models are evaluated on clean and curated datasets. However, when deployed in real-life applications, these models encounter noisy user-generated text. That said, the performance of state-of-the-art dense retrievers can substantially deteriorate when exposed to noisy text. In this work, we study the robustness of dense retrievers against typos in the user question. We observe a significant drop in the performance of the dual-encoder model when encountering typos and explore ways to improve its robustness by combining data augmentation with contrastive learning. Our experiments on two large-scale passage ranking and open-domain question answering datasets show that our proposed approach outperforms competing approaches. Ad- ditionally, we perform a thorough analysis on robustness. Finally, we provide insights on how different typos affect the robustness of embeddings differently and how our method alleviates the effect of some typos but not of others. CCS CONCEPTS •Information systems → Retrieval models and ranking . KEYWORDS dense retrieval; dual-encoder; robustness; typos; misspellings ACM Reference Format: Georgios Sidiropoulos and Evangelos Kanoulas. 2022. Analysing the Robust- ness of Dual Encoders for Dense Retrieval Against Misspellings. In Proceed- ings of the 45th International ACM SIGIR Conference on Research and Devel- opment in Information Retrieval (SIGIR ’22), July 11–15, 2022, Madrid, Spain. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3477495.3531818 1 INTRODUCTION With the advances in neural language modeling [3], learning dense representations for text has become a vital component in many in- formation retrieval (IR)