the results in Table 2, the effectiveness of the methods varies across the three settings. Particularly, robustness deteriorates when typos do not appear randomly. In detail, the most significant losses occur when typos appear on discriminative utterances. To this extent, our proposed data augmentation combined with contrastive learning approach remains the best performing one across all setting. To better understand the discrepancy in robustness between the three settings of questions with typos, we conduct the following analysis. For the setting where typos randomly appear on ques- tions, we study how the frequency on the training set of the typoed words at test time affects robustness. As shown in Figure 1, there is a strong connection between the frequency of the typoed words and the retrieval performance. As the frequency of the typoed words decreases, the performance drops significantly. To this extent, our proposed data augmentation combined with contrastive learning approach remains the best performing one, with the performance gap increasing as the frequency of the typoed word decreases. The results in Figure 1 can also explain why we observe the highest losses in performance on the setting with typos in discriminative ut- terances. In general, the discriminative utterances (entity mentions) diversity between the dataset splits is higher compared to other words appearing in questions (e.g., interrogative, linking words). [105-) [104-105) [103-104) [102-103) [0-102) Frequency of typoed words in train set. 0.0 0.2 0.4 0.6 0.8 1.0 R@50 DR DR + CL (ours) DR + Data augm. DR + Data augm. + CL (ours) Figure 1: Retrieval performance (Average Recall@50) w.r.t the frequency on the training set, of the typoed words at test- time; on MS MARCO (Dev). Questions are split into bins w.r.t the frequency of their typoed words. 3We build the new settings using the same probability for introducing