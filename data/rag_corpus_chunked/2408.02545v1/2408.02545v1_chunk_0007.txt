instruction: prompts/prompt_instructions/qa.txt data_file: TQA_train_processed.jsonl Listing 2: Example of a training configuration. Model and training parameters are specified, in addition to an instruction file containing the system prompt. tion fetched using a retrieval pipeline, prepare few- shot examples and combine everything together using a prompt template. Listing 1 demonstrates how such a processing pipeline is defined using a Y AML configuration. The main structure of the file is a list of steps, each defined by a_target_ which points to the step implementation. Each step has inputs, which is a name or list of dataset names to act upon. Other keys in a step relate to specific step logic. The first two steps in listing 1 load datasets from Hugging Face hub and from a local path. The third step shuffles and selects 10k examples from the main dataset. The forth step runs a Haystack-based (Pietsch et al., 2019) retrieval pipeline to retrieve relevant passages using questions from the loaded dataset as queries, storing them in docs_key. We note that different retrieval processes or frame- works (Liu, 2022; Chase, 2022; Lin et al., 2021) can be used in retrieval steps. The fifth step selects 3 few-shot examples from the secondary dataset, following a prompt generator step that loads a prompt template and replaces all given informa- tion according to the defined mapping dictionary. Lastly, the dataset is saved to a local path. 3.2 Training We provide a training module to fine-tune models given the datasets created by the previous process- ing module. The training module relies on the well established training framework TRL2 and sup- 2https://github.com/huggingface/trl model: _target_: ragfoundry.models.hf.HFInference model_name_or_path: "microsoft/Phi-3-mini-128k-instruct",â†’ load_in_8bit: true instruction: prompts/prompt_instructions/qa.txt lora_path: /path/to/adapter generation: do_sample: false max_new_tokens: 50 return_full_text: false data_file: my-processed-data.jsnol generated_file: model-predictions.jsonl Listing 3: Example of an inference configuration. In ad- dition to model and generation