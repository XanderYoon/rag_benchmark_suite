as aggre- gations, group-by, examples filtering, join opera- tions, and more. • Local Steps : Operate on individual examples, making them suitable for tasks such as retrieval, text processing, and field manipulation. The modular design allows for building flexible and efficient data processes, tailored to the needs of RAG-oriented training and inference. Steps can be categorized into the following non-exclusive categories: • Loaders: Load datasets from the Hugging Face1 hub or from local sources. • Selectors: Filter examples, shuffle datasets, and select subset datasets. • Retrievers: Integrate information from external databases, tools, libraries and pipelines. • Samplers: Collect random examples or features from any dataset to compile few-shot or negative examples. • Prompters: Format prompts using custom tem- plates and keyword mappings. The processing module supports the handling of multiple datasets at once, through global dataset sharing. This feature allows each step of the pipeline to access any of the loaded datasets, en- hancing flexibility and allowing for complex pro- cessing procedures. Furthermore, the module in- cludes step caching, which caches each pipeline step locally. This improves compute efficiency, and facilitates easy reproduction of results. 3.1.1 Example: Enhancing a Q&A Dataset To showcase the effectiveness of the process- ing module, we demonstrate how to enrich a question-answering dataset with external informa- 1https://huggingface.co/ model: _target_: ragfoundry.models.hf.HFTrain model_name_or_path: "microsoft/Phi-3-mini-128k-instruct",→ load_in_8bit: true lora: peft_type: "LORA" r: 16 target_modules: [ "qkv_proj"] completion_start: "<|assistant|>" train: gradient_accumulation_steps: 4 learning_rate: 2e-05 lr_scheduler_type: "cosine" num_train_epochs: 1 optim: "paged_adamw_8bit" instruction: prompts/prompt_instructions/qa.txt data_file: TQA_train_processed.jsonl Listing 2: Example of a training configuration. Model and training parameters are specified, in addition to an instruction file containing the system prompt. tion fetched using a retrieval pipeline, prepare few- shot examples and combine everything together using a prompt template. Listing 1 demonstrates how such a processing pipeline is defined using a Y AML configuration.