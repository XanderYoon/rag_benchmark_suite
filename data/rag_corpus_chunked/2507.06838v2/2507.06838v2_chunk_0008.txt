(2023a), we replaced all instances of [n] in pas- sages with (n) to prevent model confusion during data synthesis and inference. We used the fix_text function from ftfy2 to preprocess all inputs before feeding them into the model. 3.3.2 Training We adopt Llama-3.1-8B-Instruct 4 as the base model and train it using a standard supervised fine- tuning approach. The input consists of a prompt 1https://huggingface.co/datasets/castorini/ rank_zephyr_training_data 2https://pypi.org/project/ftfy Passage Selection Prompt of SETR I will provide you with {num} passages, each indicated by a numerical identifier []. Select the passages based on their relevance to the search query: {question}. {context} Search Query: {question} Please follow the steps below: Step 1. Please list up the information requirements to answer the query. Step 2. for each requirement in Step 1, find the passages that has the information of the requirement. Step 3. Choose the passages that mostly covers clear and diverse information to answer the query. Number of passages is unlimited. The format of final output should be ‘### Final Selection: [] []’, e.g., ### Final Selection: [2] [1]. Figure 2: The set-wise passage selection prompt with Chain-of-Thought information requirement identifica- tion process for SETR. including the user question and retrieved passages, while the output includes the CoT reasoning from the teacher model along with the selected passages. For the ablation study, we present two additional model variations. We refer to the original model as SETR-CoT & IRI for comparison with these variations. Full prompt details are provided in Ap- pendix A.4. • SETR-Selection only is a model trained to generate only the final selected passages with- out any reasoning process. • SETR-CoT is a model trained with general CoT reasoning using a standard “Let’s think step-by-step prompt” prompt, but does not explicitly identifying distinct information re- quirements. • SETR-CoT & IRI is