gories. Specifically, we include traditional unsu- pervised ranking models such as BM25 (Robert- son and Zaragoza, 2009), supervised dense ranking models including bge-large-en-v1.5 (Xiao et al., 2023), and bge-reranker-large (Xiao et al., 2023), as well as LLM-based ranking models such as Ran- kLlama (Ma et al., 2024), RankVicuna (Pradeep et al., 2023a), RankZephyr (Pradeep et al., 2023b), FirstMistral (Chen et al., 2024) and RankGPT (gpt-4o3) (Sun et al., 2024). Implementation Details . SETR is built upon 3gpt-4o refers to gpt-4o-2024-08-06 from OpenAI Llama-3.1-8B-Instruct4, trained for 5 epochs with an effective batch size of 512 and a learning rate of 5 × 10−6 using AdamW optimizer (Loshchilov and Hutter, 2019). To evaluate the effectiveness of SETR, we keep the first-stage retrieval and the gen- erator fixed. The first-stage retrieval uses bge-large- en-v1.5 (Xiao et al., 2023), a high-performance retrieval model, while the generator is Llama-3.1- 8B-Instruct4 which we use without fine-tuning. For RAG, we adopt the standard RAG framework (Ram et al., 2023) to generate answers based on the re- trieved contexts. All baselines are implemented uti- lizing the Rankify (Abdallah et al., 2025) toolkit5. 4.2 End-to-end QA Evaluation The main results of various ranking models are presented in Table 1. The results in RETRIEVAL ONLY are derived solely from first-stage retrievers, while RERANKING and SET SELECTION corre- spond to the results of re-ranking or selecting over the top-20 candidates retrieved by the respective first-stage retrievers. Based on the results, the key observations are as follows: (1) In terms of an- swer correctness, SETR significantly outperforms 4https://huggingface.co/meta-llama/Llama-3. 1-8B-Instruct 5https://github.com/DataScienceUIBK/Rankify all baselines by selecting the optimal set of pas- sages from the retrieved passages, achieving no- tably higher F1 and Accuracy. These results are quite impressive, considering that SETR uses 40- 50% fewer passages on average compared to base- lines. (2) The