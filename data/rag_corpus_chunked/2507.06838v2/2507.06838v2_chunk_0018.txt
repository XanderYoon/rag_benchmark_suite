whether reranking or selection-based, leverage the same powerful teacher model, GPT-4o, to gen- erate passage selections or ranking. This setup isolates the effect of the selection formulation itself by minimizing the influence of model capacity or training-specific artifacts. Table 3, which reports the method-level effects with teacher model, in- dicates that our set selection method outperforms traditional reranking strategies, highlighting the in- Model HotpotQA2Wiki MuSiQueMHRAG EM F1 EM F1 EM F1 Accuracy BUILT ONZEPHYR-7B-β(Pradeep et al., 2023b) RankZephyr (original)29.76 30.3631.19 24.926.95 10.5741.55 BUILT ONLLAMA-3.1-8B-INSTRUCT RankZephyr♣ 34.69 35.0433.87 27.838.61 12.7943.90 RankZephyr + CoT♣ 33.99 34.3833.66 27.859.43 13.2743.60 SETR-CoT & IRI36.62 38.1135.44 30.3510.79 15.4347.14 Table 4: Fair comparisons under a unified setting, with confounding factors minimized. RankZephyr ♣ and RankZephyr + CoT♣ were implemented using the same LLaMA-3.1-8B-Instruct model as our method, fine- tuned on data re-annotated by gpt-4o-2024-08-06. dividual contributions of both CoT reasoning and IRI to enhanced retrieval performance. Specifically, the SETR method with IRI con- sistently achieves strong performance across all benchmarks and demonstrates competitive or supe- rior results compared to both traditional reranking and other set selection variants. Notably, while both Rank + CoT and SETR-CoT share the same CoT prompt, the results reveal that using set-wise selection rather than integrated ranking in the final stage leads to improved retrieval outcomes. This suggests that constructing a unified ranking may lead to the omission of certain aspects of the rea- soning process, potentially resulting in information loss. Furthermore, the comparison between SETR- CoT and SETR-CoT & IRI demonstrates that ex- plicitly identifying essential information during the reasoning process helps improve selection preci- sion and ensures broader information coverage. Unified Setting for Direct Comparison. To fur- ther minimize potential bias, we create a unified training setting, in which all models are (1) built on the same base architecture (Llama-3.1-8B-Instruct), (2)