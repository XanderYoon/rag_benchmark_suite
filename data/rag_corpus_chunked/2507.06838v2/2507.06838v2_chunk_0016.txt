This is especially pronounced in multi-hop QA, where ir- relevant or contradictory evidence can mislead the generator. In contrast, SETR consistently achieves stronger performance while utilizing significantly fewer passages. On average, it uses 2.91 passages compared to the standard top 5 used in rerank- ing. This demonstrates the model’s ability to dis- criminate high-utility information from distractors, thereby maintaining both efficiency and factual pre- cision. These findings suggest that effective pas- sage selection requires balancing recall and con- ciseness, and that a smaller, curated set can outper- form longer, noisier contexts. 5.2 Effectiveness of Reasoning Components: The Role of CoT and IRI To understand the role of reasoning in passage se- lection, we conduct an ablation study with three SETR variants: (1) without any reasoning, (2) with general CoT reasoning, and (3) with our proposed IRI-based reasoning. As presented in Table 1 and Table 2, in terms of precision, we observe a significant performance improvement when applying IRI-based explicit re- quirement analysis and selection, compared to us- ing standard CoT reasoning alone, or no reason- ing process. Table 3 shows a similar trend, ap- plying IRI-based reasoning yields stronger end-to- end RAG performance compared to other methods; more details are in §5.3. These results suggest Method HotpotQA2Wiki MuSiQueMHRAG EM F1 EM F1 EM F1 Accuracy RERANKING Rank only♦ 33.85 34.4534.36 28.069.43 13.2545.69 Rank + CoT♦ 34.61 35.2634.77 28.189.52 13.5145.26 SETSELECTION SETR-Selection only♦ 38.2840.1235.8331.1411.5016.37 46.24 SETR-CoT♦ 37.46 39.4435.8531.0710.79 15.5644.95 SETR-CoT & IRI♦ 39.16 40.4935.68 31.0912.33 16.9146.40 Table 3: Ablation study with teacher model inference to isolate method-level effects. All experiments use gpt-4o-2024-08-06 as the reference model, annotated with ♦. For RERANKING , RankGPT4 prompt (Sun et al., 2024) is employed. Prompts for SET SELECTION are provided in Appendix A.4. 2Wiki and MHRAG refer to the 2WikiMultiHopQA and MultiHopRAG benchmarks, respectively. that