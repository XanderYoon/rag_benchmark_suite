key observations are as follows: (1) In terms of an- swer correctness, SETR significantly outperforms 4https://huggingface.co/meta-llama/Llama-3. 1-8B-Instruct 5https://github.com/DataScienceUIBK/Rankify all baselines by selecting the optimal set of pas- sages from the retrieved passages, achieving no- tably higher F1 and Accuracy. These results are quite impressive, considering that SETR uses 40- 50% fewer passages on average compared to base- lines. (2) The performance of LLM-based ranking baselines, such as RankLlama and RankZephyr, was less satisfactory. We observe that the rela- tively small bge-reranker-large (Xiao et al., 2023) performs comparably to, and in some cases even outperforms LLM-based baselines. This is likely due to complex questions making retrieval more challenging, introducing more noise, and requiring not only relevance but also diversity, completeness, and comprehensiveness. We posit that the key to the RAG system lies in having more useful knowl- edge and fewer distracting passages, enabling even a simple and smaller model to outperform LLMs when the correct RAG paradigm is applied, which we will discuss in detail in (ยง5.1). 4.3 Retrieval Evaluation The retrieval evaluation is conducted using both rank-based metrics such as MRR and NDCG, as well as presence-based selection metrics includ- ing Precision and Recall, on the MultiHopRAG dataset (Tang and Yang, 2024). The results of re- trieval evaluation are shown in Table 2. The results indicate that our model consistently achieves 3.8%- 4.6% higher precision compared to off-the-shelf baselines, whereas it maintains competitive perfor- mance on rank-based metrics even with a small number of passages. LLM-based rankers, paired with advanced re- trievers, perform well on rank-based metrics com- pared to the first-stage retrieval baselines. Specifi- cally, RankGPT (gpt-4o) shows notable improve- ments in both rank-based and presense-based met- rics. However, we observe a discrepancy be- tween rank-based metrics and end-to-end QA per- formance, as shown in Table 1. This discrepancy