passage selection (ยง3.2). Finally, we describe the architecture and train- ing methodology of SETR, a distilled model fine- tuned for efficient set-wise passage selection (ยง3.3), along with the data construction details (ยง3.3.1) and training procedures (ยง3.3.2). 3.1 Task Definition We define the passage retrieval task as the process of selecting an optimal set of passages from a pool of retrieved candidate passages to address a spe- cific information need, such as supporting precise and coherent responses in RAG systems. Tradi- tionally, this task has been framed as a reranking problem, where passages are scored individually and the top- k results are selected based on their relevance scores. However, we argue that relevance-based rerank- ing alone is insufficient for retrieval modules in RAG systems, which require more holistic retrieval strategies. To address this, we propose a set-wise retrieval approach that jointly optimizes the rele- vance, completeness, and conciseness of the re- trieved set. This method also eliminates the need to manually select the top- k value in reranking, streamlining the process. 3.2 Information Requirement Identification via CoT Reasoning We design a prompting strategy that enables set- wise passage selection by systematically identify- ing information requirements through a structured, step-by-step reasoning process. As illustrated in Figure 2, our prompt guides a zero-shot CoT rea- soning process that decomposes the input question into distinct information subgoals. The key process consists of three key steps: (1) enumerating the key information requirements necessary to answer the question; (2) identifying passages that contain relevant information for each requirement; and (3) selecting a subset of passages that collectively pro- vide the most comprehensive and diverse coverage to effectively answer the query. By prompting Large Language Models (LLMs) with both the question and a set of candidate pas- sages retrieved in an earlier retrieval stage, this method enables