IRI♦ 39.16 40.4935.68 31.0912.33 16.9146.40 Table 3: Ablation study with teacher model inference to isolate method-level effects. All experiments use gpt-4o-2024-08-06 as the reference model, annotated with ♦. For RERANKING , RankGPT4 prompt (Sun et al., 2024) is employed. Prompts for SET SELECTION are provided in Appendix A.4. 2Wiki and MHRAG refer to the 2WikiMultiHopQA and MultiHopRAG benchmarks, respectively. that the performance gains of our approach do not simply stem from leveraging the intrinsic thinking steps of LLMs, and highlight the critical role of our IRI step in assembling a passage set with maxi- mum information coverage, demonstrating the best performance across all metrics and benchmarks. 5.3 A More Equitable Comparison: Method-Level Effects While prior sections demonstrate that our approach improves end-to-end performance, such compari- son can still be influenced by external factors, in- cluding differences in base models, data sources, or teacher supervision. To more rigorously assess the intrinsic effectiveness of our set-wise selection approach, we conduct a method-level evaluation that explicitly controls for these confounding fac- tors. Specifically, we implement two strategies to minimize the impact of confounding factors: (1) upper bound; a teacher model directly performs the selection task, to isolate the contribution of the method itself, and (2) unified setting; all baselines are retrained using the same base model, training data, and teacher supervision, ensuring a fair and method-focused comparison. Teacher model as Upper Bound. We first design an upper-bound evaluation setup where all mod- els, whether reranking or selection-based, leverage the same powerful teacher model, GPT-4o, to gen- erate passage selections or ranking. This setup isolates the effect of the selection formulation itself by minimizing the influence of model capacity or training-specific artifacts. Table 3, which reports the method-level effects with teacher model, in- dicates that our set selection method outperforms traditional reranking strategies, highlighting