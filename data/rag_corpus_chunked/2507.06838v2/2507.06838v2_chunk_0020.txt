503 Table 5: Efficiency analysis on token usage. We report the number of output tokens generated during retrieval and the number of input tokens fed into the generator, both of which serve as proxies for computational efficiency. models or teacher supervision alone, but from our methodological reformulation of retrieval as set selection grounded in reasoning. 5.4 Efficiency Analysis An ideal retrieval method for RAG systems should not only achieve strong performance—yielding ac- curate results—but also be efficient, minimizing latency, memory usage, and compute cost for real- world deployment. While direct measurement of GPU time or inference latency depends on hard- ware and implementation choices, token-level anal- ysis offers a practical proxy for computational effi- ciency. We compare token usage across models by measuring: (1) the number of input tokens passed to the generator, and (2) the number of output to- kens generated during the retrieval stage. As shown in Table 5, all SETR variants require substantially fewer input tokens than reranking-based methods. For instance, on MultiHopRAG, SETR-CoT & IRI feeds only 1,240 input tokens into the generator, compared to 2,672 in RankZephyr. Despite this sharp reduction, SETR not only maintains answer quality but often surpasses reranking models in F1 and accuracy. Interestingly, even within SETR variants, reasoning plays a role in efficiency.SETR- Selection only is the most efficient in terms of to- ken usage, while SETR-CoT & IRI trades some marginal increase in prompt length for greater an- swer correctness and recall. This suggests a useful accuracy-efficiency trade-off spectrum that practi- tioners can tune based on resource constraints and latency budgets. 6 Discussion Our work highlights the limitations of conventional top-k retrieval in Retrieval-Augmented Generation (RAG) systems and proposes a set-wise passage selection approach to better address the unique in- formation needs of generative models. By incorpo- rating information requirement