first analyzes the user question using Chain-of-Thought (CoT) reasoning to iden- tify its information requirements, and selects an optimal subset from the full list of retrieved pas- sages, maximizing coverage and relevance. This enables our method to serve as an effective alterna- tive to rerankers in RAG systems. Experiments on multi-hop RAG benchmarks, including HotpotQA (Yang et al., 2018), 2Wiki- MultiHopQA (Ho et al., 2020), MusiQue (Trivedi et al., 2022), and MultiHopRAG (Tang and Yang, 2024), demonstrate that set-wise passage selection significantly enhances the effectiveness of RAG systems. It outperforms both proprietary LLM- based reranking and open-source rerankers, achiev- ing higher answer correctness. Moreover, retrieval performance evaluation on MultiHopRAG (Tang and Yang, 2024) indicates improvements in pre- cision and recall, further underscoring its strong retrieval capabilities even in isolation. The ablation study of SETR reveals that the per- formance boost stems from both the set-wise pas- sage selection approach and CoT reasoning for identifying information requirements, each mak- ing a distinct and effective contribution to retrieval quality. The analysis shows that both components enhance information coverage in the retrieved set while effectively rejecting negative candidates. The contributions of this work are threefold: • Set-wise Passage Selection for RAG: We propose an information requirement-based set- wise passage selection approach that ensures collective coverage of retrieved passages, opti- mizing the retrieved set as a whole rather than treating retrieval as an independent ranking task. • Comprehensive Evaluation of Set Retrieval and Generation: To validate the effective- ness of our approach, we conduct extensive evaluations on both the retrieved passage sets and the final generated outputs. Our ex- periments on multi-hop RAG benchmarks demonstrate that our method outperforms both proprietary LLM-based rerankers and open- source alternatives, achieving better answer correctness, while also improving retrieval precision and recall. • Open-Source Contribution: We release the