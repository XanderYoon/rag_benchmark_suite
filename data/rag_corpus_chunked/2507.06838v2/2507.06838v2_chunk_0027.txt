Preprint, arXiv:2309.07597. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben- gio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: A dataset for diverse, explainable multi-hop question answer- ing. Preprint, arXiv:1809.09600. Soyoung Yoon, Eunbi Choi, Jiyeon Kim, Hyeongu Yun, Yireun Kim, and Seung-won Hwang. 2024. Listt5: Listwise reranking with fusion-in-decoder improves zero-shot retrieval. arXiv preprint arXiv:2402.15838. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judg- ing llm-as-a-judge with mt-bench and chatbot arena. Preprint, arXiv:2306.05685. Honglei Zhuang, Zhen Qin, Rolf Jagerman, Kai Hui, Ji Ma, Jing Lu, Jianmo Ni, Xuanhui Wang, and Michael Bendersky. 2023. Rankt5: Fine-tuning t5 for text ranking with ranking losses. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval , pages 2308–2313. A Appendix A.1 Datasets The experiments were conducted on the following four benchmark datasets: • HotpotQA (Yang et al., 2018) is a large- scale multi-hop QA dataset with 113k ques- tion–answer pairs from Wikipedia. Each ques- tion requires reasoning over multiple docu- ments, with sentence-level supporting facts provided. It includes diverse queries and com- parison questions that test compositional rea- soning and explainability, making it a strong benchmark for multi-hop retrieval systems. • 2WikiMultiHopQA (Ho et al., 2020) is a multi-hop QA dataset combining Wikipedia text with Wikidata triples to evaluate step-by- step reasoning. Each question includes an explicit reasoning path linking entities across documents. The dataset tests compositional reasoning and requires models to use both un- structured text and structured knowledge to answer questions. • MusiQue (Trivedi et al., 2022) is a multi-hop QA benchmark designed to prevent reason- ing shortcuts by requiring genuine multi-step reasoning. It includes around 25k questions composed from