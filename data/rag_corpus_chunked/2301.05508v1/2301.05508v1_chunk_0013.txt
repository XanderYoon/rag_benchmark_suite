hat the model will be evaluated. Since we do not have labeled negative responses, a ll the remain- ing responses in the dataset can be thought of as non-relevant to the dialogue context. Computing the probability of the correct response over all other re- sponses in the dataset would give us P (r | U ) = P (U ,r) ∑ k P (U ,rk) . This computation is prohibitively expensive, and the standard procedure is to approxim ate it using a few negative samples. The negative sampling task is then as follows: given the dialogue context U ﬁnd challenging responses r− that are non-relevant for U. Negative sampling can be seen as a retrieval task, where one can us e a model to retrieve negatives by applying a retrieval function to the collection of responses using U as the query. With such a dataset at hand, we continue the training—after the int ermediate step—in the same manner as done by the intermediate training step, with the following cross-entropy loss function 11 for a batch with size B: 10 The special tokens [ U ] and [ T ] will not have any meaningful representation in the zero-shot setting, but they can be learned on the ﬁne-tuning step. 11 We refer to this loss as MultipleNegativesRankingLoss. 8 Gustavo Penha and Claudia Hauﬀ J (U, r, θ) = − 1 B ∑B i=1 [ f (Ui, ri) − log ∑B j=1,j!=i ef (Ui,rj) ] , where f (U, r) is the dot-product of the mean pooling of the last layer of the transformer model. The eﬀectiveness of a ﬁne-tuned bi-encoder model in the domain of dialogues is the fourth ﬁnding we validate he re. F5: Hard Negative Sampling A limitation of random samples is that they might be too easy for