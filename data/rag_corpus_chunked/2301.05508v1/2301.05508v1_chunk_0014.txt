ef (Ui,rj) ] , where f (U, r) is the dot-product of the mean pooling of the last layer of the transformer model. The eﬀectiveness of a ﬁne-tuned bi-encoder model in the domain of dialogues is the fourth ﬁnding we validate he re. F5: Hard Negative Sampling A limitation of random samples is that they might be too easy for the ranking model to discriminate from relevan t ones, while for negative documents that are hard the model might still str uggle. For this reason, another popular approach is to use a ranking model to retrieve negative documents using the given query with a classic retrieval te chnique such as BM25. This leads to ﬁnding negative documents that are closer to the query in the sparse representation space, and thus they are harder negatives . Since dense retrieval models have been outperforming sparse retrieva l in a number of cases with available training data, more complex negative sampling tec hniques making use of dense retrieval have also been proposed [46,12]. The eﬀectiveness of hard negative sampling for a bi-encoder model in the domai n of dialogues is the ﬁfth ﬁnding we validate here. 4 Experimental Setup In order to compare the diﬀerent sparse and dense approaches w e consider three large-scale information-seeking conversation datasets 12: MSDialog [32] contains 246K context-response pairs, built from 35.5K information seeking conversa- tions from the Microsoft Answer community, a QA forum for severa l Microsoft products; MANtIS [27] contains 1.3 million context-response pairs built from con- versations of 14 Stack Exchange sites, such as askubuntu and travel; UDCDSTC8 [16] contains 184k context-response pairs of disentangled Ubuntu IR C dialogues. Implementation Details For BM25 and BM25+RM313 we rely on the pyserini implementations [20]. In order to train resp2ctxt expansion method s we rely on the Huggingface