provements using Students t-test with Bonferroni correcti on. †=other methods from the same group 1=best from unsupervised sparse retrieval ; 2=best from supervised sparse retrieval; 3=best from zero-shot dense retrieval. For example, in F3 † indicates that row (3d) improves over rows (3a–c), 1 indicates that it improves over row (1a) and 2 indicates it improves over row (2b). MANtIS MSDialog UDC DSTC8 R@1 R@10 R@1 R@10 R@1 R@10 (0) Random 0.000 0.000 0.000 0.001 0.000 0.001 Unsupervised sparse F1 (1a) BM25 0.133† 0.299† 0.064† 0.177† 0.027† 0.070† (1b) BM25 + RM3 0.073 0.206 0.035 0.127 0.011 0.049 Supervised sparse F2 (2a) BM25 + resp2ctxt 0.135 0.309 0.074 0.208 0.028 0.067 (2b) BM25 + resp2ctxt lu 0.147†1 0.325†1 0.0751 0.2021 0.029 0.076 Zero-shot dense (ModelIntermediateData ) F3 (3a) ANCE 600K−M SM arco 0.048 0.111 0.050 0.124 0.010 0.028 (3b) TAS-B400K−M SM arco 0.062 0.143 0.060 0.157 0.019 0.050 (3c) Bi-encoder 215M −mul 0.138 0.297 0.108 0.277 0.023 0.076 (3d) Bi-encoder 1.17B−mul 0.155†1 0.341†12 0.147†12 0.339†12 0.041† 0.097†12 Fine-tuned dense (ModelN egativeSampler ) F4 (4a) Bi-encoder Random(0) 0.130 0.307 0.168 123 0.387123 0.05012 0.128123 F2 ✓ Document expansion via resp2ctxt leads to improvements ove r no expansion [25,21,19]. We ﬁnd that a naive approach to response expansion improves marginally in two of the three datasets with BM25+resp2ct xt (2a) outperforming BM25 (1a). However, the proposed modiﬁcation of predicting only the last utterance of the dialogue (resp2ctxt lu) performs better than predicting the whole utterance, as shown by BM25+resp2ctxt lu’s (2b) higher recall values. In the MANtIS dataset the R@10 goes from 0.309 when using the model trained to predict the dialogue context to 0.325 when using the one trained to p redict only the last utterance of the dialogue context. We thus ﬁnd that F2 generalizes to response retrieval for dialogues,