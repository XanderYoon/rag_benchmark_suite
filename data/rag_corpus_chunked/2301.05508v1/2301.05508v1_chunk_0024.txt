hard negative sampling. Superscripts indicate statist ically signiﬁcant improvements using Students t-test with Bonferroni correction . †=signiﬁcance against the random sampling baseline, ‡=signiﬁcance against hard negative sampling without denoi sing. MANtIS MSDialog UDC DSTC8 R@10 R@10 R@10 Baseline (1) Bi-encoder Random 0.307 0.387 0.128 Hard negative sampling (2a) Bi-encoder BM 25 0.271 0.316 0.087 (2b) Bi-encoder Bi−encoder 0.146 0.306 0.051 Denoised hard negative sampling (3a) Bi-encoder BM 25 0.257 0.358 ‡ 0.121‡ (3b) Bi-encoder Bi−encoder 0.316†‡ 0.397†‡ 0.107‡ 6 Conclusion In this work, we tested if the knowledge obtained in dense and spars e retrieval from experiments on the tasks of passage and document retrieva l generalizes to the ﬁrst-stage retrieval of responses for dialogues. Our replica bility study reveals that while most ﬁndings do generalize to our domain, a simple translatio n of the models is not always successful. A careful analysis of the domain in question might reveal better ways to adapt techniques. As future work, we believe an important direction is to evaluate learn ed sparse methods that do weighting and expansion for both the quer ies and doc- uments [5]—while resp2ctxt is able to both change the weights of the t erms in the response (by repeating existing terms) and expand terms (by adding novel terms), it is not able to do weighting and expansion for the dialogue co ntexts. Acknowledgements This research has been supported by NWO projects SearchX (639.022.722) and NWO Aspasia (015.013.027). References 1. Abdul-Jaleel, N., Allan, J., Croft, W.B., Diaz, F., Larke y, L., Li, X., Smucker, M.D., Wade, C.: Umass at trec 2004: Novelty and hard. Computer Scie nce Department Faculty Publication Series p. 189 (2004) 14 Gustavo Penha and Claudia Hauﬀ 2. Aghajanyan, A., Gupta, A., Shrivastava, A., Chen, X., Zet tlemoyer, L., Gupta, S.: Muppet: Massive multi-task representations with