dialogues is the second ﬁnding that we validate . Unlike passage and document retrieval where the queries are smalle r than the documents, for the retrieval of responses for dialogues the que ries are longer than the documents 8. This is a challenge for the generative model, since generating larger pieces of text is a more diﬃcult problem than smaller ones as the re is more room for errors. Motivated by this, we also explored a modiﬁed version of resp2ctxt that aims to generate only the last utterance of the dia logue context: resp2ctxtlu. This model is trained to generate uτ from r+ i , instead of trying to generate the whole utterance Ui = {u1, u2, ..., uτ }. The underlying premise is that the most important utterance from the dialogue is the last one , and if it is correctly generated by resp2ctxt lu, the sparse retrieval method will be able to ﬁnd the correct response from the collection. F3: Zero-shot Dense Retrieval We rely on methods that learn to represent the dialogue context and the responses separately in a dense embe dding space. Responses are then ranked by their similarity to the dialogue contex t. We rely here on pre-trained language transformer models, such as BERT [4 ] and MP- Net [37], to obtain such representations of the dialogue context an d response. This approach is generally referred to as a bi-encoder model [21] and is an ef- fective family of models 9. A zero-shot model is one that is not trained on the target data. Target data is data from the same distribution, i.e. da taset, of the evaluation dataset. One way of improving the representations of a heavily pre-trained la nguage model for the zero-shot setting is to ﬁne-tune it with intermediate data [33]. Such