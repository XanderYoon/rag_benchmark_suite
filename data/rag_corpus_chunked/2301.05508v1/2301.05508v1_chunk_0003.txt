lection of these ﬁve ﬁndings by their impact in prior works (cf. §2). Our results show that four out of ﬁve previous ﬁndings do indeed generalize to o ur domain: 2 While for most benchmarks [52] we have only 10–100 candi- dates, a working system with the Reddit data from PolyAI https://github.com/PolyAI-LDN/conversational-datasets would need to retrieve from 3.7 billion responses. From Document and Passage Retrieval to Response Retrieval f or Dialogues 3 F1 ✗ 3 Dialogue context (i.e. query) expansion outperforms a no-expans ion base- line [1,18,49,21]. F2 ✓ Response (i.e. document) expansion outperforms a no-expansion baseline [25,21,19] if the expansion model is trained to generate the most recent context (last utterance 4 of the dialogue) instead of older context (all utterances). F3 ✓ Dense retrieval in the zero-shot 5 setting underperforms sparse baselines [34,41] except when it goes through intermediate training on large a mounts of out-of-domain data. F4 ✓ Dense retrieval with access to target data 6 outperforms sparse baselines [7,15,34] if an intermediate training step on out-of-domain data is pe rformed before the ﬁne-tuning on target data. F5 ✓ Harder negative sampling techniques lead to eﬀectiveness gains [46,5 1] if a denoising technique is used to reduce the number of false ne gative samples. Our results indicate that most ﬁndings translate to the domain of re trieval of responses for dialogues. A promising future direction is thus to s tart with successful models from other domains—for which there are more d atasets and previous research—and study how to adapt and improve them for r etrieval-based conversational search. 2 Related Work In this section we ﬁrst discuss current research in retrieval-base d systems for conversational search, followed by reviewing the major ﬁndings of (un)supervised sparse and dense retrieval in the domains of passage and documen t retrieval. 2.1