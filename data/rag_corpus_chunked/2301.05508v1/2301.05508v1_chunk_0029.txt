conference on research & development in i nformation retrieval. pp. 989–992 (2018) 33. Reimers, N., Gurevych, I.: Sentence-bert: Sentence emb eddings using siamese bert- networks. In: Proceedings of the 2019 Conference on Empiric al Methods in Nat- ural Language Processing. Association for Computational L inguistics (11 2019), https://arxiv.org/abs/1908.10084 34. Ren, R., Qu, Y., Liu, J., Zhao, W.X., Wu, Q., Ding, Y., Wu, H ., Wang, H., Wen, J.R.: A thorough examination on zero-shot dense retrie val. arXiv preprint arXiv:2204.12755 (2022) 35. Robertson, S.E., Walker, S.: Some simple eﬀective appro ximations to the 2-poisson model for probabilistic weighted retrieval. In: SIGIR’94. pp. 232–241. Springer (1994) 16 Gustavo Penha and Claudia Hauﬀ 36. Robinson, J., Chuang, C.Y., Sra, S., Jegelka, S.: Contra stive learning with hard negative samples. arXiv preprint arXiv:2010.04592 (2020) 37. Song, K., Tan, X., Qin, T., Lu, J., Liu, T.Y.: Mpnet: Maske d and permuted pre- training for language understanding. Advances in Neural In formation Processing Systems 33, 16857–16867 (2020) 38. Tao, C., Feng, J., Liu, C., Li, J., Geng, X., Jiang, D.: Bui lding an eﬃcient and eﬀective retrieval-based dialogue system via mutual le arning. arXiv preprint arXiv:2110.00159 (2021) 39. Tao, C., Wu, W., Xu, C., Hu, W., Zhao, D., Yan, R.: Multi-re presentation fusion network for multi-turn response selection in retrieval-ba sed chatbots. In: WSDM. pp. 267–275 (2019) 40. Thakur, N., Reimers, N., Daxenberger, J., Gurevych, I.: Augmented sbert: Data augmentation method for improving bi-encoders for pairwis e sentence scoring tasks. arXiv preprint arXiv:2010.08240 (2020) 41. Thakur, N., Reimers, N., R¨ uckl´ e, A., Srivastava, A., Gurevych, I.: Beir: A heteroge- nous benchmark for zero-shot evaluation of information ret rieval models. arXiv preprint arXiv:2104.08663 (2021) 42. Whang, T., Lee, D., Lee, C., Yang, K., Oh, D., Lim, H.: An eﬀ ective do- main adaptive post-training method for