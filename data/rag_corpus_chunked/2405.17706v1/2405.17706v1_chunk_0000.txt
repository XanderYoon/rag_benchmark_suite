Video Enriched Retrieval Augmented Generation Using Aligned Video Captions Kevin Dela Rosa Snap Inc. Santa Monica, California, USA kevd1337@gmail.com Figure 1: Sample output of chat assistant app leveraging retrieved video content stored in the form of aligned video captions ABSTRACT In this work, we propose the use of "aligned visual captions" as a mechanism for integrating information contained within videos into retrieval augmented generation (RAG) based chat assistant systems. These captions are able to describe the visual and audio content of videos in a large corpus while having the advantage of being in a textual format that is both easy to reason about & incorporate into large language model (LLM) prompts, but also Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). MRR 2024, July 18, 2024, Washington, DC © 2024 Copyright held by the owner/author(s). typically require less multimedia content to be inserted into the multimodal LLM context window, where typical configurations can aggressively fill up the context window by sampling video frames from the source video. Furthermore, visual captions can be adapted to specific use cases by prompting the original foundational model / captioner for particular visual details or fine tuning. In hopes of helping advancing progress in this area, we curate a dataset and describe automatic evaluation procedures on common RAG tasks. CCS CONCEPTS •Information systems → Information retrieval; •Comput- ing methodologies → Visual content-based indexing and re- trieval. arXiv:2405.17706v1 [cs.AI] 27 May 2024 MRR 2024, July 18, 2024,