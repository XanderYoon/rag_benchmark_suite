embeddings are able to find hits at a relatively low K using the aligned transcript and ASR. We also see that the relevance of results at very low K suffers for the cross- modal embedding configuration, but can ultimately catch up if you have a tolerance for higher K, i.e. LLM can handle processing more retrieved documents in its context window, which is encouraging for future extensions into mutlimodal querying. 4 VIDEO ENRICHED CHAT BOT In Figure 3 we illustrate the main components in a RAG based AI chat bot application that leverages the aligned video captions to return relevant answers and corresponding video clip source. The processing is as follows: (1) Based on the user query and a choice of tool descriptions, one retriever tool is selected; we created different tools that point to specific subsets of the video catalog MRR 2024, July 18, 2024, Washington, DC Kevin Dela Rosa EMBEDDING DATABASE HIT@1 HIT@5 HIT@10 QUALITY@1 Multimodal Embeddings: Cross-modal Text to Vision Match BLIP-2 Video Frames 0.482 0.801 0.895 5.199 BLIP-2 Video Thumbnail 0.519 0.833 0.902 5.598 CLIP ViT-L/14@336px Video Frames 0.542 0.858 0.925 5.785 CLIP ViT-L/14@336px Video Thumbnail 0.553 0.859 0.926 5.889 Text Embeddings text-embedding-3-small ASR 0.741 0.936 0.969 7.424 text-embedding-3-small Visual Captions 0.65 0.878 0.932 6.605 text-embedding-3-small Title 0.629 0.905 0.95 6.503 text-embedding-3-small Title + Description 0.675 0.914 0.95 6.828 text-embedding-3-small Aligned Transcript 0.741 0.934 0.971 7.377 Table 3: Video retrieval results and average quality of answer generated using aligned visual action of top retrieved document Figure 3: Example application architecture for integrating aligned video captions to enabled video enriched RAG (2) The selected query engine tool vectorizes the query and searches the vector database to retrieve (chunked) aligned video caption text blobs. (3) The query engine tool interprets the results and summarizes into a specific pydantic