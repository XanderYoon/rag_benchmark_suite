limitations of VISA. Errors were cate- gorized into three main types as demonstrated in Figure 2. The first type, wrong source attribution, occurred in 43 cases where the model attributed the source to an incorrect section of the document, failing to identify the precise region containing the evidence. The second type, position misalignment, was observed in 4 cases where the model appeared to have the correct intent but drew the bounding box inaccurately, either slightly off position or incor- rectly sized. The third type, granularity mismatch, appeared in 3 cases where the model’s attributed source, such as a specific cell in a table or an item in a list, did not match the ground truth granularity. While these cases could potentially be considered false negatives, we leave it in error analysis to em- phasize the challenge in real-world use cases where user preferences for granularity may differ from the model’s output. 7 Conclusion In this paper, we introduced VISA, a visual source attribution approach for retrieval-augmented gen- eration pipeline. By leveraging vision-language models, VISA not only generates answers to user queries but also provides bounding boxes that visu- ally attribute the supporting evidence within docu- ment screenshots. This capability enhances trans- parency and supports users in verifying the gen- erated information effectively. Through the de- velopment of curated datasets, we demonstrated the effectiveness of VISA across diverse document types and layouts, including complex multi-page documents and multimodal content. Our experi- mental results highlight the potential of VISA to bridge the gap between information retrieval and answer generation by offering finer-grained, visu- ally grounded evidence attribution. Moving for- ward, we hope VISA represents a pioneering step for more verifiable and user-friendly RAG systems. 8 Limitations While VISA demonstrates promising results for answer generation and content grounding in vision- based RAG systems,