VLMs, such as Qwen2-VL-72B (Wang et al., 2024), can potentially be prompted to perform VISA in a zero- shot manner. However, we find that VISA remains a challenging task. Consequently, further super- vised fine-tuning on a dedicated VISA task dataset is necessary. In the next section, we introduce the datasets we crafted specifically for training and evaluating VISA. 3.3 Dataset Acquisition The training and evaluation data suitable for the VISA task needs to be formatted as follows: the input consists of a textual query and document screenshot images as multimodal inputs, while the target outputs include the textual short answer, the relevant document identifier, and the coordinates of the bounding box. To create datasets that meet these requirements, we craft existing publicly avail- able datasets to support the training and evaluation of our proposed VISA method. Wiki-VISA is derived from the Natural Ques- tions (NQ) dataset (Kwiatkowski et al., 2019). The original NQ dataset provides natural questions, along with short and long answers sourced from Wikipedia webpages. We use the short answers as answer targets. However, the original dataset does not contain the original webpage screenshots. We use the Selenium Python toolkit1 to access and render the webpage with the original URL with a history version stamp. And take a screenshot with 980 pixels width and up to 3920 pixels (4 pages) height. Using the long answer, we identify the cor- responding element in the HTML from which the long answer is derived. We then draw a bounding box around this element to obtain thecoordinates. Notably, the answers in this dataset can come from various elements, such as passages, tables, lists, or images within the webpage. Since the ques- tions and answers in Wiki-VISA are human-judged, we consider this dataset a high-quality, supervised dataset and evaluation for VISA on general