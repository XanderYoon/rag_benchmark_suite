demonstrate the benefits of aug- menting training data with FineWeb-VISA. On Wiki-VISA, combining Wiki and FineWeb train- ing data improves bounding box accuracy from 54.2% to 58.2% and improves performance on [>1] passages from 50.1% to 61.7%, indicating that FineWeb complements Wiki by enhancing the modelâ€™s ability to attribute evidence in multi-page contexts. For Paper-VISA, however, augmenting with FineWeb does not significantly improve in- domain performance. Training on Paper+FineWeb achieves a comparable bounding box accuracy to Paper alone, but it enhances zero-shot performance on Wiki-VISA (from 0.2% to 36.1%). Training on the full combination of datasets (Wiki+Paper+FineWeb) yields strong results across both domains, with 58.1% bbx accuracy on Wiki- VISA and 67.6% on Paper-VISA. This shows the importance of diverse training data for building generalizable models capable of handling differ- ent document types, layouts, and evidence modal- ities. Future work should focus on expanding the dataset diversity to further improve generalization and enable robust visual source attribution for a wide range of document structures. Question Err or T ype Wher e is t he ener gy r eleased fr om when f ood is metaboliz ed? T ype-I: W r ong sour ce attribution T ype-II: P osition misalignment T ype-III: Gr anularity mismat ch Who is t he mo vie phant om t hr ead based on? Who pla y ed sk elet or in t he mo vie mast ers of t he univ erse? Document Gr ound T rut h VIS A Output Figure 2: Type of errors in the evaluation of Wiki-VISA. Train Data Wiki-VISA Paper-VISA bbx ans bbx ans Crop, Absolute 54.2 65.2 27.8 36.2 No Random Crop 58.8 65.6 1.7 36.9 Normalized Value 56.4 64.4 0.1 37.2 No Bounding Box 0 67.6 0 35.2 Table 4: Impact of bounding box target representation and cropping