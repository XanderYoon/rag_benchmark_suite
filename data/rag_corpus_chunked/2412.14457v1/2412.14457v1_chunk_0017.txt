ans Wiki 54.2 65.2 75.6 66.5 50.1 56.0 36.8 73.1 27.8 36.2 20.5 32.6 35.1 39.7 Paper 0.2 42.6 0 46.3 0.4 33.5 0.1 48.1 68.2 43.8 58.1 41.6 78.2 45.9 FineWeb 37.6 50.2 48.9 45.1 57.3 52.3 6.6 53.1 22.0 43.3 26.5 41.7 17.4 44.9 Wiki+Fineweb 58.2 65.3 68.7 66.6 61.7 57.1 44.1 72.1 21.0 43.1 18.5 42.2 23.4 43.9 Paper+Fineweb 36.1 48.7 51.8 49.6 49.6 44.2 6.8 52.4 66.5 44.6 56.1 42.2 76.9 47.0 Wiki+Paper+Fineweb58.1 64.8 69.9 65.0 58.7 56.7 45.8 72.7 67.6 44.3 55.9 41.5 79.3 47.1 Table 3: Effectiveness of VISA trained on different combinations training data for bounding box accuracy (bbx) and answer accuracy (ans) in the single oracle candidate setting. of VISA is influenced by document characteris- tics, such as content location and modality. For Wiki-VISA, bounding box accuracy is significantly higher for passages on the first page ([<1] passage) compared to passages beyond the first page ([>1] passage). For example, the 2B variant achieves 70.0% accuracy for [<1] passages but only 18.7% for [>1] passages, indicating the challenges posed by long, multi-page documents. The larger model, the 7B variant, narrows this gap, reflecting the bet- ter handling of long-context inputs. Non-passage content, such as tables and figures, also have obvi- ously a different level of grounding effectiveness, indicating the difference of effectiveness in differ- ent visual elements. 6 Analysis 6.1 Out-of-Domain Zero-Shot Table 3 shows the effectiveness of VISA while trained with different data combinations in the sin- gle candidate setting. It enables us to study the ef- fectiveness of out-of-domain transfer and augmen- tation. First, we highlight the challenges of zero- shot generalization in VISA. Training and evaluat- ing on in-domain achieves an effective bounding box accuracy, e.g. 54.2% on average for Wiki- VISA. However, significant performance drops are observed when models