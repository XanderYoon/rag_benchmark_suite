as synthetic training and evaluation for scientific paper PDFs in the medical domain. FineWeb-VISA is based on the FineWeb-edu corpus (Penedo et al., 2024), a high-quality text corpus of crawled webpages. We sampled 60k web- page URLs and used Selenium to capture screen- shots of diverse, content-rich webpages. A passage containing more than 50 words was randomly se- lected as the target source. A bounding box was drawn around the selected content, and a VLM was prompted to generate a query and short answer supported by the target content, similar as Paper- VISA. Although Fineweb-VISA provides diverse layout, it do not guaranteed to high quality data has human annotated in Wiki-VISA or Paper-VISA that assessing a specific domain, we only leverage Fineweb-VISA as training data to analysis zeroshot and data augmentation effectiveness. 3.4 Multi-Candidates By now, each query is paired with the triplet of a positive document, target short answer, and target evidence bounding box. To set up a RAG exper- imental environment for evaluating VISA, we in addition need to let the generator take multiple can- didates as input, simulating the scenario that the generator is taking multiple retrieval candidates and attributing the evidence in most relevant documents. Given the query q, we use a retriever R to retrieve top-k candidates. And randomly sampled m âˆ’ 1 candidates that are not ground truth as hard nega- tive candidates. The hard negative candidates are mixed with the one ground truth document together as the input for the multi-document VISA. The rea- son we did not directly take top- m documents as the retrieval candidate is that we do not want VISA biased on a specific retriever and position of the candidate docs. Generally, our VISA does not rely on the type of retriever. It can be either a traditional Dataset