@5 @10 Beauty (A) Full 0.0569 0.0860 0.0369 0.0463 (B) 10% 0.0560 0.0842 0.0360 0.0450 (C) 20% 0.0550 0.0843 0.0355 0.0449 (D) 30% 0.0542 0.0843 0.0350 0.0447 Sports (A) Full 0.0331 0.0497 0.0211 0.0264 (B) 10% 0.0326 0.0492 0.0208 0.0261 (C) 20% 0.0322 0.0490 0.0204 0.0258 (D) 30% 0.0328 0.0490 0.0208 0.0260 groups. We think the main reason is that the relevant memories are not retrieved while the noisy memories are introduced. How to effectively retrieve relevant knowledge is also an open challenge in RAG [27, 46, 59]. In summary, we suggest performing retrieval augmentation when recommending the long-tailed and head items. 4.5 Alleviating Preference Drift (RQ4) As stated in Section 1, existing SeRec models trained on past data may recommend undesirable items due to preference drift. To verify whether RaSeRec is promising in alleviating this issue, we simulate this scenario by removing a certain ratio (i.e., 10%, 20%, and 30%) of the preference data with the latest timestamp from the memory bank. And, “Full” denotes using all preference data in the memory bank to remedy preference drift. From the results shown in Table 4, we find that (1) In general, the larger the preference drifts, the worse the model performance; (2) “Full” performs best as it can remedy preference drift by maintaining a dynamic memory bank with the latest preference data; and (3) In a few cases, large preference drift Table 5: Statistics of each partition. Dataset #len.range #avg.length %proportion Beauty <3 1.50 34.03% 3-6 4.15 31.18% >6 18.88 34.79% Sports <3 1.50 37.56% 3-6 4.14 33.98% >6 15.31 28.46% Clothing <2 1.00 24.54% 2-3 2.38 39.38% >3 8.06 36.08% is not necessarily worse performance, e.g., (D) on the sports dataset. The main reason is different datasets have different preferences towards short-, medium-, and long-term memories, which also greatly