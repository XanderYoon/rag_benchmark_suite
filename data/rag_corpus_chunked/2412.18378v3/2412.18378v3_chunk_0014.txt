only the RAM is being updated during fine-tuning. Formally, we adopt the same objective as Equ (5), which learns to leverage the retrieved memories for better recommendation: Lğ‘Ÿğ‘ğ‘“ ğ‘¡ = âˆ’ log  ğ‘’ Ëœhğ‘‡ vğ‘¡ +1 / âˆ‘ï¸ ğ‘£ğ‘– âˆˆ V ğ‘’ Ëœhğ‘‡ vğ‘–  . (12) In this way, RaSeRec does not have to memorize all long-tailed patterns but learns to leverage retrieved explicit memories to ac- commodate preference drift. 3.3 Inference and Complexity Analyses In this section, we first introduce the model inference process and then analyze the model complexity in terms of both time and space in detail. 3.3.1 Model Inference. During inference, RaSeRec first computes the user representation h via SeqEnc(Â·) for the input user sequence ğ‘ ğ‘¢. Then, RaSeRec retrieves top-ğ¾ similar memories (i.e., {hğ‘˜ }ğ¾ ğ‘˜=1 and {vğ‘˜ }ğ¾ ğ‘˜=1) from the memory bank M. After that, RaSeRec em- ploys RAM that consists of dual-channel MHCA to weight and aggregate valuable patterns from both {hğ‘˜ }ğ¾ ğ‘˜=1 and {vğ‘˜ }ğ¾ ğ‘˜=1. We obtain the final retrieval-augmented user representation Ëœh by com- bining both the original user representation h and the augmented user ones of the dual channels i.e., hğ‘1 and hğ‘2. Lastly, we recom- mend the top-ğ‘ items based on the dot product scores between Ëœh and item embedding matrix V. RaSeRec: Retrieval-Augmented Sequential Recommendation Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Table 1: The space and time complexity comparison between the Vanilla and SSL/Retrieval-Augmented SeRec. Paradigms Space Time Backbone RAM Encode Retrieve Augment Recommend Vanilla SeRec ğ‘‚ ( |ğœƒ | ) - ğ‘‚ (ğ¿ (ğ‘‡ ğ‘‘2 + ğ‘‡ 2ğ‘‘ ) ) - - ğ‘‚ ( | V |ğ‘‘ ) SSL-Augmented SeRec ğ‘‚ ( |ğœƒ | ) - ğ‘‚ (ğ¿ (ğ‘‡ ğ‘‘2 + ğ‘‡ 2ğ‘‘ ) ) - - ğ‘‚ ( | V