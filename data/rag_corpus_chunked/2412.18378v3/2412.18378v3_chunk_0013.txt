Augmentation. With the retrieved memories, we design a Retrieval-Augmented Module (RAM), which learns to leverage the retrieved memories to augment the current user repre- sentation. Its overall architecture is illustrated in Figure 3. Inspired by [52], RAM employs dual-channel multi-head cross attention (MHCA) which takes h as query, {hğ‘˜ }ğ¾ ğ‘˜=1 (or {vğ‘˜ }ğ¾ ğ‘˜=1) as key and {vğ‘˜ }ğ¾ ğ‘˜=1 (or {hğ‘˜ }ğ¾ ğ‘˜=1) as value to get the augmented user represen- tation. In the first channel, RAM learns to weight and aggregate {vğ‘˜ }ğ¾ ğ‘˜=1 via modeling the relationship between h and {hğ‘˜ }ğ¾ ğ‘˜=1: hğ‘1 = MHCA(h, {hğ‘˜ }ğ¾ ğ‘˜=1, {vğ‘˜ }ğ¾ ğ‘˜=1), (9) where MHCA(Â·) is the multi-head cross attention module;hğ‘1 is the first augmented representation. Analogously, RAM compute the sec- ond augmented representation hğ‘2 through aggregating {hğ‘˜ }ğ¾ ğ‘˜=1: hğ‘2 = MHCA(h, {vğ‘˜ }ğ¾ ğ‘˜=1, {hğ‘˜ }ğ¾ ğ‘˜=1). (10) Lastly, RAM weights them together and obtains the final retrieval- augmented user representation: Ëœh = ğ›¼h + ( 1 âˆ’ ğ›¼) (ğ›½hğ‘1 + ( 1 âˆ’ ğ›½)hğ‘2 ), (11) where 0 â‰¤ ğ›¼, ğ›½ â‰¤ 1 control the strength of each representation. A possible extension is to learnğ›¼ and ğ›½, e.g., designing attention mech- anism [50]. However, it is not the focus of this work, and we leave it for future exploration. We further fine-tune the model with RAFT to improve recommendations with the retrieval-augmented repre- sentation Ëœh. Specifically, we freeze the model backbone SeqEnc(Â·) and only the RAM is being updated during fine-tuning. Formally, we adopt the same objective as Equ (5), which learns to leverage the retrieved memories for better recommendation: Lğ‘Ÿğ‘ğ‘“ ğ‘¡ = âˆ’ log  ğ‘’ Ëœhğ‘‡ vğ‘¡ +1 / âˆ‘ï¸ ğ‘£ğ‘– âˆˆ V ğ‘’ Ëœhğ‘‡ vğ‘–  . (12) In this way, RaSeRec does not have to memorize all long-tailed patterns