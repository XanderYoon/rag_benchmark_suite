collaborative signals (Â§3.1); (2) retrieval- augmented fine-tuning, which learns to leverage retrieved mem- ories to augment user representation (Â§3.2). Lastly, we introduce the inference process and analyze the complexity of RaSeRec (Â§3.3). The notation table can be found in Appendix A. 3.1 Collaborative-based Pre-training In this section, we pre-train the model backbone SeqEnc(Â·) with two learning objections: (1) recommendation learning, which endows the backbone with the ability to generate the next item based on the input user sequence, and(2) retrieval training, which endows the backbone with the ability to retrieve memories with the same (or similar) preference as the input user sequence. 3.1.1 Recommendation Learning. After computing the user repre- sentation h âˆˆ Rğ‘‘ (Â§2.2), a prediction layer is built upon it to predict how likely user ğ‘¢ would adopt item ğ‘£ğ‘– at time step ğ‘¡ + 1. A simple yet effective solution is to calculate the inner product, i.e., hğ‘‡ vğ‘–. After that, we employ the next item prediction over the whole item set V as the recommendation learning objective. To be specific, we compute the negative log-likelihood with the softmax as the recommendation learning objective: Lğ‘Ÿğ‘’ğ‘ = âˆ’ log  ğ‘’hğ‘‡ vğ‘¡ +1 / âˆ‘ï¸ ğ‘£ğ‘– âˆˆ V ğ‘’hğ‘‡ vğ‘–  , (5) where h, vğ‘¡ +1, vğ‘– denote the last refined hidden representation hğ¿ ğ‘¡ , the embedding vector of the next item ğ‘£ğ‘¡ +1, and the embedding vector of item ğ‘£ğ‘– âˆˆ V , respectively. We train the model to predict the next item auto-regressively similar to the language modelingâ€™s objective [35]. 3.1.2 Retrieval Training. To retrieve memories that share the same (or similar) preference as the input user sequence, a retrieval train- ing objective is developed to maximize the agreement of positive pairs and minimize that of negative pairs. The positive pair consists of two