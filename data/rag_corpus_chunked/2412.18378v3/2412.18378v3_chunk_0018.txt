item embedding, we set the hidden size ùëë = 64. For each baseline, we follow the suggested settings reported in their original paper to set hyper- parameters. More implementation details can be seen in Appendix E. Following the leave-one-out strategy, we hold out the last inter- acted item of each user sequence for testing, the second last item for validation, and all the earlier ones for training. We measure the recommendation performance via HR and NDCG (see Appendix D), where the cut-off position (@ùëÅ ) is set as 5 and 10. 4.2 Comparison with Baselines (RQ1) Table 2 and 8 summarize the performance of all baselines and RaSeRec w.r.t. @5 and @10, respectively. From the experimental results, we observe that: (1) The performance of the Non-SeRec models is unsurprisingly worse than the vanilla SeRec models, indi- cating the necessity of modeling sequential patterns for capturing more accurate user preferences. On the other hand, SSL-Augmented SeRec models perform better than those without SSL, indicating the superiority of supplementing the recommendation task with self- supervised learning. (2) Benefiting from the retrieval-augmented mechanism, RaSeRec considerably outperforms all baseline models in 16 out of 18 cases with ùëù-value less than 0.005, demonstrating the improvement of RaSeRec over the SOTA baselines is statisti- cally significant. The reasons are mainly twofold:(i) By sustainably 1http://jmcauley.ucsd.edu/data/amazon/ Conference acronym ‚ÄôXX, June 03‚Äì05, 2018, Woodstock, NY Zhao et al. Table 2: Performance comparison (@5), where the best results are boldfaced and the second-best ones are underlined. Dataset Beauty Sports Clothing Average Method HR@5 NDCG@5 HR@5 NDCG@5 HR@5 NDCG@5 HR@5 NDCG@5 PopRec 0.0072 0.0040 0.0055 0.0040 0.0030 0.0018 0.0052 0.0033 BPR-MF 0.0120 0.0065 0.0092 0.0053 0.0067 0.0052 0.0093 0.0057 GRU4Rec 0.0164 0.0086 0.0137 0.0096 0.0095 0.0061 0.0132 0.0081 Caser 0.0259 0.0127 0.0139 0.0085 0.0108 0.0067 0.0169 0.0093 SASRec 0.0365 0.0236 0.0218