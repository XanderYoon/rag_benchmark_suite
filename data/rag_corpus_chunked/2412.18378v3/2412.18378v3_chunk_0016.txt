complexity for encoding user representations is ğ‘‚ (ğ¿(ğ‘‡ğ‘‘ 2 + ğ‘‡ 2ğ‘‘)), whereğ‘‡ is the maximum sequence length andğ‘‘ is the hidden size. In addition to encoding, RaSeRec also needs to retrieve memories and augment user representation. For retrieval, RaSeRec instantiates Faiss using Inverted File Indexing (IVF), whose retrieval complex- ity is ğ‘‚ (ğ‘˜ğ‘‘ + | V | ğ‘˜ ğ‘‘), where ğ‘˜ denotes the number of clusters and we set the number of clusters accessed as 1. On the other hand, the time complexity of augmenting user representation is ğ‘‚ (ğ¾ğ‘‘ ). Finally, these three SeRec paradigms need to compute dot prod- uct scores over all items to make recommendations, resulting in a time complexity ğ‘‚ (|V |ğ‘‘). The time complexity of additional re- trieval and augmentation processes ( i.e., ğ‘‚ (ğ‘˜ğ‘‘ + | V | ğ‘˜ ğ‘‘ + ğ¾ğ‘‘ )) is much lower than the encoding and recommendation processes (i.e., ğ‘‚ (ğ¿(ğ‘‡ğ‘‘ 2 + ğ‘‡ 2ğ‘‘) + |V | ğ‘‘)). Specifically, ğ‘˜ + | V | ğ‘˜ + ğ¾ is on the or- der of thousands, while |V | is on the order of tens of thousands. Therefore, the analytical time complexity of RaSeRec is of the same magnitude as the Vanilla and SSL-Augmented SeRec. 4 Experiments To verify the effectiveness of RaSeRec, we conduct extensive ex- periments on three benchmark datasets to answer the following research questions (RQs): â€¢ RQ1: How does RaSeRec perform compared with state-of-the-art SeRec models? â€¢ RQ2: How much gain can RaSeRec bring to the existing base backbones? â€¢ RQ3: Can RaSeRec improve long-tailed recommendation? â€¢ RQ4: Can RaSeRec alleviate preference drift? â€¢ RQ5: How do different partitions of the memory bank contribute to RaSeRecâ€™s performance? â€¢ RQ6: Can RaSeRec perform robustly against the data noise issue? â€¢ RQ7: How does the performance of