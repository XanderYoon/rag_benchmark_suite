drifts as it is trained on past user preferences, and (ii) It may fail to recall long-tailed patterns from implicit memory due to skewed data distribution. Given the above issues, we propose Retrieval-Augmented Fine-Tuning, RAFT, mak- ing the model quicker to adapt to preference drifts and easier to recall long-tailed patterns. It mainly consists of two components:(1) memory retrieval, which recalls useful memories from the mem- ory bank, and (2) representation augmentation, which leverages the retrieved memories to augment user representation. 3.2.1 Memory Retrieval. Collaborative <user sequence ğ‘ ğ‘¢,ğ‘¡ , target item ğ‘£ (ğ‘¢ ) ğ‘¡ +1 > pairs explicitly reveal the sequential patterns, where pairs sharing the same (or similar) preference as the input user se- quence can act as important references. Inspired by the above idea, we construct a reference set R by auto-regressively enumerating all <ğ‘ ğ‘¢,ğ‘¡ , ğ‘£ (ğ‘¢ ) ğ‘¡ +1 > pairs from the training data except the current input user sequence. We then employ the sequence encoder SeqEnc(Â·) to encode all pairs in R so that we can get a memory bank M, where each entry in M consists of a user representation and the corre- sponding target item embedding. Given the input representation h, RaSeRec retrieves top-ğ¾ similar user representations {hğ‘˜ }ğ¾ ğ‘˜=1 as well as their corresponding target item embedding {vğ‘˜ }ğ¾ ğ‘˜=1 from the memory bank M, where we employ the Faiss library [20] to speed up the retrieval process. 3.2.2 Representation Augmentation. With the retrieved memories, we design a Retrieval-Augmented Module (RAM), which learns to leverage the retrieved memories to augment the current user repre- sentation. Its overall architecture is illustrated in Figure 3. Inspired by [52], RAM employs dual-channel multi-head cross attention (MHCA) which takes h as query, {hğ‘˜ }ğ¾ ğ‘˜=1 (or {vğ‘˜ }ğ¾ ğ‘˜=1) as key and {vğ‘˜ }ğ¾