time and computation cost of LLM inference, such cost is unworthy if LLMs can generate correct outputs by themselves. Additionally, the strategies of existing studies in determining what to retrieve often restrict themselves to the LLM’s most recent sentence or the last few tokens. This approach may not capture the model’s real-time information needs since the LLM’s information needs may actually be related to terms that span the entire context. Retrieving documents in this manner is thus suboptimal in many cases. To overcome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic Retrieval Augmented Generation based on the Information Needs of LLMs. Our framework is specifically designed to make decisions on when and what to retrieve, based on the LLM’s information needs dur- ing the text generation process. For the timing of re- trieval, we propose RIND: Real-time Information Needs Detection, which considers the LLM’s un- certainty about its own generated content, the influ- ence of each token on subsequent tokens, and the semantic significance of each token. For the formu- lation of retrieval queries, we propose QFS: Query Formulation based on Self-attention, which inno- vates query formulation by leveraging the LLM’s self-attention across the entire context. DRAGIN is a lightweight RAG framework that can be incor- porated into any Transformer-based LLMs without further training, fine-tuning, or prompt engineer- ing. We comprehensively evaluate DRAGIN along with existing dynamic RAG frameworks over four knowledge-intensive generation benchmarks. Ex- perimental results show that DRAGIN achieves superior performance on all datasets, demonstrat- ing the effectiveness of our method. Moreover, the results of the ablation study indicate that our pro- posed new strategies for "when to retrieval" (i.e., RIND) and "what to retrieval" (i.e., QFS) perform uniformly better than other strategies in existing RAG methods despite retrieval models and LLMs. In summary, the contributions