al., 2023; Jiang et al., 2023) performs mul- tiple times of retrieval during the generation pro- cess of LLMs. It includes two steps: identifying the optimal moment to activate the retrieval mod- ule (deciding when to retrieve), and crafting the appropriate query once retrieval is triggered (deter- mining what to retrieve). Depending on when and what to retrieve, a variety types of methods have been proposed in this direction. For example, IR- CoT (Trivedi et al., 2022) adopts a global augmen- tation method where retrieval is conducted for each generated sentence, with the latest generated sen- tence used as the query. RETRO (Borgeaud et al., 2022) and IC-RALM (Ram et al., 2023) define a sliding window and trigger the retrieval module based on a preset number of processed tokens, and the last n tokens are used as the query. However, existing dynamic RAG methods face arXiv:2403.10081v3 [cs.CL] 21 Sep 2024 several critical challenges, primarily in determin- ing the optimal timing for retrieval and formulating effective queries when retrieval is triggered. First of all, existing approaches often rely on static rules to decide when to retrieve, neglecting the assess- ment of necessity and potential risks involved. On the one hand, depending on the quality of the input query and retrieval models, unnecessary retrieval augmentation may introduce irrelevant or noisy data to LLMs which could jeopardize the quality of the outputs. On the other hand, conducting retrieval augmentation will inevitably increase the time and computation cost of LLM inference, such cost is unworthy if LLMs can generate correct outputs by themselves. Additionally, the strategies of existing studies in determining what to retrieve often restrict themselves to the LLM’s most recent sentence or the last few tokens. This approach may not capture the model’s real-time information needs since the LLM’s information needs may