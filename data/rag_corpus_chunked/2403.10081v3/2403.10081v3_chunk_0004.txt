that DRAGIN achieves superior performance on all datasets, demonstrat- ing the effectiveness of our method. Moreover, the results of the ablation study indicate that our pro- posed new strategies for "when to retrieval" (i.e., RIND) and "what to retrieval" (i.e., QFS) perform uniformly better than other strategies in existing RAG methods despite retrieval models and LLMs. In summary, the contributions of our paper are as follows: • We propose a novel dynamic RAG framework: DRAGIN. In contrast to previous works, our framework optimizes when and what to retrieve based on the real-time information needs of the LLM. • We evaluate existing dynamic RAG methods and DRAGIN on four knowledge-intensive datasets using three different LLMs. Experimental results indicate that DRAGIN achieves state-of-the-art (SOTA) performance. 2 Related Work 2.1 Single-round Retrieval-augmented LLM LLMs have demonstrated significant effectiveness across a wide range of tasks. However, their built- in knowledge can sometimes fall short when deal- ing with knowledge-intensive tasks. To address this limitation, Retrieval-Augmented Generation (RAG) strategies are widely employed to enhance the performance of LLMs. One of the most di- rect methods is single-round retrieval augmenta- tion (Khandelwal et al., 2019; Borgeaud et al., 2022; Lewis et al., 2020; Guu et al., 2020; Izac- ard and Grave, 2020; Jiang et al., 2022; Shi et al., 2023), which involves using the initial input as a query to retrieve information from an external corpus. The retrieved external knowledge is then incorporated as part of the input for the model. Previous research has explored single-round re- trieval augmentation extensively. For instance, RE- PLUG (Shi et al., 2023) treats LLMs as a black box and leverages them to generate training data for the retrieval model. From a different perspective, UniWeb (Li et al., 2023d) proposes an adaptive search engine-assisted learning method that can self-assess whether the