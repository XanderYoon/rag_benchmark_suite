varying thresh- old values within the RIND module on the perfor- mance of the DRAGIN framework. We present the experimental results on the HotpotQA dataset in Table 5. Our experimental results show that DRA- GIN’s performance remains stable across threshold settings, indicating a low sensitivity to changes in this hyperparameter. The threshold value is pivotal in determining the retrieval module’s activation fre- quency. As the threshold increases, the frequency Table 5: Comparasion between different threshold of RIND for LLaMA-13B-Chat model on the HotpotQA dataset. The best results are in bold. threshold EM F1 Prec. 0.3 0.295 0.3856 0.3873 0.4 0.297 0.387 0.389 0.5 0.299 0.3897 0.3915 0.6 0.304 0.3931 0.3946 0.7 0.304 0.3927 0.3937 0.8 0.301 0.392 0.3927 0.9 0.301 0.3944 0.3947 1 0.293 0.3869 0.3875 Table 6: The influence of the query formulation meth- ods on various dynamic RAG frameworks, with the Hot- potQA dataset as the evaluation benchmark. The best results are in bold. L13B indicates LLaMA2-13B-Chat, V13B indicates Vicuna-13b-v1.5. EM F1 Prec. L13B FLARE 0.262 0.3674 0.3792 Full Context 0.252 0.3584 0.3711 FS-RAG 0.255 0.3574 0.3685 FL-RAG 0.241 0.3394 0.3495 DRAGIN 0.314 0.4238 0.4401 V13B FLARE 0.225 0.3366 0.3420 Full Context 0.221 0.3402 0.3457 FS-RAG 0.216 0.3432 0.3507 FL-RAG 0.214 0.3268 0.3264 DRAGIN 0.288 0.4164 0.4226 of the retrieval module’s activation decreases, sug- gesting that adjusting the threshold can strike a balance between the system’s efficiency and the accuracy of its outputs in practical applications. 5.4 Query Formulation This subsection delves into the impact of query formulation techniques on the performance of dy- namic RAG frameworks. We standardize the tim- ing of trigger retrieval to RIND, which is proven to be the most effective timing based on the experi- mental results detailed in section 5.3. We focus on the comparison between DRAGIN and three exist- ing frameworks: