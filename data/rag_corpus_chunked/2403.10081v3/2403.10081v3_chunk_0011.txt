the query and utilizes an off-the-shelf retrieval model (e.g. BM25) to retrieve relevant informa- tion from external knowledge bases. Suppose the retrieved documents are denoted as Di1, Di2, and Di3. Upon successful retrieval, the next step of the dynamic RAG framework is to integrate this exter- nal knowledge into the LLM’s generation process. This integration begins with truncating the LLM’s output at the identified position i for retrieval aug- mentation: T ′ = truncate(T, ti), (6) where T ′ represents the truncated output, T is the original sequence generated by the LLM, and ti is the token at which the need for external knowl- edge was identified by RIND. To integrate the re- trieved knowledge Di1, Di2, and Di3, we adopt a meticulously designed prompt template 3, which is structured as follows: The entire input for LLM: Below are the external knowledge refer- ences: [1] Di1 [2] Di2 [3] Di3 Please answer the question based on the external knowledge: Question: xxx Answer: T’ At this point, the LLM continues generating con- tent based on the retrieved external knowledge and the truncated output T ′. Following the integration of the retrieved knowledge, the LLM resumes gen- erating content from the truncation point, enhanced with additional information. This procedure allows the LLM to bridge the previously identified knowl- edge gap, facilitating a more informed and precise continuation of its output. Suppose at a subsequent position j where RIND detects again that the LLM requires external knowl- edge. In that case, the QFS module is triggered again at position j to generate a new query, re- trieving a new set of documents Dj1, Dj2, and Dj3 to replace Di1, Di2, and Di3. The LLM will then continue generating from position j based on the newly retrieved documents, following the same process. 4 Experimental