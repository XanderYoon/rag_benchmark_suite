have a stable income I Figure 1: An illustration of our DRAGIN framework. may not adequately cover all the external knowl- edge that the model requires (Jiang et al., 2023). Therefore, some researchers have begun to ex- plore multi-round retrieval augmentation. For ex- ample, RETRO (Borgeaud et al., 2022) and IC- RALM (Ram et al., 2023) trigger retrieval every 4 to 32 tokens, and IRCot (Trivedi et al., 2022) triggers retrieval every sentence. However, solely relying on fixed interval-based retrieval without considering the information needs of the LLM it- self could produce suboptimal results. Inspired by this, FLARE (Jiang et al., 2023) triggers retrieval when encountering an uncertain token. Specifically, if any token in the generated text has a probability lower than a certain threshold, the retrieval module is triggered. 3 Methodology In this section, we introduce the DRAGIN frame- work in detail. DRAGIN consists of two com- ponents: Real-time Information Needs Detection (RIND) and Query Formulation based on Self- attention (QFS), as illustrated in Figure 1. We introduce RIND in section 3.1, and QFS in sec- tion 3.2. 3.1 Real-time Information Need Detection As discussed above, most existing dynamic RAG frameworks trigger the retrieval module based on static, predefined rules. To the best of our knowl- edge, the only notable exception is FLARE (Jiang et al., 2023) which triggers retrieval dynamically when the LLMâ€™s confidence (i.e., the generation probability) on the next token is lower than certain thresholds. However, the necessity of retrieval augmentation not only depends on the generation confidence, but also depends on the importance of the token, the se- mantic of the token, and the influence of each token on subsequent tokens. To address the limitations of the existing approaches, we propose an enhanced approach for triggering retrieval within dynamic RAG frameworks, named Real-time Information Needs