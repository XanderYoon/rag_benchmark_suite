it satisfies attribute #7. B. Similarity Matching Score As per attributes and #1 and #4, we will use f (cp, ct) to denote the similarity measure between a predicted cell, cp, and a ground truth cell, ct. f can be any similarity measure appropriate for the downstream task. Exact match for product reference numbers, Intersection-over-Union for bounding boxes, etc. To make the metric F1-score-like, we have to constrain f to be between 0 and 1: 0 ≤ f (cp, ct) ≤ 1, for all cp, ct. We will use use gf (rowp, rowt) as the sum of the similarity scores of the corresponding cells in the predicted row, rowp, and the ground truth row, rowt. C. Row Matching Let’s denote Rp and Rt as the sequence of rows in the predicted and ground truth line items, respectively. We then denote R′ p and R′ t as subsequences of rows in Rp and Rt, respectively. The goal is to find equal-length subsequences ˜Rp and ˜Rt such that the sum of the similarity scores of the corresponding cells is maximized: ˜Rp, ˜Rt = arg max R′p|Rp,R′ t|Rt X i gf (R′ p[i], R′ t[i]) (1) Because we concern ourselves with subsequences instead of subsets of rows, it is more appropriate to use a Levenshtein Distance-like algorithm to find ˜Rp, ˜Rt rather than a Maximum- Weight Bipartite Matching-based algorithm as in ANLS* and DocILE. This penalizes swapped or shuffled rows in the predictions. This approach is similar to the one used in the GriTS metric, but in one dimension instead of two, and does not enforce column-order preservation. D. General Line Items Recognition Metric To define the General Line Items Recognition Metric (GLIRM), we first define the GLIRM-Precision and GLIRM- Recall scores as follows: GLIRM-Precf (Rp, Rt) = (1 /|Rt|) X i gf