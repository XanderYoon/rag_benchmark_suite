information from the document into key-value pairs. And the goal of LIR is to extract information into a list of line items where each line item corresponds to a row in a table formatted into column key-value pairs. And unlike Table Structure Recognition, the order of the columns do not matter so long as the columns are mapped to the proper, predefined column keys [2]. To summarize and motivate RASG: the goal of BDIE is to transform a blob of information into a structured format to pass to downstream tools (i.e. APIs). We can teach machine learning models to use tools through supervised finetuning. We can then force them to output in the format we expect using structured generation. We can also teach sufficiently-powerful, pretrained models to use new tools on out-of-distribution datasets by taking advantage of in-context learning. Finally, to be able to use commercial LLMs ”out-of-the-box”, we can structure the text prompt to look like the original document through prompt engineering. II. R ETRIEVAL AUGMENTED STRUCTURED GENERATION Retrieval Augmented Structured Generation (RASG) is composed of four components: (1) Retrieval Augmented Generation which allows us to teach LLMs to use new tools using In-Context Learning [3]; (2) Supervised Finetuning which enhances the correctness of the extracted outputs; (3) Structured Generation which ensures that the outputs are parse-able by downstream programs [4]; and (4) Structured Prompting which infuses layout information into the prompt [5]. All four components are necessary to beat strong multi- modal baselines on BDIE using an open-source 7B LLM, Hermes 2 Pro - Mistral 7B [6]. But only a subset are necessary when using GPT-3.5 [7]. A. Notes for Finetuning for Structured Generation The language model used must output both the right content and the right structure of said content. Finetuning significantly helps with the former, less