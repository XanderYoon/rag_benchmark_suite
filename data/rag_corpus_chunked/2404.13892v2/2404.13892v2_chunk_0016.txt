and ğ‘Ÿğ‘˜ âˆˆ R1Ã—4ğ¹ respectively. (2) These two representations are used to form ğ‘Ÿğ‘‘ âˆˆ R1Ã—4ğ¹ by taking their difference, ğ‘Ÿğ‘‘ = ğ‘Ÿğ‘˜ âˆ’ ğ‘Ÿğ‘. We make a difference between two features with extremely similar timbre, which allows the discriminative model to pay more attention to other differential information, such as background noise. (3) This output is sent to a sample-wise ASP layer (denoted as ASPğ¾ (Â·)) to form the intermediate representation ğ‘Ÿğ‘’ âˆˆ R1Ã—8ğ¹ . (4) ğ‘Ÿğ‘’ is concatenated with ğ‘Ÿğ‘, and sent to a fully connected layer to make the final decision. Through this scheme, the RAD-based detection model can take into account numerous particularly similar bonafide samples and make comprehensive judgments on their contents and distributions. This enables the model to achieve more accurate detection results by accounting for many additional highly similar authentic cases. 3.4 Performance Optimization In order to speed up the process of training and testing, two ap- proaches are used for optimization. Locally Stored Features. To speed up the training and testing pro- cess, we pre-compute and cache the WavLM features of all audio ICMR â€™24, June 10â€“14, 2024, Phuket, Thailand Zuheng Kang et al. segments in the knowledge retrieval database. Specifically, each raw audio segment ğ‘¥ğ‘› is passed through the WavLM model to extract the corresponding feature representation ğ‘¦ğ‘›,ğ‘™. The retrieved fea- ture  ğ‘¦ğ‘›,ğ‘™ are stored locally, and the indexes in the database only store pointers to these pre-extracted feature paths. For training, the entire pipeline operates on the pre-computed features rather than raw audio, with the cached test features, retrieved database features, and corresponding labels, making the training process extremely fast. For testing, this design allows efficient retrieval of audio contents without repetitively invoking the computationally expensive WavLM feature extraction each time. Time-wise Speedup. The acoustic features extracted by WavLM