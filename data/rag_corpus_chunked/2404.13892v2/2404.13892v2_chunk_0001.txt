CONCEPTS •Information systems → Clustering and classification. ∗Both authors contributed equally to this research †Corresponding author: Jianzong Wang, jzwang@188.com Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ICMR ’24, June 10–14, 2024, Phuket, Thailand © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0619-6/24/06. . . $15.00 https://doi.org/10.1145/3652583.3658086 KEYWORDS audio deepfake, deepfake detection, retrieval-augmented detection, retrieval-augmented generation, LLM, voice conversion, text-to- speech ACM Reference Format: Zuheng Kang, Yayun He, Botao Zhao, Xiaoyang Qu, Junqing Peng, Jing Xiao, and Jianzong Wang. 2024. Retrieval-Augmented Audio Deepfake Detection. In Proceedings of the 2024 International Conference on Multimedia Retrieval (ICMR ’24), June 10–14, 2024, Phuket, Thailand. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3652583.3658086 1 INTRODUCTION Recent artificial intelligence (AI) techniques have enabled the gen- eration of synthesized audio known as DeepFakes (DF) with in- creasing degrees of fidelity to natural human speech. Sophisticated DF generation techniques, such as text-to-speech (TTS) and voice conversion (VC) to mimic the timbre, prosody, and intonation of the speaker, can now generate audio perceptually indistinguishable from genuine recordings. However, the potential malicious use of such AI-synthesized speech has serious personal and societal im- plications, including disruption of automatic speaker verification (ASV) systems, propagating misinformation, and defaming repu- tations. As a result, the vulnerability of current audio-based