Retrieval-Augmented Audio Deepfake Detection Zuheng Kang∗ Ping An Technology (Shenzhen) Co., Ltd. Shenzhen, China kangzuheng896@pingan.com.cn Yayun He∗ Ping An Technology (Shenzhen) Co., Ltd. Shenzhen, China heyayun097@pingan.com.cn Botao Zhao Ping An Technology (Shenzhen) Co., Ltd. Shenzhen, China zhaobotao204@pingan.com.cn Xiaoyang Qu Ping An Technology (Shenzhen) Co., Ltd. Shenzhen, China quxiaoyang343@pingan.com.cn Junqing Peng Ping An Technology (Shenzhen) Co., Ltd. Shenzhen, China pengjq@pingan.com.cn Jing Xiao Ping An Insurance (Group) Company of China Shenzhen, China xiaojing661@pingan.com.cn Jianzong Wang† Ping An Technology (Shenzhen) Co., Ltd. Shenzhen, China jzwang@188.com ABSTRACT With recent advances in speech synthesis including text-to-speech (TTS) and voice conversion (VC) systems enabling the generation of ultra-realistic audio deepfakes, there is growing concern about their potential misuse. However, most deepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a single model, result- ing in performance bottlenecks and transparency issues. Inspired by retrieval-augmented generation (RAG), we propose a retrieval- augmented detection (RAD) framework that augments test samples with similar retrieved samples for enhanced detection. We also extend the multi-fusion attentive classifier to integrate it with our proposed RAD framework. Extensive experiments show the supe- rior performance of the proposed RAD framework over baseline methods, achieving state-of-the-art results on the ASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets. Further sample analysis indicates that the retriever consistently retrieves samples mostly from the same speaker with acoustic character- istics highly consistent with the query audio, thereby improving detection performance. CCS CONCEPTS •Information systems → Clustering and classification. ∗Both authors contributed equally to this research †Corresponding author: Jianzong Wang, jzwang@188.com Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this