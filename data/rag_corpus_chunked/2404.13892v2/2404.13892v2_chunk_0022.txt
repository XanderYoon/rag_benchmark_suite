best reporting result, demonstrating the effectiveness and superiority of our proposed method. Notably, although Guo et al. [9] utilizes a similar WavLM feature extractor and MFA net- work, our proposed RAD framework improves its performance, overcoming the limitations of single-model approaches. In our analysis, the RAD framework first retrieves the most sim- ilar audio samples, which are likely from the same speaker, and then performs careful comparisons between these samples and the test sample. For the detection model, it only needs to consider the differences between the two, rather than relying on fuzzy prior knowledge for detection. In contrast, our proposed method is more robust. Specifically, by focusing on fine-grained differences rather than generalized knowledge, our method can more accurately dis- tinguish more detailed information. Results on ASVspoof 2021 DF evaluation set. We further test our model on the ASVspoof 2021 LA and DF evaluation set, results are shown in Table 2. In the DF subset, our method achieves SOTA performance on the DF subset with an EER of 2.38%. In the LA subset, we obtain an EER of 4.89%, which is also quite a competitive performance, but still better than the baseline system [9] without RAD. Further analysis and ablation studies are needed to a fully Table 2: Comparative results of our proposed method with other systems in the ASVspoof 2021 LA and DF evaluation set with pooled EER (%). System Configuration LA DF Fan et al. [7] f0+Res2Net 3.61 – Doñas et al. [18] wav2vec2+ASP 3.54 4.98 Wang et al. [25] wav2vec2+LGF 6.53 4.75 Tak et al. [21] wav2vec2+AASIST 0.82 2.85 Fan et al. [7] WavLM+MFA 5.08 2.56 Ours WavLM+RAD-MFA 4.83 2.38 Table 3: Ablation studies on ASVspoof 2021 DF dataset for the effectiveness of each component with pooled EER (%). -L and -S: large and small. ft: