that exclude all samples already present in our experimental data. This allows us to increase the number of bonafide samples available for each speaker in the retrieval task. Metrics. We evaluated our proposed model on these datasets using two standard metrics: the minimum normalized tandem detection cost function (min t-DCF) [14] and pooled equal error rate (EER). The min t-DCF measures the combined (tandem) performance of the ASV systems, and the EER reflects the independent DF detection capability. 4.2 Implementation Details Data Processing. The original audio recordings in the database are segmented into clips of 4 seconds in length. Audio recordings over the 4-second duration are truncated to 4 seconds. For audio record- ings shorter than 4 seconds, the clips are padded to the 4-second length by repeating the recording. No additional processing such as voice activity detection (VAD) is applied to the audio samples prior to segmentation. The audio segments are first encoded into short features using a WavLM model, and are then shortened into more compact short features through a time-wise speedup model with parameter ùúè = 10. Vector Database. In order to store and query embeddings from vector databases more conveniently, we created ùêø databases to store the audio feature vectors extracted at each layer of the WavLM model. When performing a database retrieval, the query audio is converted to query embedding, and the top 10 most similar WavLM short features will be retrieved. Retrieval-Augmented Audio Deepfake Detection ICMR ‚Äô24, June 10‚Äì14, 2024, Phuket, Thailand Table 1: Comparison with other anti-spoofing systems in the ASVspoof 2019 LA evaluation set, reported in terms of pooled min t-DCF and EER (%). System Configuration min t-DCF EER(%) Hua et al. [11] DNN+ResNet 0.0481 1.64 Zhang et al. [31] FFT+SENet 0.0368 1.14 Ding et al. [6] SAMO 0.0356 1.08 Tak et