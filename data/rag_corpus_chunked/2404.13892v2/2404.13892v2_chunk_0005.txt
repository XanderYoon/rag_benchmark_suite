detection, such as typical artifacts for bonafide or synthetic spoofed examples. Then, the deepfake detector could integrate these retrieval results and the suspected audio into its decision process. This retrieval-augmented approach has several advantages. The model gains access to a much larger knowledge base beyond what can be encoded only in its model parameters. The retrieved results also provide supporting evidence for decisions, improving model performance. Furthermore, the system can update or modify its knowledge database for differ- ent detection tasks, since the model has learned to characterize a limited type of DF synthesizing methods. In summary, augmenting deepfake detectors with conditional retrieval of external data is an attractive direction. Developing DF detection methodology with a retrieval-augmented approach is worthy of further exploration. To implement the above-mentioned issue, we made the following contributions: ‚Ä¢ We proposed a retrieval augmented detection (RAD) frame- work which innovatively retrieves similar samples with addi- tional knowledge, and incorporates them into the detection process for improved detection performance. ‚Ä¢ We extend the multi-fusion attentive classifier to integrate with RAD. ‚Ä¢ Extensive Experiments show that our proposed method achieves state-of-the-art results on the ASVspoof 2021 DF set and com- petitive results on the 2019 and 2021 LA sets, demonstrating the effectiveness of the proposed retrieval-augmented ap- proaches. 2 PRELIMINARY 2.1 Traditional Frameworks (1) Pipeline Framework. The most common pipelines typically in- clude separate components for feature extraction, and classification (Figure 1-1). Specifically, the front-end feature extractor first con- verts the raw speech signalùë• into a speech featuresùë¶. These speech features are then passed to the back-end classifier, which analyzes the speech features that make a bonafide vs. spoof decision ùëß. Such architectures leverage the capabilities of efficient hand-crafted fea- tures or semantically rich self-supervised pre-trained features to obtain highly informative speech representations. The back-end classifier then