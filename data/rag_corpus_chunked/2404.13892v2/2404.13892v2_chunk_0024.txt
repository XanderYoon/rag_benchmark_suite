with a pooled EER of 2.38%. (2) Removing the proposed RAD framework for similar sample retrieval increases the pooled EER to 2.90%. This validates the effectiveness of the RAD framework, which answers the re- search Question 1. However, this result is slightly higher than that of Guo et al. [9], which may be due to different parameter settings and time-wise speedup operations. ICMR â€™24, June 10â€“14, 2024, Phuket, Thailand Zuheng Kang et al. Table 4: Ablation study of the effect of different time- wise speedup parameter ğœ on DF detection performance of ASVspoof 2021 DF dataset, using pooled EER (%). Speedup (ğœ =) 5 10 20 Original 4.68 4.98 5.45 Fine-tune 2.36 2.38 2.54 (3) Excluding the supplementary VCTK dataset slightly increases the pooled EER to 2.64%, indicating that updating the knowl- edge with additional related data could improve the detection performance, which answers the research Question 2. (4) Replacing WavLM-L with WavLM-S significantly increases the pooled EER to 9.15%, highlighting the importance of the feature extractor in the overall framework. (5) Without fine-tuning, the EER rises drastically to 9.62% and 4.98% for WavLM-S and WavLM-L respectively. This observa- tion clearly highlights the positive influence of fine-tuning in enhancing DF detection performance, since fine-tuning com- bines spoofed data instead of using bonafide data alone, thereby improving the discriminatory capability of DF samples. (6) We also tried the variation structure of removing the ğ‘Ÿğ‘ branch and directly connecting ğ‘Ÿğ‘’ (denoted in Figure 5) to the classifier slightly increases the pooled EER to 2.49%, suggesting that not only the difference of the feature, but also the original feature play the role for performance improvement. Effect of Time-wise Speedup Parameter. Table 4 examines whether time-wise speedup affects the performance of DF detection. We tested the original and the fine-tuned WavLM-Large feature ex- tractor