to DF detection, we extend the Multi-Fusion Attentive (MFA) classifier [9], named RAD-MFA, which combines the raw query input for detection and the retrieved similar bonafide samples to make comprehensive analysis for detections. Specifically, Figure 5 illustrates the overall structure of our proposed detection model, and Figure 5 shows the MFA sub-modules in detail. MFA Module. The MFA Module in our framework handles the test feature Ëœğ‘¦ğ‘ and the retrieved features  Ëœğ‘¦ğ‘˜,ğ‘™ . For conciseness, these features are denoted by ğ‘¦ in Figure 5. Specifically, the MFA module is implemented through the following steps: Figure 5: The structure of detection model architecture. âŠ• denotes the concatenation. This process illustrates the 3rd get results stage of Figure 3-RAD in detail. (1) The input feature ğ‘¦ âˆˆ RğµÃ—ğ¿Ã—ğ‘‡ Ã—ğ¹ is passed through ğ¿ parallel time-wise attentive statistic pooling (ASP) layers (denoted as ASPğ‘‡ (Â·)) to eliminate the time dimension. Here, ğµ denotes a virtual dimension. (2) The last outputs are concatenated and passed through a fully connected layer to transform the features to RğµÃ—ğ¿Ã—2ğ¹ . (3) These outputs are then passed through a layer-wise ASP layer (denoted as ASPğ¿ (Â·)) to form the intermediate representation ğ‘Ÿ âˆˆ RğµÃ—4ğ¹ . Extended RAD-based MFA. The RAD-MFA is implemented through the following steps: (1) The test feature Ëœğ‘¦ğ‘ âˆˆ R1Ã—ğ¿Ã—ğ‘‡ Ã—ğ¹ and the retrieved features Ëœğ‘¦ğ‘˜,ğ‘™ âˆˆ Rğ¾ Ã—ğ¿Ã—ğ‘‡ Ã—ğ¹ are sent to the same MFA module, creat- ing intermediate representations ğ‘Ÿğ‘ âˆˆ R1Ã—4ğ¹ and ğ‘Ÿğ‘˜ âˆˆ R1Ã—4ğ¹ respectively. (2) These two representations are used to form ğ‘Ÿğ‘‘ âˆˆ R1Ã—4ğ¹ by taking their difference, ğ‘Ÿğ‘‘ = ğ‘Ÿğ‘˜ âˆ’ ğ‘Ÿğ‘. We make a difference between two features with extremely similar timbre, which allows the discriminative model to pay more attention to other differential information, such as background noise. (3) This output is sent to a