by the deeper layers. WavLM Fine-Tuning. Since WavLM is trained only on bonafide audio during pre-training, it may not have exposure to spoofed samples, which potentially leads to incorrect classifications. There- fore, we first fine-tune the entire WavLM feature extractor in an Figure 2: The baseline structure for fine-tuning. ICMR â€™24, June 10â€“14, 2024, Phuket, Thailand Zuheng Kang et al. Figure 3: The overview of the RAG and RAD pipeline. Triangular edge rectangles represent vectors for retrieval databases. In RAG, long rectangles represent document chunks. In RAD, long rectangles with/without an outline represent long/short features, rounded edge rectangles represent audio segments. end-to-end manner without the RAD framework. That is, shown in Figure 2, the speech is encoded into short features by a train- able WavLM model E and time-wise speedup method S, which is then encoded into intermediate representations by an MFA mod- ule. These representations are then classified as either bonafide or spoofed by a fully connected layer. By jointly optimizing the parameters, we obtain a fine-tuned WavLM model that can serve as an improved feature extractor in the subsequent RAD frame- work. In the subsequent RAD inference phase, we only leverage the fine-tuned WavLM and discard the back-end model. 3.2 Retrieval Augmented Detection To address the performance limitations imposed by the detection bottleneck, we propose the retrieval augmented detection (RAD) framework. Similar to the RAG framework, the proposed RAD approach consists of three main stages, but with some procedural modifications compared to RAG. (1) Build Knowledge Retrieval Database. As shown in the stage 1 (blue section) of Figure 3-RAD, the bonafide audio dataset ğ‘¥ â€² is segmented into smaller audio segments {ğ‘¥ğ‘› } at the ğ‘›th sample. These audio segments can be encoded to latent long feature repre- sentations n ğ‘¦â€² ğ‘›,ğ‘™ o âˆˆ Rğ‘ Ã—ğ¿Ã—ğ‘‡ â€² Ã—ğ¹