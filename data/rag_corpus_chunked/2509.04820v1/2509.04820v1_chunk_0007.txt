framework designed to maximize recall RetrievingQuery Retain as many relevant chunks as possible. Chunk Filter(rule-based) Chunk Cropping(LLM-based) Numerous Candidate ChunksDrop Trash Chunks LRM Answer Cropped Chunks Figure 2: One-SHOT Strategy. This category includes methods such as Token-Constrained Top-K (retain as many relevant chunks as possible), along with tech- niques like chunk filter and chunk cropping. within a fixed context window. Rather than select- ing a fixed number of top- k (e.g., top-5) chunks, the system dynamically selects as many as possible relevant chunks that can fit within a given token budget, enhancing evidence coverage in a single re- trieval, denoted as Token-Constrained Top-Kmax. A few components are further designed: 3.1.1 Token-Constrained Top-K max To mitigate the issue of golden chunks being ex- cluded under a fixed Top-k setting, we propose a Token-Constrained Top-Kmax strategy that aims to maximize recall within a predefined token bud- get(e.g., 32,000 tokens). Each candidate chunk is associated with a relevance score ri (e.g., em- bedding similarity) and a token count ti, and the goal is to select a subset of chunks that together fit within the context window while maximizing the total relevance. Let xi ∈ {0,1} be a binary variable indicating whether chunk i is selected, and Tmax be the token limit. The selection problem can be formalized as: max nX i=1 ri ·x i s.t. nX i=1 ti ·x i ≤T max, x i ∈ {0,1} (1) This formulation effectively prioritizes chunks with high relevance-per-token ratios, enabling dense and informative context construction within the model’s input limits. 3.1.2 Key Optimization Components As illustrated in Fig. 1(b), such a greedy retrieval inevitably introduce some unrelated chunks. To further refine the evidence retrieved by the Token- Constrained Top-Kmax strategy, we design two complementary optimization components:chunks filterandchunks summary. Thechunk filtercomponent (rule-based) se- lectively removes irrelevant chunks