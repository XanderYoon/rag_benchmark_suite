Our iterative retrieval strategy implements a reason- ing agentic RAG (Liang et al., 2025) that leverages the reasoning and function-calling capabilities of large reasoning language models (LRMs) to per- form adaptive information retrieval. 3.2.1 Architecture Overview As shown in Fig. 3, the iterative retrieval system follows a multi-turn paradigm where the language reasoning model acts as an intelligent agent capa- ble of making informed decisions about when and how to retrieve additional information. Unlike tra- ditional RAG systems that rely on explicit pipeline components, our approach embeds the core func- tionalities implicitly within the model’s reasoning Query Is further retrieving required? Final Answer Delete irrelevant chunks. Context Append Retrieving Loop Rewrited Query Yes No Highly Relevant Chunks Retrieved Chunks LRM LRM Chunk Delete (Fallback Search at 1st Round) Figure 3: Iterative retrieval strategy, with fallback mod- ule to avoid query drift and chunk delete to avoid re- trieval laziness. process, managing context analysis, tool invoca- tion, and information synthesis naturally through the model’s inherent reasoning abilities. Similar to existing agentic RAG models, e.g., Search-O1 (Li et al., 2025b) and Search-R1 (Jin et al., 2025b), the system employs a structured rea- soning process encapsulated within <think> and </think> tags, where the model evaluates infor- mation sufficiency, identifies knowledge gaps, and formulates search queries. When additional infor- mation is required, the model generates structured function calls using the <tool_call> format. The system provides two primary tools: chunk_search for information retrieval (still use the small “fish- ing net”) andchunk_delete for context refinement and information overload prevention. 3.2.2 Multi-Turn Retrieval Process The iterative retrieval process operates within a configurable maximum turn limit (typically set to 5 turns) to balance thoroughness with efficiency. In each turn, the system performs the following steps: 1.Reasoning Phase: The model analyzes the current context, including the original query and