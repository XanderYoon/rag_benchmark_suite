high relevance-per-token ratios, enabling dense and informative context construction within the model’s input limits. 3.1.2 Key Optimization Components As illustrated in Fig. 1(b), such a greedy retrieval inevitably introduce some unrelated chunks. To further refine the evidence retrieved by the Token- Constrained Top-Kmax strategy, we design two complementary optimization components:chunks filterandchunks summary. Thechunk filtercomponent (rule-based) se- lectively removes irrelevant chunks and augments missing but potentially useful ones by analyzing chunk meta information such as temporal expres- sions, locations, and named entities. Specifically, the drop operation filters out chunks that lack align- ment with query entities, while the add opera- tion supplements the retrieved set with additional chunks containing matching or complementary el- ements. This rule-based filtering improves both precision and recall of the retrieval results. Thechunk croppingcomponent (LLM-based) further crops the remaining related chunks. It lever- ages LLM reasoning to assess and refine the ini- tial evidence holistically. Given a specific related chunk that survives the filtering process, the LLM evaluates the contents inside this chunk carefully with respect to the original query and crop out the information deemed irrelevant or redundant. Chunks are basically refined to be shorter after this process, resulting in a more condensed and infor- mative evidence set for answer generation. In practice, both chunk filter and chunk crop- ping are conducted first before the token length is satisfied, such that the recall is being possibly maximized. 3.2 Iterative Retrieval Strategy: “Casting A Small Net Multi-Times!” Our iterative retrieval strategy implements a reason- ing agentic RAG (Liang et al., 2025) that leverages the reasoning and function-calling capabilities of large reasoning language models (LRMs) to per- form adaptive information retrieval. 3.2.1 Architecture Overview As shown in Fig. 3, the iterative retrieval system follows a multi-turn paradigm where the language reasoning model acts as an intelligent agent capa-