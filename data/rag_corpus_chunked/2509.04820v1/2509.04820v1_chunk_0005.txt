dense se- mantic matching, re-ranking, and multi-hop query- ing, while also introducing refined indexing strate- gies like fine-grained chunking and metadata-aware retrieval. Modular RAG rethinks the Naive RAG by breaking down the end-to-end process of indexing, retrieval, and generation into discrete, configurable modules. This design allows for greater architec- tural flexibility and enables system developers to incorporate diverse techniques into specific stages, such as enhancing retrieval with fine-tuned search modules (Lin et al., 2023). In response to specific task demands, various restructured and iterative module designs have also emerged. As a result, modular RAG has increasingly become a dominant paradigm in the field, supporting both serialized pipeline execution and end-to-end learning across modular components. Despite these advances, many RAG systems re- main constrained by static control logic, making them ill-suited for complex QA tasks where key evidence may be scattered or initially missed. Re- cent work on Agentic RAG introduces reasoning and tool use into retrieval, enabling more adap- tive behavior (Ravuru et al., 2024; Li et al., 2025a; Wu et al., 2025). Motivated by this, we explore two complementary strategies: a One-SHOT re- trieval method with token-aware evidence selection, and an agent-driven iterative framework. These ap- proaches aim to improve retrieval robustness and adaptivity in real-world QA scenarios. 2.2 Agentic RAG The year 2025 is marked as the year of agentic AI, with applications emerging such as agentic LLMs and so on (Ruan et al., 2023; Kong et al., 2024; Zhang et al.). Recent progress in RAG has moved beyond static, rule-based pipelines toward more dynamic, decision-driven systems broadly known asAgentic RAG. These systems embed retrieval decisions into the modelâ€™s reasoning flow, enabling LLMs to actively determine when and how to inter- act with external tools during generation. A growing body of work has demonstrated the effectiveness of prompting