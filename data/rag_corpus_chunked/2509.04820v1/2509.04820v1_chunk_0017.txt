to asking about withdrawal procedures, leading to irrelevant retrieval results. + Fallback Search benefits easy QAs more, i.e., L1 and L2 without retrival reasoning need, vul- nerable to query drift. Fallback search performs parallel retrieval using both the model’s reformu- lated query and the original user query during the Method L1 L2 L3 L4 Avg Basic RAG (Top-5) 89.5 88.5 76.0 70.0 81.0 Basic Agentic (Multi-turn)86.5 86.0 81.0 80.5 83.5 + Fallback Search 90.0 89.5 84.0 82.5 87.5 + Chunk Delete 91.5 91.0 88.5 89.0 90.0 Improvement over Baseline+2.0 +2.5 +12.5+19.0+9.0 Table 4: Ablation study of iterative retrieval compo- nents. Each row builds incrementally on the previous configuration. first retrieval turn, similar to a residual link design, significantly increases the model performance in L1 (+3.5%) and L2 (+3.5%), avoiding query drift. This boost is more evident than L3 (+3.0%) and L4 (+2.0%). This enhancement resulted in consistent improvements across all question levels, effectively mitigating the performance degradation observed in simple questions while maintaining benefits for complex queries. + Chunk Delete instead benefits hard QA more, i.e., L3 and L4 with retrieval reasoning need, vul- nerable to retrieval laziness. As mentioned, we ob- servedretrieval laziness: the agent is lazier to conduct the next retrieval when the previous round context is heavier.+ Chunk Deletefurther boosts L3 (+4.5%) and L4 (+6.5%) performance, more than L1 (+1.5%) and L2 (+1.5%). Method L1 L2 L3 L4 Avg Basic RAG (Top-5)89.51.00 88.51.00 76.01.00 70.01.00 81.01.00 Agentic (Qwen3)91.51.22 91.01.34 88.51.58 89.02.22 90.01.59 Agentic (DeepSeek)83.01.86 93.01.85 76.02.02 74.02.17 81.51.97 Agentic (DeepSeek∗) 92.21.86 96.91.85 92.72.02 90.22.17 93.11.97 Table 5: Comparison with DeepSeek-R1, with accuracy as the main result and the average retrieval times exe- cuted as the subscript. The original DeepSeek results are mostly lower than Qwen3 due to dozens of questions being rejected, so we report the relative