supports our decision of deployment based onQwen3. 4.4 Combine both? “Cast A Big Net Multi-Times” Overviewing the two strategies in Table 1 and Table 4, we can see that “different paths lead to the same goal”, both strategies, either “cast a bigger net” or “cast a small net multi-times”, reach the similar accuracy of 90% - 91%. For practitioners working with government documents and sufficient token budgets, “cast a bigger net” is recommended due to fewer retrieval rounds and runtime; for those with limited tokens and who are comfortable with more runtime, “cast a small net multi-times” is recom- mended. Combining Both: To explore the potential synergies between One-SHOT and iterative ap- proaches, we combined elements from both strate- gies. Specifically, we replaced the fixed Top-5 re- triever in the Iterative Retrieval Strategy’s fallback search mechanism with the Token-Constrained Top- K retriever from our One-SHOT strategy, testing various context budgets to maximize golden chunk recall in the first retrieval round. Surprisingly, all combined configurations under- performed the original iterative approach. Analysis revealed that the longer working context after the first retrieval round (due to Token-Constrained Top- Kmax) caused the LLM-based chunk delete tool to perform poorly, frequently removing genuinely use- ful chunks that were critical for answering the ques- tions (see Appendix C for a detailed case study). When we removed the chunk delete from the combined strategy, performance improved com- pared to the combined strategy with chunk delete, but still fell short of the original iterative approach. It revealed that without the chunk delete, the longer working context after the first retrieval round led to severe retrieval laziness. Even when information was incomplete, the model tended to avoid fur- ther retrieval operations, effectively degenerating into a One-SHOT strategy. This explains why the combined approach without chunk delete achieved scores