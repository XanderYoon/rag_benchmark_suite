cover my housing provident fund contributions?" Model-Reformulated Query:"Regulations on housing provident fund withdrawal time limits after resignation" Analysis:The original query seeks information about recovering or reclaiming housing provident fund contributions from a previous employer after a 3-year gap. However, the model’s autonomous reformulation shifts the focus to withdrawal regula- tions and time limits, fundamentally changing the intent from recovery/reclaim to withdrawal proce- dures. This query drift leads to retrieval of irrele- vant chunks about standard withdrawal processes rather than the specific legal provisions for recov- ering contributions from former employers, ulti- mately resulting in an incorrect or incomplete an- swer. This example demonstrates how autonomous query reformulation in agentic systems can deviate from the user’s original intent, particularly affect- ing the retrieval of relevant evidence and degrading overall system performance. B Retrieval Laziness To validate the retrieval laziness phenomenon dis- cussed in Section 4.3, we conducted a controlled experiment to measure how context length affects the model’s tendency to initiate follow-up retrieval calls. Experimental Setup:We manually injected re- dundant irrelevant chunks into the initial retrieval results to reach specific context lengths while en- suring that the retrieved chunks contained only par- tial golden chunks—insufficient to fully answer the user’s question. We then measured the prob- ability that the model would make a subsequent chunk_searchcall. Context LengthFollow-up Retrieval Probability 3k tokens 95% 6k tokens 90% 9k tokens 50% 12k tokens 25% Table 6: Retrieval laziness validation: probability of initiating follow-up retrieval calls at different context lengths. Results:As shown in Table 6, the model’s propensity to continue searching decreases dramat- ically as context length increases. With shorter contexts, the model correctly identifies information gaps and performs follow-up searches in the major- ity of cases. However, this rate drops significantly when the context becomes longer, demonstrating severe retrieval laziness in extended contexts. This