it observes (i.e., the user’s encrypted queries) to infer information about the user’s interests. The goal of PIR-RAG is to ensure the server learns nothing about the specific document cluster the user is interested in. 3.2 Offline Phase: Corpus Preprocessing Before any queries can be served, the server preprocesses the document corpus in a one-time setup consisting of two stages. Embedding and Clustering. Each document in the corpus is converted into a numerical vector embedding using a standard model (e.g., bge-base-en-v1.5). The server then applies a clustering algorithm, such as K-means, to group these embeddings into n semantic clusters. The centroids of these clusters are made public for client-side use. Chunk-Transposed Database Construction. For each cluster, the documents are concate- nated and partitioned into fixed-size chunks. This collection of chunks from all clusters is then organized into a chunk-transposed matrix of size m × n, where m is the number of chunks per clus- ter and n is the number of clusters. This structure is the key to our performance, as it allows the retrieval of an entire cluster’s documents to be formulated as a single matrix-vector multiplication. 3.3 Online Phase: Private Retrieval When a user wants to issue a query, the online private retrieval process unfolds in several key stages. 4 Figure 1: The PIR-RAG system architecture. (1) Offline Setup: The server partitions the document corpus into semantic clusters. (2) Online Query: The client identifies the closest cluster locally and uses a fast LWE-based PIR scheme to privately download the entire cluster for local re-ranking. Client-Side Query Formulation. The user’s client software first computes the embedding for the query. It then compares this embedding to the public centroids of the n clusters and identifies the index i of the closest cluster. Following this, the client constructs an n-dimensional one-hot