Int. Symp. Mix. Augment. Real. (ISMAR). , no. November, pp. 187 –196, 2012, doi: 10.1109/ismar.2012.6402556. [12] A. Dey and C. Sandor, “Lessons learned: Evaluating visualizations for occluded objects in handheld augmented reality,” Int. J. Hum. Comput. Stud. , vol. 72, no. 10 –11, pp. 704 –716, 2014, doi: 10.1016/j.ijhcs.2014.04.001. [13] B. Dresp, S. Durand, and S. Grossberg, “Depth perception from pairs of overlapping cues in pictorial displays,” Spat. Vis., vol. 15, no. 3, pp. 255–276, 2002, doi: 10.1163/15685680260174038. [14] P. Dunn-Rankin, G. A. Knezek, S. Wallace, and S. Zhang, Scaling Methods. 2004. [15] M. Farne, “Brightness as an indicator to distance: relative brightness per se or contrast with the background?,” Perception, vol. 6, pp. 287– 293, 1977. [16] D. E. Fox and K. I. Joy, “On polyhedral approximations to a sphere,” in Proceedings. Computer Graph ics International (Cat. No.98EX149), 1998, pp. 426–432, doi: 10.1109/CGI.1998.694296. [17] M. Fujimura and C. Morishita, “Depth Representation Method by Color Tone for 3D Graphics Modeler,” 2011 Int. Conf. Complex, Intelligent, Softw. Intensive Syst., pp. 639–342, 2011. [18] L. Gombač, K. Č. Pucihar, M. Kljun, P. Coulton, and J. Grbac, “3D virtual tracing and depth perception problem in mobile AR,” Conf. Hum. Factors Comput. Syst. - Proc., vol. 07-12-May-, pp. 1849–1856, 2016, doi: 10.1145/2851581.2892412. [19] C. R. C. Guibal and B. Dresp, “Interaction of color and geometric cues in depth perception: when does ‘red’ mean ‘near’?,” Psychol. Res., vol. 69, no. 1–2, pp. 30–40, 2004, doi: 10.1007/s00426-003-0167-0. [20] H. Hartridge, “THE VISUAL PERCEPTION OF F INE DETAIL,” Optom. Vis. Sci. , vol. 25, no. 3, pp. 148 –152, 1948, doi: 10.1097/00006324-194803000-00012. [21] H. Hartridge, “THE VISUAL PERCEPTION OF FINE DETAIL,” Optom. Vis. Sci. , vol. 25, no. 3, pp. 148 –152, 1948, doi: 10.1097/00006324-194803000-00012. [22] A. K. Hebborn, H. Nils, and M. Stefan, “Occlusion Matting :