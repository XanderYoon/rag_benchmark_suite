closer than a darker version of the same color, regardless of fidelity. 2 RELATED WORK 2.1 Depth Perception in AR and VR Depth perception has been a widely studied topic in AR and virtual reality (VR), but most work has focused on HMDs [4]. Swan et al. [51] provided an excellent overview of previous work of depth perception in AR and VR and noted that distances are consistently underestimated in VR scenes. Thompson et al. [55] proposed that image quality was not the reason for underestimation in VR after investigating the effects of environment quality on depth perception. Interestingly, Kjelldahl and Prime [25] noted that 3D wireframe objects were more difficult for participants to make depth judgments on compared to a solid object on a desktop monitor. These studies ar e highly relevant to our experiment as investigations of the effects of object fidelity on depth perception. However, they are focused on different platforms and do not investigate those effects for handheld mobile AR devices. Swan et al. [51] also surveyed several methods for estimating depth in mixed reality, such as perceptual matching, blind walking, triangulation by walking, and forced -choice tasks. They described a forced choice task that requires observers to make discrete depth choices, such as whether one object is nearer or further than another [51]. We chose to use a forced-choice task, as opposed to a perceptual matching task , due to the simplicity of forced -choice tasks. Perceptual matching is a more complicated task that requires users to adjust the position of a target object until it appears to be the same depth as a reference object. Due to the outbreak of COVID-19, participants completed our study remotely using their own mobile device and were unable to interact face to face with the experimenter, thus necessitating