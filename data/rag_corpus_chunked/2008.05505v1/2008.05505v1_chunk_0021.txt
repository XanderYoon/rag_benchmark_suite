towards the camera more than the other). Participants were asked to position the image targets in the center of the screen at the beginning of each condition and were required to recalibrate if they moved away by more than 5% of the screen. Minor movement was permitted, and virtual objects had motion parallax consistent with the real world. The s izes of the virtual objects were controlled by the application and kept equal. Figure 4: Depiction of our studyâ€™s setup and pair comparisons task. 3.7 Procedure Before participation in the study, participants filled out a background survey. They were then asked to print out the sheet of paper containing the image targets. Afterwards, p articipants installed an Android application on their device and were asked to disable all color distortion applications (e.g., blue light filter). The participant would then undergo the paired comparison experiment with the first model in their assigned Latin squares ordering. The participant would be presented with a pair of objects respectively o n the left and right side of the screen , each with a different color condition. They were instructed to select the object that appears closer to them based on their initial impulse. Selection was done by tapping on the object with their finger. After the result is recorded, the participant was presented with the next pair of color conditions after a 500-millisecond delay. This delay is based off of a similar successful paired comparison experiment that also evaluated depth perception [59]. Both the ordering of the pairs shown and the positions (left or right) of the color conditions within the pair was randomized to prevent any bias. This procedure was outlined by Dunn -Rankin et al. [14]. After all pairs of color conditions were presented to the participant, they were given the next