tasks. Perceptual matching is a more complicated task that requires users to adjust the position of a target object until it appears to be the same depth as a reference object. Due to the outbreak of COVID-19, participants completed our study remotely using their own mobile device and were unable to interact face to face with the experimenter, thus necessitating a simple task . Additionally, forced-choice tasks have seen success in analyzing color as a depth cue on objects displayed on a desktop monitor [3]. Depth perception in AR has seen notable work in the last decade. Swan et al. [53] investigated depth matching in AR and found that observers overestimated the matching distance of a virtual object compared to a real object at a reaching distance, although this study was conducted using head-worn AR. Rosales et al. [44] also found that distances to off-ground objects were perceived differently than distances to on -ground objects in a study using head -worn AR. Kruijff et al. [26] provided a thorough overview of perception issues in a wide range of AR platforms. They described depth distortion as one of the most common issues in AR and noted that relative brightness and color can cause problems in depth perception in both handheld mobile AR and head -worn AR. They also described other pictorial depth cues, such as occlusion, relative size, and aerial perspective [26]. Adams [1] noted that distance perception in AR is inconsistent and that consistent depth cues may improve depth perception in AR. Adams focused on shadows as depth cues, while our study focuses on color and luminance. More recently, there has been interest in examining depth perception in handheld mobile AR. Swan et al. [52] were the first to investigate distance judgments o f real and virtual objects in a