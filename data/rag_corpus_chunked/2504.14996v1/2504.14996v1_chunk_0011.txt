sys- tems and remote human oversight, making them vulnerable to f ailures in networked coordination. Imagine a scenario where multiple container ships are en route to an intelligen t port when a connectivity failure isolates the port’s AI from remote human supervisors. If AI lacks fallback autonom y, it may either pause vessel docking, causing congestion and fuel waste, or rigidly follow pre-set schedules without accounting for new variables, such as worsening weather or an emergency requiring priority docking. Conversely, an AI system capable of temporarily assuming control could reconﬁgure docking priorities, reroute vessels, or coordi nate local autonomous systems while signalling uncertaint y levels and awaiting human re-engagement. First, the shift between human-led and AI-led operations sh ould not be considered as a binary switch but a gradual, interactive transition. Research should explore not only h ow AI may signal autonomy escalation ( e.g., when it detects a disruption and takes over), but also how it prepares humans for re-engagement when connectivity is restored. Second, if AI must make decisions in the absence of human inpu t, it must also communicate how certain or un- certain it is about those decisions after reconnecting. Res earch could explore how AI expresses its own conﬁdence levels, ﬂagging moments when its fallback autonomy is opera ting with incomplete or ambiguous data. For example, in an intelligent port AI might autonomously reroute a vesse l but signal uncertainty due to missing weather reports, prompting a human operator to validate the decision once rec onnected. Third, continuing in a similar vein, once human operators re gain control, understanding what the system did in the user’s absence is critical in restoring situational awa reness. Research should investigate how AI can generate interpretable, interactive autonomy logs, where operator s can review, adjust, or override AI-driven decisions.