going anywhere’ at the end?” Decision: {"asr": "speaker says ’I’m not going anywhere’" } • Text Query: “What phrase appears on the protest sign?” Decision: {"ocr": "protest sign text" } • Visual Query: “Describe the color and shape of the vehicle” 2 Decision: {"visuals": "vehicle passing by, focus on color" } • Scene Query: “A man is walking down a street in a city” Decision: {"visuals": "man wearing hat and coat walking" } The router demonstrates clear understanding of modality-specific cues, successfully routing speech-related queries to ASR, text-reading queries to OCR, and visual description queries to the visual index. Technical Implementation: Our implementation uses SigLIP SoViT-400m large with mean-pooled 1 frame per second for visual embeddings and OpenAI text-embedding- 3-large for ASR and OCR text encoding. We chose lin- ear rank fusion over reciprocal rank fusion (RRF) as both yielded similar performance (within 0.5% Recall@5) but linear fusion offers better computational efficiency for real- time deployment. 3.2. Modality-Specific Index Construction Each modality index is optimized for its content character- istics and expected query patterns. The ASR index uses sentence-level segmentation to capture semantic units while maintaining temporal context. OCR text is processed with spatial clustering to group related screen elements. Visual embeddings are computed from keyframes selected to max- imize content diversity within each clip. Index construction follows consistent preprocessing pipelines to ensure fair comparison across modalities. Text content is normalized for punctuation and casing, while vi- sual content is standardized for resolution and aspect ratio. All embeddings are L2-normalized before indexing to en- able consistent cosine similarity computation. System Architecture: The complete routing pipeline pro- cesses queries through several stages: (1) LLM-based intent analysis and modality selection, (2) parallel index queries for selected modalities, (3) rank fusion of results, and (4) fi- nal ranking with modality provenance tracking. Each