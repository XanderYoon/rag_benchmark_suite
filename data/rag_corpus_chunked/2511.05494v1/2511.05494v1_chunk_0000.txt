Customized Retrieval-Augmented Generation with LLM for Debiasing Recommendation Unlearning Haichao Zhang, Chong Zhang, Peiyu Hu, Shi Qiu, Jia Wang † Xi’an Jiaotong-Liverpool University Email: haichao.zhang22@student.xjtlu.edu.cn, jia.wang02@xjtlu.edu.cn Abstract—Modern recommender systems face a critical chal- lenge in complying with privacy regulations like the “right to be forgotten”: removing a user’s data without disrupting recommendations for others. Traditional unlearning methods address this by partial model updates, but introduce propagation bias—where unlearning one user’s data distorts recommenda- tions for behaviorally similar users, degrading system accuracy. While retraining eliminates bias, it is computationally prohibitive for large-scale systems. To address this challenge, we propose CRAGRU, a novel framework leveraging Retrieval-Augmented Generation (RAG) for efficient, user-specific unlearning that mitigates bias while preserving recommendation quality. CRA- GRU decouples unlearning into distinct retrieval and generation stages. In retrieval, we employ three tailored strategies designed to precisely isolate the target user’s data influence, minimizing collateral impact on unrelated users and enhancing unlearning efficiency. Subsequently, the generation stage utilizes an LLM, augmented with user profiles integrated into prompts, to re- construct accurate and personalized recommendations without needing to retrain the entire base model. Experiments on three public datasets demonstrate that CRAGRU effectively unlearns targeted user data, significantly mitigating unlearn- ing bias by preventing adverse impacts on non-target users, while maintaining recommendation performance comparable to fully trained original models. Our work highlights the promise of RAG-based architectures for building robust and privacy- preserving recommender systems. The source code is available at: https://github.com/zhanghaichao520/LLM rec unlearning. Index Terms —Machine Unlearning, Recommender Systems, Large Language Model, Prompt Learning I. I NTRODUCTION Recommender systems (RS) rely heavily on user-generated data to deliver personalized experiences [1]–[3], raising con- cerns over privacy and data integrity. Users now demand the “right to be forgotten” under regulations like GDPR [4], while poisoned or outdated data further threaten model quality [5].