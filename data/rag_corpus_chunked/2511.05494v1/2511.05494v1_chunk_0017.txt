models and State-of-the-art (SOTA) models? • RQ2: What is CRAGRU’s time efficiency relative to existing exact and approximate unlearning approaches? • RQ3: How effectively does CRAGRU eliminate the influ- ence of forgotten data to ensure unlearning completeness? • RQ4: How do different retrieval strategies impact un- learning completeness and mitigate bias without degrad- ing model utility? A. Experimental Setup 1) Datasets: We evaluated our model on three publicly available datasets, which have been widely used for evaluating the performance of recommendation models. i) MovieLens 100K (ML-100K) 1: the MovieLens dataset is one of the 1https://grouplens.org/datasets/movielens/ most widely used datasets in recommendation research [46], containing 100,000 user ratings. ii) MovieLens 1M (ML- 1M): This is an extended version of the MovieLens dataset, containing 1,000,000 user ratings. iii) Netflix2: This is the official dataset from the Netflix Prize competition. Specifically, we reserve 10% of the original dataset as the forgetting set Df and split the remaining data into training, validation, and test sets with a 70/10/20% ratio. Table I provides a summary of the statistics for the three datasets, and Avg. Inter. represents the average number of user interactions in each dataset. TABLE I STATISTICS OF THREE PUBLIC DATASETS . Dataset Users Items Interactions Avg. Inter. Sparsity ML-100K 944 1,683 100,000 106 93.71% ML-1M 6,041 3,707 1,000,209 165 95.53% Netflix 7315 17,129 2,266,452 309 98.19% 2) Compared Models: Our method is model-agnostic and can be applied to any recommendation model. In this paper, we compare CRAGRU with State-of-the-art unlearning methods across two representative recommendation models: • BPR [47]: This is a widely used recommendation model, where the core idea is to optimize matrix factorization using a Bayesian personalized ranking objective. • LightGCN [1]: This is an advanced collaborative filtering model that improves recommendation performance by simplifying the graph convolutional network. The compared