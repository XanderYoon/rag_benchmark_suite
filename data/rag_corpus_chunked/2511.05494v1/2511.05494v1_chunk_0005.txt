machines [22], [23], and fast Bayes data deletion based on statistical query learning [24]. However, due to the limited application scenarios and lack of generalization of these methods, it is difficult to apply them to non-convex models such as deep neural networks with huge parameter spaces. To improve the generalization of unlearning, Bour- toule et al. proposed SISA [25], a model-agnostic unlearning framework. The core idea is to divide the original dataset into multiple shards, train sub-models with these shards, and finally summarize the sub-model results. During the unlearning process, only the sub-models of the labeled shards need to be retrained. Subsequently, chen et al. proposed GraphEraser [9], which enhanced the data partitioning method for graph-based datasets based on SISA and improved the performance of model unlearning in graph data scenarios. As large language models continue to develop, some studies have begun to utilize these models for unlearning [26], [27]. For instance, Chen et al. introduced lightweight unlearning layers within transformers, utilizing a selective teacher-student objective. Their method has demonstrated effective performance in clas- sification and generation tasks [26]. B. Recommendation Unlearning Recommendation Unlearning aims to enable the model to “forget” information about specific users or items to satisfy privacy protection requirements or facilitate model updates. Existing methods can be broadly categorized into the follow- ing types: RecEraser [10] retains collaborative information through data partitioning and aggregation; however, adher- ing to the SISA [25] paradigm restricts both performance and efficiency. Unlearn-ALS [28] introduces a fine-tuning optimization approach tailored for bilinear models. AltEraser [17] breaks down the Unlearning problem into multiple sub- problems to simplify computation. FRU [29] concentrates on unlearning within federated recommendation systems, striving to eliminate the influence of particular users. Additionally, some studies employ influence functions to estimate the impact of data on the model, enabling rapid updates