data from the retrieval process, thus eliminating the need for retraining. Therefore, when unlearning is required for certain data Du f ⊆ D u, we use a filter function to exclude this information from user data, get the filtered dataset: Dfiltered u = Filter( Du, Du f ). We provide recommendations based on Dfiltered u to facilitate efficient unlearning. Specifically, we propose three filter strategies to minimize the performance impact of unlearning and enhance unlearning efficiency. 1) User Preference-based Filtering: This strategy aims to select the most representative interaction records from a user’s historical interactions based on their inherent preferences, minimizing performance loss during unlearning. The core idea is to categorize items, analyze the proportion of a user’s interactions within each category, and sample interactions proportionally. Specifically, we define the set of categories as C = {c1, c2, ..., cn}, where n is the total number of categories. There exists a mapping function fc : I → C , map each item i ∈ I to a category c ∈ C . For user u, the historical interaction data is Du = {i1, i2, ..., im}, where ij ∈ I represents the interacted item, and m is the total number of historical interactions for user u. We define Du,c as the subset of user u’s interactions in category c: Du,c = {i ∈ D u | fc(i) = c}. (2) The interaction proportion pu,c of user u in category c is calculated as: pu,c = |Du,c| |Du| , where | · | denotes the cardinality of a set. Given a target number of interactions to retain K (e.g., K = 100 ), the number of interactions Kc to retain for each category c is: Kc = ⌊pu,c × K⌋, where ⌊·⌋ is the floor function. Finally, we randomly sample Kc