forgetting mechanism from the backbone architecture, CRAGRU enables precise removal of targeted user data (e.g., preferences or interactions) without modifying the original model parameters. CRAGRU ensures unlearning avoids costly backbone retraining while ensuring compatibility with arbitrary recommendation systems. The backbone model learns a function fb : U × I → R that predicts the preference score ˆru,i for user u and item i: ˆru,i = fb(u, i; θb), where θb represents the model parameters. For each user u ∈ U , the backbone model generates predicted scores for all items in I and selects the Top- K items (e.g. K = 50 ) with the highest scores as the candidate item list Icand u for subsequent recommendation: Icand u = topK i∈I(ˆru,i, K). (1) Here, topKi∈I(ˆru,i, K) denotes the selection of the set of K elements with the highest predicted scores ˆru,i for the user u. This candidate list Icand u will be used in subsequent stages by the LLM to generate the final recommendations. IV. P ROPOSED FRAMEWORK : CRAGRU The overall framework of CRAGRU is illustrated in Fig- ure 2. We propose a RAG-based approach for recommendation unlearning with three stages: Retrieval, Augmentation, and Generation. In the retrieval stage, we design three filtering strategies to flexibly select the key information that influences the user’s final recommendation results. By filtering out the user data that needs to be forgotten, we can achieve user- level unlearning. In the Augmentation stage, we combine the key information obtained from the previous stage with the candidate items and auxiliary information to construct the prompt. We then use the prompt generated in the augmentation stage to call the LLM and obtain the recommendation results, thus achieving user-level unlearning. A. Retrieval with Filtering for Unlearning In this phase, we retrieve user-related information from a dy-