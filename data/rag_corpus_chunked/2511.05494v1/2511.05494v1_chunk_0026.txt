to 0.2827. 2) Diversity-aware retrieval ensures representation of different item clusters to avoid overfitting to specific behaviors. While slightly less precise than preference- based filtering, it reduces retrieval bias with lower computa- tional cost via global distribution optimization. 3) Attention- aware retrieval—using multi-head attention to score and pri- oritize impactful interactions—achieves the highest gains. On ML-1M, it improves NDCG@10 by 5.71% (BPR) and 6.16% (LightGCN). This is because it can capture complex rela- tionships between user interactions and candidate items more effectively by evaluating the importance of interaction from multiple perspectives. Compared with approximate unlearning methods such as SCIF and IFRU (see Table II), which often suffer from residual embedding shifts, CRAGRU’s filtering strategies ensure that only unbiased, non-forgotten interactions contribute to the prompt, avoiding semantic leakage. VI. C ONCLUSION In this paper, we address a key limitation of existing recom- mendation unlearning methods—their tendency to propagate unintended influence to related users due to coarse-grained unlearning at the dataset level. To overcome this, we pro- pose CRAGRU, a novel framework that leverages Retrieval- Augmented Generation (RAG) to enable fine-grained, user- level unlearning while minimizing unlearning bias. CRAGRU employs three retrieval filtering strategies to isolate the impact of forgotten users and preserve recommendation quality for non-target users. Extensive experiments on three real-world datasets with BPR and LightGCN backbones demonstrate that CRAGRU outperforms state-of-the-art models in both efficiency and utility. REFERENCES [1] X. He, K. Deng, X. Wang, Y . Li, Y . Zhang, M. Wang, Lightgcn: Sim- plifying and powering graph convolution network for recommendation, in: ACM SIGIR 2020, 2020, pp. 639–648. [2] W. Liu, C. Chen, X. Liao, M. Hu, J. Yin, Y . Tan, L. Zheng, Federated probabilistic preference distribution modelling with compactness co- clustering for privacy-preserving multi-domain recommendation., in: IJCAI, 2023, pp. 2206–2214. [3] Y . Hu, Y