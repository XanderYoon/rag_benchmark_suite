coherent prompt that the LLM can effectively interpret. C. LLM-based Recommendation Generation By using the prompt P (u) constructed for each user, LLM is called to generate the result of the final recommendation. ˆyu = fLLM(P (u); θLLM), where ˆyu is the generated recommendation for user u, fLLM represents a large language model that generates text, such as Llama or GPT-4 series, and θLLM represents the LLM’s parameters. In this paper, our model uses llama3.1-8b as the recommendation generator. Due to filtering in the retrieval phase, the LLM does not receive any information that needs to be forgotten, ensuring that the generated recommendation ˆyu complies with the requirements for forgetting. D. Privacy Analysis Our proposed method ensures precise unlearning by ex- plicitly filtering out data to be unlearned during the retrieval phase, effectively preventing the LLM from accessing sensitive information. Consequently, this design inherently guarantees strong privacy protection. Specifically, as the data intended for unlearning ( Dunlearn u ) are excluded during retrieval, recommendation score ( ˆyu) generated by the LLM solely rely on the filtered dataset (Dfiltered u ). This mechanism enforces conditional independence between the recommendation results and the sensitive, un- learned data, effectively preventing unintended leakage and strengthening privacy guarantees, aligning with established privacy-preserving practices in retrieval-augmented systems. V. EXPERIMENTS In this section, we evaluate the performance of CRAGRU by answering the following four research questions (RQs): • RQ1: Can our method achieve performance comparable to retrained models and State-of-the-art (SOTA) models? • RQ2: What is CRAGRU’s time efficiency relative to existing exact and approximate unlearning approaches? • RQ3: How effectively does CRAGRU eliminate the influ- ence of forgotten data to ensure unlearning completeness? • RQ4: How do different retrieval strategies impact un- learning completeness and mitigate bias without degrad- ing model utility? A. Experimental Setup 1)