0.3603 0.0439 GraphEraser 0.3980 0.0941 0.6343 0.1001 0.8099 0.0957 0.4878 0.1157 0.7032 0.1215 0.8618 0.1181 RecEraser 0.4303 0.1032 0.6673 0.1086 0.8361 0.1038 0.4959 0.1303 0.7129 0.1314 0.8772 0.1254 SCIF 0.2789 0.0793 0.4014 0.0734 0.5265 0.08270 0.3388 0.1002 0.4762 0.0931 0.6286 0.1042 IFRU 0.1111 0.0677 0.2020 0.0955 0.3030 0.1202 0.1818 0.1035 0.2600 0.1388 0.3508 0.1760 CRAGRU 0.7266 0.3230 0.8190 0.2759 0.8651 0.2286 0.6691 0.2717 0.7827 0.2400 0.8428 0.2072 of different methods, we ignore the inference time of other models and evaluate by comparing the training time required for each method to complete the same unlearning task. The experimental results demonstrate that our method has a sig- nificant time advantage. Specifically, we randomly selected a user from the dataset, and the average interactions of the user between different datasets are shown in Table I. Our task was to perform unlearning on all interactions of this user. For partition-aggregation-based methods, i.e. SISA, GraphEraser, and RecEraser, we followed their recommended parameter settings. All experiments were run on an NVIDIA GeForce RTX 4090 GPU and the total unlearning time was recorded for each method. The results are shown in Table III. The lower the time, the higher the unlearning efficiency. Bold text in the table represents the best values, while underlined text represents the second-best values. Our method achieved the best results across all datasets. As shown in Table III, TABLE III TRAINING TIME COMPARISON ON DIFFERENT DATASETS AND MODELS ML-100K ML-1M Netflix BPR LightGCN BPR LightGCN BPR LightGCN Retrain 248s 141s 1935s 4209s 527s 1019s SISA 27s 28s 298s 435s 116s 131s GraphEraser 26s 17s 302s 269s 310s 640s RecEraser 29s 35s 386s 275s 404s 880s SCIF 18s 18s 66s 64s 299s 177s IFRU 55s 57s 78s 90s 104s 117s CRAGRU 14s 14s 15s 15s 16s 17s Improve 1.8x 1.2x 4.4x 4.3x 7.3x 6.9x