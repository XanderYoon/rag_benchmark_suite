affecting unrelated users. and RecEraser [10] for recommendation scenarios. Alterna- tively, approximate unlearning methods aim for efficiency by estimating and reversing the impact of data to be forgotten. Among these, IFRU [11], [12], and SCIF [13] have been proposed to approximate the impact of individual training data points via influence function. However, these methods often struggle with the computational burden of calculating Hessian matrices for large models [14]. Despite the distinct mechanisms of these exact and approximate approaches, a pervasive challenge known as unlearning bias can emerge, undermining their practical utility. This unlearning bias refers to the unintended and detri- mental impact on recommendation quality for remain users by the unlearning request. It arises because the influence of the user being “forgotten” is often entangled with remaining users due to collaborative effects [15]. However, both primary paradigms of unlearning can suffer from this: Exact unlearning methods (e.g., sharding) introduce bias as data removal alters sub-models, negatively impacting co-located users in the same shard [8], [16]. Similarly, approximate unlearning methods, such as influence functions, may inadvertently shift the em- beddings of behaviorally similar users, leading to degraded recommendations for these remaining users. As illustrated in Figure 1, if User A, a Harry Potter fan, requests their data be unlearned, these methods might degrade recommendations for other Harry Potter fans (Users B and C). Beyond quality, ex- isting partition-aggregation unlearning methods face efficiency limitations. Liu et al. [17] show small unlearning requests arXiv:2511.05494v1 [cs.IR] 10 Sep 2025 often necessitate retraining nearly all sub-models, rendering these methods computationally impractical under continuous or high-volume unlearning scenarios. To overcome these limitations, we propose CRAGRU, a novel approach that reframes unlearning as a targeted informa- tion retrieval problem within a Retrieval-Augmented Genera- tion (RAG) architecture, leveraging Large Language Models (LLMs). This RAG paradigm is crucial because