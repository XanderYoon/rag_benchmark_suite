im} and candidate item ic, each head h ∈ {1, 2, ..., H} calculates an attention score: Attentionh(ic, Du) = softmax  Qh(ic)Kh(Du)T √dk  Vh(Du), (6) where Qh(ic) is the query for ic in the head h. Kh(Du) and Vh(Du) are the keys and values for Du in head h. dk is the key dimension. The outputs of all H heads are concatenated and then projected to the desired output dimension dmodel using a linear transformation with the output projection matrix WO ∈ R(H×dv)×dmodel: MultiHead(ic, Du) = Concat(Attention1, ..., AttentionH )WO. (7) Attention Weight Calculation: For candidate item ic, it computes each interaction ij ∈ D u’s weight αj,c: αj,c = exp(score(ij, ic))Pm k=1 exp(score(ik, ic)) . (8) Here, score (ij, ic) can be from MultiHead (ic, Du). αj,c shows how important ij is for ic, and m represents the number of user. Model-based Filtering: We use the computed attention weights αj,c to select the K most relevant interactions from Du for each candidate item ic. We rank the interactions in Du based on their attention weights αj,c and select the Top- K interactions to form the filtered interaction set Dfiltered u (ic): Dfiltered u (ic) = Top-K(Du, {αj,c}m j=1), (9) where Top-K(S, w) is a function that returns the K elements from set S with the highest weights in w. B. Prompt Construction and Augmented We make a prompt for the LLM. This prompt uses filtered user data, candidate items, and other information. We use a template P for the prompt: P (u) = Format(Icand u , Dfiltered u , C). (10) Here, Icand u is the candidate items for user u from the basic recommendation model. Dfiltered u is the filtered user data ob- tained in Section IV-A. C is extra information for the LLM, like user