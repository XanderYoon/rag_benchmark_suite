allocation of retention ratios across categories, maximizing overall performance under a fixed total retention ratio (e.g., retaining a total of K interactions, corresponding to a total retention ratio K ′). Formally, let x = [x1, x2, ..., xn] be a vector where xc denotes the retention ratio for category c. Our objective is to find the optimal x∗ such that: x∗ = arg max x X c∈C M [c][xc] s.t. X c∈C xc = K ′. (4) We employ dynamic programming to solve this optimization problem. Define DP [i][j] as the maximum sum of Hit Rates considering the first i categories with a total retention ratio of j. The state transition equation is: DP [i][j] = max xi∈{10%,20%,...}∩[0,j] {DP [i−1][j−xi]+M [i][xi]}, (5) where DP [0][j] = 0 for all j. The final result, DP [n][K ′], represents the maximized total Hit Rate, and backtracking yields the optimal allocation x∗. Given the optimal x∗, we randomly sample xc percent of interactions from Du,c for each category c to construct the filtered interaction set Dfiltered u . This strategy intelligently allocates limited interaction re- sources, maximizing recommendation performance while en- suring a balanced representation of categories. 3) Attention-aware Filtering: This strategy uses Multi- Head Attention to find important user interactions. It selects useful interactions for better recommendations and efficient unlearning. Multi-Head Attention: It uses H attention heads to capture different aspects of information. For user u’ interactions Du = {i1, i2, ..., im} and candidate item ic, each head h ∈ {1, 2, ..., H} calculates an attention score: Attentionh(ic, Du) = softmax  Qh(ic)Kh(Du)T √dk  Vh(Du), (6) where Qh(ic) is the query for ic in the head h. Kh(Du) and Vh(Du) are the keys and values for Du in head h. dk is the key dimension. The outputs of all