For instance, LLMRec [42] strengthens recommendation sys- tems by adopting three simple yet effective LLM-based graph augmentation strategies. However, directly applying LLMs for recommendations often encounters challenges such as high computational costs and slow inference speeds. To address these issues, some studies have adopted alternative approaches, such as combining LLM-based data augmentation methods with classical Collaborative Filtering (CF) [43], aiming to enhance recommendation performance while ensuring the re- liability of the results. III. PRELIMINARIES A. Problem Formulation Recommendation Task: In a typical recommendation sce- nario, we are given a set of users U = {u1, u2, ..., um} and a set of items I = {i1, i2, ..., in}, where m and n denote the number of users and items, respectively. The interactions between users and items can be represented as a rating matrix R ∈ Rm×n, where Rui denotes the rating given by user u to item i. In this work, we consider explicit feedback in the form of ratings ranging from 1 to 5. We define the dataset D = {(u, i, r)|u ∈ U , i ∈ I , r ∈ { 1, 2, 3, 4, 5}}, where (u, i, r) mean that user u’s rating for item i is r. The goal of a recommendation model is to predict the missing ratings in R. Specifically, given user u’s historical interaction records Ru = {Rui|i ∈ I} , the recommendation model aims to learn a prediction function ˆRui = f (u, i|Ru) that can accurately predict the rating of user u for item i. Recommendation Unlearning: In recommendation systems, the objective of recommendation unlearning is to respond to users’ withdrawal requests by eliminating the impact of specific data from the trained model. Assume user u can submit any data withdrawal request Du f ⊆ D u to