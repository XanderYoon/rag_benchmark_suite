of LLMs for low-resource languages, fine -tuning these models for the target language can be an effective strategy. However, selecting the best method and optimized model presents a significant challenge in this domain. This research addresses this challenge in the context of the Persian language. In the present study, the performance of several fine-tuned models was evaluated. These models included PersianMind - 7B [29] and PersianLlama -7B [30] from the University of Tehran (based on Llama 2), and NeuraOrcaGemma-7B (based on Google's Gemma model). The results of these evaluations indicated that none of these models achieved acceptable accuracy and often suffered from hallucination errors Deeper analyses revealed that some language models are fundamentally unsuitable for fine -tuning on a specific target language. This issue stems from the volume of training data. According to our findings, at least 0.02% of the model's total training corpus must be dedicated to the target language to achieve desirable performance; otherwise, the weight update process leads to incomplete learning of associations and meanings in the new language [31]. Furthermore, it was observed that fine -tuning models for the Persian language not only results in insufficient understanding of this language but also adversely affects the model's performance in other languages, including the model's primary language (English). For instance, the PersianLlama - 7B model (based on Llama 2) and the NeuraOrcaGemma-7B model (based on Gemma), which were optimized to improve understanding of Persian, exhibited a significant decline in their performance accuracy in English. These findings underscore the importance of considering the volume and quality of training data in the fine -tuning process of large language models for low-resource languages. They also highlight the need to develop new and more efficient methods for optimizing these models for Persian. F. Precise Evaluation of the RAG System's Performance in Answering