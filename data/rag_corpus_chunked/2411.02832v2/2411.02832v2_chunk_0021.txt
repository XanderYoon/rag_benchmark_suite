This challenge arises because most existing models are optimized for the English language and may not perform desirably in Persian, especially given the limitations of training resources. To address this issue, a comprehensive process for model evaluation and selection was designed and implemented. Table VI presents the results of evaluation of LLMs for the PersianRAG. TABLE II. RESULTS OF EVALUATING LANGUAGE MODELS IN THE IMPLEMENTED RAG PIPELINE Model Wrong Middle Correct GPT 3 48% 12% 40% PXRL 18% 2% 80% Aya 101 6% 3% 91% Ultimately, two models with the best performance were identified: • Persian-XLM-Roberta-Large Model: An encoder- only model that enables the generation of extractive responses. • Command-R Model: This model was selected due to its architectural similarity to the Aya -101 model, which had previously yielded satisfactory results. A real RAG pipeline was developed based on this model, and through various versions, its accuracy gradually improved. TABLE III. ACCURACY ACHIEVED WITH THE COMMAND-R MODEL ON THE PERSIANQUAD DATASET Pipeline Wrong Middle Correct v1.0 24% 0% 76% v2.0 13% 0% 87% v3.0 11% 0% 89% Ultimately, the highest accuracy achieved in the initial version was 76%, obtained using the Persian -XLM- RoBERTa-Large model. By implementing improvements in embeddings, hybridizing the retriever, adjusting the chunk size, and other optimizations, this accuracy increased to 89% on 1,000 test samples from the PersianQuAD dataset. E. Selecting the Best Fine-Tuned LLMs for the Target Language In the pursuit of enhancing the performance of LLMs for low-resource languages, fine -tuning these models for the target language can be an effective strategy. However, selecting the best method and optimized model presents a significant challenge in this domain. This research addresses this challenge in the context of the Persian language. In the present study, the performance of several fine-tuned models was evaluated. These models included