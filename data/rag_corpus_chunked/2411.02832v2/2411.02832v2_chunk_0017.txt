value for that embedder would be 748 We concluded that combining different retrievers and using a hybrid approach could increase pipeline accuracy by up to 4%. This approach includes using search -based retrievers like BM25 along with dense retrievers. By adjusting various top_k values and adding a document_joiner at the end of the indexing pipeline, better accuracy could be achieved compared to using either method alone [26]. In our final pipeline, the top_k value for BM25 was set to 4 and for dense retriever to 8. The document_joiner directs all documents to extractive or generative models, sending up to 12 documents to the model. It also removes duplicates and considers the document with the highest score. And also i ncorporating Reranker models into RAG systems significantly enhances retrieval accuracy by refining the ranking of retrieved chunks. Our experiments demonstrate that after retrieving results from a vector database using the 'cohere-embed-multilingual-v3.0' embedding mod el, the addition of the 'cohere-rerank-multilingual-v3.0' as a Reranker substantially improves performance. Specifically, the Top -1 accuracy of correctly indexed chunks increased from 93.5% to 98.7%. This improvement indicates that the Reranker effectively reorders the retrieved chunks, ensuring that the most relevant chunks are ranked first, which enhances the overall effectiveness of the RAG system's retriever module. C. Prompt engineering In this research, focusing on the Persian language, we concluded that selecting the appropriate language for writing prompts based on different LLMs has a significant impact on the overall performance of the system. Language models that support only a limited number of languages react differently to the input prompt language compared to multilingual models. Specifically, in monolingual models or those with limited support, using a language in which the model has greater proficiency (usually English) leads t o a better understanding of the instructions and assigned tasks. In