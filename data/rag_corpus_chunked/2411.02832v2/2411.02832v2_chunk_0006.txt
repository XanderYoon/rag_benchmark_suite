find the sections of the knowledge base that have the highest semantic similarity to the query. This optimized retrieval process allows the system to pass precise information to subsequent stages. I. Related Chunks This section collects texts identified by the retriever as relevant and feeds them into the system as the next input. These are key parts of information directly related to the user’s query. J. Prompt Builder The Prompt Builder combines the user’s query with relevant sections extracted from the knowledge base, forming a complete and comprehensive prompt for the language model. The combination ensures that the language model receives relevant information alongsi de the user’s question, leading to more accurate responses. K. Language Model The language model is responsible for generating the final response. Utilizing the final query constructed by the Prompt Builder, this model produces a relevant and logical answer. Language models, leveraging millions of parameters and based on extensive textual data on which they have been trained, possess the ability to generate natural and human-like language. In this research, we have employed both extractive models, specifically the BERT -base models, and their generative counterparts, namely LLMs. L. Response The response generated by the language model is presented to the user. This response may include textual explanations, numerical results, or even advanced analyses. M. Hyperparameters Optimizer The hyperparameters optimizer is a component of the system responsible for enhancing its overall performance. By adjusting various hyperparameters at different stages, such as data processing, vector transformations, and information retrieval, this compone nt helps the system operate at maximum efficiency. These optimizations can include parameters like the Top K, which refers to the number of most relevant and similar results retrieved from the documents, embedding dimensions, the number of retrieved chunks , chunk size, chunk overlap, and other key variables.