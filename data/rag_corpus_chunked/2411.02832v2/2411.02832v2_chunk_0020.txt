may not suffice, and it may be necessary to incorporate additional contextual information. To optimize this process, another LLM chain can be employed at the beginning of the pipeline to intelligently identify and add the necessary types and am ounts of metadata. In conclusion, by implementing the aforementioned set of strategies and conducting continuous optimizations, we were able to significantly enhance ### Instructions [Specific guidelines for the AI model] ### User Query [The user's question or request] ### Retrieved Information [Relevant data retrieved by the RAG system] ### Your Response: [Space for the AI-generated response] the performance of the implemented RAG system in terms of information retrieval and generating relevant responses. These advancements are particularly important for low -resource languages like Persian, which face specific challenges in natural language processing. â€¢ Language Model: The language model is responsible for generating the final response. Utilizing the final query constructed by the Prompt Builder, this model produces a relevant and logical answer. Language models, leveraging millions of parameters and based on extensive t extual data on which they have been trained, possess the ability to generate natural and human -like language. In this research, we have employed both extractive models, specifically the BERT -base models, and their generative counterparts, namely LLMs. D. Finding a Model for Answering Questions in the Target Language In the present study, the main challenge was selecting an appropriate model for answering questions in Persian using RAG technology. This challenge arises because most existing models are optimized for the English language and may not perform desirably in Persian, especially given the limitations of training resources. To address this issue, a comprehensive process for model evaluation and selection was designed and implemented. Table VI presents the results of evaluation of LLMs for the PersianRAG. TABLE II. RESULTS OF EVALUATING