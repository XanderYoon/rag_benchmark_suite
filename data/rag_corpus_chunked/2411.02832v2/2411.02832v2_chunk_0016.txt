7.9 3.6 3.7 LaBSE 80.7 9.1 2.5 2.3 LaBSE-sentence- embeddings 80.7 9.1 2.5 2.3 persian-sentence- transformer-news- wiki-pairs-v3 88.1 5.3 2.1 1.3 jina-embeddings-v3 88.8 4.1 1.7 1.9 cohere-embed- multilingual-v3.0 93.5 2.9 1.1 0.3 Most models reviewed were open-source and available on platforms like Hugging Face, except for one from Cohere, which is not open -source. This diversity allowed us to comprehensively assess the performance of various models in Persian language processing. To compare different embedder models, a subset of data was extracted from the main dataset, PersianQuad [25]. The original dataset consists of columns for Paragraph, Question, and GoldAnswer, designed for training and evaluating QA systems. However, for the purpose of comparing embedders, only the Paragraph and Question columns were used. The evaluation was conducted within the context of an information retrieval framework, where better embeddings result in improved retrieval performance. Next, this subset was processed separately by each embedder model, and the results were stored in a vector database. Using Cosine Similarity, the quality of various embeddings was evaluated by selecting the Question as input and searching for the most similar paragraphs in the vector database. The top ten most similar paragraphs were compared to the actual paragraph, and the rank of the actual paragraph among the top ten was recorded. If the rank was ‘n’, a unit was added to Top n. For example, if in 1,000 tuples, the actual paragraph was ranked first 748 times, the Top 1 value for that embedder would be 748 We concluded that combining different retrievers and using a hybrid approach could increase pipeline accuracy by up to 4%. This approach includes using search -based retrievers like BM25 along with dense retrievers. By adjusting various top_k values and adding a document_joiner at the end of the indexing pipeline, better accuracy could be achieved