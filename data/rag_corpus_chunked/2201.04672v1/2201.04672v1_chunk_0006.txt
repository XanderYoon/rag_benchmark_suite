documents from broad research areas, 50 queries about the pandemic that interest people, and 46,167 query-document relevance labels. Experimental settings and metrics We follow the common two-step prac- tice for the large-scale document retrieval task [7, 19,28]. The initial retrieval is performed on the whole corpus with full texts through BM25 [30], a traditional yet widely-used baseline. In the second stage, we further conduct re-ranking on the top 100 candidates using diﬀerent graph models. The node features and query embeddings are initialized with pretrained models from [4,44]. NDCG@20 is adopted as the main evaluation metric for retrieval, which is used for the competition leader board. Besides NDCG@ K, we also provide Precision@K and Recall@K (K =10, 20 for all metrics). 3.2 Evaluation of Concept Maps We empirically evaluate the quality of concept maps generated from Section 2.2. The purpose is to validate that information in concept maps can indicate query- document relevance, and provide additional discriminative signals based on the 1 https://ir.nist.gov/covidSubmit/ 2 https://github.com/allenai/cord19 Graph Neural Networks for Document Retrieval 5 Table 2. The retrieval performance results of diﬀerent models. Type Methods Precision (%) Recall (%) NDCG (%) k=10 k=20 k=10 k=20 k=10 k=20 Traditional BM25 55.20 49.00 1.36 2.39 51.37 45.91 Anserini 54.00 49.60 1.22 2.25 47.09 43.82 Structure-OrientedGIN 35.24 34.36 0.77 1.50 30.59 29.91 GAT 46.48 43.26 1.08 2.00 42.24 39.49 Semantics-Oriented N-Pool 58.24 52.20 1.38 2.41 53.38 48.80 E-Pool 59.60 53.88 1.40 2.49 56.11 51.16 RW-Pool59.84 53.92 1.42 2.53 56.1951.41 initial candidates. Three types of pairs are constructed: a Pos-Pos pair consists of two documents both relevant to a query; a Pos-Neg pair consists of a relevant and an irrelevant one; and a Pos-BM pair consists of a relevant one and a top-20 one from BM25. Given a graph pair Gi and Gj, their similarity is calculated