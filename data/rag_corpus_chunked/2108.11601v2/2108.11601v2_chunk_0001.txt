Gu et al., 2016) and code documentation/summarization (Ahmad et al., 2020; Wei et al., 2019; Allamanis et al., 2018). Despite initial success, most of the generated code still suffers from poor code quality (Xu et al., 2021). Therefore, the question remains—how to generate better code from a given summary and vice versa. Source code generation and summarization, how- ever, are intrinsically complex and challenging. They involve generating diverse token sequences such as different variables, operators, keywords, classes, and method names (Parvez et al., 2018), which requires understanding the programming lan- guages at lexical, syntax, and semantics levels. To combat these issues, recent studies ( e.g., Ah- mad et al. (2021); Guo et al. (2021); Xu et al. (2020); Feng et al. (2020a); Xu et al. (2020)) take a learning-based approach—they train representa- tions of code and the associated text by leveraging existing high-quality source code and short text descriptions available in open-source repositories and question answering forums such as GitHub and Stack Overﬂow. Then ﬁne-tune the represen- tation models on the downstream tasks. Although these dataset contains high-quality human-written code and text, since the existing approaches do not directly leverage them during the generation pro- cess, the gain achieved by these approaches is still limited, especially when the source code is long. To overcome this, we take advantage of the ex- isting high-quality source code and their descrip- tion by including them directly in the generation process that are retrieved via information retrieval technique. In this work, we present REDCODER, a Retrieval augment ED COD e g Eneration and summaRization framework. While designing RED- CODER, we take motivation from how developers take advantage of existing resources. For example, developers often search for relevant code in the code repository, and if found, adapt the retrieved code in their own context. Similarly,