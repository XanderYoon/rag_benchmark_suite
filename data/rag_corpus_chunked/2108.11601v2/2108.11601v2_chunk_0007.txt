module in our proposed framework, REDCODER. 3 Proposed Framework: REDCODER Our proposed code generation and summarization framework, REDCODER generates the target code or summary by augmenting the input x with rele- vant code snippets or summaries. We build our re- triever module by training a DPR model differently from (Karpukhin et al., 2020). With an intelligent scheme, we then augment the retrieved candidates and their pairs (if available) to provide auxiliary supervision to the generator. We brieﬂy describe the model components in this section. 3.1 Retriever: SCODE-R Architecture The retriever module of RED- CODER is built upon the DPR model (Karpukhin et al., 2020) and we call it SCODE-R (Summary and CODE Retriever). SCODE-R composed of two encoders that encode source code and natural lan- guage summary. We use bidirectional Transformer encoders (Vaswani et al., 2017) that are pre-trained on source code and natural language summaries. Speciﬁcally, we explore CodeBERT (Feng et al., 2020b) and GraphCodeBERT (Guo et al., 2021) as the code and summary encoders for SCODE-R. Input/Output SCODE-R takes an input se- quence x (code or summary) and retrieves a set of relevant documents from a database of output sequences Y (if the input is code, then the output Figure 4: Training scheme of the retriever module (SCODE-R) of our proposed framework REDCODER for the code generation task. Unlike in open-domain QA (Karpukhin et al., 2020), we do not use “hard” neg- atives (e.g., candidates retrieved by BM25 that do not exactly match the reference) during ﬁne-tuning. is summary and vice versa). SCODE-R returns the the top-k output sequences {Y1, Y2, . . . ,Yk}, where sim(x, Yi)≥ sim(x, Yj)∀j > i. Training We ﬁne-tune SCODE-R using a set of parallel examples (xi, yi) of code and summaries. As mentioned in Section 2.2, DPR originally pro- posed to