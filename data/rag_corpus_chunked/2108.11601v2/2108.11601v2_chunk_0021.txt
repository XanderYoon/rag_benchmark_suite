proposed that leverage retrieved in- formation along with the input code. For example, Zhang et al. (2020) retrieves similar code snippet and use those as an auxiliary input for summa- rization. On the other hand, Hayati et al. (2018) retrieves related summaries for augmenting sum- marization input. Different from these approaches, REDCODER leverages both the retrieved code and its summary to augment the input. Code Generation. Generating source code is a major stepping stone towards automated program- ming. Yin and Neubig (2017), and Rabinovich et al. (2017) proposed code generation as abstract syntax tree generation to ensure its syntactic cor- rectness. Recent advancements in pre-training lan- guage models on unlabeled source code data (Lu et al., 2021; Ahmad et al., 2021) showed colossal promise towards learning code syntax and seman- tics, resulting in improved code generation models. take roughly 30 minutes to perform the evaluation. Code Retrieval and Others. Numerous software engineering applications require information re- trieval. Sadowski et al. (2015); Xia et al. (2017); Stolee et al. (2014); Sim et al. (2011) show that developers search for related code, API examples for implementing or adapting new APIs. Design of REDCODER is inspired by developers’ behav- ior while writing code. Developers use search en- gines for retrieving off-the-shelf libraries (Hucka and Graham, 2018), or “usable” source code (Rah- man et al., 2018) for adapting in the development process (Nasehi et al., 2012; Arwan et al., 2015; Ponzanelli et al., 2014). Similarly, REDCODER retrieves existing code or summaries and adapts them to generate the target code or summary. In contrast, Hashimoto et al. (2018) optimizes a joint objective; Zhang et al. (2020); Liu et al. (2021) do not consider any decoder pre-training, Lewis et al. (2020) ﬁne-tunes both of the retriever and the generator end-to-end. For open domain QA, Izac- ard