• GPT-2, CodeGPT-2, and CodeGPT-adapted are GPT-style models that are pre-trained on natural language (Radford et al., 2019) and code corpora CodeXGLUE (Lu et al., 2021). • PLBART (Ahmad et al., 2021) is the generator module of our proposed framework. In addition, we train an LSTM based Seq2Seq model with attention mechanism (Luong et al., 2015) and a Transformer model (Vaswani et al., 2017) on the benchmark datasets. Methods CodeXGLUE (Java) CodeXGLUE (Python) Concode (Java) BLEU EM CodeBLEU BLEU EM CodeBLEU BLEU EM CodeBLEU SCODE-R 36.6 21.0 37.9 35.6 19.2 35.1 70.3 61.7 72.0 REDCODER 36.3 29.4 41.4 32.1 27.5 38.0 76.7 67.5 76.5 REDCODER-EXT 42.8 37.0 47.3 38.9 34.5 43.8 81.7 76.2 81.7 Table 5: Results on code generation keeping the target code in the retrieval database. Settings Methods Python Java RoBERTa 0.587 0.599 Cross- RoBERTa (code) 0.610 0.620 Encoder CodeBERT 0.672 0.676 GraphCodeBERT 0.692 0.691 Bi- DPR 0.093 0.064 DPR (code) 0.398 0.462Encoder SCODE-R 0.690 0.686 Table 6: MRR results on code retrieval from the val- idation and test set in CodeXGLUE. Our bi-encoder retriever SCODE-R is comparable with other cross- encoder models while it is much faster. DPR refers to Karpukhin et al. (2020) and DPR (code) is trained with BM25 “hard” negative training schema built upon our source code datasets. 5 Results 5.1 Code Generation Table 2 and Table 3 show the evaluation results on code generation from summary descriptions on CodeXGLUE, and Concode datasets, respec- tively. First, we compare REDCODER with the state-of-the-art code generation models. They are transformers models pre-trained with differ- ent objectives using external resources of differ- ent sizes. Among them, the relatively strong base- line PLBART has an EM score of 18 on the Con- code dataset while it rarely generates any code that matches the real target code in CodeXGLUE