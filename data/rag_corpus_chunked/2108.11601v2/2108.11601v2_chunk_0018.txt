results when we did not ﬁlter the target from the retrieval (summa- rization results are in Appendix). As expected, SCODE-R performances are much better than those in Table 2, 3, and 4. In all cases, RED- CODER gets more enhanced when target is present in the retrieval database. For the code generation task, we plot the recall@k curve for k upto 10 for both Java and Python on CodeXGLUE dataset when the retrieval contains the target in Figure 6. As we can see, SCODE-R signiﬁcantly out- performs in both languages and for all k values. Bi-encoder SCODE-R vs cross-encoder retriev- ers Table 6 shows the retrieval performance of different alternative retrieval techniques that we considered in REDCODER. SCODE-R performs comparably well with GraphCodeBERT while be- ing signiﬁcantly faster and scalable (Humeau et al., 2020). Note that, SCODE-R also uses Graph- CodeBERT to initialize its encoders (see Figure 4). However, SCODE-R’s design of using different encoders for query and documents enables pre- indexing of database and faster retrieval in practice. Performance vs target length Figure 7 shows the code generation performances of different mod- els w.r.t.the target code length for Python. While the generator model (PLBART)’s performance consistently decreases with increasing code size, the retriever (SCODE-R) performs consistently well. Such consistent performance from SCODE- R boosts performance of REDCODER (and also REDCODER-EXT) signiﬁcantly higher than the generative model counterpart. For Java, we ﬁnd similar results (details in Appendix). Performance vs #retrievals Figure 8 shows that typically the performance improves more with more retrievals on both tasks. However, roughly 5 Figure 7: (Python) Code gen. BLEU vs target len. CodeXGLUE (Java) gen. CodeXGLUE (Python) gen. CodeXGLUE (Java) sum. CodeXGLUE (Python) sum. Figure 8: Code gen. and sum. performance vs #re- trievals. In general performance improves with higher number of augmented candidates. code