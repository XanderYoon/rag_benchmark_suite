guage: Promise and challenges. arXiv preprint arXiv:2101.11149. Wen-tau Yih, Kristina Toutanova, John C Platt, and Christopher Meek. 2011. Learning discriminative projections for text similarity measures. In Proceed- ings of the ﬁfteenth conference on computational nat- ural language learning, pages 247–256. Pengcheng Yin and Graham Neubig. 2017. A syntactic neural model for general-purpose code generation. In Proceedings of the 55th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 440–450, Vancouver, Canada. Association for Computational Linguistics. Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, and Xudong Liu. 2020. Retrieval-based neural source code summarization. In 2020 IEEE/ACM 42nd International Conference on Software Engi- neering (ICSE), pages 1385–1397. IEEE. Supplementary Material: Appendices A Qualitative Example In Figure 11, we show an example of generated code by a baseline and different modules of RED- CODER. The input summary asks to write a code (in Java) to get a MuxerStream given a position . We show two of the corresponding retrieved code, their summaries (for bimodal instances), generated code of PLBART, REDCODER, and REDCODER-EXT. As can be seen, PLBART gen- erates a basic but relevant code; both retrieved code (rank-1 and rank-3) contains the statements with variable cPtr one of them is of MuxerStream class, and another is from DeMuxerStream class. REDCODER generates a somewhat correct code of MuxerStream class and it takes the position argument too. Seemingly, while fusing the re- trieved code, we suspect that as the tentative func- tion name MuxerStream mentioned in the in- put summary does not match the function name DeMuxerStream of the rank-3 retrieved code, it only adapts one line containing cPtr from rank-3 retrieved code (line #3) and takes the rests includ- ing the function deﬁnition (i.e., line #1) from the rank-1 retrieved code. Now when REDCODER- EXT is allowed to leverage