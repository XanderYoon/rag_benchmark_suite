are available. Yet, to incorporate information, we augment the retrieved information only in the in- put level. It does not modify the underlying archi- tecture of the generator module —preserving its model agnostic characteristics. We evaluate the effectiveness of REDCODER on two popular programming languages (Java and Python) on both code generation and code sum- marization tasks. The empirical results show that, REDCODER’s concept ofretrieval augmented gen- eration elevates the state-of-the-art code generation from an Exact Match score of 18.6 to 23.4 and the summary generation BLEU-4 score from 18.45 to 22.95 even when we forcefully remove the tar- get candidate from the retrieved code or summary. With further experiments, we establish the impor- tance of both the retrieved code and retrieves sum- mary in the generation process. The source code for reproducing our experiments are at https: //github.com/rizwan09/REDCODER. 2 Background We ﬁrst introduce the problem formulation and discuss the fundamentals of the retriever and gen- erator components that REDCODER is built upon. 2.1 Problem Formulation Our goal is two folds: (i) code generation: Gener- ating source code (C), given their natural language description, such as code summaries, code com- ments or code intents (S); (ii) code summarization: Generating natural language summaries S, given source code snippets C. Fig 2 shows an example. Let X and Y denote a collection of input and output sequences ( X = S1, . . . , Sn, Y = C1, . . . , Cn in code generation, X = C1, . . . , Cn, Y = S1, . . . , Sn in summary generation ). We as- sume that we have access to a retrieval database consisting of an extensive collection of source code (e.g., aggregated from GitHub or Stack Overﬂow) or summaries ( e.g., docstrings, code comments) (YR). Note