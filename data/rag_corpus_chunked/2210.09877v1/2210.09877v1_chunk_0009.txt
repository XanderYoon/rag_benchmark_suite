two minute overlapping segments as described in [9]. Then, we take all the relevant segments as positive documents for the different queries. As there is a substantial number of segments that are irrelevant (as the whole dataset contains 3.5 Mn segments), we down sample this data and get a negative segment set of ‚âà 14000 segments that are not relevant to any of the labelled queries. This set of positive and negative segments make up the smaller scale dataset that we use in our empirical experiments. We refer to this dataset as Podcast Small dataset. We use the Wikifier [25] to associate Wikipedia concepts to both the queries (query + description) and the podcast segments as the models in section 3.1 require. 3.4. Experiments The empirical experiments we run in this work aim to answer RQ 1 and 2. We use the Podcast Small dataset for these experiments. In a proactive information retrieval setting, the user queries are inferred from users‚Äô historical interactions. We treat the query description provided in the dataset in the place of the features extracted from the user history. We hypothesise that the query description, can be used in two ways, i) as the user context that can be used in a zero effort query to make up the context and rank relevant documents from the corpus and/or ii) as a mean to disambiguate the true meaning of a short query provided by the user without prompting the user to provide further clarifications. To answer RQ1, we aim to see if there is a significant alignment between the Wikipedia concepts present in the query and a relevant document in contrast to a non-relevant document. To measure this quantitatively, we measure the Jaccard similarity coefficient ùúå between the query and the document using the sets of Wikipedia