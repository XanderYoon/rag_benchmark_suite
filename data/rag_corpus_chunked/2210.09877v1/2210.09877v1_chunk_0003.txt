costs significantly. The next best, Dublin City University model (DCU) uses a variety of features ranging from text, WordNet based synonyms and entities for expanding the query [ 14]. As the DCU model uses automatically extracted entities (via Named Entity Recognition) to expand the query, we consider this work as the most relevant model to our proposal. But, we also annotate the segments with Wikipedia concepts/entities further differentiating our work from theirs. User queries, inherently are short, averaging two to three key words in general [15]. Exploiting auxiliary information available to recover the context of the search is essential in such scenarios. In recent competitions such as the podcast segment retrieval challenge, the queries used were accompanied by a small description that provided the contextual information about the query itself. It was evidenced that the leading models in this challenge had to use the description to extract features and sometimes use the identified keywords to make queries to external search engines to further expand the queries [9]. However, in a real world system, such information is not available. Hence a proactive IR system has to rely on the user interactions from the past to build the context [16]. In this work, we use the query context as a proxy representation extracted by a proactive IR system. Proactive information retrieval is a field in IR that gained a lot of attention recently. Supporting user information queries with minimal/zero effort will enable users to use IR systems more effectively. However, a key part of facilitating information retrieval tasks proactively is building systems that can capture the relevant signal from the user that indicate the informational needs of them. Prior works in this domain have identified several ways to harvest user intent. The simplest approach in this direction is to explicitly ask questions