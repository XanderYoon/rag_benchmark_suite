previous works have explored Wikipedia- based concept modelling for query expansion [7, 8] exclusively, our work deviates from these works as we focus on i) simultaneously adding Wiki features to the documents, ii) ranking documents with noisy texts and iii) using the query description (proxy for context extracted from user history) for query disambiguation. Latest neural ranking models dominate the state- of-the-art in IR albeit neural models struggle in the presence of noise in text [5] making much simpler, computationally efficient IR models such as BM25, DPH and PL2 much more suitable for noisy data [ 9]. Prior evidence has demonstrated the success of simpler models such as BM25 with the exception of failure on long documents [ 10]. However, more sophisticated probabilistic models such as DPH [11], motivated by the Divergence from Randomness (DFR) framework based on a hypergeometric distribution and Popper normalisation instead of Laplace normalization, have outperformed the BM25 model when it comes to noisy text [9]. This emerging need for retrieving from noisy-text has led to recent competitions such as the podcast segment retrieval challenge [12] that has paved way to improving the state-of-the-art. This competition is relevant to our work as we also tackle proactive IR in noisy text. While the best performing model within the competition uses a neural approach, it uses token embeddings rather than document embeddings [13]. The leading model uses a re-ranking model trained on an orthogonal dataset adding to computational costs significantly. The next best, Dublin City University model (DCU) uses a variety of features ranging from text, WordNet based synonyms and entities for expanding the query [ 14]. As the DCU model uses automatically extracted entities (via Named Entity Recognition) to expand the query, we consider this work as the most relevant model to our proposal. But, we also