represents the concepts extracted from the query ğ‘, description ğ‘‘ and segment ğ‘  . Ent_Wiki_rel , This model expands the DCU model by enriching the query, description and the segment with Wikipedia concepts. This formulation is presented in equation 4. ğ‘Ÿğ‘’ğ‘™(ğ‘, ğ‘‘, ğ‘ ) = ğ‘“ (ğ‘txt+ğ‘‘ent+ ğ‘wiki+ ğ‘‘wiki, ğ‘ txt+ ğ‘ wiki) (4) The two proposed models help us validate RQ2 by i) Wiki_rel model validating if replacing named-entities with Wikipedia features improves the ranking models and ii) Wiki_Ent_rel model validating if adding Wikipedia features improves the model. 3.3. Data As per section 3, we use the Podcast segment retrieval task to demonstrate usefulness of Wikipedia features in proactive information retrieval. The Spotify podcast Dataset contains approx 100,000 transcripts from around 60,000 hours of audio data culminating in the largest corpus of transcribed speech data. The episodes in the dataset were randomly sampled from 105,360 English podcast episodes published between January 1, 2019 to March 1, 2020 on Spotify with 10% of the podcasts from professional creators with high production values and the other 90% coming from amateurs [ 26]. The data is also provided with training and testing topics (queries) along with human relevance judgements. There are 8 topics in the training dataset and another 50 topics in the test set. To keep the computational costs low, we run the experiments outlined in section 3.4 exclu- sively using the training data in the podcast dataset. We first transform the dataset into two minute overlapping segments as described in [9]. Then, we take all the relevant segments as positive documents for the different queries. As there is a substantial number of segments that are irrelevant (as the whole dataset contains 3.5 Mn segments), we down sample this data and get a negative segment set of â‰ˆ 14000 segments that are not relevant