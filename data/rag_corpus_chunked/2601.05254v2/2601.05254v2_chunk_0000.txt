TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation Wenbiao Tao1, Xinyuan Li1, Yunshi Lan1, Weining Qian1 1East China Normal University Correspondence:yslan@dase.ecnu.edu.cn Abstract Retrieval-Augmented Generation enhances lan- guage models by retrieving external knowl- edge to support informed and grounded re- sponses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summariza- tion queries. GraphRAG introduces a graph- based paradigm for global knowledge reason- ing, yet suffers from inefficiencies in informa- tion extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph mainte- nance. TagRAG introduces two key compo- nents: (1) Tag Knowledge Graph Construction, which extracts object tags and their relation- ships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which re- trieves domain-centric tag chains to localize and synthesize relevant knowledge during in- ference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on Ultra- Domain datasets spanning Agriculture, Com- puter Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average winning rate of 78.36% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG. 1 Introduction Retrieval-Augmented Generation (RAG) (Lewis et al., 2020) is a framework that enhances the out- put of language models by retrieving relevant doc- uments from an external knowledge source and conditioning the generation process on both the in- put query and the retrieved content, enabling more informed and factually grounded responses (Fan Entity/Relationextraction CommunitysummarizationDocuments KnowledgeGraph NewDocuments Entity/Relationextraction DocumentsGraph Knowledge Knowledgesummarization NewDocuments Knowledgesummarization UserLLMQuestions Merge AnswersRetrieve Response：IncrementalKnowledgeInsertion：KnowledgeGraphConstruction ：Retrieval-AugmentedGeneration Figure 1: Inefficient graph construction and reasoning. et al., 2024). For Large Language Models (LLMs), RAG