Incremental analysis: winning rates (%) of TagRAG v.s. baselines with Qwen3-4B across four datasets in 10 rounds. The red horizontal line represents equilibrium and values above it indicate TagRAGâ€™s advantage. v.s. NaiveRAG v.s. GraphRAG v.s. LightRAG v.s. MiniRAG large base small large base small large base small large base small Comprehensiveness 94.0 93.7 93.1 85.3 86.0 86.1 85.1 81.5 82.3 55.2 57.5 59.9 Diversity 95.5 95.6 96.3 85.5 85.6 87.2 88.1 87.3 86.8 64.7 69.2 66.0 Empowerment 88.3 90.9 90.5 81.6 84.4 85.2 85.7 84.9 85.7 59.7 62.8 64.5 Overall 89.7 89.9 91.1 81.9 82.8 85.1 84.0 82.5 83.3 58.4 60.7 62.8 Table 3: Retriever adaption analysis: winning rates (%) of TagRAG v.s. baselines with Qwen3-4B on CS, equiped with different retrievers of bge-large-en-v1.5, bge-base-en-v1.5 and bge-small-en-v1.5. 6.4 Incremental Analysis To validate that our proposed method can accom- modate incremental scenarios, we incrementally construct a knowledge graph from 10 documents in the UltraDomain CS dataset. After each round of increment, we generate diverse questions involving all current documents to test the global reasoning capabilities of different methods. In Figure 4, Tag RAG has a steady lead over Naive RAG, Graph RAG and Light RAG, with average winning rates reaching over 80%. Even though there is a close tie with TagRAG in the first round, MiniRAG loses as the documents increase. This proves that TagRAG has a stable global inference capability in incremen- tal scenarios with multiple rounds, as the mecha- nism of tag chain fusion naturally has the advantage of infinite scaling. 6.5 Retriever adaption analysis To demonstrate that our performance does not solely depend on the effect of a powerful searcher, we perform a retriever adaption analysis. As shown in Table 3, retrievers of different sizes are applied to the comparison. Even with a lower performance retriever, TagRAG still