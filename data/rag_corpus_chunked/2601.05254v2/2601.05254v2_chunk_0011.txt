following standard evaluation on Graph-based RAG methods (Edge et al., 2024; Guo et al., 2025; Chen et al., 2025), we chose four corpus from the comprehensive UltraDomain (Qian et al., 2025) benchmark, Agriculture, CS, Legal and Mix. Fol- lowing LightRAG, we used GPT-4o-mini to gener- ate 125 global questions for each dataset, covering different domains and different tasks. The dataset details and question generation prompt can be seen in Appendix A.2 and C. To validate the performance and efficiency of global question answering, we compare TagRAG with two types of baselines.(1) Zero-shot LLM Generation:We call Qwen3-4B (Team, 2025), Qwen3-30B-A3B (Team, 2025) and Llama-3.3- 70B-Instruct (Grattafiori et al., 2024) to directly answer the questions.(2) Retrieval-Augmented Generation:NaiveRAG (Lewis et al., 2020) fo- cuses on local context through dynamic document retrieval. GraphRAG (Edge et al., 2024) utilizes entity graphs and community summaries for global 5 knowledge synthesis. LightRAG (Guo et al., 2025) is a lightweight baseline that integrates graph struc- tures with dual-level text indexing for fast and real-time updates. MiniRAG (Fan et al., 2025) achieves high efficiency on small language models via semantic-aware graph indexing and lightweight topology-based retrieval. Detailed descriptions are shown in Appendix A.3. 5.2 Evaluation Metrics Four evaluation metrics were used to assess the performance of the comparison methods:Com- prehensiveness: How much detail does the an- swer provide to cover all aspects and details of the question?Diversity: How varied and rich is the answer in providing different perspectives and in- sights on the question?Empowerment: How well does the answer help the reader understand and make informed judgments about the topic?Over- all: Which answer is better overall? We utilize the powerful model GPT-4o-mini, gemini-2.5-pro and claude-sonnet-4.5-20250929 to determine the winner for each of the two com- parison methods based on the above metrics. For each dataset, we also exchange the