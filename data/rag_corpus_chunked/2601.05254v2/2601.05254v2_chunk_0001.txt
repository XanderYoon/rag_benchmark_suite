uments from an external knowledge source and conditioning the generation process on both the in- put query and the retrieved content, enabling more informed and factually grounded responses (Fan Entity/Relationextraction CommunitysummarizationDocuments KnowledgeGraph NewDocuments Entity/Relationextraction DocumentsGraph Knowledge Knowledgesummarization NewDocuments Knowledgesummarization UserLLMQuestions Merge AnswersRetrieve Response：IncrementalKnowledgeInsertion：KnowledgeGraphConstruction ：Retrieval-AugmentedGeneration Figure 1: Inefficient graph construction and reasoning. et al., 2024). For Large Language Models (LLMs), RAG has become the most important technol- ogy to help them land effectively in the fields of medicine (Zhao et al., 2025), law (Wiratunga et al., 2024), finance (Barry et al., 2025), etc. The emergence of GraphRAG (Edge et al., 2024) solves this problem by extracting entities from doc- uments, dividing knowledge communities, and gen- erating community summaries, thereby refining global information. The new paradigm of intro- ducing knowledge summarization into RAG at the graph level makes it realistic for LLMs to gen- erate responses from a global view. However, GraphRAG still suffers from the drawbacks of in- efficient information extraction and expensive re- source calls. To solve these problems, some meth- ods, such as LightRAG (Guo et al., 2025) and KET- RAG (Huang et al., 2025b), simplify the knowledge graph structure, avoiding complicated community divisions and reducing construction costs signif- icantly. Besides, for improving the efficiency of inference, methods like MiniRAG (Fan et al., 2025) and FG-RAG (Hong et al., 2025) retrieve relevant subgraphs to generate query-aware fine-grained an- swers. However, these approaches are divorced from a global perspective. Although it is possi- ble to inject the intrinsic knowledge of LLMs into the entity in the process of building the graph, it is difficult to compensate for the comprehensive 1 arXiv:2601.05254v2 [cs.IR] 12 Jan 2026 understanding of the complete resource library. Based on the above issues, we revisit GraphRAG and present the following two research questions. • (RQ1) How to