dataset preprocessing ﬁles for MS-CO CO being unavailable 0.0 0.2 0.4 0.6 0.8 1 R ecall 0.4 0.5 0.6 0.7 0.8 0.9 1 P r ecision BLIP -2 (NF) BEIT -3 X - VLM(NF) V iL T IMR AM VSRN SCAN AD V(2048bit) AD V(64bit) UCCH D ADH (a) MS-COCO Image → Text 0.0 0.2 0.4 0.6 0.8 1 R ecall 0.4 0.5 0.6 0.7 0.8 0.9 1 P r ecision (b) MS-COCO Text → Image 0.0 0.2 0.4 0.6 0.8 1 R ecall 0.9 0.9 0.9 1.0 1.0 1 P r ecision (c) Flickr30K Image → Text 0.0 0.2 0.4 0.6 0.8 1 R ecall 0.9 0.9 0.9 1.0 1.0 1 P r ecision (d) Flickr30K Text → Image Fig. 3 : Precision-recall curves of the selected models for the (i → t) and (t → i) tasks on the MS-COCO and Flickr30K datasets by ViLT is less suitable for category-level retrieval due to both its architectural design and training approach. ViLT is trained using a binary matching approach where the model learns to distinguish correct pairings from a limited set of negative samples [ 26]. This setup trains the model to give high scores only to exact correct pairing while treating all other combinations as non-matches. However, for category-level retrieval, we need a model that can identify many relevant items that share semantic similarities with the query, not just ﬁnd the single exact match. As a result, fusion- based models like ViLT, while eﬀective at speciﬁc 10 Instance Retrieval Recall@k: Flickr30K Image to Text Text to Image @50 @100 @200 @50 @100 @200 Coarse-Grained ADV64bit 93 96.4 98.2 82.9 90.2 95.7 UCCH 68.4 81.3 88.5 68.7 80.6 89.5 DADH 8.6 16.3 28.0 8.3 15.4 26.3 T able 3 : Extended top-k retrieval results (k=50, 100, 200) for CG