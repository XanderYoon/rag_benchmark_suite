(n/a) f or these fusion-based models due to the number of relevant samples often exceeding the top-k of th eir reranking range. Hence, results for the no-fusion (NF) variants BLIP-2 and X-VLM are also provided retrieval prohibitively expensive computationally. This computational burden has driven the ﬁeld towards dual-encoder architectures, which avoid query-time attention by computing and storing embeddings independently for each modality. For fusion-reranking, the time complexity is O(n × k), where k is the reranking shard threshold, which leads to improved costs relative to full atten- tion. In the case of BLIP-2 and X-VLM, we kept k = 128 irrespective of the increase in sample size, which leads to a linear increase in attention computation time. However, if the k value were also scaled to the number of retrieval candidates, the computational complexity would approximate O(n × m). Such attention mechanisms, therefore, may be impractical for large-scale applications where query latency is critical. 5.4 Scaling similarity search with F AISS The ﬁnal step in retrieval, similarity search, is typically independent of the encoding model. Assuming no query-time attention or reranking, the model’s task is complete once samples are encoded. These encoded samples are then typi- cally passed to a separate specialised similarity search implementation. In that case, the only factors aﬀecting similarity search time are the embedding type (real-valued continuous or bitwise hash code embeddings) and the embedding dimen- sions. To explore the practical implications of using CG binary hash codes compared to FG con- tinuous embeddings, we employ Facebook AI Sim- ilarity Search (F AISS) [ 53], a robust and widely adopted [ 54–56] similarity search implementa- tion oﬀering various indexes for both exhaus- tive search and Approximate Nearest Neighbour Search (ANNS). By using F AISS, we transition 12 Encoding Time Size (1M/5M) Img/Txt 1K/5K 10K/50K 100K/500K 1M/5M