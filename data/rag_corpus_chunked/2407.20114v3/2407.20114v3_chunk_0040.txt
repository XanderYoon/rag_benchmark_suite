Part V 13, Springer, pp 740–755, https://doi.org/10.1007/978-3-319-10602-1 48 [14] Faghri F, Fleet DJ, Kiros JR, et al (2017) VSE++: Improving visual-semantic embed- dings with hard negatives. In: Proceedings of the British Machine Vision Conference, p 12, https://doi.org/10.48550/arXiv.1707.05612 [15] Kiros R, Salakhutdinov R, Zemel RS (2015) Unifying visual-semantic embed- dings with multimodal neural language models. Transactions of the Association for Computational Linguistics pp 1–13. 17 https://doi.org/10.48550/arXiv.1411.2539 [16] Simonyan K, Zisserman A (2015) Very deep convolutional networks for large- scale image recognition. International Conference on Learning Representations https://doi.org/10.48550/arXiv.1409.1556 [17] He K, Zhang X, Ren S, et al (2016) Deep residual learning for image recognition. In: Proceedings of the IEEE conference on com- puter vision and pattern recognition, pp 770– 778, https://doi.org/10.1109/CVPR.2016.90 [18] Lee KH, Chen X, Hua G, et al (2018) Stacked cross attention for image-text matching. In: Proceedings of the European Conference on Computer Vision (ECCV), pp 201–216, https://doi.org/10.1007/978-3-030-01225-0 13 [19] Ren S, He K, Girshick R, et al (2015) Faster R-CNN: Towards real-time object detection with region proposal networks. Advances in neural information processing systems 28. https://doi.org/10.1109/TPAMI.2016.2577031 [20] Wang Z, Liu X, Li H, et al (2019) CAMP: Cross-modal adaptive message pass- ing for text-image retrieval. In: Proceed- ings of the IEEE/CVF international con- ference on computer vision, pp 5764–5773, https://doi.org/10.1109/ICCV.2019.00586 [21] Li K, Zhang Y, Li K, et al (2019) Visual semantic reasoning for image- text matching. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp 4654–4662, https://doi.org/10.1109/ICCV.2019.00475 [22] Li K, Zhang Y, Li K, et al (2022) Image-text embedding learning via visual and textual semantic reasoning. IEEE Transactions on Pattern Analysis and Machine Intelligence 45(1):641–656. https://doi.org/10.1109/TPAMI.2022.3148470 [23] Devlin J, Chang MW, Lee K, et al (2019) BERT: Pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the 2019 Conference of the North American Chapter