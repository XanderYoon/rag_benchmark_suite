hybrid coarse-to-ﬁne approaches that leverage insights from this study to bal- ance retrieval performance and eﬃciency. These directions aim to further bridge the gap between FG and CG methodologies, potentially leading to more robust and scalable image-text retrieval systems. Declarations Code availability . The source code for the FiCo-ITR library and toolkit can be found in the project’s GitHub repository: https://github.com/MikelWL/FiCo-ITR. Conﬂict of interest. The authors declare no Conﬂict of interest. Ethical approval. This article contains no data or other information from studies or experimenta- tion involving human or animal subjects. 16 References [1] Ma H, Zhao H, Lin Z, et al (2022) EI-CLIP: Entity-aware interventional contrastive learning for e-commerce cross-modal retrieval. In: IEEE/CVF Con- ference on Computer Vision and Pattern Recognition (CVPR), pp 18030–18040, https://doi.org/10.1109/CVPR52688.2022.01752 [2] Zhang Y, Wang Q, Pan P, et al (2021) Fashion focus: Multi-modal retrieval sys- tem for video commodity localization in e-commerce. In: AAAI Conference on Artiﬁcial Intelligence, pp 16127–16128, https://doi.org/10.1609/aaai.v35i18.18033 [3] Nakatsuka T, Hamasaki M, Goto M (2023) Content-based music-image retrieval using self-and cross-modal feature embed- ding memory. In: Proceedings of the IEEE/CVF Winter Conference on Appli- cations of Computer Vision, pp 2174–2184, https://doi.org/10.1109/W ACV56688.2023.00221 [4] Gong Y, Cosma G, Finke A (2023) Neural-based cross-modal search and retrieval of artwork. In: 2023 IEEE Symposium Series on Computa- tional Intelligence (SSCI), pp 264–269, https://doi.org/10.1109/SSCI52147.2023.10371948 [5] Yang Y, Shang X, Li B, et al (2024) Detection-free cross-modal retrieval for person identiﬁcation using videos and radar spectrograms. IEEE Transactions on Instrumentation and Measurement https://doi.org/10.1109/TIM.2024.3372210 [6] Truong QT, Salah A, Tran TB, et al (2021) Exploring cross-modality uti- lization in recommender systems. IEEE Internet Computing 25:50–57. https://doi.org/10.1109/MIC.2021.3059027 [7] Gan Z, Li L, Li C, et al (2022) Vision- language pre-training: Basics, recent advances, and future trends. Foun- dations and Trends ® in Computer Graphics and Vision 14(3–4):163–352.