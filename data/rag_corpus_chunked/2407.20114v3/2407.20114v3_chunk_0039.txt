spectrograms. IEEE Transactions on Instrumentation and Measurement https://doi.org/10.1109/TIM.2024.3372210 [6] Truong QT, Salah A, Tran TB, et al (2021) Exploring cross-modality uti- lization in recommender systems. IEEE Internet Computing 25:50–57. https://doi.org/10.1109/MIC.2021.3059027 [7] Gan Z, Li L, Li C, et al (2022) Vision- language pre-training: Basics, recent advances, and future trends. Foun- dations and Trends ® in Computer Graphics and Vision 14(3–4):163–352. https://doi.org/10.1561/9781638281337 [8] Luo X, Wang H, Wu D, et al (2023) A survey on deep hashing methods. ACM Transactions on Knowledge Discovery from Data 17(1):1– 50. https://doi.org/10.1145/3532624 [9] Chen H, Ding G, Liu X, et al (2020) IMRAM: Iterative matching with recur- rent attention memory for cross-modal image-text retrieval. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 12655–12663, https://doi.org/10.1109/CVPR42600.2020.01267 [10] Hu P, Zhu H, Lin J, et al (2022) Unsu- pervised contrastive cross-modal hashing. IEEE Transactions on Pattern Analysis and Machine Intelligence pp 3877–3889. https://doi.org/10.1109/TPAMI.2022.3177356 [11] Zhu L, Wang T, Li F, et al (2023) Cross- modal retrieval: A systematic review of meth- ods and future directions. arXiv preprint https://doi.org/10.48550/arXiv.2308.14263 [12] Plummer BA, Wang L, Cervantes CM, et al (2015) Flickr30k entities: Collect- ing region-to-phrase correspondences for richer image-to-sentence models. In: Pro- ceedings of the IEEE international confer- ence on computer vision, pp 2641–2649, https://doi.org/10.1109/ICCV.2015.303 [13] Lin TY, Maire M, Belongie S, et al (2014) Microsoft COCO: Common objects in context. In: Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Pro- ceedings, Part V 13, Springer, pp 740–755, https://doi.org/10.1007/978-3-319-10602-1 48 [14] Faghri F, Fleet DJ, Kiros JR, et al (2017) VSE++: Improving visual-semantic embed- dings with hard negatives. In: Proceedings of the British Machine Vision Conference, p 12, https://doi.org/10.48550/arXiv.1707.05612 [15] Kiros R, Salakhutdinov R, Zemel RS (2015) Unifying visual-semantic embed- dings with multimodal neural language models. Transactions of the Association for Computational