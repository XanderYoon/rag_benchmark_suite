→ t) and (t → i) tasks—suggest that CG models have room to be used as initial retrieval candidate screening steps, provided the eﬃciency gained by employing such a strategy outweighs the information that is lost in this initial screening step. CG limitations. The CG models DADH and UCCH were unable to properly capture instance- level relationships compared to the FG ones, as evidenced by their achieved R@1 scores (Table 2). Speciﬁcally, on the Flickr30K dataset, DADH achieves R@1 scores of 0.1% for (i → t) and 0.2% for (t → i) retrieval, while UCCH achieves R@1 scores of 12.7% and 8.7%, respectively. On the larger MS-COCO dataset, DADH achieves an R@10 score of 4.7% for (i → t) and 3.0% for (t → i) retrieval, whereas UCCH achieves R@10 scores of 26.5% and 24.5%, respectively. This limited recall performance is primarily due to the objec- tive function of these coarse models not targeting instance-level retrieval. Model comparison and attention mecha- nisms. The recall performance diﬀerence between models employing query-time attention (BLIP-2, X-VLM, ViLT, IMRAM, SCAN) and those that do not is notable for its limited magnitude. In the case of pretrained models, the state-of-the- art fusion-reranking model BLIP-2 outperforms the dual-encoder model BEIT-3 by a moderate R@1 diﬀerence of 6.4 and 6.9 on the MS-COCO (i → t) and (t → i) tasks, respectively. The eﬀec- tiveness of dual-encoder architectures is further evidenced by BEIT-3 achieving superior perfor- mance across all evaluation metrics compared to the full fusion-based ViLT, demonstrating that competitive retrieval performance can be attained without extensive inter-modal interaction at query time. Similarly, among non-pretrained models, the cross-attention model IMRAM outperforms the global-representation model VSRN by a modest R@1 diﬀerence of 4.2 for the MS-COCO (i → t) task and 1.6 for (t → i) task. Whether