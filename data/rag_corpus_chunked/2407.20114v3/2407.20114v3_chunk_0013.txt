as the negative normalised count of dif- fering bits: − ∑(x ̸= y)/n where n is the bit length • Inner product similarity x ·y, particularly suit- able for embeddings trained with dot-product- based loss functions For traditional binary hash codes (0s and 1s), we implement Hamming distance which calcu- lates the number of diﬀering bits between two hash codes eﬃciently on CPUs. The library also supports hash codes represented as -1s and 1s, enabling the use of inner product, cosine simi- larity, and Euclidean distance. This design choice allows users to leverage GPU acceleration for hash code comparisons, potentially boosting perfor- mance in GPU-centric environments. For contin- uous embeddings, all measures except Hamming distance are applicable. 4) Retrieval tasks. Given a similarity matrix, FiCo-ITR implements two retrieval task 6 evaluations: Instance-level retrieval and category- level retrieval. For the instance-level retrieval task, the objective is to search for the retrieval sample which directly corresponds to the query sample. Given an image with multiple captions, for the (i → t) task, retrieving any one of the multiple captions of the query image is considered a 100% recall. For the (t → i) task, the speciﬁc image cor- responding to the query caption must be retrieved for the query to be correct. For the category-level retrieval task, the objective is to retrieve samples that share at least one of multiple semantic cate- gory labels with the query sample. This approach results in a broader deﬁnition of relevance, where a large amount of samples in the retrieval set may be considered relevant to a given query based on shared category labels. 5) Evaluation metrics. With the retrieval results produced by the retrieval tasks, for instance-level retrieval, we use recall at k (R@k) as the primary retrieval performance metric, deﬁned as follows: R@k =