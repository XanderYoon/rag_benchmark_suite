For CG models, FiCo-ITR provides the toolkit to extract 4096D VGG-19 features for images and 300D Doc2Vec features for text. Images are preprocessed by resizing to VGG-19’s expected 224× 224 pixels and applying standard normal- isation (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]). The VGG-19 network, pretrained on ImageNet, has its ﬁnal three layers removed to obtain the feature vectors. Text features are generated using Doc2Vec trained on the combined training and test captions, with minimum word count thresholding to handle vocabulary sparsity. For traditional FG models, we refer to the Bottom- Up Attention [ 50] repository for Faster R-CNN to extract 36 region proposals per image with 1024- dimensional features, whereas the raw text is given as input to each model’s speciﬁc encoder. VLP models process raw data using their respective transformer encoder stacks. 2) Model encoding interface. The frame- work provides standardised interfaces for han- dling model outputs while maintaining evaluation consistency across diﬀerent encoding approaches. While the actual encoding process is model- speciﬁc and outside the scope of our framework, FiCo-ITR implements pre-encoding dataset man- agement and post-encoding output handling. For 5 Fig. 2 : An extendable framework of the FiCo-ITR library and toolkit. The p ipeline consists of ﬁve main components: 1) Data Pre-Processing, which standardises da taset handling and oﬀers optional label generation via Query2Label (Q2L) [ 49] for unlabeled datasets; 2) Model Encoding, supporting embeddin gs in the form of binary hash codes and continuous embeddings, as well as direct similarity matrices; 3) Similarity Measures, implementing four distance measures for unifor m similarity calculation; 4) Retrieval Tasks, implementing instance- and category-level retrieval for b oth (i → t) and (t → i); and 5) Evaluation Metrics, reporting Recall@K for instance-level retrieval and mAP@ K with P/R curves for category-level retrieval dataset management, the toolkit provides