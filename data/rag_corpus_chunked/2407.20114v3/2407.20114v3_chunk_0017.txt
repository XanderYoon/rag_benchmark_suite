steps where their top-k results are passed to a FG model for further reranking. For category-level retrieval, we employ mAP@10, mAP@100, and mAP@N (where N is the total number of retrieval candidates), oﬀering a comprehensive view of per- formance across increasing retrieval depths while having several relevant samples available. To fur- ther illustrate the trade-oﬀ between precision and recall in category-level retrieval, we include 11- point interpolated precision-recall curves. 5 Comparative experiments 5.1 Instance-level retrieval results This experiment aims to empirically assess the comparative performance of CG and FG models in instance-level retrieval tasks. Through the use of the proposed FiCo-ITR library, the instance- level Recall@k evaluation results for the selected models on the Flickr30K and MS-COCO datasets are reported in Table 2, with additional results at higher top-k levels for the CG models being reported in Table 3. From these results, the fol- lowing observations can be made: Where CG succeeds. The model ADV in its 64-bit CG setting achieves moderate success, with R@10 scores of 75.0% for (i → t) and 60.5% for (t → i) retrieval. The improvement of ADV over DADH and UCCH can primarily be attributed to adopting instance-level matching as the primary objective function. In its 2048-bit hash code FG setting, ADV achieves retrieval performance com- parable to other continuous embedding-based FG models (Table 2). The extended top-k results in Table 3—where ADV 64bit attains R@100 scores of 96.4% and 90.2% for the (i → t) and (t → i) tasks—suggest that CG models have room to be used as initial retrieval candidate screening steps, provided the eﬃciency gained by employing such a strategy outweighs the information that is lost in this initial screening step. CG limitations. The CG models DADH and UCCH were unable to properly capture instance- level relationships compared to the