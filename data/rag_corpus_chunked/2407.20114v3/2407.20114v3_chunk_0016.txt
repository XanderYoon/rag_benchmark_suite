the key architectural approaches in ITR (as detailed in Table 1). Our model selection thus aims to span the architectural spectrum: For VLP models, we include the fusion-encoder ViLT [ 26], dual-encoder BEiT-3 [ 28], and hybrid dual+fusion rerank models BLIP-2 [ 32] and X- VLM [ 52]. Traditional FG models are represented through both local+global attention (IMRAM [ 9], SCAN [18]) and global-only attention (VSRN [ 21]) approaches, while CG models cover the main paradigms: supervised (DADH [ 39]), unsupervised (UCCH [ 10]), and quantisation-based (ADV [ 48]) approaches. Some eﬃciency-focused VLP models 7 of interest (LightningDot [ 33], VLDeformer [ 34], and HiVLP [ 35]) could not be included due to practical constraints such as inaccessible data dependencies or lack of public implementations. To partially address this gap, we implement dual- encoder-only variants of BLIP-2 and X-VLM to promote eﬃciency (BLIP-2 NF and X-VLM NF). Additionally, we evaluate ADV in two conﬁgura- tions: as a CG model with 64-bit hash codes and as a FG model with 2048-bit codes. Table 1 provides a detailed overview of the architectural character- istics and computational requirements across our model selection. Evaluation metrics. We use the following conﬁgurations of the metrics implemented in the FiCo-ITR library for our experiments: Instance- level retrieval performance is assessed using R@1, R@5, and R@10. Additionally, we explore R@50, R@100, and R@200 for the CG models to exam- ine the viability of their use case as ﬁrst-screening steps where their top-k results are passed to a FG model for further reranking. For category-level retrieval, we employ mAP@10, mAP@100, and mAP@N (where N is the total number of retrieval candidates), oﬀering a comprehensive view of per- formance across increasing retrieval depths while having several relevant samples available. To fur- ther illustrate the trade-oﬀ between precision and recall in