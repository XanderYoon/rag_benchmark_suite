is the author’s version for arXiv. 2 machinery of epistemic suppression. And in A Scanner Darkly, the protagonist’s mind is split, caught between competing realities, unable to trust even its own perceptions. Today, AI systems – designed to optimize clarity and reinforce coherence – risk becoming the new Ministry of Truth, delivering seamless, authoritative answers that conceal the complexities of knowledge rather than illuminating them [Deliu 2025]. As Aldous Huxley warned in Brave New World, the greatest threat to human autonomy may not come from overt oppression but from pleasure-driven compliance [Huxley 1932]. Technology, in such a system, becomes a tool of social conditioning – shaping behavior, numbing re sistance, and manufacturing a passive consensus through comfort and efficiency. But what if AI did not pacify the mind, but unraveled it? What if, instead of acting as an oracle of certainty, it functioned as an engine of doubt – an architect of cognitive dissonance ? This paper introduces Cognitive Dissonance AI (CD -AI): an AI designed not to provide comfort, but to create conflict – not to resolve contradictions, but to sustain them. In a world dominated by algorithmic reinforcement of belief, CD-AI challenges the very foundations of human cognition. It compels users to engage in epistemic struggle, question their biases, and navigate the unstable terrain of contradictory truths. Rather than delivering the illusion of knowledge, it forces users to fight for it. AI has become a fundamental component of human reasoning, aiding decision-making in business, scientific research, law, ethics, and public policy [Deliu 2024, 2025; Tiron-Tudor et al. 2025]. AI-augmented reasoning systems are typically designed to optimize clarity, reduce cognitive strain, and enhance structured judgment through fact -checking, logical inference, and argument synthesis. While such systems improve efficiency, they may also weaken users’ ability to engage with uncertainty and