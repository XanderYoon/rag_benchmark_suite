engage with contradiction through guided exposure, they become more open to opposing perspectives and develop more reflective cognition. Yet, most current AI systems are optimized for cognitive ease (i.e., delivering fast, confirmatory answers that reinforce biases and discourage epistemic struggle). CD-AI proposes a shift. Rather than resolving tension prematurely, AI should introduce controlled cognitive dissonance – deliberately sustaining contradiction to promote deeper reflection. This approach aligns with the principle of productive struggle in education: temporary discomfort fosters long-term learning [Bjork & Bjork 2011]. 2.3 CD and HAII In HAII, CD often emerges when AI -generated outputs clash with a user’s expectations or existing beliefs. While large language models (LLMs) like GPT-4 are optimized to generate coherent and plausible answers, research shows users often resist outputs that challenge their views [Rahwan et al. 2019]. Take, for example, an AI that supports a controversial economic policy. A user who opposes it may reject the response, question the AI’s credibility, or reinforce their preexisting stance. This reveals a core challenge: if AI aligns too closely with the user (and its biases), it risks becoming an echo chamber; if it pushes too hard and challenges users too aggressively, it risks alienation (Figure 2). CD-AI navigates this tension by introducing dissonance in a controlled and reflective way: (i) encouraging engagement, not rejection, of opposing viewpoints; (ii) delaying closure, giving users space to reflect before deciding; (iii) moderating discomfort, sustaining CD without cognitive overload. Figure 2. Echo AI affirms; CD-AI engages. Rather than resolving contradiction instantly or avoiding it entirely, CD -AI acts as a reasoning partner – not just a passive information source. This approach reflects argumentative reasoning models, which suggest humans think best not in isolation, but through structured intellectual dialogue [Lippi & Torroni 2016; Mercier & Sperber 2017]. 5 2.4 The Neuroscience of