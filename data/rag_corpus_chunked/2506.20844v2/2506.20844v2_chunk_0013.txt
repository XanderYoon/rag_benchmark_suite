to use a fixed re- trieval cut-off (i.e., selecting a predefined number of top-ranked documents for verification). One of the most inefficient approaches is setting the cut-off equal to the maximum number of evidence per claim in the dataset, ensuring that all possible evidence is re- trieved. This heuristic has not previously caused major issues since general fact-checking datasets contain a relatively balanced num- ber of supporting documents per claim. However, the imbalance in SciFact-Open suggests that the simple approach may not be suitable for open-domain scientific fact-checking with two major drawbacks: (1) Inefficiency.Although the maximum number of gold evi- dence documents in the SciFact-Open dataset is 24, less than one third of claims have more than two. Using the maximum number as a cut-off would be inefficient due to the large number of documents that would have to be processed by the verifier. (2) Inaccuracy.Introducing irrelevant evidence into downstream verification degrades fact-checking performance, whether the noise is semantically related or completely random [76] (as discussed in Section 2). To address these challenges in the current and future studies of scientific fact-checking, we proposed a research direction based on flexible cut-off strategy for retrieving evidence based on claim characteristics. RD.2. Flexible cut-off for Retrieved Evidence Ranked List Truncation (RLT) refers to the task of selecting an opti- mal prefix of a ranked list of retrieved documents, with the goal of balancing retrieval effectiveness and efficiency. Prior work explores both heuristic and learned approaches, using either relevance labels or features derived from score distributions to determine the cut-off point [10, 52, 59, 61, 103, 109]. A related line of work is stopping methods in technology-assisted review (TAR) [14, 15, 85], which aim to retrieve as much relevant information as possible while min- imising the effort spent on examining irrelevant documents. Both