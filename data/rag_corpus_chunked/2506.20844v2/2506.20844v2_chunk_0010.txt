and approximately 2 in SciFact-Open. To illustrate this improvement, we conducted a case study examining how different retrieval methods ranked specific evidence documents (Table 2). Compared to monoT5-3B, +Verifi- cation successfully elevated the ranks of E2, E3 and E5, retrieving three additional pieces of evidence within the top 5 results. Notably, E5, ranked 302nd by monoT5-3B, was effectively rescued by adding verification feedback in +Verification, demonstrating the value of integrating verification-informed retrieval signals. These findings highlight a promising research direction: shift- ing from semantic-only retrieval towards evidence-aware retrieval, where retrieval models explicitly account for evidential value. Our results suggest that leveraging well-performing verification models can help refine retrieval systems by distinguishing between purely ICTIR â€™25, July 18, 2025, Padua, Italy Xingyu Deng, Xi Wang, Mark Stevenson semantic relevance and plausible evidential relevance among unan- notated documents. Furthermore, to continually improve evidence- aware retrieval, we propose the development of tailored IR systems capable of identifying evidential information, thereby enhancing evidence retrieval for scientific fact-checking. RD.1. Benchmark tailored IR system for fact-checking The preliminary study presented in this work outlined a framework to enhance evidence retrieval beyond only semantic relevance. To overcome the limitations of existing IR systems in scientific fact- checking scenarios, it is imperative to develop specialised IR sys- tems capable of handling the specific challenges of verification tasks. However, training an IR system on a single fact-checking dataset risks poor generalizability and potential overfitting, particularly due to data imbalance, a common issue in the relatively small datasets characteristic of scientific fact-checking [ 97, 116]. Furthermore, poor verification performance deteriorates retrieval accuracy, cre- ating a vicious feedback loop that further degrades overall system effectiveness. A multi-pronged strategy could mitigate these chal- lenges by pooling verification signals from various high-performing verifier models, leveraging large-scale datasets such as FEVER [90] to improve