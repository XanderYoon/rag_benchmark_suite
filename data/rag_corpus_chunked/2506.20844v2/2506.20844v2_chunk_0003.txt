set- tings that employ rich, diverse and timely evidence sources, as seen in FEVER (using Wikipedia) [90] and AVeriTeC (using web-wide resources) [78]. In document level evidence retrieval, current arXiv:2506.20844v2 [cs.IR] 29 Jun 2025 ICTIR ’25, July 18, 2025, Padua, Italy Xingyu Deng, Xi Wang, Mark Stevenson general fact-checking systems over-rely on commercial search APIs, which do not consider the specific requirements of fact-checking [77, 91, 116]. Such reliance on commercial search APIs – with lim- ited adaptability – has left document retrieval methodologies under- explored in fact-checking, especially for domain-specific corpora such as scientific fact-checking. Current scientific fact-checking sys- tems primarily employ off-the-shelf IR methods [97], such as lexical matching and semantic relevance ranking, which do not scale effec- tively for large-scale scientific corpora. In addition, the distribution of relevant evidence across scientific topics is highly imbalanced, which degrades both retrieval effectiveness and efficiency, espe- cially for claims with scarce supporting literature. SciFact-Open [101], which extends the original SciFact dataset [ 100] for large- scale evaluation, illustrates this issue: verification performance on SciFact-Open drops by at least 15 F1 points for all well-performed fact-checking systems developed in SciFact [101]. While increasing corpus size enhances evidence diversity, it also amplifies retrieval noise, reducing efficiency in both retrieval and verification. Beyond that, high semantic relevance does not guarantee high evidential relevance, and irrelevant yet semantically similar documents can introduce noise into downstream verification [ 117]. These chal- lenges underscore the necessity of developing tailored document retrieval systems specifically designed for scientific fact-checking, as effective retrieval is a prerequisite for accurate claim verification. Beyond document-level evidence retrieval, within-document evidence retrieval is also essential for processing complex sci- entific literature. Scientific papers, unlike general fact-checking documents, are long, structured, domain-specific and involve addi- tional metadata. As scientific fact-checking evolves from abstract- based to