two components: 1) the semantic relevance score, computed using an off-the-shelf reranker model, and (2) the verification success feedback score, derived from a fine-tuned verifier model, indicating the degree to which a docu- ment is evidential for a given claim. The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers ICTIR â€™25, July 18, 2025, Padua, Italy Document Reranker Top-k documents Verification NEI Support Refute 0.1 0.2 0.7 Claim 0.8 0.86 Retrieved documents 0.92 0.31 0.07 0.04 0.02 0.01 relevance scores verification feedback monoT5-3B MultiVerS rerank Figure 1: Pipeline of experiment Approaches. monoT5-3B [64] has demonstrated strong perfor- mance as a reranker for SciFact, as evidenced by its widespread use as a strong baseline in studies [55, 86] on the BEIR benchmark [89]. It also demonstrated state-of-the-art performance in evidence retrieval for verification [68, 97, 102]. The model assigns a predicted score, ğ‘ ğ‘Ÿ ğ‘,ğ‘‘, representing the semantic relevance for a document ğ‘‘ to a claim ğ‘ as defined in Equation 1. ğ‘“ (ğ‘, ğ‘‘) â†’ ğ‘ ğ‘Ÿ ğ‘,ğ‘‘, ğ‘  ğ‘Ÿ ğ‘,ğ‘‘ âˆˆ ( 0, 1) (1) MultiVerS is the best-performing verifier model on SciFact [ 97, 102]. We reproduced this model using the official implementation1 while adjusting the negative sampling parameter from 20 to 5 to avoid over-fitted verification feedback. The model predicts the veri- fication outcome as per the calculated probabilities for a document ğ‘‘ either supporting ğ‘ğ‘Ÿ ğ‘,ğ‘‘, refuting ğ‘ğ‘  ğ‘,ğ‘‘ or providing insufficient in- formation ğ‘ğ‘› ğ‘,ğ‘‘, relative to a claim ğ‘, as follows: ğ‘‰ (ğ‘, ğ‘‘) = ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ (ğ‘ğ‘Ÿ ğ‘,ğ‘‘, ğ‘ğ‘› ğ‘,ğ‘‘, ğ‘ğ‘  ğ‘,ğ‘‘ ) (2) +Verification (Ideal Reranker Model) combines semantic relevance and verification feedback to refine evidential retrieval. The final retrieval score is calculated by summing the semantic score (ğ‘ ğ‘Ÿ ğ‘,ğ‘‘) and the verification probabilities (ğ‘ğ‘Ÿ ğ‘,ğ‘‘ and ğ‘ğ‘› ğ‘,ğ‘‘), followed