multi- modal representation. Chen et al. (2020b) first select the most salient items of a table to construct the BERT representation for the table search, where different types of table items and salient signals are tested. The proposed content selection technique improves the performance of ad-hoc table retrieval. On the other hand, using the que- ries to select the table content can lead to a significant increase in the processing time because extracting data table representations cannot be performed offline. Trabelsi et al. (2020b) proposed to include summary vectors about the contents of the table, both in terms of values in each column and values in selected rows. The summary vec- tors compress each row and each column into a fixed length feature vector using word embedding of data values. Inspired by recent progress of transfer learning on graph neural networks, Trabelsi et al. (2020c) proposed to represent a large collection of data tables using graphs. In particular, a knowledge graph representation using fact triples < subject, predicate, object> indicates the relations between entities, then R-GCN (Schlichtkrull et al., 2018), which is an extension of GCN for knowledge graphs, is applied on knowledge graphs to learn representations for graph nodes and relations. Information Retrieval Journal 1 3 8.2 Question‑answering Question-answering (QA) (Diefenbach et al., 2018; Lai et al., 2018; Wu et al., 2019) is the task that focuses on retrieving texts that answer a given user’s question. The extracted answers can have different lengths, and vary from short text, passage, paragraph or docu- ment. QA also includes choosing between multiple choices, and synthesizing answers from multiple resources in case the question looks for multiple pieces of information. The QA problem presents multiple challenges. The question is expressed in natural lan- guage, and the objective is to search for short answers