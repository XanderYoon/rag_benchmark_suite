The main neural components that led to the breakthrough in mul- tiple fields are convolutional and recurrent neural networks. Information retrieval (IR) also benefits from deep neural network models leading to state-of-the-art results in multiple tasks. * Mohamed Trabelsi mot218@lehigh.edu Zhiyu Chen zhc415@lehigh.edu Brian D. Davison davison@cse.lehigh.edu Jeff Heflin heflin@cse.lehigh.edu 1 Computer Science and Engineering, Lehigh University, Bethlehem, PA, USA Information Retrieval Journal 1 3 Retrieval models take as input a userâ€™s query, and then present a set of documents that are relevant to the query. In order to return a useful set of documents to the user, the retrieval model should be able to rank documents based on the given query. This means that the model ranks the documents using features from both the query and documents. Traditional ranking models for text data might utilize OKAPI/BM25 (Robertson et al., 1994) which computes the score of matching between the query and document based in part on the presence of query terms in each document. Machine learning algorithms can learn ranking models, and the input to these models are a set of often hand-crafted features. This setting is known as learning to rank (LTR) using hand-crafted features. These features are domain specific and time-consuming in terms of defining, extracting, and validating a set of specific features for a given task. In order to overcome the limitations of using hand- crafted features, researchers proposed deep ranking models that accept raw text data as an input and learn suitable representations for inputs and ranking functions. A key feature in information retrieval models is the relevance judgement. A ranking model with sufficient capacity is needed to capture the matching signals, and map doc- ument-query pairs to accurate prediction of a real-valued relevance score. Deep neural networks are known for their ability to capture complex