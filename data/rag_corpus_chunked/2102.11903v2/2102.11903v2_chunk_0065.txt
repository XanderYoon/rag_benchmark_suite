typical scenario is to have a query that contains keywords. In such cases, the relevance matching is needed to achieve better retrieval results. Relevance matching is introduced by Guo et al., (2016) to solve the case of heteroge- neous query and document in ad-hoc document retrieval. The query can be expressed by keywords, so a semantic signal is less informative in this case because the composition and grammar of a keyword-based query are not well defined. In addition, the position of a given token in a query has less importance than the strength of the similarity signal, so some neural ranking models, like DRMM (Guo et al., 2016), do not preserve the position information when computing the query-document feature vector. An important signal in the relevance matching is the exact matching of query and document tokens. In traditional retrieval models, like BM25, exact matching is primarily used to rank a set of documents, and the model works reasonably well as an initial ranker. Incorporating exact matching into neural ranking models can improve the retrieval performance mainly in terms of recall for keyword-based queries because as in traditional ad-hoc document retrieval, the document has more content than the query and the presence of query keywords in a document is an initial indicator of relevance. From the review of many neural ranking models, we can conclude that both seman- tic and relevance matching signals are important to cover multiple scenarios of ad-hoc retrieval tasks. This is empirically justified by achieving significant improvements in retrieval results when using neural ranking models that guarantee both matching signals. For example, the joint model, proposed by MacAvaney et al. (2019), combines the repre- sentation of [CLS] from BERT and existing relevance-based neural ranking models. This model has a semantic matching signal from [CLS] because BERT is