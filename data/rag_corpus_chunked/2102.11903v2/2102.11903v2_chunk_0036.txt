a passage of a document to be rel- evant to a query. A neural architecture should be able to capture local matching patterns. Also, a neural ranking model should incorporate query context into the ranking model in order to solve the ambiguity problem. For example, the query “river bank” should have a lower relevance score with a sentence or passage containing “withdrawal from the bank” despite having the word “bank” in common. For the first step of the query-centric assumption, DeepRank assumes that the relevance occurs around the exact matching positions of query tokens in a document as shown in Fig. 5. The local relevance signal in the second step is measured using CNN filters with all possible combinations of widths and heights that are applied to the local interaction tensor. DeepRank encodes the position of the query-centric context using the document location that a query token matches exactly; this feature is appended to the CNN feature map to obtain the query-centric feature vector for each exact matching position. Finally, in the third step, DeepRank aggregates the local relevance in two phases. In the first phase, query-centric features of a given query token are passed through LSTM or GRU to obtain a relevance representation for each query token. Then, in the second phase, a Term Gat- ing Network is used to globally aggregate relevance representations of query tokens as in DRMM. DeepRank only considers query context for tokens that have an exact match in a given document, so it ignores query tokens that have similar meaning to a word in a document. Fig. 5 Query-centric assumption. The sentences that are used in this example are extracted from Wikipe- dia. Each query token is shown with a different color that corresponds to the query-centric context in the document. A binary judgement