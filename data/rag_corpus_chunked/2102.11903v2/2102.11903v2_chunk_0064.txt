the contextual information of frames after extracting frame-based features using pretrained CNN. As in BERT where the self-attention is used to capture token interactions, Yang et al. (2020) introduce a multi-head self-attention for video frames. So, this neural ranking model for video retrieval covers multiple proposed categories for the document retrieval which are: representation-focused models, context-aware based representation, and attention-based representation (with both attention and self-attention). 9 Lessons learned and future directions In this section, we summarize the important signals and neural components that are incor - porated into the neural ranking models, and we discuss potential research ideas for docu- ment retrieval. Information Retrieval Journal 1 3 9.1 What are the important matching signals in document retrieval? The neural ranking models that are previously described present two important matching techniques: semantic matching and relevance matching (Guo et al., 2016). Semantic match- ing is introduced in multiple text matching tasks, such as natural language inference, and paraphrase identification. Semantic matching, which aims to model the semantic similar - ity between the query and the document, assumes that the input texts are homogeneous. Semantic matching captures composition and grammar information to match two input texts which are compared in their entirety. In information retrieval, the QA task is a good scenario for semantic matching, where semantic and syntactic features are important to compute the relevance score. On the other hand, semantic matching is not enough for docu- ment retrieval, because a typical scenario is to have a query that contains keywords. In such cases, the relevance matching is needed to achieve better retrieval results. Relevance matching is introduced by Guo et al., (2016) to solve the case of heteroge- neous query and document in ad-hoc document retrieval. The query can be expressed by keywords, so a semantic signal is less informative