query and document in an early stage. In interaction-focused models, F captures the interactions between query and document. For example, Guo et al. (2016) introduced a Deep Relevance Matching Model (DRMM) to perform term matching using histogram-based features. The interaction matrix between query and document is computed using pairwise cosine similarities between the embed- dings of query tokens and document tokens. DRMM builds a histogram-based feature to extract matching patterns from different levels of interaction signals rather than different positions. In order to control the contribution of each query token to the final relevance score, the authors propose a term gating network with a softmax function. The histogram feature in DRMM (Guo et al., 2016) is computed based on a hard assign- ment of cosine similarities between a given query token and the document tokens. This his- togram-based feature counts the total number of document tokens with a similarity to the query token that falls within the predefined binâ€™s range of the histogram. The histogram- based representation is not differentiable for the purpose of updating the ranking model parameters in the back-propagation phase, and not computationally efficient. To solve this problem, kernel pooling for soft-match signals is used in K-NRM (Xiong et al., 2017b). Pairwise cosine similarities are compared against a set of K kernels, where each kernel rep- resents a normal distribution with a mean and standard deviation. Then, kernel pooling is M( , ) Relevance score ( , ) Document ( tokens) Query ( tokens) Fig. 3 Overview of the general architecture of interaction-focused models. An interaction function is used to map the query and document to an interaction output. A ranking function M is used to map the interac- tion output to a real-valued relevance score Information Retrieval Journal 1 3 applied to summarize the cosine similarities