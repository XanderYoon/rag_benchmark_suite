efficient. For the second type, the loss function is differentiable, but it is not directly related to the evaluation measures (Cao et al., 2007; Huang & Frey, 2008; Volkovs & Zemel, 2009). For example, in ListNet (Cao et al., 2007), the probability dis- tribution of permutations is used to define the loss function. Since a ranking list can be seen as a permutation of documents associated with a given query, a model represent- ing the probability distribution of permutations, like the Plackett-Luce (Plackett, 1975) model, can be applied for ranking in ListNet. 6 Model categories We discuss neural ranking models that are proposed in the document retrieval literature based on multiple dimensions. These dimensions capture the neural components and design of the proposed methods in order to better understand the benefits of each design principle. 6.1 Representation‑focused models vs. interaction‑focused models When extracting features from a query-document pair, the feature extractor F can be applied separately to the query and document, or it can be applied to the interaction between the query and document. M( , ) Feature vector of Feature vector of Relevance score Document ( tokens) Query ( tokens) Fig. 2 Overview of the general architecture of representation-focused models. Two deep neural networks are used to map the query and document to feature vectors. A ranking function M is used to map the feature vectors of the query and document to a real-valued relevance score Information Retrieval Journal 1 3 6.1.1 Representation‑focused models The general framework of representation-focused models is shown in Fig. 2. In representa- tion-focused models, two independent neural network models NNQ and NND map the query q and the document d, respectively, into feature vectors NNQ(q) and NND(d) . Thus the fea- ture extractor F for a query-document pair is given by: In the particular