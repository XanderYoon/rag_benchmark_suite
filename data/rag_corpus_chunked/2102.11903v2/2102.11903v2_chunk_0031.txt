Information Retrieval Journal 1 3 authors proposed a Position-Aware Convolutional Recurrent Relevance (PACRR) match- ing model to capture information about the position of a query term and how it interacts with tokens from a document. In order to extract local matching patterns from the cosine similarity interaction matrix, the authors applied CNN filters with multiple kernel sizes. A max-pooling is then applied over the depth channel (number of CNN filters) of the feature maps. This operation assumes that only one matching pattern from all filters is important for a given kernel size representing a query and document n-gram size. The final feature vector is computed using a second k-max pooling over the query dimension in order to keep the strongest signals for each query token. McDonald et al. (2018) proposed a model called PACRR-DRMM that adapts a PACRR model for the DRMM architecture in order to incorporate contextual information of each query token. A PACRR-based document-aware query token encoding is used instead of the histogram-based feature of DRMM. Then, like in DRMM, each PACRR-based fea- ture is passed through a MLP to independently score each query encoding. Finally, the resulting scores are aggregated using a linear layer. Unlike DRMM, PACRR-DRMM does not include a term gating network that outputs a weight for each query token, because the PACRR-based feature already includes inverse document frequency (IDF) scoring for each query token. Jaech et al. (2017) designed a neural ranking model called Match-Tensor that explores multiple channel representation for the interaction tensor to capture rich signals when com- puting query-document relevance scores. The similarity between query and document is computed for each channel. Two bi-LSTMs are used to encode the word embedding-based representation of the query and document into LSTM states. The encoded sequences cap- ture the sequential structure of query and