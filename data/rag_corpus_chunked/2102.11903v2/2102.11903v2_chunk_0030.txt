passages of a document. As in Match-SRNN (Wan et al., 2016b) and MatchPyramid (Pang et al., 2016a, b), DeepRank (Pang et al., 2017) has an input interaction tensor between query and document. The input tensor is fed to the GRU network to compute a query-centric feature vector. CNN-based ranking models: A CNN is used in multiple interaction focused models including (Dai et al., 2018; Hui et al., 2017; Jaech et al., 2017; Lan & Xu, 2018; McDonald et al., 2018; Nie et al., 2018; Pang et al., 2016b; Tang & Yang, 2019). Hu et al. (2014) pre- sented ARC-II which is an interaction-based method. ARC-II lets the query and document meet before their feature vectors are fully developed by operating directly on the inter - action matrix. Given a sliding window k1 that scans both query and document by taking overlapping sub-sequences of tokens with length k1 , a 1− D convolution is applied to all sequences that are formed by concatenating tokens from the sliding window of query and document. The next layers are composed of a 2 × 2 non-overlapping max-pooling and 2− D convolution. Several max-pooling and CNN layers can be added to the model, and the final feature vector is fed to a MLP to predict the query-document relevance score. Hui et al. (2017) argued that retrieval methods are based on unigram term matches, and they ignore position-dependent information such as proximity and term dependencies. The Information Retrieval Journal 1 3 authors proposed a Position-Aware Convolutional Recurrent Relevance (PACRR) match- ing model to capture information about the position of a query term and how it interacts with tokens from a document. In order to extract local matching patterns from the cosine similarity interaction matrix, the authors applied CNN filters with multiple kernel sizes. A max-pooling is