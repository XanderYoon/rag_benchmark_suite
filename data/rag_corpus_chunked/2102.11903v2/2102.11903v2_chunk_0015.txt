order to learn embeddings for entities in RDF graphs. Recently, researchers have explored a new direction called graph neural networks (Cai et al., 2017) to solve multiple tasks (Zhou et al., 2018). Graph neural networks capture rich relational structures between nodes in a graph using message passing and encode the global structure of a graph in low dimensional feature vectors known as graph embed- dings. The Graph Convolutional Network (GCN) (Kipf & Welling, 2017) can capture high order neighborhood information to learn representations of nodes in a graph. The success of GNNs has boosted research on various tasks. R-GCN (Schlichtkrull et al. 2018) pio- neered the use of graph convolutional networks to model relations in knowledge graphs. The embeddings learned by R-GCN have shown to be effective for downstream tasks such (1)p(l âˆ£ /u1D421/u1D703)= softmax(W/u1D421/u1D703) Information Retrieval Journal 1 3 as entity classification and link prediction. More recently, Xu et al. (2020a) first construct a product knowledge graph and then propose a self-attention-enhanced distributed repre- sentation learning method with an efficient multi-task training schema to learn the graph embeddings, which can improve the performance of downstream tasks such as search rank- ing and recommendation. GNNs are also introduced in table retrieval, where Trabelsi et al. (2020c) first construct a knowledge graph from table collections and then learn the graph embeddings in order to rank tables. 3 Document retrieval Information retrieval is a broad research area that covers a variety of content types and tasks. In this survey, we focus on the document retrieval and ranking task and propose detailed descriptions and groupings of multiple neural ranking models in the document retrieval. In terms of scope, we focus on text-based document retrieval, where the input to the neural ranking model is raw text, and the output is a ranked list of