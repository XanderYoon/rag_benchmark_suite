their empirical study that the interaction-based neural architectures generally lead to bet- ter results than the representation-focused architectures in information retrieval tasks. Although the representation-focused models offer the advantage of efficient computation by having the same feature vector for a document in all tasks, a static feature representation is unable to capture the matching signals in different tasks and datasets. On the other hand, the interaction-focused neural networks can be computationally expensive, as they require pairwise similarities between embeddings of query and document tokens, but they have the advantage of learning the matching signals from the interaction of two inputs at the very beginning stages. 6.2 Context awareâ€‘based representation As suggested by Wu et al. (2007), if there is some relevant information in a document, the relevant information is located around the query terms in the document, which is known as the query-centric assumption. An example of the query-centric assumption is shown in Fig. 5. The query-centric assumption is closely related to human judgement of relevance which consists of three steps (Wu et al., 2007). The first step consists of finding candidate locations in the document for relevant information to the query. Then the objective of the second step is to judge the local relevance of the candidate locations. Finally, the third step consists of aggregating local relevance information to assess the overall relevance of the document to the query. Inspired by human judgment of relevance, the DeepRank (Pang et al., 2017) archi- tecture considers two information retrieval principles. The first principle is query term importance: a user expresses his request via query terms and some terms are more important than others (Fang et al., 2004). The second principle is the diverse matching requirement of query-centric contexts, which indicates that the distribution of matching Retrieval score Document ( tokens) Query