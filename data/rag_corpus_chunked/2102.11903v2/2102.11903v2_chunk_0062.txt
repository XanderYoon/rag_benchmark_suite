a simple ranking function, such as cosine similar - ity, is used to predict the relevance score of a query-image pair. The Siamese architecture is used in multiple CBIR domains such as retrieving aerial images from satellites (Khokhlova et al., 2020) and content-based medical image retrieval (CBMIR) (Chung & Weng, 2017). CBMIR helps clinicians in the diagnosis by exploring similar cases in medical databases. Retrieving similar images for diagnosis requires extracting content-based feature vectors Information Retrieval Journal 1 3 from medical images, such as MRI data, and then identifying the most similar images to a given query image by comparing the extracted features using similarity metrics. 8.4 Ad‑hoc video search Ad-hoc video search (Awad et al., 2016) consists of retrieving video frames from a large collection of videos where the retrieved videos are relevant to the user’s query. Similar to document retrieval, text-based video retrieval using the filename, text surrounding the video, etc, has achieved high performance for the video retrieval with a simple query that has few keywords (Snoek & Worring, 2009). Recently, researchers have focused on sce- narios where the query is more complex and defined as natural language text. In this case, a cross-modal semantic matching between the textual query and the video is captured to retrieve a set of relevant videos. Two categories are defined for existing methods on complex query-based video retrieval: concept-based (Snoek & Worring 2009; Yuan et al., 2011; Nguyen et al., 2017) and embedding-based (Li et al., 2019; Cao et al., 2019; Miech et al., 2018, 2019) catego- ries. In concept-based methods, visual concepts are used to describe the content of a video. Then, the user’s query is mapped to related visual concepts which are used to retrieve a set of videos by aggregating matching signals from the visual concepts. This approach