single excerpt of a document is better than a full document for high recall in retrieval. In addition, using sentence-level representation is related to research in pas- sage-level document ranking (Liu & Croft, 2002). For each document, its relevance to the query can be predicted using the maximum relevance of its component sentences which is denoted as the best sentence. Yang et al. (2019a) generalize the best sentence concept by choosing the top-k sentences from each document based on the retrieval score calculated by BERT for sentence pair classification setting. A weighted sum of the top-k sentence- level scores, which are computed by BERT, is then applied to predict the retrieval score of the query-document pair. In the training phase, BERT is fine-tuned on microblog data or QA data, and the results show that training on microblog is more effective than QA data for ad-hoc document retrieval (Yang et al., 2019a). The hidden state of the [CLS] token is also used by Nogueira and Cho (2019) to rank candidate passages. For long document tasks such as document retrieval on ClueWeb09-B (Dai et al., 2018), XLNet (Yang et al., 2019b) uses TransformerXL (Dai et al., 2019) instead of BERT. Trans- formerXL uses a relative positional encoding and segment recurrence mechanism to cap- ture longer-term dependency. XLNet (Yang et al., 2019b) results in a performance gain around 1.87% for NDCG@20 compared to the BERT-based model. Qiao et al. (2019) explore multiple ways to fine-tune BERT on two retrieval tasks: TREC Web Track ad-hoc document ranking and MS MARCO (Nguyen et al., 2016) pas- sage re-ranking. Four BERT-based ranking models are proposed which are related to both representation and interaction based models using the [CLS] embedding, and also the embeddings of each token in the query and document. The authors show that BERT