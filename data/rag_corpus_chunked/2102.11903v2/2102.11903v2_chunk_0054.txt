al., 2018) ✓ E ✓ HiNT (Fan et al., 2018) ✓ ✓ L PACRR-DRMM (McDonald et al., 2018) ✓ L ✓ ABEL-DRMM (McDonald et al., 2018) ✓ ✓ ✓ EDRM (Liu et al., 2018) ✓ ✓ E ✓ Information Retrieval Journal 1 3 Table 1 (continued) Method symmetric attention ordered tokens representation interaction injection of CI exact matching KB Deep LM KABLSTM (Shen et al., 2018) ✓ ✓ ✓ ✓ E ✓ NPRF (Li et al., 2018) ✓ ✓ DeepTileBars (Tang and Yang 2019) ✓ ✓ L DRCN (Kim et al., 2019) ✓ ✓ ✓ ✓ E DRr-Net (Zhang et al., 2019) ✓ ✓ ✓ ✓ E BERT (sentence pair classification) (Yang et al., 2019a) ✓ ✓ ✓ E Se BERT as a passage re-ranker (Nogueira and Cho 2019) ✓ ✓ ✓ E Se BERT (Term-Trans) (Qiao et al., 2019) ✓ ✓ ✓ ✓ E Em Joint BERT (MacAvaney et al., 2019) ✓ ✓ ✓ E ✓ Se Contextualized similarity tensors (MacAvaney et al., 2019) ✓ ✓ ✓ ✓ E Em Augmented BERT (Dai and Callan 2019) ✓ ✓ ✓ E Se monoBERT+duoBERT (Nogueira et al., 2019) ✓ ✓ ✓ E Se TKL (Hofstätter et al., 2020) ✓ ✓ E ✓ MarkedBERT (Boualili et al., 2020) ✓ ✓ ✓ E ✓ Se BERT-based ranking model (Zhan et al., 2020a) ✓ ✓ ✓ E Se ColBERT (Khattab and Zaharia 2020) ✓ ✓ ✓ E Em Information Retrieval Journal 1 3 Table 1 shows the main IR features of each neural ranking model from all proposed catego- ries. The neural ranking models are sorted in chronological order based on the publication year. Unsurprisingly, in recent years, there have been more proposed neural ranking models that are based on BERT because deep contextualized language models achieve state-of-the- art results in multiple tasks for