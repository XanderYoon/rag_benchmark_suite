documents from the first stage. The classification set- ting of BERT with sentence pairs is used to compute the relevance scores. The third stage, called duoBERT, is a pairwise learning strategy that computes the probability of a given document being more relevant than another candidate document. Documents from the sec- ond stage are ranked using duoBERT relevance scores in order to obtain the final ranked list of documents. The input to duoBERT is the concatenation of query, first document, and second document, where [SEP] is added between the sentences, and [CLS] is added to the beginning of the concatenated sentence. As explained earlier, exact matching is an important matching signal in traditional IR models, and relevance matching-based neural ranking models incorporate the exact match- ing signal to improve retrieval results. In order to directly incorporate exact matching sig- nal in the sentence pair classification setting of BERT for document retrieval, Boualili et al. (2020) proposed to mark the start and end of exact matching query tokens in a document with special markers. 7 Neural ranking models features To summarize the neural models from the five categories, we propose nine features that are frequently presented in the neural ranking models. Fig. 8 Overview of a possible joint model for document retrieval that incorporates both the semantic and relevance matching. BERT is used as a semantic matching component, where the embedding of the [CLS] token is considered as a semantic feature. An existing relevance-based neural ranking model extracts the relevance feature from a query-document pair Information Retrieval Journal 1 3 1. Symmetric: We describe a neural ranking architecture as symmetric if the relevance score does not change if we change the order of inputs (query-document or document-query pairs). In other words, for a given query and document, there are no special computations