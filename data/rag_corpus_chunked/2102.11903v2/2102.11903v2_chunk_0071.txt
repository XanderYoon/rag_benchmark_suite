sliding windows of size w << m , the time and memory complexity is reduced from O(m2) to O(m × w) . Recently, Kitaev et al. (2020) improved the efficiency of Transformers and proposed the Reformer which is efficient in terms of memory and runs faster for long sequences by reducing the com- plexity from O(m2) to O(m × log(m)) . The Reformer presents new opportunities to achieve the trade-off between high retrieval results and low computation time. ElMo provides deep contextualized embeddings without the length limit constraint and can be used as a semantic matching component as it is pre-trained on the next word prediction. A possible multi-stage ranking architecture, that has a trade-off between retrieval results and computation time, can be composed of a first stage that re-ranks a set of candidate documents obtained from BM25 using an ElMo-based semantic and relevance model (example of relevance models: K-NRM, Conv-KNRM, DRMM, etc). Then, for the sec- ond stage, the top ranked documents from the first stage are re-ranked using a BERT- based semantic and relevance model. This multi-stage model has the potential to reduce the number of documents that should be ranked with BERT. Information Retrieval Journal 1 3 10 Summary An end-to-end LTR architecture for ad-hoc document retrieval consists of extracting fea- tures from a query-document pair using a feature extractor, and mapping the extracted features to a real-valued relevance score using a ranking function. A core component of such a system is a neural ranking model, and in this survey, we have presented several such models. We began by introducing deep learning terminologies and techniques in Sect. 2 in order to cover the major components that are used in different neural ranking models. Then, We present the document retrieval field in Sect. 3. The objective of the