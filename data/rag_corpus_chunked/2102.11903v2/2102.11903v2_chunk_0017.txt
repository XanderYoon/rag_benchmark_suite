a query reformulation and expansion (Azad & Deepak, 2019). Many neural ranking models have complex architectures, therefore computing the Query Query Processing Indexing Neural Ranking Model Relevant docs Neural ranking component User Return Relevant docs Unsupervised ranking Candidate docs Fig. 1 Overview of the flowchart of the neural ranking based document retrieval. The neural ranking com- ponent is highlighted within the red box. The inputs to the neural ranking model are the processed query and the candidate documents that are obtained from the traditional ranking phase. The final output of the neural ranking model is a ranking of relevant documents to the user’s query Information Retrieval Journal 1 3 query-document relevance score using the neural ranking model for every document in the initial large collection of documents leads to a significant increase in the latency for obtaining a ranked list of documents from the user’s side. So, the neural ranking com- ponent is usually used as a re-ranking step that takes two inputs which are the candidate documents and the processed query. The candidate documents are obtained from an unsu- pervised ranking stage, such as BM25, which takes as inputs the initial set of indexed doc- uments and the processed query. During the unsupervised ranking, recall is more impor - tant than precision to cover all possible relevant documents and forward a set of candidate documents, that has both relevant and irrelevant documents, to the neural based re-ranking stage. The output of the ranking model is a set of relevant documents to the user’s query which are returned to the user in a particular order. The inputs to neural ranking models consist of queries and documents with variable lengths in which the ranking model usually faces a short query with keywords, and long documents from different authors with a large