I. I NTRODUCTION Retrieval-augmented generation (RAG) [1] systems enhance large language models (LLMs) [2] by incorporating external knowledge to generate coherent responds based on a given context, improve the response accuracy and reduce hallucina- tions. However, the quality of the generated response in RAG systems heavily depends on the retrieval process. Selecting the most relevant data from a database based on the user query is essential for the system to generate accurate and contextually appropriate response. A common approach for retrieval in RAG is top- k selection by first ranking the entries from the knowledge-base based on similarity scores between their embeddings and the user query and then selecting the top- k entries. For image and text retrieval, CLIP-based methods [3] are widely used due to their strong performance in aligning image and text embeddings across modalities. While effective in capturing general semantic similarity, CLIP struggles to detect irrelevancy as accurately as relevancy, making it less reliable for context-sensitive tasks. One fundamental limitation of CLIP is its tendency to assign high similarity scores to visually or semantically generic content, even when it is irrelevant to the query. For example, consider a query like “a child playing soccer”. A CLIP-based retrieval system might assign high similarity to images of any Fig. 1. Re-ranking via relevancy score (RS). child or soccer scene, even if the images lack both elements to- gether. This inability to effectively filter out irrelevant data can lead to suboptimal retrieval, and consequently, hallucinations in downstream tasks. In multi-modal RAG systems, where accuracy depends on precise alignment between the retrieved data and the user query, such limitations can significantly degrade the system’s reliability. Re-ranking techniques offer a promising solution to refine initial retrieval results by re-evaluating the relevance of re- trieved entries before passing them to the response generation