details in [9]) is a specialized metric designed to evaluate the relevancy of a piece of information from the vector database to the user query in multi-modal RAG systems. The RS model is designed by using a VLM with specific fine-tuned head that learns the semantic relationship between a user query and a retrieved entry, such as an image or a text document. The training of the RS model leverages a carefully curated dataset that includes a human-annotated dataset as well as synthetic query-context pairs generated by ChatGPT partially verified by human evaluators. We build a balanced dataset where each entry is a triplet comprising an image, and a pair of positive and negative statements with respect to the image. The dataset is partitioned into a training dataset of 121,000 triplets and an evaluation dataset of 2000 triplets. The training on a balanced dataset ensures that the RS model captures not only the general semantic alignment but also fine-grained contextual relevance/irrelevance. To compute RS, the RS model takes the query and an entry (e.g., an image or text) as an input and produce a scalar score between 0 and 1 as an output. The higher the score, the higher the relevancy, i.e., the score 1 is the highest relevancy and 0 is the ultimate irrelevancy. By design, the RS score is naturally normalized by using a sigmoid activation function at the last layer of our fine-tuned head. During training, the RS model minimizes a modified version of RLHF loss function that penalizes mismatched query-context pairs while rewarding alignment with the most relevant entries. This enables the RS model to differentiate between truly relevant data and entries that might exhibit superficial similarity to the query. Compared to CLIP-based methods, which rely on cosine similarity between embeddings to rank image-text pairs, RS