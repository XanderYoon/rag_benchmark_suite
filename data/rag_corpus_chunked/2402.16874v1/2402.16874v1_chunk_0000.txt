1 Enhancing Retrieval Processes for Language Generation with Augmented Queries Julien Pierre Edmond Ghali, Kosuke Shima, Koichi Moriyama, Atsuko Mutoh, Nobuhiro Inuzuka Nagoya Institute of Technology, Japan Corresponding author: Julien Pierre Edmond Ghali, julienpe.ghali@gmail.com 2 Abstract In the rapidly changing world of smart technology, searching for documents has become more challenging due to the rise of advanced language models. These models sometimes face difficulties, like providing inaccurate information, commonly known as "hallucination." This research focuses on addressing this issue through Retrieval-Augmented Generation (RAG), a technique that guides models to give accurate responses based on real facts. To overcome scalability issues, the study explores connecting user queries with sophisticated language models such as BERT and Orca2, using an innovative query optimization process. The study unfolds in three scenarios: first, without RAG, second, without additional assistance, and finally, with extra help. Choosing the compact yet efficient Orca2 7B model demonstrates a smart use of computing resources. The empirical results indicate a significant improvement in the initial language model's performance under RAG, particularly when assisted with prompts augmenters. Consistency in document retrieval across different encodings highlights the effectiveness of using language model-generated queries. The introduction of UMAP for BERT further simplifies document retrieval while maintaining strong results. Keywords: Retrieval-Augmented Generation, Large Language Model, Artificial Intelligence, Natural Language Processing, Word Embedding, Schizophrenia Material and methods: the code is available at this link: https://github.com/JulienGha/RAGDoc2Vec. Due to copyrights reason, the data used are not available, but users can try with their own data. 3 1. Introduction In the field of language processing and machine learning, the quest for precision and contextual understanding in document retrieval has become more crucial than ever to address the phenomenon of "hallucination" [1], referring to the generation of inaccurate, non-sensical, or detached text, that occurs when using large language models (for