users can try with their own data. 3 1. Introduction In the field of language processing and machine learning, the quest for precision and contextual understanding in document retrieval has become more crucial than ever to address the phenomenon of "hallucination" [1], referring to the generation of inaccurate, non-sensical, or detached text, that occurs when using large language models (for example when an output includes a reference that doesnâ€™t exists). At the heart of this quest is the concept of Retrieval-Augmented Generation (RAG) [2], a method of providing a model with factual knowledge and basing its response on it. However, this system may encounter difficulties in terms of scalability, or its ability to find the right documents; the size of the input message given to our model being limited, it is not possible to simply provide it with a complete book on the subject and simply prompt it to use only the relevant parts. In this article, we present a query augmentation model that could enhance the way RAG models generate responses. Query Augmentation represents a strategic alignment of user queries during document retrieval with the advanced capabilities of language models such as T5 [3], BERT [4], GPT [5] or Orca2 [6]. In our research, the goal was to generate, from an initial user query, a response likely to be found in a document. Our intuition was that in an environment using document and query vectorization, it was more likely to retrieve the desired information with similar data rather than through a question or question/answer training. In the context of augmented generation for our research, query augmentation is not limited to providing the right answers; it's about designing queries that guide the AI model to understand and reflect the semantic nuances of the user's demand, ultimately leading to more relevant