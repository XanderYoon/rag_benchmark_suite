the risks tied to content generation and retrieval. Striking a balance between pushing the 16 boundaries of innovation and using these models responsibly is key to ensuring our work has a positive impact on society. Limitations Our research encountered constraints primarily stemming from hardware limitations, specifically the utilization of 8GB of GPU RAM. The processing time for a single query averaged around 10 minutes, particularly for generating answers spanning approximately 60 words. Additionally, constrained by both RAM and budget considerations, we opted for the utilization of local language models with limited capacity, exemplified by the Orca2 7B model. These limitations, while impacting the scale and speed of our query optimization process, served as crucial parameters that shaped the scope of our experimentation and analysis. During the preparation of this work the author(s) used Chat GPT 3.5 in order to spell check and assist during writing. After using this tool/service, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication. This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors. 17 References List 1. Shuster, K., Poff, S., Chen, M., Kiela, D., & Weston, J. (2021). Retrieval augmentation reduces hallucination in conversation. arXiv preprint arXiv:2104.07567 2. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33, 9459-9474. 3. Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., ... & Wei, J. (2022). Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416. 4. Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. 5. Radford, A., Narasimhan, K., Salimans, T.,