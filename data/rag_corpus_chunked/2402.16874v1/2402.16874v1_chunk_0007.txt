users to distill their original prompts into the underlying questions they seek to answer. Subsequently, the generator, trained to comprehend and generate human-like text, transforms the user’s prompt into an augmented query. This augmented query is carefully crafted to mirror the language commonly found in documents related to the user’s inquiry. By employing a language model generator for query augmentation, the system facilitates a more refined and contextually aligned interaction with document retrieval. The generated augmented queries serve as effective probes, enhancing the precision of the retrieval process. The interest in utilizing this approach lies in its ability to bridge the gap between user input and 9 the language structures prevalent in relevant documents, ultimately leading to more accurate and relevant document retrieval results. 4.3 Retrievers We decided to use word embedding methods due to the nature of our Prompt Augmenter; we were looking for similar documents with a document. • TF-IDF: time complexity: o (n * m) o Where 'n' represents the number of documents, 'm' is the average number of unique terms in a document. • Doc2Vec: time complexity: o (n * d * e + n * n * d) o Where 'n' is the number of documents, 'd' is the dimensionality of the document vectors, and 'e' is the number of training epochs for Doc2Vec, we used 400. The first term represents the training complexity, and the second term represents the retrieval complexity for calculating cosine similarity between the query vector and all document vectors. • BERT: time complexity o (n * e + n * d2) when using dimension reduction o Where n is the number of documents, e is the time complexity of encoding a single document with BERT, d is the number of dimensions in the UMAP space, it scales quadratically with the