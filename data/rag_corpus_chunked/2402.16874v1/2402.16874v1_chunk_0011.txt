experiment on diverse patients that paranoia, a symptom of schizophrenia, is the product of grandiosity and guilt, and can also be associated with bipolarity, written by Lake C. [17]. Employing resources like those underscores our system's capability to deliver fine-tuned results, by using RAG alone. Regarding our evaluation metric and the intricacy of assessing Large Language Models (LLM) answers – if not ROUGE or BLEU for retrieval – we decided to propose our own based on a tree structure. We employed the logic outlined in Fig 2., signifying that a score for an answer is between 1 and 4, 4 being the highest score. If the answer is totally unrelated, as we can see sometimes when an output is unrelated training data, then the score is 1. If an answer is wrong, no matter the justification and how the system followed the procedure the score will only be 2. A correct answer but without properly respecting the constraints or the context is 3, while an answer that use the given context and respect the constrains (less than a specific number of words for example) will be given a 4. 13 Figure 2. Answer evaluation system To evaluate our different prompts, the results displayed on the Tab 1., where for each system we put the of each evaluation made with our system. 14 TF-IDF Doc2Vec BERT&UMAP No RAG & No query augmentation 3 RAG & No query augmentation 3.2 3.3 3.5 RAG & query augmentation 3.6 3.5 3.8 Table 1. Score based on retrieval methods Conclusion After carefully checking Tab 1. and the extra tables in Annex A, a clear improvement in the initial language model's performance is noticeable. RAG contributes to refining its capabilities, similar to fine-tuning. The prompt augmenter plays a crucial role in delivering factual responses, especially evident