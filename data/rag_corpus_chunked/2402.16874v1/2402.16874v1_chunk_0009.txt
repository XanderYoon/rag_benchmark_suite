preceding (n-1) and succeeding (n+1) sentences. This decision assumed that relevant information and contextual clues are often dispersed before and after the identified sentence, contributing to a more comprehensive understanding of the content. 4.4 Generator In our framework, the generator functions as an answer generation tool centered around documents, powered by a language model generator. When presented with a user query and a context formed by retrieved documents, the system directs the model through a systematic procedure. This involves instructing the model to craft a response to the user's query within specific constraints, here the size of the answer due to computation constraints and the, prompting the incorporation of pertinent knowledge from the provided context. Throughout this process, the model generates a response by tapping into its trained knowledge base and considering the context extracted from documents. The anticipated outcome is a concise, relevant, and contextually embedded response that aligns with both the user's query 11 and the information gleaned from the retrieved documents. This approach ensures that the model provides informative and contextually fitting answers, meeting the user's inquiry in coherence with the available document context. 5. Results We applied our system to address a diverse set of 10 queries, following a systematic evaluation approach. Initially, we generated responses without incorporating Retrieval-Augmented Generation (RAG). After, we produced responses employing our three distinct retrieval methods but without our prompt augmentation technique, so just with the initial query. Finally, we utilized our three retrieval methods alongside prompt augmentation for response generation. For the augmentation process, we selected Orca2 7b, a Small Language Model recognized for its outstanding performance compared to other Large Language Models. This choice was influenced by its impressive results combined with minimal GPU memory requirements, ensuring efficiency in our experimentation. As the source for retrieval, we first thought