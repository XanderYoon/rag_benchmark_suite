system highlights their known strengths and weaknesses. BERT shows the best results, but the computation time is the highest, making it difficult to apply on a large-scale system. TF-IDF stands here as the best ratio performance/cost, while being the fastest it is also the one that benefit the most from our augmented query, being more reliable than Doc2Vec, due to its word counting nature. Doc2Vec, despite being performant, shows the weakest results from our query augmenter. Ethical Consideration In delving into the ethical considerations of our research, it's crucial to recognize the ongoing concerns tied to AI and language models. As these models get fancier, there's a growing worry about unintended consequences and ethical dilemmas. A big concern here is making sure these models are used responsibly, creating content that aligns with ethical norms and societal values. Now, when we layer on Retrieval-Augmented Generation (RAG) and our innovative methods, it adds another ethical dimension. If the documents used to train the model raise a red flag â€“ then there's a risk of people sneaking in harmful content. This could mean the model ends up spreading information that might hurt individuals or communities. The real challenge is that AI systems struggle to grasp the subtle differences between what's harmless and what might cause harm, a struggle we've seen in early versions of models like ChatGPT. So, the ethical focus in our research is on building solid safeguards and oversight to tackle the risks tied to content generation and retrieval. Striking a balance between pushing the 16 boundaries of innovation and using these models responsibly is key to ensuring our work has a positive impact on society. Limitations Our research encountered constraints primarily stemming from hardware limitations, specifically the utilization of 8GB of GPU RAM. The processing time for a single query