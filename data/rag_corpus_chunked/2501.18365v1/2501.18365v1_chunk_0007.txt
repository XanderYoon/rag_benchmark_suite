component (i.e., the LLM) G, and a corresponding corpus C = {ğ‘‘ } containing a large collection of knowledge documents. Whenever the system receives a user query ğ‘, the retrieval component R first retrieves RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Figure 1: Overview of our RbFT. Specifically, RbFT consists of two sub-tasks: Defects Detection and Utility Extraction, which aim to identify the types of retrieval defects and generate the final answer with limited useful information, respectively. In the figure, green text indicates relevant information, while red text represents incorrect counterfactual information. the top-ğ‘˜ most relevant documents Dğ‘ = {ğ‘‘ğ‘ 1 , ğ‘‘ğ‘ 2 , ..., ğ‘‘ğ‘ ğ‘˜ } âŠ‚ C from the corpus C: Dğ‘ = R (ğ‘, C) (1) Then, the LLM G generates a response ğ‘Ÿ based on the query ğ‘ and relevant documents Dğ‘, where the expected outputğ‘Ÿ should ideally match the ground-truth answer ğ‘. Thus, the entire workflow can be formalized as: ğ‘Ÿ = G (ğ‘, Dğ‘) = G (ğ‘, R (ğ‘, C)) (2) It is evident that, aside from the understanding and generation capabilities of the LLM itself, the quality of the generated response ğ‘Ÿ is highly dependent on the capability of the retrieverR along with the quality of the corpus C. Either an underperforming retriever or a low-quality corpus can significantly degrade the response quality. Since these retrieval-side issues are unavoidable in real- world scenarios, our work focuses on enhancing the capability of the generation component G to minimize their negative impact. 3.2 Retrieval Defects As mentioned above, due to the limitations of the retrieverâ€™s perfor- mance and the quality of the corpus, the retrieval component often cannot guarantee that all returned documents fully meet the user queryâ€™s information needs, resulting in various