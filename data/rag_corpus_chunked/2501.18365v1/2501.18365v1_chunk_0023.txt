6.4%) 37.1* ( â†“ 8.2%) 40.4 Mix 36.8* 43.7 (â†“ 1.6%) 39.2 ( â†“ 11.7%) 44.4 34.2* 39.5(â†“ 2.7%) 37.1* ( â†“ 8.6%) 40.6 Hard (ğœ = 1.0) Noisy 16.9* 28.4*(â†“ 8.7%) 28.9* ( â†“ 7.1%) 31.1 15.9* 22.9* (â†“ 6.9%) 23.1* ( â†“ 6.1%) 24.6 Irrelevant 7.1* 24.3*(â†“ 13.8%) 25.4* ( â†“ 9.9%) 28.2 12.4* 18.3*(â†“ 14.5%) 18.6* ( â†“ 13.1%) 21.4 Counterfactual 9.0* 22.7*(â†“ 32.8%) 30.3* ( â†“ 10.4%) 33.8 8.9* 16.4*(â†“ 34.7%) 21.6* ( â†“ 13.9%) 25.1 Mix 11.4* 25.7*(â†“ 19.4%) 29.5* ( â†“ 7.5%) 31.9 11.0* 19.5* (â†“ 18.8%) 21.2* ( â†“ 11.7%) 24.0 Vanilla RAG and other enhancement methods. Moreover, in high- difficulty scenarios, RbFT further expands its lead over competing approaches, indicating its superior capability in handling harsh re- trieval environments. This consistent and substantial performance improvement indicates that RbFT is not only highly effective in addressing complex retrieval defects but also better suited for real- world applications, where potential retrieval defects are common. As a result, since fluctuations in the quality of retrieved documents are unavoidable in real-world scenarios, our RbFT method, with its capability to provide stable and reliable retrieval-generation responses and maintain strong and consistent robustness, is better suited to meet practical requirements, making it a valuable solution for practical application. 6.2 Ablation Study To further verify the effectiveness and interrelation of the two tasks in RbFT (i.e., Defects Detection and Utility Extraction), we conduct ablation experiments by fine-tuning LLMs using each task individ- ually (referred to as Vanilla + DD and Vanilla + UE, respectively) to explore their respective roles. Specifically, we adopt the same training steps, learning rate, and LoRA parameters as those used in RbFT. It is worth noting that, since the instructions and output format of the Defects Detection task differ from those of the original QA