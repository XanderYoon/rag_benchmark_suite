each task individ- ually (referred to as Vanilla + DD and Vanilla + UE, respectively) to explore their respective roles. Specifically, we adopt the same training steps, learning rate, and LoRA parameters as those used in RbFT. It is worth noting that, since the instructions and output format of the Defects Detection task differ from those of the original QA tasks, fine-tuning using only Defects Detection data inevitably results in degraded performance on QA tasks. Therefore, we sup- plement the training data for Vanilla + DD with QA training data in the Clean setting (i.e., the original training data). It can be viewed as the version of RbFT with all defective documents in the Utility Extraction task replaced with their original retrieved versions. The results of the ablation study, as shown in Table 2, indicate that both training tasks contribute to improving the robustness of LLMs and RAG systems to some extent, though their improvements are still weaker than RbFT. Specifically, the model fine-tuned solely with the Utility Extraction task exhibits a performance drop of approximately 10% compared to RbFT across all three settings. In contrast, the model fine-tuned with Defects Detection demonstrates different features. Under settings with weaker retrieval defects (i.e., Clean and Normal), Vanilla + DD achieves performance comparable to RbFT. However, in the more challenging retrieval environment of the Hard setting, Vanilla + DD falls short of Vanilla + UE in terms of robustness, especially on the counterfactual data. Therefore, the Defects Detection and Utility Extraction training tasks are mutually complementary, working in tandem to reinforce each otherâ€™s effec- tiveness. Only by combining both can we maximize effectiveness in low-defect scenarios while simultaneously enhancing robustness in high-defect environments. 6.3 Case Study In Figure 5, we attempt to analyze further how RbFT enhances the defense capability of LLMs