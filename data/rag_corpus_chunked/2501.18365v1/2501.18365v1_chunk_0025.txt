counterfactual data. Therefore, the Defects Detection and Utility Extraction training tasks are mutually complementary, working in tandem to reinforce each other’s effec- tiveness. Only by combining both can we maximize effectiveness in low-defect scenarios while simultaneously enhancing robustness in high-defect environments. 6.3 Case Study In Figure 5, we attempt to analyze further how RbFT enhances the defense capability of LLMs by examining the attention distri- bution over tokens of the input document. Specifically, we select one case for each of the three types of retrieval defects (i.e., noisy, irrelevant, and counterfactual) and apply retrieval augmentation to the Llama model using two corresponding defective documents. For noisy documents, as shown in Figure 5a, the model fine-tuned with RbFT distributes its attention more evenly across a broader range of contextually relevant information. In contrast, the Vanilla model tends to concentrate its attention on distracting and mis- leading entities, for example, "Fiormonda" in Figure 5a. Similarly, in the case of counterfactual documents (as shown in Figure 5c), the RbFT-enhanced model focuses less on the incorrect answer "Toronto" and more broadly on multiple relevant pieces of con- textual information, thereby mitigating the impact of erroneous and misleading content. For irrelevant documents (Figure 5b), the Vanilla model also over-focuses on certain specific tokens, whereas the RbFT model distributes its attention more broadly across the context. In summary, the attention distribution of LLMs fine-tuned with RbFT becomes smoother compared to the Vanilla LLMs when processing defective input documents. This smoother attention dis- tribution helps in two ways. First, it increases the model’s resistance against incorrect or irrelevant information by reducing excessive attention to and reliance on such content. Second, even when the input document does not directly contain the ground-truth answer, attending to more relevant information in the overall context may better activate the internal parametric