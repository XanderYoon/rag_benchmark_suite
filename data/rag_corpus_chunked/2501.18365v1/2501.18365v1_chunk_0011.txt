Ability to assess the quality of input content. A robust LLM should effectively distinguish the quality of documents, deter- mining which documents are genuinely helpful in addressing the question and which are useless. On the one hand, distinguishing the input documents helps LLMs develop critical thinking and reduces their dependency on the retrieved results. On the other hand, accurate identification of useful information is also critical to prevent retrieval defects from affecting the final output. • Ability to fully utilize useful information in the overall context. Once the model has developed an initial ability to as- sess input quality, it should be able to extract and exploit key information from high-quality and useful content while filtering out irrelevant or misleading content. Besides, the model should not only be capable of information filtering but also be able to synthesize multi-source information during answer generation to ensure the accuracy and completeness of the output. Therefore, the core of our strategy lies in equipping LLMs with stronger self-detection and extraction capabilities, enabling them to maintain efficient and accurate outputs in complex real-world scenarios. To achieve this goal, we design two specialized training tasks, namely Defect Detection and Utility Extraction, corresponding to input content assessment and effective information filtering, respectively (as shown in Figure 1). The joint training of these tasks enables the LLM to improve its resistance to interference in complex input environments, thereby enhancing the overall robustness of the RAG system. 4.1 Task I: Defects Detection The Defect Detection task aims to train the LLM to identify whether each retrieved document contributes to answering the user’s query. If a document is useless, the LLM must also classify it into one of three defect types, i.e., noisy, irrelevant, or counterfactual document. We treat the original retrieved documents as positive examples and randomly replace