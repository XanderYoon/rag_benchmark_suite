limitations by integrating LLMs with external knowledge sources, enabling en- hanced factual accuracy, up-to-date information access, and im- proved domain-specific performance [17, 26, 44]. Due to its effec- tiveness, RAG has been widely adopted to provide LLMs with a flexible mechanism for knowledge augmentation, enhancing their performance in varying scenarios [5, 14]. Despite their popularity, existing RAG systems suffer from a critical challenge: the performance of RAG systems heavily relies on the quality of the information provided by the retriever [25, 45, 54]. Since the real-world retriever and its corresponding knowledge base could be defective and imperfect [7, 36], the retrieved documents provided to the LLM may contain inaccurate, irrelevant, or even malicious and misleading information [4, 48]. Such low-quality or harmful information may hinder the LLM from accessing accurate knowledge, leading to inaccurate or misleading responses [53, 54, 59], significantly degrading the performance and reliability of RAG systems (as discussed in §3.2). Therefore, an imperative challenge arises: how to enhance the robustness of LLMs and RAG systems against retrieval defects, ensuring their ability to generate accurate responses even with defective retrieval results? Although there are several studies working on the robustness of RAG systems against retrieval defects through designing sophisti- cated inference mechanisms [48, 51–54], they are limited in several perspectives. First, a critical issue is the significant increase in in- ference costs, which severely limits the RAG pipeline’s runtime efficiency. This issue arises because existing studies mostly require generating intermediate results, which the LLM must aggregate or evaluate to produce the final response. Second, more impor- tantly, these methods tend to fail under severe retrieval defects or other challenging conditions since they do not fundamentally address the LLM’s dependency on input knowledge. For instance, RobustRAG [53] follows an "isolate-then-aggregate" pipeline, where answers are independently generated for each retrieved