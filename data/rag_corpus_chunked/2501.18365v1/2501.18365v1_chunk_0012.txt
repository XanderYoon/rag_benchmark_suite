Task I: Defects Detection The Defect Detection task aims to train the LLM to identify whether each retrieved document contributes to answering the user‚Äôs query. If a document is useless, the LLM must also classify it into one of three defect types, i.e., noisy, irrelevant, or counterfactual document. We treat the original retrieved documents as positive examples and randomly replace them with different types of defective documents at a probability of ùúè. To improve the efficiency, we adopt a listwise input format, where the LLM evaluates the entire list of retrieved documents at once. The prompt for this task is as follows: Input: Determine whether the following documents help answer the given question. The assessment includes: Assessment 1: The document helps answer the question. Assessment 2: The document is possibly relevant but does not help answer the question. Assessment 3: The document is irrelevant and does not help answer the question. Assessment 4: The document contains incorrect information and does not help answer the question. Only give me your assessment for each document and do not output any other words. Documents: Doc 1: { document 1 } Doc 2: { document 2 } ...... Question: { question } Output: Doc 1 helps answer the question. / Doc 1 is possibly relevant but does not help answer the question. / Doc 1 is irrelevant and does not help answer the question. / Doc 1 contains incorrect information and does not help answer the question. Doc 2 ...... RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects Conference acronym ‚ÄôXX, June 03‚Äì05, 2018, Woodstock, NY 4.2 Task II: Utility Extraction In the Utility Extraction task, we aim to train the LLM to extract as much useful information as possible from the defective retrieval result. The LLM can either directly utilize the extracted