need for benchmarks that link retrieval ac- curacy with generative quality, considering real-world applications. NA NA Continued on next page 4 Deploying Large Language Models with Retrieval Augmented G eneration Research Paper Summary Main Findings Models Retrieval Retrieval- Augmented Gen- eration for Large Language Models: A Survey [24] This survey explores RAG paradigms (naive, advanced, and modu- lar RAG), key technolo- gies in retrieval, gen- eration, and augmen- tation, and introduces evaluation frameworks and benchmarks. The survey discusses op- timization strategies and retrieval types (iterative, recursive, and adaptive), and explores future prospects for scaling RAG for production- ready systems. NA NA Retrieval- Augmented Gen- eration for Natural Language Process- ing: A Survey [25] This survey reviews different techniques of RAG, especially in the retriever and the retrieval fusions. Provides algorithms for implementing and dis- cusses the RAG training for the application of RAG in representative natural language process- ing tasks and industrial scenarios NA NA Improving the do- main adaptation of retrieval augmented generation (RAG) models for open domain question answering [26] This paper introduces RAG-end2end, which uses an auxiliary training signal to incor- porate domain-speciﬁc knowledge and evalu- ates it across datasets from three domains. The RAG-end2end model shows better performance than the original RAG and improves DPR perfor- mance more effectively than ﬁnetuning. pre-trained BART DPR (Pretrained dense retriever) uses 2 BERT models, FAISS indexing Evaluating Retrieval Quality in Retrieval- Augmented Genera- tion [27] This study presents eRAG, a method where each document in the retrieval list is indi- vidually used by the LLM, and the output is evaluated against ground truth labels for downstream tasks. Experiments show that eRAG improves corre- lation with downstream RAG performance and Kendall’s tau, while also being up to 50 times more efﬁcient in GPU memory usage compared to end-to-end evaluations. T5-small