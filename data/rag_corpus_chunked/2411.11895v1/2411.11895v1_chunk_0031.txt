OpenAIEmbedd i ng s 3 from langchain . text_splitter import CharacterT ex t Sp l i tt e r 4 from langchain . vectorstores import Chroma 5 6 text_splitter = Character Te x t Sp l it t er ( chunk_size =1000 , 7 chunk_overlap =50) 8 docs = text_splitter . split_documen t s ( documents ) 9 embeddings = OpenAIEmbed di ng s () 10 db = Chroma . from_document s ( documents = docs , embedding = e mbeddings ) 11 ret = db . as_retriever ( search_type = " similarity " , search_kwargs ={ " k ":3}) Listing 1: Initializing splitter for chunking documents an d also initializing embeddings model database and retrieve r. 4. After that, we create the embeddings. Since we are using C HATGPT as our large language model, we must use OpenAI’s embeddings. Below is the sample code, which sho ws one approach of implementing this. 5. The embeddings are stored in an instance of the C HROMA vector database. 1 from langchain . vectorstores import Chroma 2 from langchain . indexes import V e c t o r s t o r e I n d e x C r e a t o r 3 from langchain . embeddings . openai import OpenAIEmbedd i ng s 4 5 embeddings = OpenAIEmbed di ng s () 6 index = V e c t o r s t o r e I n d e x C r e a t o r( 7 text_splitter = text_splitter , 8 vectorstore _c ls = Chroma 9 ) . from_loaders ([ loader ]) 10 persist_di re ct o ry = ’ ../../ db ’ 11 if ( os . path . isdir ( persist_di re c to ry ) ) : 12 vectordb = Chroma