the system architecture. 4.4 Semantic Retrieval For the semantic search and retrieval component of our system, we conducted an extensive evaluation of various vector stores, both open-source and commercial, including C HROMA , P INECONE , and E LASTIC SEARCH . A key ﬁnding from our evaluation was that misalignments between the generate d responses and the user’s queries often stemmed from issues in the retrieval process rather than the LLM itself. To address this, we implemented functionality to display links to the documents retrieved during the search. This approach not only provided users with citations for fact-checking but also allowed us to diagnose and reﬁne our retrieval strat egies when incorrect documents were retrieved. We also implement relevance-checking approaches, which we will di scuss in the evaluation section. Initially, we chunked documents without overlap, but furth er experimentation revealed that overlapping chunks im- proved retrieval accuracy. We also varied the number of retr ieved results and tested different retrieval strategies, including similarity search, maximum marginal relevance, and hybrid approaches that combine keyword search with semantic retrieval. This iterative process helped us ident ify the optimal conﬁguration for our speciﬁc documents and use case. Recent research underscores the effectiveness of Retrieva l-Augmented Generation (RAG) approaches, particularly when combining semantic retrieval from vector databases wi th other techniques like knowledge graphs or ﬁne-tuning strategies. Knowledge graphs offer a complementary retrie val method, storing and querying information in the form of entity-attribute-attribute value triples. However, ge nerating knowledge graphs from proprietary documents pose s signiﬁcant challenges, especially when dealing with incon sistently structured documents that have evolved over time within various departments of an organization. Fine-tuning, including Parameter Efﬁcient Fine-Tuning (PEFT), also presents challenges. While PEFT is less resource - intensive than traditional ﬁne-tuning, it still requires c reating a training set,