include zero-shot pr ompting [6], where the model is given only instructions but no examples, few-shot prompting where the model is given instructions and a few examples 2 Deploying Large Language Models with Retrieval Augmented G eneration Figure 1: Large Language Model Landscape [7], chain-of-thought prompting [8] where the model is guid ed through steps for problem-solving, R EACT [9] where the model is guided using reasoning and task-speci ﬁc actions in an interleaved manner, or some combination of these different approaches. 2.1 Retrieval Augmented Generation Retrieval-Augmented Generation (RAG) is an approach that e nhances the capabilities of Large Language Models (LLMs) by augmenting their prompts with information retrie ved from a knowledge base that the LLM has not seen during training. This method adds domain-speciﬁc context t o the generated responses, leveraging the LLM’s ability to generate text while incorporating embeddings from existing documents stored in vector databases. These databases are speciﬁcally designed to store, query, and retrieve sentenc e embeddings, making them integral to the RAG approach. The ﬁeld of RAG has rapidly evolved, as highlighted by variou s studies such as those surveying various RAG method- ologies [21], [22], [23], [24], [25] and exploring advanced implementations like RAG- END 2END [26]. The table 1 summarizes various research efforts in the ﬁeld o f Retrieval-Augmented Generation (RAG), each address- ing different aspects and challenges of integrating retrieval mechanisms with large language models (LLMs) as well as the evaluation challenges of RAG systems. Key studies include the foundational work [19] that showed how incorporat- ing retrieval into individual tasks with a single retrieval -based architecture is capable of achieving strong perform ance 3 Deploying Large Language Models with Retrieval Augmented G eneration across several tasks. The survey [21] highlights RAG’s appl ications across multiple NLP tasks but notes areas