d e x C r e a t o r( 7 text_splitter = text_splitter , 8 vectorstore _c ls = Chroma 9 ) . from_loaders ([ loader ]) 10 persist_di re ct o ry = ’ ../../ db ’ 11 if ( os . path . isdir ( persist_di re c to ry ) ) : 12 vectordb = Chroma ( 13 persist_dire c to r y = persist_directory , 14 embedding_f un c ti o n = embeddings ) 15 else : 16 vectordb = createDB ( 17 docs = docs , 18 embeddings = embeddings , 19 persist_di re ct o ry = persist_di re c to ry ) 20 retriever = db . as_retriever ( 21 search_type = " similarity " , 22 search_kwargs ={ " k ":3}) 23 r = retriever . g e t _ r e l e v a n t _ d o c u m e n t s( q ) [: top ] Listing 2: Chunking Indexing and Storing the embeddings in t he Chroma vector database and Initializing the retriever. 6. Steps 1 to 5 happen once in a separate application workﬂow. When a user uploads new documents, we repeat the process for those new documents. 7. The application has a React.js frontend and a Python Flask API backend. When a user asks the chatbot, for example, “What features are in the latest release of a particular product?” the question gets sent to the backend Python Flask API in a serialized JSON object along with the co ntext history. Note that here, C HATGPT is expected to understand the meaning of the “latest” release. It would have to scan through all the documents to identify which release is the latest in this case. 8. When the question arrives at