Artiﬁcial Intelligence Systems 1 Introduction Recently, the landscape of artiﬁcial intelligence (AI) has changed drastically. With the emergence of large language models and their capabilities of generating textual respon ses based on various prompting techniques. A recent article by Bloomberg Intelligence (BI) [1] on the explosive growth of generative AI in the next d ecade predicts, “With the inﬂux of consumer generative AI programs like Google’s B ARD and OpenAI’s C HATGPT, the generative AI market is poised to explode, growing to $1.3 trillion over the next 1 0 years from a market size of just $40 billion in 2022.” As we develop cutting-edge applications that use large lang uage models, we must explore the various possibilities, understand the shortcomings, and develop ways to circumven t any obstacles to ensure a reliable human-artiﬁcial intelligence system. There are different approaches, even within the narrow scop e of implementing a solution, that use a large language model (LLM) to retrieve information from proprietary unstr uctured documents. Current approaches for retrieving information from unstructured text include ﬁne-tuning an L LM, parameter efﬁcient ﬁne-tuning approaches such as LORA [2], preﬁx tuning [3], prompt tuning [4], p-tuning [5], va rious approaches in prompt engineering such as zero- shot [6], few-shot [7], chain-of-thought [8] and R EACT [9]. It is essential to understand the business case and appl y appropriate approaches, often requiring experimentation such as prototyping and evaluating what works best. V arious libraries and tools have emerged to support the fast develop ment of LLM systems based on information retrieval from proprietary data. [10] [11] [12] These tools enable the LLMs to behave as agents, [13] function as reasoning engines, and invoke various tools supplied to the LLM to generate the required outcome. In addition, the LLM itself can be used to evaluate the