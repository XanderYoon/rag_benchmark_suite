within the system. The subsequent se ctions provide a detailed breakdown of the implemen- tation steps, highlighting key decisions, challenges enco untered, and the strategies employed to achieve the desired functionality. 4.1 Workﬂow After outlining the system architecture and detailing the d esign principles, we focus on the operational workﬂow of the prototype. This workﬂow is central to the system’s funct ionality, ensuring that each component interacts seam- lessly with the others. The steps outlined below provide a cl ear path from data ingestion to the ﬁnal user interaction, illustrating how the system processes, indexes, and retrie ves information to meet user queries efﬁciently. In the following workﬂow subsection, we break down the syste m’s operations step by step, starting from how doc- uments are read and processed to how user queries are handled and responses generated. This structured approach ensures that each stage of the process is clearly understood , enabling a smooth transition from design to fully func- tional implementation. Algorithm 1 Algorithm for Retrieval Augmented Generation using LLM 1: Create a prompt template with basic instructions to the LLM a nd include placeholders for retrieved document, user query and chat history 2: Instantiate splitter to chunk documents 3: docs = Split documents using splitter 4: Instantiate embeddings = OpenAIEmbeddings() 5: Instantiate V ector Database Chroma to store the split docum ents "docs" and their embeddings 6: Specify the vector database search type and number of top mat ching results for retrieval 7: Instantiate retriever 8: Save vector database in a persistent directory 9: while Chat session not exited do 10: Get the query from the application’s UI 11: Generate Embeddings for the query 12: Search top 3 results from the vector database that have embed dings "similar" to the query embeddings 13: Update the prompt template with