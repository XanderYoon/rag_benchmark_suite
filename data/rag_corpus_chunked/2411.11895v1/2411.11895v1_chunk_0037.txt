a basic structure with all the system instructi ons, calling it the prompt template. 2. This template contained placeholders for “follow-up que stions,” where the follow-up question would later be embedded. 3. It also contained placeholders for “sources” where the re trieved documents would be embedded and place- holders for the chat history and user questions. 4. For contextual history, we had to introduce speciﬁc begin and end tags for the instructions in the prompt. We found that it was helpful to demarcate the prompt and the hi story. For example, consider these tags: < |im_start| >< |im_end| >. 5. We also provided examples for follow-up questions, such a s the following. What are the features of the latest release of this product? 4.3 Logging Incorporating robust logging mechanisms is essential for t he effective operation and optimization of LLM-based sys- tems. Logging every input and output interaction with the LL M is not just a best practice for troubleshooting; it is also vital for ﬁne-tuning the model over time. Tracking the numbe r of tokens in each input, context, and response—whether the LLM is hosted locally or accessed via an API—provides val uable insights. This data is crucial for planning infras- tructure requirements and ensuring the scalability of the s ystem, particularly as trafﬁc increases. Logging also aids in understanding the model’s behavior, identifying patter ns of errors or inefﬁciencies, and making informed decision s about future adjustments to the system architecture. 4.4 Semantic Retrieval For the semantic search and retrieval component of our system, we conducted an extensive evaluation of various vector stores, both open-source and commercial, including C HROMA , P INECONE , and E LASTIC SEARCH . A key ﬁnding from our evaluation was that misalignments between the generate d responses and the user’s queries often