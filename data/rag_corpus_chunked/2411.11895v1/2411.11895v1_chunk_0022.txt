Pub- lished Upto 200,000 tokens ✗ The table 3 compares several prominent LLMs, including GPT f rom OpenAI, Gemini from Google, Llama from Meta, and Claude from Anthropic. It details key attributes such as whether each model supports multimodal inputs, its access methods, parameter sizes, token context windows, and open- source availability. For instance, GPT is not open-source. In contrast, Llama, developed by Meta, is open-source and su pports up to 405 billion parameters but does not handle multimodal inputs. Gemini and Claude, from Google and Anthr opic, respectively, support multimodal inputs but have varying access methods and token context capabilities. Thi s comparison helps in selecting the most suitable LLM based on speciﬁc requirements such as model size, context wi ndow, and open-source needs. When selecting a large language model (LLM) for deployment, it is essential to begin with a thorough evaluation of models that have been benchmarked on recognized datasets . Resources such as the Open LLM Leaderboard [33] and survey research papers [34] provide valuable insights i nto the performance and suitability of different LLMs for speciﬁc use cases. However, the selection process must also consider the organ ization’s resource constraints and policies. Critical dec i- sions include whether to use locally hosted models like LLaMA or public API models like ChatGPT, as well as whether to opt for open-source models or proprietary solutions. The size of the model and the choice between versions should be guided by the available infrastructure for hosting, the c ost associated with token usage, and the overall billing rat es. While larger models generally excel at complex reasoning tasks, smaller models that have been ﬁne-tuned can often de- liver superior performance for speciﬁc tasks [35]. This mak es model selection not just a technical decision but also one that involves strategic