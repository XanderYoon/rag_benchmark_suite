on the ﬁndings, are essential for maintaining the long-term security and reliability of RAG systems in any operational environment. 5.1.3 User acceptance test with pilot users To evaluate the practical application of our system, we cond ucted alpha testing with pilot users, measuring both qualitative and quantitative metrics through post-survey questionnaires (Please refer Appendix C). This process hel ped assess the system’s ﬁtness, conﬁdence, and projectability , providing valuable insights into its readiness for broade r deployment. Please refer Table 6 The post-survey results of the RAG application highlighted a mix of opinions, though feedback was generally positive compared to initial expectations. While users were initial ly enthusiastic about the potential of generative AI to im- prove efﬁciency, communication, and transparency, the majority rated their ﬁrst impression of the RAG application as 20 Deploying Large Language Models with Retrieval Augmented G eneration Table 6: Post-Survey Analysis Summary Question No. Summary of Response Percentage 1. First impression of the RAG ap- plication Most users had an “Ok” ﬁrst im- pression of the RAG application. Majority 2. Rating of the RAG applica- tion Users felt the application needed improvements, with varying levels of feedback on the extent of the re- quired improvements. - Some improvements: 52% - Signiﬁcant improvements: 28% - Minor tweaks: 13% - Ready for use: 7% 3. Effectiveness with context estab- lished The application often provided the correct answers when context was established. Majority 4. Effectiveness without con- text The application rarely provided cor- rect answers without context. Majority 5. Helpfulness of citation links All users found the citation links helpful, with suggestions for im- provement. 100% 6. Recommendation to team Most users would recommend the application to their team, though some expressed reservations due to needed modiﬁcations. Majority 7. Productivity improvement Most users believed the application would moderately