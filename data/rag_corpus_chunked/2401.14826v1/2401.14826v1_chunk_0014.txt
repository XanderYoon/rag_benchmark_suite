the dataset we have at hand is not large. The main objective of this paper is to provide a proof-of-concept that models trained using domain-specific perceptual features can lend a significant advan- tage in cross-modal retrieval applications. From Table 2, we see that augmenting with additional data has a minor but positive effect on the results whereas PCA tends to im- prove performance for non-augmented datasets. For the augmented case, PCA actually worsened the performance. 5 MID-LEVEL FEATURES AS EXPLANATIONS It is instructive to look at an individual example. The mid-level features that our model predicts from the audio recordings, and which it uses to establish a relationship to textual descriptions, can be viewed as a kind of explanation of the model’s retrieval choice, pointing to musical qualities in the performance that may have in- fluenced the decision. In the example shown in Figure 3, the piece in question is J.S.Bach’s Praeludium in C major from hisWell-Tempered Clavier (Book I), for which our database contains seven different recordings, by Walter Gieseking, Glenn Gould, Hélène Grimaud, Wilhelm Kempff, Sviatoslav Richter, Martin Stadtfeld, and one com- pletely expressionless, mechanical MIDI performance derived from the score. Given the query "shy, magical, deep, delicate, . . . ", the sys- tem returns the Grimaud performance (which is the "correct" one, as these descriptions were indeed associated with her performance by the human annotators); "mechanical, boring, beginner" returns, again correctly, the MIDI rendering. (The baseline MTR model also gets the Grimaud right, but returns Sviatoslav Richter in response to "mechanical, boring, beginner"). The mid-level feature profiles predicted from these text queries by our model (i.e., its ‘translation’ Expressivity-aware Music Performance Retrieval FIRE 2023, December 15–18, 2023, Panjim, India of free text into mid-level feature space) explain its decisions quite well and conform both to our