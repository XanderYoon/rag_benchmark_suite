between response quality and computational efficiency throughout sev- eral model sizes. • Large Models deliver outstanding performance but they are less practical for real-time or cost-sensitive installations since they need large computational re- sources. www.ijacsa.thesai.org 9 | P a g e (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 16, No. 2, 2025 • Medium Models fit for uses with intermediate hard- ware availability since they offer a useful compro- mise between dependability of performance and low resource usage. • Small Models are quick and light-weight, yet they usually underperform on jobs needing sophisticated thinking. Nonetheless, the unexpected findings in Llama3.2:3b suggest that smaller models can still show good performance. This trade-off emphasizes the need of choosing the suit- able model size depending on particular application criteria including accuracy, speed, and resource availability. D. Surprising Performance of Llama3.2:3b This study’s outstanding discovery is the exceptional per- formance of Llama3.2:3b, despite its classification as a small model. It outperformed a number of medium and even big models, achieving the highest results in answer faithfulness and answer relevance. According to this finding, factors including pre-training quality, data efficiency, and architectural upgrades can have an impact on model performance, in addition to parameter size. The potential for smaller models to produce high-quality outputs in resource-efficient environments is un- derscored by the robust performance of Llama3.2:3b when used in conjunction with effective frameworks such as RAG. E. Implications for Domain-Specific Tasks The research emphasizes both the difficulties and potential benefits of utilizing general-purpose LLMs for specialized tasks, including responding to inquiries about quranic studies. Although large models excelled in aligning responses with the given dataset, their effectiveness is significantly dependent on the quality and organization of the retrieved content. This re- search demonstrates how important it is to add domain-specific knowledge [4],