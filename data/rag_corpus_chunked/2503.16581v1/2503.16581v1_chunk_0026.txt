deliv- ering high-quality responses. Models like Llama3.2:1b and Phi3.5:3.8b scored the lowest across all metrics, reflecting their inability to process complex queries effectively due to their smaller parameter size. Inter- estingly, Llama3.2:3b emerged as an outlier, achieving performance levels comparable to the large models, particularly in answer faithfulness (4.619) and an- swer relevance (4.857). This unexpected performance demonstrates the efficacy of architectural improve- ments and pre-training techniques, even on smaller models. Although small models are computationally efficient and well-suited for lightweight tasks [41], their overall limitations render them less suitable for complex queries that necessitate a deep comprehen- sion of semantics. B. Effectiveness of the RAG Framework The implementation of the Retrieval-Augmented Gener- ation (RAG) framework significantly enhanced the response quality of the evaluated models [42]. By incorporating ex- ternal knowledge from the descriptive Qur’anic dataset, the models can retrieve pertinent information prior to formulating responses. This method alleviated the prevalent issue of hallu- cination, where language models produce factually inaccurate or irrelevant responses. The results demonstrate that the larger models derived the greatest advantage from the RAG framework, as their higher parameter sizes facilitated more effective integration of the retrieved context, resulting in enhanced performance across all metrics. Medium and small models showed enhancements, nevertheless, their capacity limitation affected the integration of retrieved knowledge, leading to lower context alignment and fewer accurate responses. C. Trade-Off Between Computational Resources and Response Quality The results of this research highlight the trade-off between response quality and computational efficiency throughout sev- eral model sizes. • Large Models deliver outstanding performance but they are less practical for real-time or cost-sensitive installations since they need large computational re- sources. www.ijacsa.thesai.org 9 | P a g e (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 16, No. 2, 2025 • Medium Models fit for