Human Evaluators In this research, human evaluators were instrumental in evaluating the responses produced by the large language models (LLMs) [31]. The evaluations were carried out using a specially designed website that focused on optimizing the evaluation process and maintaining consistency. The website offered evaluators with questions and responses from several LLMs, allowing for a systematic assessment using preset criteria which are context relevance, answer faithfulness, and answer relevance. 1) Evaluator Selection: The evaluators were selected with careful consideration to guarantee that they had the proper knowledge and comprehension of quranic studies, given that the study centers on inquiries pertaining to Islamic content. Criteria for selection included: • Knowledge of quranic studies : Evaluators who had either formal education or significant experience in Islamic studies were prioritized. • Analytical Skills : In order to evaluate the quality of responses across multiple dimensions, evaluators were required to possess strong analytical skills. • Familiarity with Evaluation Tasks: It was considered beneficial to have prior experience analyzing textual data or utilizing NLP technologies. Evaluators from a variety of backgrounds were included to make sure the replies were evaluated fairly and without bias. 2) Evaluation Platform: The evaluation process was con- ducted through a dedicated website designed to facilitate efficient and user-friendly assessments. The platform included the following features: • Query-Response Display: ◦ Each evaluation session displayed a prompt (query) along with responses generated by different LLMs. ◦ Responses were anonymized to prevent bias, ensuring that evaluators were not influenced by the identity of the LLM responsible for generating a response. • Scoring Interface: Evaluators rated each response based on the three evaluation criteria: ◦ Context Relevance: Precision and alignment of the response with the query. ◦ Answer Faithfulness: Accuracy of the response in relation to the retrieved dataset content. ◦ Answer Relevance: Appropriateness