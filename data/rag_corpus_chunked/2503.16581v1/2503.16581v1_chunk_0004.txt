into the use of descriptive datasets for religious education and AI-based knowledge systems [19]. The evaluation criteria consist of context relevance, response faithfulness, and answer relevance, and they are evaluated using human evaluation. [14]. This study provides a robust framework for integrating LLMs with descriptive datasets, thereby contributing to the expanding field of domain-specific AI applications [20]. It emphasizes the strengths and limitations of current LLMs in managing sensitive religious topics and establishes a foun- dation for future developments in AI-driven educational and informational tools. The rest of this paper is organized as follows: Section 1 introduces the challenges of using LLMs for Quranic studies and outlines the research objectives. Section 2 reviews related work, discussing previous studies on LLM applications in re- ligious text analysis and RAG-based retrieval systems. Section 3 provides a detailed description of the experimental setup, covering the dataset, NLP tasks and evaluation guidelines, dataset selection and curation, human evaluators, metrics for quality evaluation, large language models, and hardware and software configuration. Section 4 presents the experimental results of various LLM models. Section 5 discusses key findings, including performance insights based on model size, the effectiveness of the RAG framework, the trade-off between computational resources and response quality, the surprising performance of Llama3.2:3b, and implications for domain- specific tasks. Section 6 concludes the paper by summarizing the main contributions and providing suggestions for future research. II. M ATERIALS AND METHODS This section outlines the methodical strategy employed in our research. We begin by analyzing the dataset, detailing its source, structure, and descriptive content. Subsequently, the systemâ€™s responsibilities are thoroughly delineated, en- compassing the formulation of solutions to user concerns concerning Islamic doctrines [21]. In addition, we provide a summary of the rules that have been set for human evaluators who are responsible for evaluating the outputs