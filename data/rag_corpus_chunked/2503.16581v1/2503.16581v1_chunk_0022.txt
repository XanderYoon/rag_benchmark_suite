and 0.317, respectively. These models demonstrated decent performance but lagged behind the large models in handling complex or nuanced queries. • Small Models (Green) : The small models strug- gled overall, with Llama3.2:1b achieving the lowest score of 0.254. Phi3.5:3.8b and Phi3:3.8b performed moderately with scores of 0.333, while Gemma2:2b achieved 0.413. Notably, Llama3.2:3b outperformed all expectations with a score of 0.508, surpassing even some medium and large models. 2) Answer Faithfulness: Answer faithfulness as shown in Figure 2 measures whether the responses remain consistent with the retrieved content, avoiding inaccuracies or hallucina- tions. www.ijacsa.thesai.org 7 | P a g e (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 16, No. 2, 2025 Fig. 2. Answer Faithfulness by the 13 LLMs. • Large Models (Red) : The large models dominated this metric, with Llama3.2:3b (exceptionally perform- ing despite its small category) achieving the top score of 4.619. Llama3:70b and Llama3.1:70b scored 4.571 and 4.476, respectively, while Gemma2:27b and QwQ:32b followed with scores of 4.238 and 4.095. Their ability to maintain faithfulness highlights the advantages of larger parameter sizes. • Medium Models (Yellow) : The medium mod- els showed reliable performance, with Gemma2:9b scoring 4.143 and Llama3:8b achieving 3.762. Llama3.1:8b, while consistent, lagged slightly behind with 3.238. These models balanced faithfulness and efficiency but struggled with queries requiring deep contextual reasoning. • Small Models (Green) : The small models faced significant challenges. Llama3.2:1b recorded the low- est faithfulness score of 1.381, and Phi3.5:3.8b achieved 2.000, indicating frequent inconsistencies. While Phi3:3.8b scored slightly higher at 2.476, Llama3.2:3b stood out with a score of 4.619, showcas- ing exceptional faithfulness that rivaled larger models. 3) Answer Relevance: Answer relevance as shown in Fig- ure 3 assesses whether the generated responses address the query’s intent effectively. Fig. 3. Answer Relevance by the 13