semantic similarity [22]. • Storage in a Vector Database : The organized and scalar data was kept in a scaled vector database so that it would be easy to find the right descriptions during query processing [23],[22]. This particular dataset provides lots of information that goes beyond the actual text of the Qur’an, including contextual and interpretative details. Based on this, it is a great instrument for evaluating the ability of LLMs to produce responses that are true, accurate, and relevant to the context in which they are being used. By emphasizing descriptive elements, the dataset ensures that responses align with established interpretations and scholarly perspectives. B. NLP Tasks and Evaluation Guidelines A Retrieval-Augmented Generation (RAG) architecture will be utilized in order to accomplish the objective of this study, which is to evaluate large language models (LLMs) in the context of answering questions related to quranic studies [24]. The RAG approach combines LLMs with semantic retrieval to provide contextually relevant and authoritative responses from a descriptive dataset. The primary tasks and evaluation guidelines used to assess the system’s performance are outlined in full below [14]. 1) NLP Tasks: The research’s primary NLP task is to generate semantically pertinent and contextually accurate re- sponses to inquiries regarding quranic studies. The system em- ploys a Retrieval-Augmented Generation (RAG) architecture, combining retrieval-based and generative methodologies, to ensure that responses are both dataset-based and linguistically coherent. The system executes the following tasks: • Semantic Search and Retrieval: Upon a user’s query submission, the system does a semantic similarity search over the vectorized dataset obtained from Qur’anic surah descriptions [19]. This procedure de- termines the most contextually pertinent entries from the dataset to respond to the query. • Response Generation: The retrieved descriptions are submitted to the LLMs, which produce a compre- hensive response [14].