language models meet vector databases: A survey,” arXiv preprint arXiv:2402.01763, 2024. [24] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana, and S. Nanayakkara, “Improving the domain adaptation of retrieval aug- mented generation (rag) models for open domain question answering,” Transactions of the Association for Computational Linguistics , vol. 11, pp. 1–17, 2023. [25] A. Y . Alan, E. Karaarslan, and ¨O. Aydin, “A rag-based question answering system proposal for understanding islam: Mufassirqas llm,” arXiv preprint arXiv:2401.15378 , 2024. [26] D. Tam, A. Mascarenhas, S. Zhang, S. Kwan, M. Bansal, and C. Raffel, “Evaluating the factual consistency of large language models through summarization,” arXiv preprint arXiv:2211.08412 , 2022. [27] W. Zhou, S. Zhang, H. Poon, and M. Chen, “Context-faithful prompting for large language models,” arXiv preprint arXiv:2303.11315 , 2023. [28] C. Wang, S. Cheng, Q. Guo, Y . Yue, B. Ding, Z. Xu, Y . Wang, X. Hu, Z. Zhang, and Y . Zhang, “Evaluating open-qa evaluation,” Advances in Neural Information Processing Systems , vol. 36, 2024. [29] Y . Huang, S. Chen, H. Cai, and B. Dhingra, “Enhancing large language models’ situated faithfulness to external contexts,” arXiv e-prints , pp. arXiv–2410, 2024. [30] S. S. Monir, I. Lau, S. Yang, and D. Zhao, “Vectorsearch: Enhancing document retrieval with semantic embeddings and optimized search,” arXiv preprint arXiv:2409.17383 , 2024. [31] A. Elangovan, L. Liu, L. Xu, S. Bodapati, and D. Roth, “Considers- the-human evaluation framework: Rethinking human evaluation for generative large language models,” arXiv preprint arXiv:2405.18638 , 2024. [32] K. Feng, K. Ding, K. Ma, Z. Wang, Q. Zhang, and H. Chen, “Sample- efficient human evaluation of large language models via maximum discrepancy competition,” arXiv preprint arXiv:2404.08008 , 2024. [33] F. Moons and E. Vandervieren, “Measuring agreement among sev- eral raters classifying subjects into one-or-more (hierarchical) nom- inal categories.