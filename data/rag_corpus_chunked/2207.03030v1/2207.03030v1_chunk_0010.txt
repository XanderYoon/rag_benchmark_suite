Entries 1 RAG (Petroni et al., 2021) BART-Large 44.4 27.0 71.3 86.3 59.2 44.7 13.1 2 DPR + FiD (Piktus et al., 2021) T5-Base 51.6 38.3 72.7 89.0 82.2 74.0 15.7 3 KGI (Glass et al., 2021) BART-Large 45.2 – 61.0 85.6 84.4 72.6 18.6 4 Re2G (Anonymous, 2022) BART-Large 51.7 – 76.3 89.6 87.7 – 18.9 5 Hindsight (Paranjape et al., 2021) BART-Large – – – – – – 19.2 6 SEAL+FiD (Bevilacqua et al., 2022) T5-? 53.7 40.5 70.9 89.5 83.7 74.7 18.3 Ours (Alt-200 passages) 7 GTR + FiD with treatment ˆT T5-Base 52.4 30.1 78.9 87.1 83.4 81.5 18.4 8 T5-XL 61.2 39.1 84.6 92.3 85.2 83.7 20.6 training examples change the most under our relevance-label sampling strategy: We see that for both passage variants, both tasks improve considerably with the proposed sampling. Comparing lines 7 & 8 we observe a gain for TriviaQA of 12.7 EM and 4.9 Accuracy for T-REx. For the other tasks on our alternative passage-units, we observe small, but signiﬁcant gains on NQ, and zsRE. The other tasks FEVER, WOW, and HotpotQA only result in non-signiﬁcant changes inside the 95% conﬁdence interval. Retrievable units. To observe the impact of our alterna- tive passage aggregation strategy we need to compare the pairs of lines 5 & 7 as well as lines 6 & 8. Even though the properties of the two passage collections are very dif- ferent, the results of the retrieval augmented generation are very similar. Our alternative approach is slightly better on NQ, HotpotQA, and WOW. Overall, we also notice, that our passage sampling strategy works slightly better on the alternative passages, resulting in the best overall results of our ablation. Therefore, we select this combination (line 8) for the following experiments. Scaling the generator capacity. In most NLP settings,