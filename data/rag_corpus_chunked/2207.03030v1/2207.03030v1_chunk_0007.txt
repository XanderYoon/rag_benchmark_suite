20.1 ±.2 8 GTR + FiD with treatment ˆT T5-Base 56.0 ±.3 31.8 ±.2 78.4 ±.2 89.6 ±.4 82.5 ±.1 71.4 ±.3 19.9 ±.2 9 T5-Large 60.7 ±.5 35.4 ±.2 81.8 ±.2 92.1 ±.2 82.9 ±.1 72.9 ±.4 19.9 ±.2 10 T5-XL 62.9 ±.4 39.0 ±.2 84.3 ±.2 92.8 ±.4 84.1 ±.2 75.2 ±.3 21.0 ±.3 Alternative retrievable units. The initial KILT release offers a ﬁne-granular view on the Wikipedia collection. The raw paragraph collection contains 111.4 million items, with a strong concentration of very short sequences (< 20 words), as shown in Figure 2. This is not a practical number of pas- sages to index with dense retrieval methods (as the memory requirement is determined by the number of passages). A standard aggregation approach, proposed by Karpukhin et al. (2020) for DPR is to aggregate the raw data to passages of up to 100 words. It adds as many words to a new passage until 100 words or a changed document are reached, which breaks most paragraphs at the boundaries in half. There- fore, we propose an alternative aggregation strategy to relax the strict length requirement and favoring not to break up paragraphs. We aggregate whole raw-paragraphs until they reach 200 words, or start a new passage if they do not ﬁt. This change results in a very different length distribution, as shown in Figure 2. It results in only 27.7 million passages, compared to 35.7 million of the original chunking. In both cases the title of the page is added to all passages. Implementation. All our experiments are based on the T5X framework (Roberts et al., 2022). We use a ﬁxed GTR-Base dense retrieval model (Ni et al., 2021), which is pre-trained on the MSMARCO passage retrieval task (Bajaj et al., 2016) and has been shown to generalize