RAG (Lewis et al., 2020), and REALM (Guu et al., 2020) are trained on individual tasks. In their initial baseline setup Petroni et al. (2021) already studied the impact of multi-task retrieval training; Maillard et al. (2021) continued to study various conﬁgurations for KILT multi-task single-model retrieval. Lewis et al. (2021) trained the RePAQ-retriever system on multiple tasks, but for their FiD defer mechanism used task-speciﬁc FiD checkpoints. For context-given question answering Khashabi et al. (2020) trained UniﬁedQA on multiple QA tasks. Improved RAG training. Many of the recent papers im- proving RAG-style models optimized end-to-end processes (f.e. EMDR2 (Singh et al., 2021)), ensembling multiple modules (f.e. R2-D2 (Fajcik et al., 2021)), or creating multi- ple training loops to update the indexed documents multiple times (f.e. Hindsight (Paranjape et al., 2021)). Our approach differs, as we focus on the selection of the available train- ing data in a multi-task setting. For more information on retrieval-enhanced machine learning models, we refer the reader to Zamani et al. (2022). 6. Conclusion We proposed a simple yet effective approach for multi-task training of the FiD retrieval-augmented generation model on the KILT benchmark. We cleaned (and downsampled were necessary) the training set by removing query-answer pairs with low relevance conﬁdence. We demonstrated that this approach substantially improves two imbalanced tasks, and has a smaller beneﬁt on two of the remaining ﬁve tasks. By scaling the model capacity we achieve state-of-the-art results on ﬁve KILT tasks evaluated by the leaderboard. Acknowledgements This research was supported in part by the Google Visiting Scholar program and in part by the Center for Intelligent Information Retrieval. Any opinions, ﬁndings, and conclu- sions or recommendations expressed in this material are those of the authors and do not necessarily reﬂect those of the sponsors. We would like to thank Jianmo