Multi-Task Retrieval-Augmented Text Generation with Relevance Sampling Sebastian Hofst¨atter 1 Jiecao Chen 2 Karthik Raman 2 Hamed Zamani 3 Abstract This paper studies multi-task training of retrieval- augmented generation models for knowledge- intensive tasks. We propose to clean the training set by utilizing a distinct property of knowledge- intensive generation: The connection of query- answer pairs to items in the knowledge base. We ﬁlter training examples via a threshold of conﬁ- dence on the relevance labels, whether a pair is answerable by the knowledge base or not. We train a single Fusion-in-Decoder (FiD) generator on seven combined tasks of the KILT benchmark. The experimental results suggest that our sim- ple yet effective approach substantially improves competitive baselines on two strongly imbalanced tasks; and shows either smaller improvements or no signiﬁcant regression on the remaining tasks. Furthermore, we demonstrate our multi-task train- ing with relevance label sampling scales well with increased model capacity and achieves state-of- the-art results in ﬁve out of seven KILT tasks. 1. Introduction Retrieval augmented generation models are trained as a unit consisting of retrieval and generation modules (Lewis et al., 2020). The knowledge base accessed by the retriever module offers many beneﬁts for practical use, such as main- tainability through updates and domain adaptations. On the other hand, this setup brings additional complexity to the text generation tasks, as we now administer connections of a query-answer pair to relevant items in the knowledge base, for a more holistic view including retrieval performance (Zamani et al., 2022). The coverage sparsity of relevance judgements of large collections and the resulting reliability issues are well studied, yet still a timely problem in the re- trieval community (Zobel, 1998; V oorhees, 2001; Craswell et al., 2021; Hofst¨atter et al., 2021). This challenge is exacer- 1TU Wien, Austria (work conducted during