O., Clark, P., and Hajishirzi, H. Uniﬁedqa: Crossing format boundaries with a single qa system. arXiv preprint arXiv:2005.00700, 2020. Kwiatkowski, T., Palomaki, J., Redﬁeld, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., et al. Natural questions: a benchmark for ques- tion answering research. Transactions of the Association for Computational Linguistics, 7:453–466, 2019. Levy, O., Seo, M., Choi, E., and Zettlemoyer, L. Zero-shot relation extraction via reading comprehension. arXiv preprint arXiv:1706.04115, 2017. Lewis, M., Liu, Y ., Goyal, N., Ghazvininejad, M., Mo- hamed, A., Levy, O., Stoyanov, V ., and Zettlemoyer, L. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehen- sion. arXiv preprint arXiv:1910.13461, 2019. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., K¨uttler, H., Lewis, M., Yih, W.-t., Rockt¨aschel, T., et al. Retrieval-augmented generation for knowledge- intensive nlp tasks. Advances in Neural Information Pro- cessing Systems, 33:9459–9474, 2020. Lewis, P., Wu, Y ., Liu, L., Minervini, P., K¨uttler, H., Pik- tus, A., Stenetorp, P., and Riedel, S. Paq: 65 million probably-asked questions and what you can do with them. Transactions of the Association for Computational Lin- guistics, 9:1098–1115, 2021. Maillard, J., Karpukhin, V ., Petroni, F., Yih, W.-t., O˘guz, B., Stoyanov, V ., and Ghosh, G. Multi-task re- trieval for knowledge-intensive tasks. arXiv preprint arXiv:2101.00117, 2021. Ni, J., Qu, C., Lu, J., Dai, Z., ´Abrego, G. H., Ma, J., Zhao, V . Y ., Luan, Y ., Hall, K. B., Chang, M.-W., et al. Large dual encoders are generalizable retrievers. arXiv preprint arXiv:2112.07899, 2021. Paranjape, A., Khattab, O., Potts, C., Zaharia, M., and Manning, C. D. Hindsight: Posterior-guided training of retrievers for improved open-ended generation. arXiv preprint arXiv:2110.07752, 2021. Petroni, F., Piktus, A., Fan, A., Lewis, P. S. H., Yazdani, M., Cao, N. D., Thorne,