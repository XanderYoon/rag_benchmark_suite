fine-tuned model and hyperparameter settings can be found in the Appendix 10, 11. Query data preprocessing Query data tends to be brief and lack sufficient contextual cues, which can hinder the retrieval modelâ€™s ability to fully interpret user intent. To address this, we experimented with three distinct preprocessing methods. First, Default (FT stella 400M) used raw queries without any modifications. Second, Keyword Extraction + LLMLingua involved extract- ing key terms from each query while removing redundant words. Lastly, Query Expansion with LLM employed a large language model to enrich the queries with additional contextual information. Corpus data preprocessing Corpus data utilized in our study comprised a variety of for- mats, from plain text to tabular data. Recognizing that a simple preprocessing strategy would be insufficient for such a diverse dataset features, we implemented task-specific methods. First, the Default dataset is the raw corpus without any modifications. For the Corpus Markdown Restructuring, we restructured documents using markdown formatting to enhance clarity and preserve inherent structural elements. Additionally, we implemented two specialized methods for the MultiHiertt dataset, where tabular data is emphasized. Corpus Table Augmentation refers to 5 Accepted at the ICLR 2025: Advances in Financial AI Workshop augmenting table cells with textual annotations of rows and columns, as in Investment Return, 2016 = $192 (in millions). This better captures the implications within the table by attaching distant row and column data. Corpus Table Extraction focuses on isolating and emphasizing the intrinsic structure of tabular data by removing non-tabular text within the chunk (Lee & Roh, 2024). Hybrid Retrieval To determine the optimal balance between sparse search and dense search that fully reflects the characteristics of the task, we sought to identify the optimal alpha value. We incremented alpha from 0 to 1 in steps of 0.025, computed the total score corresponding