query, thereby resolving challenges related to information omission and hallucination. Overall, the results validate the robustness and effectiveness of our RAG pipeline in the finance do- main. The substantial performance gains and enhanced retrieval quality provide a reliable foundation for applications in financial contexts, where precise information retrieval and specialized expertise are critical. This work lays the groundwork for future research aimed at optimizing RAG in finance and outlines possible applicability to other domain-specific natural language processing tasks. 7 F UTURE WORK Our proposed method overcomes the limitations of the existing RAG pipeline through improve- ments on retrieval tailored to the finance domain, thereby opening new possibilities for natural language processing in specialized contexts. However, several remaining challenges warrant further investigation. First, our proposed method faces difficulties in incorporating rapidly changing financial data. Because financial markets continuously generate time-sensitive information such as corporate disclosures, news, and fluctuations in stock prices, in-depth research on techniques for efficiently retrieving and indexing streaming data is essential. Moreover, the need for a multilingual extension of the RAG framework becomes evident when considering the global nature of financial environ- ments (Zhao et al., 2024). Second, security problems must be addressed. Derner et al. (2024) has already highlighted the susceptibility of large language model-based systems to various threats, including malicious prompt attacks. To mitigate these risks and ensure AI safety, it is crucial to adopt the layered security strategies presented in Shamsujjoha et al. (2025), as exemplified by LLaMA Guard (Inan et al., 2023). Finally, adherence to ethical regulations in the finance domain and broader AI governance guide- lines, represented by EUâ€™s Ethics guidelines for trustworthy AI (Commission et al., 2019), calls for robust monitoring and oversight when deploying this pipeline in real-world settings. Future research could focus on establishing systems that continually evaluate inference processes