structure of tabular data by removing non-tabular text within the chunk (Lee & Roh, 2024). Hybrid Retrieval To determine the optimal balance between sparse search and dense search that fully reflects the characteristics of the task, we sought to identify the optimal alpha value. We incremented alpha from 0 to 1 in steps of 0.025, computed the total score corresponding to each ratio, and then evaluated the resulting matches using the NDCG@10 metric to observe the trend in score changes. The alpha value that yielded the highest NDCG@10 score was designated as the optimal alpha. Reranking In the reranking stage, the selected models were “bge-ranker-v2-m3 (BAAI)” and “voyage-rerank-2 (V oyage AI)”, based on MTEB. We utilized the top-20 retrieval results from the fine-tuned stella en 1.5B v5 model as the reranking target. The reranked results were evaluated using NDCG@10. Selection Agent The selection agent processes the top-10 retrieved documents. Acting as a financial expert, the agent selects only the documents actually useful in answering the query, based on factual accuracy, relevance, and clarity. This reduces token overhead and improves response quality. The prompt we used can be found in the Appendix A.2 Generation We evaluated the generated responses, referencing two metrics from RAGAS (Es et al., 2023): Answer Relevance and Context Precision without reference. Answer Relevance quantifies how directly the generated answer addresses the query by reverse-engineering questions from the answer and averaging their cosine similarities with the query. Context Precision without reference employs GPT-4o mini to compare context chunks with the generated response, ensuring that relevant information is prioritized. A key component is our DPO-trained(Rafailov et al., 2023) GPT-4o mini. We generated answers using the gpt-4o-2024-08-06 at two temperature settings (0.1 and 1.0) for identical queries, then evaluated responses on financial terminology and clarity to divide preferred and non-preferred