query 0.2716↑ 0.2682↑ 0.2985↑ 0.2843↑ 0.3370↑ 0.4488↑ 0.3925↑ +0.34 nDCG@10 for BERT using RemoveStopWords), removing un- necessary information from the original query on certain cases. 6 CONCLUSION In this work we studied the robustness of ranking models when faced with query variations. We first described a taxonomy of trans- formations between two queries for the same information need that characterizes how exactly a query is modified to arrive at one of its variants. We found six different types of transformations, and we focused our experiments on the ones that do not change the query semantics: misspelling, naturality, ordering and paraphrasing. They account for 57% of observed variations in the UQV100 dataset. For each of these four categories we proposed different methods to automatically generate a query variation based on an input query. We studied the quality of the generated query variations, and based only on the valid ones we analyzed how robust retrieval pipelines are to them. Our experimental results on two different datasets quantify how much each model is affected by each type of query variation, demonstrating large effectiveness drops of 20% on aver- age when compared to the original queries from the test sets. We found rank fusion techniques to somewhat mitigate the drops in effectiveness. Our work highlights the need of creating test collections that include query variations to better understand model effectiveness. As future work, we believe that it is important to study (I) how to automatically generate high quality query variation generators for categories that do change the semantics—while maintaining the same information need—of the query and (II) techniques to improve the robustness of existing ranking pipelines. REFERENCES [1] Nasreen Abdul-Jaleel, James Allan, W Bruce Croft, Fernando Diaz, Leah Larkey, Xiaoyan Li, Mark D Smucker, and Courtney Wade. 2004. UMass at TREC 2004: Novelty and