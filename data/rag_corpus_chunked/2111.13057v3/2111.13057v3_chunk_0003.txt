for ranking [41]. If, for example, the word order of the origi- nal query from TREC-DL-2019 right pelvic pain causes is changed to causes pelvic pain right , the retrieval effectiveness of the resulting ranking drops by 46%. Similarly, paraphrasing define visceral to what is visceral reduces the retrieval effectiveness by 38%. In our work, we quantify the extent to which different retrieval models are susceptible to different types of query variations as mea- sured by their drop in retrieval effectiveness. In contrast to prior works that either analyze behaviour of models when faced with modifications to the documents [32], analyze models through the arXiv:2111.13057v3 [cs.IR] 15 Feb 2022 Woodstock ’18, June 03–05, 2018, Woodstock, NY Gustavo Penha, Arthur Câmara, and Claudia Hauff lens of IR axioms [12, 48] or analyze NLP models via general natu- ral language text adversarial examples [23, 49], we instantiate our query variations based on user-created data. Concretely, we manu- ally label a large fraction of UQV100 queries1 and extract six types of frequently occurring query transitions: gen./specialization, as- pect change, misspelling, naturality, ordering and paraphrasing—an example of each is shown in Table 1. The last four of these cate- gories change the query syntax but not its semantics. For each of the syntax-changing categories, we develop automated approaches that enable us to generate query variations of each category for any input query. With these query variation generators in place, we conduct extensive empirical work on the recent TREC-DL-2019 [16] and ANTIQUE [25] datasets to answer the following research ques- tion: Are retrieval pipelines robust to different variations in queries that do not change its semantics? To this end we consider seven ranking approaches: two traditional lexical models (BM25 [50] and RM3 [1]), two neural re-ranking approaches that do not make use of transformers (KNRM