striving to achieve a balance between creativity and coherence [5]. In this vein, we introduce a new framework called Loops On Retrieval augmented generation (LoRAG). The LoRAG framework aims to tackle the challenges encountered by conventional generative models, such as maintaining coher- ence, relevance, and informativeness in the generated text. By integrating loops into the retrieval process, LoRAG endeavors to establish a dynamic interplay between the generative model and the retrieved information, promoting a more contextually aware and coherent generation. A. Motivation The rationale behind LoRAG originates from the deficien- cies identified in current text generation models. While purely generative models demonstrate proficiency in creativity, they frequently encounter challenges related to factual precision and contextual coherence. Conversely, retrieval-based models excel in providing accurate information but may exhibit short- comings in fluency and imaginative output. LoRAG endeavors to leverage the advantages of both approaches by incorporating a loop mechanism that iteratively enhances the generation through engagements with the retrieved content. B. Objective The principal aim of this study is to investigate the efficacy of LoRAG in enhancing the caliber of generated text by progressively integrating information from a retrieval mech- anism. Our goal is to illustrate the capability of LoRAG in mitigating common challenges encountered in text generation tasks, including coherence, relevance, and context retention. II. R ELATED WORK The domain of retrieval-augmented generation has seen significant research endeavors dedicated to amalgamating the merits of generative and retrieval-based methodologies. Re- markable strides have been taken to enhance the relevance, coherence, and informativeness of generated text. A. Retrieval-augmented Generation Models Early efforts to integrate retrieval mechanisms with gener- ative models include techniques like the Dual Encoder archi- tecture [7], [13], which employs distinct encoders for context and response. The context encoder handles input information, while the response encoder generates the output. Despite