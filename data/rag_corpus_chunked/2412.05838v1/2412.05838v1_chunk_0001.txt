workflows that require integration with diverse, dynamic, or private data sources. By leveraging specialized agents and a modular execution environment, the system provides an efficient and robust solution for handling complex, heterogeneous data environments in generative AI applications. Keywords Multi-Agent RAG Systems · Retrieval-Augmented Generation · Large Language Models · Database Integration · Generative AI arXiv:2412.05838v1 [cs.AI] 8 Dec 2024 1 Introduction Large Language Models (LLMs) have significantly advanced natural language processing by enabling sophisticated query interpretation and text generation. [1, 8] Despite their capabilities, LLMs are limited by their reliance on static pre-trained datasets, which restricts their ability to incorporate dynamic, domain-specific, or private data into their responses. Retrieval-Augmented Generation (RAG) systems address this challenge by integrating external data retrieval with generative processes, providing more context-aware and accurate outputs. Traditional RAG systems typically employ single-agent architectures where a single system is responsible for query generation, data retrieval, and response synthesis. While effective for basic use cases, these monolithic designs often face limitations when dealing with diverse data sources, such as relational databases, document stores, and graph-based data [19]. These systems also require elaborate prompts containing schemas, examples, and user queries, leading to inefficiencies in token usage, increased processing latency, and potential inaccuracies in query handling. To overcome these challenges, this paper proposes a Multi-Agent RAG system [22, 23]. Unlike traditional approaches, this system delegates the task of query generation to specialized agents, each tailored to a specific type of database. These agents generate optimized, database-specific queries without directly executing or retrieving data. Queries are executed in a separate execution environment, ensuring compatibility with diverse data storage systems. The retrieved context is then combined with the user’s original query and processed by a generative agent, which synthesizes a coherent and contextually relevant response. The proposed system introduces a modular design