Generated Query: db.Projects.find({ "assigned_to": "Saba Attar", "status": "completed" }); Neo4j Agent Few-Shot Prompt Schema Overview: Graph: ResearchNetwork Nodes: - Researcher {name: string, field: string} 5 Relationships: - COLLABORATES_WITH - WORKS_ON Example 1: Question: List all collaborators of Arnab Mitra Utsab. Generated Query: MATCH (r:Researcher {name: ’Arnab Mitra Utsab’})-[:COLLABORATES_WITH]->(collaborator:Researcher) RETURN collaborator.name; Example 2: Question: Find researchers working on AI projects in the domain of healthcare. Generated Query: MATCH (r:Researcher)-[:WORKS_ON]->(project) WHERE project.domain = ’AI in Healthcare’ RETURN r.name; 3 Related Work and Research Contributions 3.1 Single-Agent RAG Systems This study focuses on improving Single-Agent [21] Retrieval-Augmented Generation (RAG) systems to solve complex problems more effectively. It addresses the limitations of traditional LLMs, such as weak reasoning and context handling, by using evidence-based reasoning to guide response generation. This approach simplifies the process by having a single agent retrieve and use relevant evidence for better output. The study shows that single-agent RAG systems can achieve strong performance in knowledge-intensive tasks, offering a more efficient alternative to multi-agent systems while still delivering high-quality results [3]. The Speculative RAG framework enhances single-agent RAG systems by using a two-LM approach for improved efficiency and accuracy. A smaller, distilled specialist LM drafts multiple responses from different document subsets, while a larger generalist LM verifies these drafts in a single pass. This method reduces token use, mitigates position bias, and speeds up processing. Extensive testing on benchmarks such as TriviaQA, MuSiQue, PubHealth, and ARC-Challenge shows that Speculative RAG boosts accuracy by up to 12.97% and cuts latency by 51% compared to conventional RAG systems, setting a new standard for single-agent RAG performance [15]. Although pre-trained language models are good at storing knowledge, they have trouble updating and precisely accessing it, particularly when performing knowledge-intensive operations. To overcome this, RAG models integrate non-parametric memory, such as a vector index