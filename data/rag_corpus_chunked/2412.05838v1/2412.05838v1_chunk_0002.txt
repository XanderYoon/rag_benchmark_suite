database. These agents generate optimized, database-specific queries without directly executing or retrieving data. Queries are executed in a separate execution environment, ensuring compatibility with diverse data storage systems. The retrieved context is then combined with the user’s original query and processed by a generative agent, which synthesizes a coherent and contextually relevant response. The proposed system introduces a modular design that improves scalability, enhances retrieval accuracy, and supports seamless integration with polyglot data environments [ 20]. By delegating specific tasks to specialized agents and incorporating a centralized execution mechanism, this system addresses the inefficiencies of traditional single-agent [21] RAG implementations. It offers a robust solution for integrating domain-specific and heterogeneous data into generative AI workflows, making it well-suited for a wide range of real-world applications. 2 Background 2.1 Retrieval-Augmented Generation (RAG) Retrieval-Augmented Generation (RAG) extends the capabilities of LLMs by incorporating external or private data into the response generation process. Unlike traditional LLMs that generate responses based solely on their pre-trained knowledge [1], RAG systems retrieve relevant domain-specific data from external sources to provide contextually accurate and up-to-date outputs. This is particularly useful when dealing with private or proprietary data that is inaccessible to the LLM during training. [3, 9, 10] The retrieval phase is critical in RAG as it forms the foundation for accurate and relevant responses. For example, when a user asks, “What is Machine Learning?” the LLM can generate a generic response from its pre-trained knowledge. However, if the user asks, “What is the role of AI and ML in the XYZ development team?” the system needs to retrieve private context, such as “The XYZ team uses AI for predictive analytics and natural language processing,” to provide a tailored and meaningful response. The integration of retrieved context with generative capabilities ensures that the outputs are both accurate