system resolves these challenges by delegating tasks to specialized agents, each tailored to handle a specific type of database. For example, a MySQL agent is responsible for generating optimized SQL queries for relational databases [10], while a MongoDB agent specializes in document-based data retrieval. By focusing solely 2 on one database type, each agent can generate precise and efficient queries, reducing the workload and complexity associated with a single-agent architecture. This division of labor not only improves accuracy and speed but also allows the system to scale seamlessly by adding new agents for emerging data sources. The modular design ensures adaptability, making the Multi-Agent [22, 23] RAG system robust and effective in managing diverse data environments. 2.3 Choice of LLM in RAG The choice of Large Language Models (LLMs) [1, 5, 4, 2] is a crucial consideration in the design and implementation of Retrieval-Augmented Generation (RAG) systems. LLMs serve as the foundation for query generation and response synthesis, but their token limits and processing capabilities significantly impact the system’s efficiency and scalability. LLMs can be broadly categorized into two types: local models [?] and API-based models [6, 7, 5]. Both categories have unique advantages and challenges, making the decision highly dependent on factors such as data sensitivity, computational resources, and scalability requirements. Local LLMs, such as Mistral, Zephyr, and Llama [4], operate within an organization’s infrastructure, providing complete control over sensitive or proprietary data. This makes them particularly suitable for industries like healthcare and finance, where data privacy and regulatory compliance are critical. Local deployment ensures that no sensitive data leaves the premises, mitigating risks associated with data breaches. However, these models require substantial computational resources, including high-performance GPUs, for efficient operation, which can increase the cost and complexity of deployment.[5, 2]. API-based LLMs, such as OpenAI’s GPT models and