number and distribution of features, ranging from a 2DoF translation model, to a 4DoF similarity model, and ﬁnally to an 8DoF homogra- phy model. The feature extraction and tracking can be done using standard methods, including ﬁnding good features to track [19]. The feature locations with their IDs and motion vectors (with camera motion subtracted) for an entire frame, (a) (b) Figure 2: A comparison between (a) homography tracking and (b) perspective tracking of 500 consecutive frames. along with the full-frame camera motion model, are packed into the motion data and sent to the region tracking module. 3.2. Region tracking Using solely the motion data produced by the motion analysis module, the region tracking algorithm tracks in- dividual objects or regions while discriminating them from others. To track an input region, we ﬁrst crop the motion data to a corresponding dilated sub-region. Then, using iter- atively reweighted least squares (IRLS) we ﬁt a parametric model to the region’s weighted motion vectors to determine the region’s movement across consecutive frames. Our importance weights wi for each vector vi are of the form wi = pi ei with pi being the prior of a vectorvi’s impor- tance and ei the iteratively reﬁned ﬁtting error. Each region has a tracking state that deﬁnes the priorpi, and includes the mean velocity, the set of inlier and outlier feature IDs, and the region centroid. Note that by relying on feature IDs we implicitly capture the region’s appearance since each fea- ture’s patch intensity stays roughly constant over time. Ad- ditionally, by decomposing a region’s motion into that of the camera motion and the individual object motion, we can even track featureless regions. An advantage of our architecture is that the motion anal- ysis yields a compact motion metadata over the full image, enabling great ﬂexibility