corners of the target (a quadrilateral) across frames. In this scenario, a homography transforma- tion is commonly used to describe the inter-frame move- ment of the quadrilateral [16]. Speciﬁcally, a homography matrix is ﬁrst estimated from feature correspondences be- tween frames, and applied to update the position of the quadrilateral. While a homography has 8 degrees of free- dom, in reality, the rigid body transformation that the target undergoes in 3D space is limited to 6 degrees of freedom. Consequently, the under-constrained nature of the homogra- phy transform produces quadrilateral shapes which are not physically possible. These estimation errors, accumulated over time, cause skew artifacts (even disregarding camera lens distortion) as shown in ﬁg. 2a. Instead, we advocate using a perspective transform to estimate the updated corner locations of the quadrilateral. Given the 3D coordinates of features in the previous frame and the corresponding 2D coordinates in the current frame, we solve for the rigid body transformation (3D rotation and translation) from the target local coordinates to the camera coordinates using Levenberg-Marquardt optimization. In ﬁg. 2b, we demonstrate that our approach reduces skew ar- tifacts and maintains the tracking quality and accuracy for as long as possible. 3.4. Pose estimation: calibration-free 6DoF The method for planar target tracking described above is restricted to scenarios with known object geometry. How- ever, our goal is to enable 6DoF pose estimation for all kinds of targets, to enable users to place 3D virtual ob- jects in the viewﬁnder, making them appear to be part of the real-world scene. Our key insight to enable this is to decou- ple the camera’s translation and rotation estimation, treating them instead as independent optimization problems. We employ our image-based region tracker to estimate translation and relative scale differences. The result mod- els the 3D translation of a