Instant Motion Tracking and Its Applications to Augmented Reality Jianing Wei, Genzhi Ye, Tyler Mullen, Matthias Grundmann, Adel Ahmadyan, Tingbo Hou Google Research {jianingwei, yegenzhi, tmullen, grundman, ahmadyan, tingbo }@google.com Abstract Augmented Reality (AR) brings immersive experiences to users. With recent advances in computer vision and mo- bile computing, AR has scaled across platforms, and has increased adoption in major products. One of the key chal- lenges in enabling AR features is proper anchoring of the virtual content to the real world, a process referred to as tracking. In this paper, we present a system for motion tracking, which is capable of robustly tracking planar tar- gets and performing relative-scale 6DoF tracking without calibration. Our system runs in real-time on mobile phones and has been deployed in multiple major products on hun- dreds of millions of devices. 1. Introduction Mobile phones carry an enormous amount of computa- tional power in a small package, making them an excel- lent platform for real-time computer vision and augmented reality applications. Recent releases of ARCore [1] and ARKit [2] scaled Augmented Reality (AR) to hundreds of millions of mobile devices across major mobile computing platforms. Their success is built on advances in computer vision, e.g. SLAM [20, 13, 18] and increases in on-device computational power. A critical component of AR is the ability to anchor vir- tual content to the real world by tracking the environment. Tracking provides the 3D transform that enables the accu- rate placement and rendering of virtual content in the real world. Augmentation using virtual content can be simply overlaying a 2D texture, or rendering complex 3D charac- ters into real scenes. In this paper, we propose a novel instant motion tracking system, based on robust feature tracking, as well as global and local motion estimation. With a shared motion