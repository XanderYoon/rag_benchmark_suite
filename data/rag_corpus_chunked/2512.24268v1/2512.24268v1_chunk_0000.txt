RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation Pankayaraj Pathmanathan1, Michael-Andrei Panaitescu-Liess1, Cho-Yu Jason Chiang3, and Furong Huang1,2 1University of Maryland College Park,2Capital One,3Peraton Labs etrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines—corpus poisoning—where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses:RAGPartandRAGMask.Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments. 1. Introduction Large Language Models (LLMs) (OpenAI et al., 2024, DeepSeek-AI et al., 2025) have demonstrated re- markable capabilities in reasoning, problem-solving, and generalization, fueling deployment in real-world domains such as healthcare (Wang et al., 2023) and finance (Loukas et al., 2023). Despite these successes, LLMs remain limited by their static training data, resulting in outdated knowledge, hallucinations (Huang et al., 2025), and gaps in domain-specific expertise. Retrieval-Augmented Generation (RAG) has recently gained popularity (Lewis et al., 2021) as a strategy to mitigate these limitations. RAG enhances LLMs by dynamically retrieving external documents relevant to a query from large corpora—such as Wikipedia (Thakur et al., 2021) or financial reports (Maia et al.,