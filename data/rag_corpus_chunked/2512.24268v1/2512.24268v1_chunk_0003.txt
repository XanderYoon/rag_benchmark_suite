requiring perfect or highly accurate retrieval. To satisfy these properties, we propose addressing corpus poisoning earlier—at the retrieval stage. This is feasible in practice because retrievers are typically smaller models than long-context LLMs, and their similarity computations (e.g., dot products in embedding space) are highly parallelizable. Motivated by deep partition-and-aggregation defenses (DPA) (Levine and Feizi, 2021, Sun et al., 2022) and perturbation-based defenses like RAP (Yang et al., 2021), we propose two complementary retrieval-stage defenses:RAGPartandRAGMask. RAGPart leverages dense retrievers’ training dynamics, particularly the observation that document fragments often preserve the semantic meaning of the full document in embedding space. For example, dense retrievers such as Contriever (Izacard et al., 2022) explicitly define positive training pairs by treating randomly cropped portions of a document as semantically equivalent to the whole, inducing an inductive bias in the retriever’s embedding space. We empirically observe that this behavior generalizes across multiple dense retrievers. By exploiting the similarity between full-document and fragment embeddings, RAGPart formulates a defense to mitigate the effect of poisoned content. RAGMask, on the other hand, targets a different vulnerability: poisoning often hinges on a small set of influential tokens that disproportionately affect similarity scores. By selectively masking these tokens and measuring the resulting similarity shift, RAGMask identifies and suppresses poisoned documents. 2 RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation Our contributions are summarized as follows. • We propose two retrieval-stage defenses—RAGPartandRAGMask—that are both computationally efficient and effective at mitigating corpus poisoning, without modifying the LLM or relying on strong retriever assumptions. • Wedemonstratetheefficacyofthesedefensesacrosstwobenchmarkdatasetsandfourdistinctpoisoning strategies. In addition to evaluating against existing attacks, we introduce a stronger, interpretable poisoning attack—AdvRAGgen—and show that our defenses remain robust under this more challenging threat model. • We present a theoretical result demonstrating the superiority of RAGPart over a naive combinatorial approach that