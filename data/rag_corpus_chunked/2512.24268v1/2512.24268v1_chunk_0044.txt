a poison at the retrieval stage; rather, we argue that one should consider a generation-level defense as this is due to the deficiency of the retriever. If one is to solve this problem in a retrieval defense, then they should consider enhancing the retriever with more hard negatives (a document that is getting retrieved but is not actually a relevant document; i.e., harder to discriminate document). The attack we proposed (AdvRAGgen) to some level does create such a document (where it blends the query into the adversarial document), thatâ€™s why it was a relatively harder attack to defend against, although our proposed defenses show an acceptable level of robustness against the attack. One may ask in what scenarios our assumption of the attack is practical. RAGs are used in e-commerce or in retrieving law documents in many cases. In the case of an e-commerce website, a malicious 23 RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation product seller may add a poison to make his product retrievable for an irrelevant query in order to increase their sales. Similarly, in the case of a legal RAG system, one may try to make a document with an incorrect judgment retrievable with malicious intentions. 24 RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation B. Attack B.1. AdvRAGgen We use an instruction-tuned Mistral 7B model (Jiang et al., 2023) as the generator. Given a query and an irrelevant document from the training set, the generator is prompted to paraphrase the document into a retrievable form. Initially, the generator lacks knowledge of what is considered retrievable for a given query. To address this, we fine-tune the generator using three types of feedback (listed below), applying direct preference optimization (DPO) (Rafailov et al., 2024). Specifically, two paraphrases are generated and