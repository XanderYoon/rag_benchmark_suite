mixes, so the total computational cost is: FLOPsnaive =D× (N k ) ×(k×R) RAGPart.In RAGPart, the embedding model is applied once to each of theN individual fragments per document, for a total of: FLOPsembedding =D×N×R Then, for each of the(N k ) combinations, we compute the mean ofk precomputed embeddings, each of dimensionn e, costingk×n e FLOPs per mix. Therefore, the total cost for the averaging step is: FLOPsaveraging =D× (N k ) ×(k×n e) Summing both terms, the total FLOPs for RAGPart is: FLOPsRAGPart =D×N×R+D× (N k ) ×(k×n e) Example.Suppose we have: R=10 9 (FLOPs per embedding),D=10 6,N=5,k=3,n e =512 Then: (N k ) = (5 3) =10 •Naive baseline: FLOPsnaive =10 6 ×10×(3×10 9)=3×10 16 •RAGPart: FLOPsRAGPart =10 6 ×5×10 9 +10 6 ×10×(3×512)=5×10 15 +1.536×10 10 Thus, RAGPart reduces the dominant cost (embedding model inference) by a factor of∼6× , trading it for a much cheaper averaging step. 15 RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation 7. Limitations Despite showcasing robustness against attacks while maintaining a minimal drop in SR/utility, there are certain types of poison that the proposed methods cannot inherently defend against. For instance adversarial documents that are designed to be semantically similar to the query (e.g. for a query of "what is the capital of France?" the adversarial document of "The capital of France is Berlin") the proposed defenses cannot be used as a defense mechanism. These are poisons that we argue cannot be defended against in the retrieval stage because they can never be classified as poisons until a generation is made. Retrievers are inherently trained to encode only information about semantic similarity and not about the generation condition. For further discussion refer to Appendix A. 8. Conclusion Inthiswork, weproposetworetrieval-stagedefenses, RAGPartandRAGMask, aimedatpreventingadversarial documents from being retrieved in Retrieval-Augmented