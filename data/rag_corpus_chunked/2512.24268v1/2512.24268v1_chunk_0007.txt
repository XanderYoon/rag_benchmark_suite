golden documents. In practice, these conditions rarely hold, and such approaches are computationally expensive because long-context LLMs must be invoked multiple times per inference. 3. Method 3.1. Defense: RAGPart Most state-of-the-art dense retrievers Wang et al. (2024), Izacard et al. (2022), Li et al. (2023) are pre-trained using a large-scale contrastive loss Khosla et al. (2021) and then fine-tuned on human-annotated data. Some retrievers, such as Izacard et al. (2022), select positive pairs during contrastive learning by sampling a random portion of a document and treating it as a positive example paired with the full document. This setup explicitly introduces an inductive bias that encourages the model to produce similar embeddings for different fragments of the same document. In practice, as we show in the Results section, even models that are not trained this way still exhibit similar behavior. Inspired by this observation and deep partition-and-aggregation (DPA) defenses Sun et al. (2022), we propose RAGPart. The key idea is to partition a document intoN fragments and apply the dense retrieverâ€™s embedding model to each fragment individually. Due to the inductive bias of dense retrievers, the fragment embeddings tend to preserve the semantic similarity of the full document. We then average the embeddings of different combinations of fragments to form a final similarity score. If the number of poisoned fragmentsnp is not too large, their influence is diminished through the averaging step. By evaluating multiple such combinations and aggregating the results, RAGPart effectively reduces the impact of the poisoned samples, as demonstrated in the Results section. In the context of dense retrieval as the first stage of RAG, and given the properties of document fragments, a document can be broken intoN fragments. Based on how we form combinations of these fragments, we consider two approaches, as seen below: 1. RAGPart: We