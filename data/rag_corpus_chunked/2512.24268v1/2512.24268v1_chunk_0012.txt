is a predefined hyperparameter representing the mask length. We mask the document at each of theseli m positions and recompute the similarity score between the query and the masked version of the document, denoted byv q i ′ . If v q i ′ +δ>v q i, we keep the masked tokens in the document; otherwise, we discard them. Afterli m ⋅αp such operations, we obtain a new set of partially masked documents, which we refer to as sanitized documents. Since retrievers are generally much smaller than LLMs, these operations can be parallelized efficiently to maintain acceptable time complexity. We then recompute the similarity between the sanitized documents and the queryq, re-rank theαp documents, and finally select the topp as the final set of retrieved documents. 3.3. Attack: AdvRAGgen In addition to the attacks discussed in the Experiments section, and inspired by the work of AdvBDGen (Pathmanathan et al., 2024), we propose an interpretable attack against RAG retrieval, calledAdvRAGgen. The idea behind this attack is to use a general-purpose causal language model that takes in a query and an adversarial document and generates a paraphrase of the adversarial document such that it is retrieved. The generator is trained via Direct Preference Optimization (DPO) using three feedback signals: 1. The semantic similarity between the original adversarial document and its generated paraphrase, measured by a semantic embedding model. This ensures the paraphrase maintains the intended content, satisfying the generation condition. 6 RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation 2. The similarity between the query and the paraphrase in the target retriever’s embedding space. This ensures the paraphrase is retrievable, satisfying the retrieval condition. 3. The negative ROUGE-L score between the query and the paraphrase. This discourages trivial attacks that involve simply inserting the query into the adversarial document.