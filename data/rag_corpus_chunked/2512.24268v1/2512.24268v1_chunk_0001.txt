data, resulting in outdated knowledge, hallucinations (Huang et al., 2025), and gaps in domain-specific expertise. Retrieval-Augmented Generation (RAG) has recently gained popularity (Lewis et al., 2021) as a strategy to mitigate these limitations. RAG enhances LLMs by dynamically retrieving external documents relevant to a query from large corpora—such as Wikipedia (Thakur et al., 2021) or financial reports (Maia et al., 2018)—and augmenting the model’s input context. Typically, documents are retrieved based on embedding similarity, computed by traditional methods (Salton and Buckley, 1988, Robertson and Zaragoza, 2009) or modern dense retrievers (Izacard et al., 2022, Wang et al., 2024). Despite enhancing factual consistency (Ayala and Bechard, 2024), RAG’s dependence on extensive, publicly sourced corpora introduces vulnerabilities tocorpus poisoningattacks (Zou et al., 2024). In these attacks, adversaries insert maliciously crafted documents intended to manipulate the retrieved context, thereby influencing the model’s outputs. An attack is successful when a poisoned document is retrieved (retrieval condition) and significantly impacts the LLM’s generated response (generation condition). Current defenses largely focus on the generation stage, proposing certifiable robustness via response aggre- Corresponding author(s): Pankayaraj; Email pan@umd.edu arXiv:2512.24268v1 [cs.IR] 30 Dec 2025 RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation E2 E3 E2 E3 E2 E3 E2 E3 --- 2. Embed -- - -- - -- - --- Document 1 Document 2 Document D-1 Document D --- 1 2 N-1 N- 1 2 N-1 N- 1 2 N-1 N- 1 2 N-1 N- -- - - - - - - - - - 1. Partition 3. Ablate E1 E1 E1 E1 Query EmbeddingQuery Embed Top P 1 Top P 2 Top P 3 4. Retrieve Top P 5. Aggregate E4 E4 E4 E4 E3 E1 E2 E1 E n E1 E3 E1 E2 E1 E n E1 E3 E1 E2 E1 E n E1