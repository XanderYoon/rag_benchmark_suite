result in better task outcomes or human performance. In addition, t he use of these systems could potentially undermine hu- man capabilities as people develop an overreliance on AI sys tems for tasks ranging from simple to complex [4, 14]. For example, while tools like GitHub Copilot may increase codin g quality and eﬃciency [23], the mechanism of autocom- plete does not inherently enhance individuals’ programming skills or understanding [17]. Similarly, while ChatGPT and similar LLMs can increase the speed and improve the ﬂuency of writing deliverables, they do not necessarily improve individuals’ inherent writing abilities and potentially r esulting in biased outcomes and content lack of depth[13, 19 ]. Amidst these ﬁndings, we consider the current landscape of A I tools reveals a concerning pattern: the design of AI systems is often output-driven yet overlooks its impact on h uman cognitive capabilities. Recent research has started to pay attention to how generative AI (GenAI) impacts individuals’ critical thinking and researchers have found mixed This paper was presented at the 2025 ACM Workshop on Human-AIInteraction for Augmented Reasoning (AIREASONING-2025-01). This is the authors’ version for arXiv. Authors’ addresses: Katelyn Xiaoying Mei, kmei@uw.edu, Un iversity of Washington, , Seattle, W A, USA, ; Nic Weber, nmweber@uw.edu, University of Washington, , Seattle, W A, USA, . Permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee pr ovided that copies are not made or distributed for proﬁt or commercial advantage and th at copies bear this notice and the full citation on the ﬁrst pa ge. Copyrights for components of this work owned by others than ACM must be honored. Abstrac ting with credit is permitted. To copy otherwise, or republi sh, to post on servers or to