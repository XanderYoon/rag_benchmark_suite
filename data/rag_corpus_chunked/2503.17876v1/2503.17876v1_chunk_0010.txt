with the de- sired emotional undertones, aligning with the target attributes. 2. Gradient-Guided Refinement:Employs a gradient-guided retrieval-generation mechanism to adjust the generated text at each step, ensuring continual alignment with the target emotional attributes for contextually and emo- tionally coherent output. As shown in Figure 3, we can also understand the EICL in terms of a prob- ability space. The regions Ie, Iz, and I (i) d are interpreted as states within the Title Suppressed Due to Excessive Length 7 () Fig. 3. The geometric diagram illustrates the emotion-influenced iterative generation process. Representations for the event schema, the document, and the I-th discrete demonstration are symbolized by Ie, Ix, and I(i) d correspondingly. probability space. Ie represents the initial emotional context, Iz the influence of the document context, and I (i) d the iterative demonstration towards the true value. The overlapping areas and the vector R symbolize the adaptive process of the learning model.In each iteration, the system enhances the fidelity of learn- ing outcome I (i) d , bringing it nearer to the true value.Using such an effective guide, we can make the final generated content closer to the patient’s space, which refers to a concept or psychological space that summarizes the patient’s emotional and health background. It plays a significant role in predicting and aligning with the emotional and informational needs of patients in the model. To realize this, we adopt a suffix-tuning method to transform continuous tasks into discrete data usable for training while keeping the LM (Language Model) parameters unchanged. Mathematically speaking, this is the search for the opti- mal parameters ϕ that maximize the log-likelihood function given a training set D and fixed model parameters θ. max ϕ P (y|x; θ; ϕ) = max ϕ X yi P (yi|h>i; θ; ϕ) (2) In equation 2,