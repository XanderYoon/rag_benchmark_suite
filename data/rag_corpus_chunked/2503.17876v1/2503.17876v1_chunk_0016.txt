the survey, enabling cross-verification of data reliability. These methodologies combined to form a robust framework, optimizing the authenticity of the satisfaction metrics obtained. Notably, the patient satisfaction percentages progressively increase for the variants of Ours - Ours (w/o TEIR) , Ours (w/o EICL) , and Ours, with Ours achieving the highest satisfaction rate at 36.83% (221 out of 600). This is attributed to the positive impact of the TEIR and EICL features on the Ours model’s ability to attract and satisfy patients. The inclusion and optimization of these features in the final iteration of Ours evidently contribute to its superior performance in patient satisfaction, underscoring the significance of continuous model enhancement and feature integration in the development of medical con- sultation models. In the evaluation of various language models, as displayed in Table 2, we have witnessed significant advancements in model performance on the Chinese medical QA dataset. The table outlines the results for a series of models, including T5 Title Suppressed Due to Excessive Length 11 (fine-tuned),the previously five model, and Ours model. It’s noteworthy that Ours, which is an enhanced iteration based on the fundamental approach of HuatuoGPT through the Integrated Argument Generation (IAG) enhancement, demonstrates marked improvements over its counterparts, particularly in metrics such as BLEU-1, GLEU, ROUGE-1, and Distinct-2—critical indicators of the model’s linguistic precision and contextual understanding, as shown in Table 2. The results indicate a significant improvement of Ours over the state-of-the-art (SOTA) models (24.68 to 26.12 for BLEU-1 and 8.07 to 8.23 for GLEU), and a comparable leap over another SOTA improvement (27.93 to 29.07 for ROUGE-1 and 0.93 to 0.96 for Distinct-2). Compared to ChatGLM variants, our model shows a significant advantage; however, DoctorGLM performs poorly on BLEU and GLEU metrics. This could be due to the model’s potential difficulty in handling