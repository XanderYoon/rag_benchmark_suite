Creating a Taxonomy for Retrieval Augmented Generation Applications Irina Nikishina1, Özge Sevgili1,2, Mahei Manhai Li3, Chris Biemann1,2, Martin Semmann2, 1Language Technology Group, University of Hamburg, Germany 2 HCDS Group, University of Hamburg, Germany 3 Information Systems, University of Kassel, Kassel, Germany Correspondence: irina.nikishina@uni-hamburg.de Abstract In this research, we develop a taxonomy to con- ceptualize a comprehensive overview of the constituting characteristics that define retrieval augmented generation (RAG) applications, fa- cilitating the adoption of this technology for different application domains. To the best of our knowledge, no holistic RAG application taxonomies have been developed so far. We employ the method foreign to ACL and thus contribute to the set of methods in the taxon- omy creation. It comprises four iterative phases designed to refine and enhance our understand- ing and presentation of RAG’s core dimen- sions. We have developed a total of five meta- dimensions and sixteen dimensions to compre- hensively capture the concept of RAG applica- tions. Thus, the taxonomy can be used to better understand RAG applications and to derive de- sign knowledge for future solutions in specific application domains. 1 Introduction Large Language Models (LLMs) have been iden- tified to have several core limitations. These in- clude a tendency to generate incorrect or mislead- ing information (hallucinations) (Liang et al., 2024; Nonkes et al., 2024), poor arithmetic capabilities, a lack of interpretative power, the high costs associ- ated with model revisions, limitations in handling less popular or low-resource concepts and entities, and an inability to reference sources accurately (Barnett et al., 2024; Soudani et al., 2024; Zhao et al., 2024). Several approaches have been devel- oped to mitigate the limitations of LLMs, while retrieval augmented generation (RAG) is as of now deemed as one of the most promising (Gao et al., 2024). RAG primarily enhances LLMs by incorpo-