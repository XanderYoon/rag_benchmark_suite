process. The last three failure points relate to the generated out- put: the incorrect format of the output, incorrect specificity (“not specific enough or is too specific to address the user’s need”), and incomplete out- put that misses essential information even though being extracted by the retriever. When combining RAG with another system, the most common limitation is extra overhead: addi- tional retrieval and interaction processes lead to increased latency of the system. Moreover, speed time also depends on the gap between retrievers and generators: the integration process and increased system complexity might be other bottlenecks that should be considered. When applying RAG to LLMs or other generators with a limited context size, lengthy context might become a problem: the models might not be able to accept the whole re- trieved data as input and the generation process will take much more time than expected. D16 Future Directions: The last dimension out- lines future directions for the RAG systems based on the findings of Zhao et al. (2024). The most straightforward directions are further development of RAG methodologies, enhancements, and appli- cations. This might include new interactions be- tween the retriever and generator, various modu- lar RAG architectures with looping, and more ad- vanced pre- and post-processing steps. Another direction is efficient deployment and processing. When discussing limitations, most of the integra- tion limitations were related to efficiency and la- tency. Hopefully, future research on RAG capac- ities will allow shorter system response time and easier deployment. Another important research direction is the incorporation of long-tail and real- time knowledge. With the rapid growth of the data, it is extremely difficult to constantly update large re- trievals in RAG. Many existing works apply a static database for knowledge retrieval, which requires re-indexing and/or computing additional represen- tations. Zhao et al.