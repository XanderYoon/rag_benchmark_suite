shorter system response time and easier deployment. Another important research direction is the incorporation of long-tail and real- time knowledge. With the rapid growth of the data, it is extremely difficult to constantly update large re- trievals in RAG. Many existing works apply a static database for knowledge retrieval, which requires re-indexing and/or computing additional represen- tations. Zhao et al. (2024) expect newer techniques to solve the issue, as well as provide better retrieval of less commonly referenced data. Lastly, the com- bination of other techniques might be also seen as a promising direction, e.g. integration of RAG with the new state space model architecture like Mamba (Gu and Dao, 2024) or RWKV (Peng et al., 2023). 5 Discussion RAG application systems are an emerging technol- ogy that has received considerable attention outside the NLP community, which addresses the limita- tions of LLM applications (Gao et al., 2024; Leiser et al., 2024). While recent studies address both the applications of LLMs and methods to mitigate their shortcomings, RAGs have not yet been fully recognized outside NLP community or explored as a potential solution to these limitations. Thus, our taxonomy provides a basis for applying RAGs as an emerging technology for novel fields of ap- plication. Based on our taxonomy, we see that the broader community can engage in a socio-technical perspective for guiding future RAG applications. Domain-specific applications: Our taxonomy shows that different mediums of generation are 7 gaining interest, including conceptual modeling approaches (Baumann et al., 2024). For example, process modeling already leverages generative AI for improving and (re-) designing organizational processes (van Dun et al., 2023). RAGs appear to make such application systems much more viable, as our taxonomy provides us an example, where knowledge structure already incorporates concep- tual process modeling types (Baumann et al., 2024). Thus,