LLM performance, or it can be used (Chen et al., 2024). Used thus leads to different forms. It can be trainable to be adjusted in each context or it can be looped as a specification of the paradigm modular RAG. D8 RAG Process: In this dimension, processes in RAG models are discussed mostly based on the information by Gao et al. (2024). Five character- istics are considered, i.e., pre-retrieval, retrieval, post-retrieval, generation, and post-generation. The pre-retrieval step involves some techniques applied before the retrieval step, for instance, chunking, vectorizing, indexing, and some other strategies to e.g., optimize indexing, enhance user input, etc. In the retrieval step, the relevant information to the user input is retrieved. Post-retrieval includes meth- ods to improve the retrieved information during integration with user input, e.g. re-rank the infor- mation or subgraph construction (He et al., 2024). In the generation step, LLM provides a response to the prompt that contains the retrieved information and user input. Post-generation contains strategies that can be applied after generation, e.g. output rewrite (Zhao et al., 2024). Note that there exist various modules to enhance different components (see Gao et al. (2024) for more information). D9 Retrieval Type: There are different types of retrieval augmentation methods (Li et al., 2022). In this dimension, three characteristics are con- sidered, i.e., sparse-vector retrieval, dense-vector retrieval, and task-specific retrieval (Li et al., 2022). Sparse-vector retrieval involves methods, e.g., TF- IDF, BM25, etc. Dense-vector retrieval contains models based mostly on low-dimensional dense vectors, e.g., BERT-encoders, and relying often on vector databases. In task-specific retrieval, the re- trieval module is based on task (Li et al., 2022) and might comprise a database (Radeva et al., 2024). Some research works directly using the edit dis- tance between natural language texts (Hayati et al., 2018) or abstract syntax