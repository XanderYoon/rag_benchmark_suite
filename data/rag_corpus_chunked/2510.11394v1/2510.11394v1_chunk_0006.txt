similarity metrics, alternative approaches leverage NLI models to determine entailment relation- ships between answer sentences and retrieved passages, assigning citations based on classification results. ALCE implemented this NLI approach as a representative post-processing baseline method. Effective evaluation methodologies are indispensable for advanc- ing citation generation research, with established approaches en- compassing both human assessment and automated metrics [25, 38]. VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification SIGIR-AP 2025, December 7â€“10, 2025, Xiâ€™an, China Figure 1: Overview of VeriCite framework. The pioneering human evaluation framework, Attributable to Iden- tified Sources (AIS) [27], measures textual faithfulness to source materials through a structured protocol: annotators first exam- ine model-generated text to determine whether each statement requires external source substantiation, then verify (1) the presence of explicit source attribution, and (2) content consistency between generated claims and corresponding source materials. While hu- man evaluation offers superior accuracy, its significant drawbacks include high labor costs and low efficiency. To address these chal- lenges, researchers proposed AutoAIS [7] based on AIS, which lever- ages NLI models to approximate human judgment. This automated approach refines evaluation granularity to the sentence level by examining entailment relationships between responses and source materials. Building upon this foundation, ALCE redefines citation recall and citation precision metrics while establishing the first benchmark for LLM attribution evaluation. This benchmark incor- porates multi-dimensional evaluation of fluency, correctness, and citation quality. Further advancing the field, CAQA [13] introduces a comprehensive four-category framework (Supported, Insufficient, Contradictory, Irrelevant) for fine-grained attribution evaluation, enabling more precise quantification of attribution performance. 3 VeriCite framework 3.1 Task Formulation Following previous work [8, 20], the formal description of this task is as follows: Given a query ğ‘, top-ğ‘˜ passages ğ‘ƒ={ğ‘ 1, ğ‘2, . . . , ğ‘ğ‘˜ } are retrieved, and the LLM needs to generate an answer