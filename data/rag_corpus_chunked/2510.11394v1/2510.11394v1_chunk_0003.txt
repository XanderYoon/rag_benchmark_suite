metrics such as BLEU [ 24] and ROUGE [ 18], or employing Natural Language Inference (NLI) classifiers to eval- uate entailment relationships [ 7]. Classic similarity metrics are computationally efficient, but their effectiveness is constrained by the challenge of determining thresholds. Conversely, although NLI models deliver higher accuracy, yet fundamentally struggle to han- dle cases where a single statement requires multiple citations [8]. To address the aforementioned issues, we propose a novel frame- work namedVeriCite, which strengthens the reliability of cita- tions through rigorous verification. In contrast to previous stud- ies which primarily focused on the answer generation process or post-processing stages, VeriCite concentrates on the phase after retrieved passages are obtained but before final answer generation commences. VeriCite consists of three stages: initial answer gener- ation, supporting evidence selection, and final answer refinement (as illustrated in Figure 1). The initial answer generation stage gen- erates a response based on all retrieval passages and uses an NLI model to verify the citations in the statement, ensuring the reliabil- ity of the answer. The subsequent supporting evidence selection stage thoroughly extracts potentially useful evidence from each passage. This evidence must also undergo verification through the NLI model, and the verified evidence is then marked with citations. The final answer refinement stage integrates the initial answer and the extracted evidence, with the LLM responsible for reorganizing the order of the statements to improve fluency, removing redundant content, and merging citations. VeriCite aims to pre-screen the content within retrieved passages that is genuinely valuable for answer generation, pre-attributing citations to these high-quality segments to ensure source traceabil- ity. This preprocessing approach helps eliminate noise from the input, significantly alleviating the cognitive load on LLMs when extracting key information from long contexts. Furthermore, the strategy of pre-attributing citations reduces the modelâ€™s attribution difficulty, enabling