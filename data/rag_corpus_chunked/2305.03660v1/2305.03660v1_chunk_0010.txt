the LLM. Ik denotes the iteratively constructed impression from the LLM using reﬁne prompt P r constructed using the impressions from the previous iterations, instructions Q and Sk denoting the kth sentence from the sentence corpus. Ik = LLM(P r(Q, Ik−1, Sk)) Reﬁne mechanism is available with LLM based frameworks like langchain [Chase (2022)] and llama-index [Liu (2022)]. As the size of context for RAG based generations could vary in diﬀerent clinical settings, the paper proposes the usage of reﬁne approach. In the context of our experiments, for this paper reﬁne mechanism was not required as we experimented with smaller K = 1 , 2, 3 values and the context were still within the limit of LLMs and iterative response building was not required. In addition to free text radiology report generation, we also hypothesize that it would be more useful to have the radiology reports in a structured format including key attributes of interest from the retrievals. These attributes of interest could be pathologies, severity related to pathology, severity, size, or position etc. We use prompt engineering with few shot examples to generate a structured radiology report output. 3.1. Retrieval Corpus We base the retrieval corpus on the train impressions of the CXR-PRO dataset [Ramesh et al.] which consists of 374,139 free-text radiology reports and their associated chest radiographs. As CXR-PRO is based on MIMIC-CXR which is a de-identiﬁed dataset, no protected health information (PHI) is included. CXR-PRO is an adapted version of the MIMIC-CXR dataset [Johnson et al. (2019)]] with prior references omitted. It addresses 6 CXR-RePaiR-Gen the issue of hallucinated reference to priors produced by radiology report generation models. We use the impressions sections of the radiology reports in the corpus and consider both report-level impressions and as well as the sentences comprising the report-level impressions as