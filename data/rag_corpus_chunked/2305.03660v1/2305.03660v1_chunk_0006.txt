generation are based on the retrieved records from CXR-ReDonE. 2. Related Work Recent works in radiology report generation approached the problem as a generative task like the work of Chen et al. (2020) which used a Transformer decoder architecture R2Gen and the work of Miura et al. (2020) which focused on generating complete, consistent, and clinically accurate reports using a reward-based reinforcement leaning approach by name M2 Trans. Endo et al. (2021) in their work CXR-RePaiR approached radiology report generation problem using a retrieval approach and set a new SOTA benchmark using more clinically reliable metrics. The retrieval was based on their constrastively pretrained vision-language model using the MIMIC-CXR dataset [Johnson et al. (2019)]. A new clinical eï¬ƒcacy sim- ilarity metric Semb was introduced in the paper to calculate the semantic similarity using the last hidden representations from the CheXbert [Smit et al. (2020)] labeler between the 4 CXR-RePaiR-Gen reference report and the predicted report. The paper also used the BERTScore metric [Zhang et al. (2019)] as another measure for semantic similarity. Ramesh et al. (2022) in their work addressed one key issue pertaining to all automated radiology report generation approaches which are prior report references in the radiology report which impacts the quality of report generation. They built a new dataset CXR-PRO [Ramesh et al.] by addressing this issue on the MIMIC-CXR dataset [Johnson et al. (2019)]. They also retrained CXR-RepaiR using the CXR-PRO dataset and an updated architecture ALBEF [Li et al. (2021)] and set the current SOTA for the radiology report generation task. They also used the RadGraph F1 [Yu et al. (2022)] score as an additional metric to measure the completeness and accuracy of the clinical entities available in the predicted report using the RadGraph model [Jain et al. (2021)] With the rise of the LLMs,