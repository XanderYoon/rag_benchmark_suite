et al.] and index it in the vector database. We use the same model for generating the contrastively aligned image embedding for the input radiology image x and use the embedding to retrieve the top-K records from the reports or sentences corpus based on dot- product similarity. The top-K reports or sentences that have the highest similarity to the in- put image embeddings are selected for augmenting the generation usingtext-davinci-003, gpt-3.5-turbo and gpt-4 models. We generate impression I by prompting the LLM with prompt P passing in the retrieved top-K sentences of the sentence corpus S as the context along with instructions Q for the generation. I = LLM(P (Q, k∑ i=1 Si)) Where top K sentences from S is selected using the function argmaxs∈S(R), f(s, x), f indicating the similarity dot product function on the input sentence s and radiology image x as in CXR-RePaiR. If the size of the context records for the LLM generation is beyond the token limit of the LLM, we propose to use the reﬁne methodology for iteratively generating the response from the LLM. We generate an initial impression from the LLM by prompting the LLM with the ﬁrst retrieved report or sentence of the top K records from the radiology text corpus as the context and then we pass the initial impression response generated by the LLM, second sentence or report as context and so on to get a ﬁnal reﬁned answer from the LLM. Ik denotes the iteratively constructed impression from the LLM using reﬁne prompt P r constructed using the impressions from the previous iterations, instructions Q and Sk denoting the kth sentence from the sentence corpus. Ik = LLM(P r(Q, Ik−1, Sk)) Reﬁne mechanism is available with LLM based frameworks like langchain [Chase (2022)] and llama-index [Liu (2022)]. As the