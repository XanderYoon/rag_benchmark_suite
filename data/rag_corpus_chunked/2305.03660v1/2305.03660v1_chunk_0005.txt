reports or sentences corpus. This can help in decision making when planning to practically use these systems in a real clinical setting. • Our paper also shows how we can leverage prompt engineering in LLM to inject user intents and requirements to produce radiology reports in diﬀerent output formats relevant for the downstream application with few-shot learning. Our approach achieves better clinical metrics with a BERTScore [Yu et al. (2022)] of 0.2865 (∆+ 25.88%) and Semb score [Endo et al. (2021)] of 0.4026 (∆+ 6.31%) over the pre- vious state-of-the-art retrieval method CXR-ReDonE. In clinical settings, the improvement of these scores means we are able to generate radiology reports that are closer to the ground truth impression semantically, at the same time being very concise reducing the noise from 3 CXR-RePaiR-Gen Figure 1: We project all the text embeddings of sentences from radiology impression using a contrastively pretrained vision-language encoder (CXR-ReDonE) to a vector database index and retrieve the most matching sentences for an input image embedding using the same encoder model. The retrieved impression reports or sentences form the context of the prompt to the LLM along with instructions to generate the impression. the retrievals. We are also on par with CXR-ReDonE on the RadGraph F1 metric [Yu et al. (2022)]. This metric measures if we are able to retrieve all the clinical entities accurately. We cannot exceed on this metric beyond the retrieval model CXR-ReDonE as the RAG generation are based on the retrieved records from CXR-ReDonE. 2. Related Work Recent works in radiology report generation approached the problem as a generative task like the work of Chen et al. (2020) which used a Transformer decoder architecture R2Gen and the work of Miura et al. (2020) which focused on generating complete, consistent, and clinically accurate reports using a