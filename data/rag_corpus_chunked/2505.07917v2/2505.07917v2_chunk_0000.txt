Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation Linus Stuhlmann ∗, Michael Alexander Saxer ∗, Jonathan F ¨urst School of Engineering, Zurich University of Applied Sciences, Winterthur, Switzerland E-mails: linus.stuhlmann@zhaw.ch, michael.saxer@zhaw.ch jonathan.fuerst@zhaw.ch ∗Equal contribution. Abstract—Biomedical question-answering (QA) systems re- quire effective retrieval and generation components to ensure accuracy, efficiency, and scalability. This study systematically examines a Retrieval-Augmented Generation (RAG) system for biomedical QA, evaluating retrieval strategies and response time trade-offs. We first assess state-of-the-art retrieval methods, including BM25, BioBERT, MedCPT, and a hybrid approach, alongside common data stores such as Elasticsearch, MongoDB, and FAISS, on a≈10% subset of PubMed (2.4M documents) to measure indexing efficiency, retrieval latency, and retriever performance in the end-to-end RAG system. Based on these insights, we deploy the final RAG system on the full 24M PubMed corpus, comparing different retrievers’ impact on overall performance. Evaluations of the retrieval depth show that retrieving 50 documents with BM25 before reranking with MedCPT optimally balances accuracy (0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains stable (82ms ± 37ms), while MedCPT incurs the main computational cost. These results highlight previously not well-known trade-offs in retrieval depth, efficiency, and scalability for biomedical QA. With open- source code, the system is fully reproducible and extensible. Index Terms—Biomedical Information Retrieval, Retrieval- Augmented Generation, Hybrid Retrieval, Large Language Mod- els, PubMed, Information Retrieval Systems. I. INTRODUCTION Large Language Models (LLMs) have demonstrated strong biomedical question-answering (QA) capabilities [1]. How- ever, LLMs can produce factual inaccuracies, lack specific domain knowledge, and lack verifiability [2]. A major con- cern ishallucination, where LLMs generate factually in- correct responses due to their probabilistic nature. These hallucinations, together with a lack of verifiability, are par- ticularly problematic in healthcare, where misinformation can lead to serious consequences. To mitigate these risks, Retrieval-Augmented Generation (RAG)systems leverage