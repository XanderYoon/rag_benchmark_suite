for response generation. ForMedCPT, the query is encoded into a vector and compared against document embeddings for similarity search. The retrieved documents are reranked by a cross-encoder, and only those with positive relevance scores are used for response generation. ForHybrid Retrieval, BM25 first retrieveskcandidate documents, which are then reranked by MedCPT’s cross-encoder. Only relevant documents are passed to the LLM. Our results show that the hybrid retrieverachieves thebest answer correctnesson all metrics (Table III). TABLE III: Performance metrics of the end-to-end RAG system using different retrievers. RAG with Retriever Accuracy Recall Precision F1 Score GPT-3.5 / Hybrid Retriever0.86 0.86 0.89 0.86 GPT-3.5 / MedCPT 0.83 0.83 0.86 0.84 GPT-3.5 / BM25 0.72 0.72 0.83 0.74 GPT-3.5 / BioBERT 0.63 0.63 0.85 0.67 IV. EVALUATION OF THEFINALSYSTEM After selecting the most efficient and effective components, we evaluate the final hybrid RAG system on the full 24M- document PubMed corpus forretrieval effectiveness,response time, andanswer correctness. A. Effect of Retrieval Depth on Performance To evaluate the impact of retrieval depth on performance, we experimented with different configurations of BM25 retrieval, varying the number of initially retrieved documents while keeping the reranking step fixed at the top 10 (Table IV). TABLE IV: Comparison for different retrieval depths (BM25), with reranking applied to the top 10 documents. Docs Accuracy Recall Precision F1 Score Retrieval Time (s)Total Time (s) 20 0.89 0.88 0.89 0.88 0.39±0.07 1.52±0.42 50 0.90 0.90 0.89 0.90 0.82±0.13 1.91±0.36 100 0.87 0.87 0.88 0.87 1.54±0.16 2.62±0.44 B. Analysis of Retrieval Depth Trade-offs Elasticsearch BM25 retrieval has an average response time of82±37ms, which remains constant across all retrieval depths since it ranks all documents regardless of how many are later passed to reranking. The primary factor affecting response time is the cross-encoder reranking step using Med- CPT, which processes a subset of the