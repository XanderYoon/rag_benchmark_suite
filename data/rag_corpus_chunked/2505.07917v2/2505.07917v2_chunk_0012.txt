language models with retrieval,”arXiv preprint arXiv:2403.03187, 2024. [3] S. M. T. I. Tonmoy, S. M. M. Zaman, V . Jain, A. Rani, V . Rawte, A. Chadha, and A. Das, “A comprehensive survey of hallucination mitigation techniques in large language models,” 2024. [4] I. Alonso, M. Oronoz, and R. Agerri, “Medexpqa: Multilingual bench- marking of large language models for medical question answering,” 2024. [5] G. Xiong, Q. Jin, Z. Lu, and A. Zhang, “Benchmarking retrieval- augmented generation for medicine,”arXiv preprint arXiv:2402.13178, 2024. [6] S. Robertson, H. Zaragozaet al., “The probabilistic relevance frame- work: Bm25 and beyond,”Foundations and Trends® in Information Retrieval, vol. 3, no. 4, pp. 333–389, 2009. [7] J. Lee, W. Yoon, S. Kim, D. Kim, S. Kim, C. H. So, and J. Kang, “Biobert: a pre-trained biomedical language representation model for biomedical text mining,”Bioinformatics, vol. 36, no. 4, p. 1234–1240, Sep. 2019. [Online]. Available: http://dx.doi.org/10.1093/bioinformatics/ btz682 [8] Q. Jin, W. Kim, Q. Chen, D. C. Comeau, L. Yeganova, W. J. Wilbur, and Z. Lu, “Medcpt: Contrastive pre-trained transformers with large-scale pubmed search logs for zero-shot biomedical information retrieval,” Bioinformatics, vol. 39, no. 11, p. btad651, Nov 2023. [9] X. Ma, Z. Yang, and H. Zhang, “A hybrid first-stage retrieval model for biomedical literature,” inProceedings of the CEUR Workshop on Biomedical Information Retrieval, 2020. [Online]. Available: https://ceur-ws.org/V ol-2696/paper 92.pdf [10] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal, H. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschelet al., “Retrieval- augmented generation for knowledge-intensive nlp tasks,”Advances in Neural Information Processing Systems, vol. 33, pp. 9459–9474, 2020. [11] A. Krithara, A. Nentidis, K. Bougiatiotis, and G. Paliouras, “Bioasq- qa: A manually curated corpus for biomedical question answering,” Scientific Data, vol. 10, no. 1, p. 170, 2023. [12] M. Douze, A. Guzhva, C. Deng, J. Johnson,