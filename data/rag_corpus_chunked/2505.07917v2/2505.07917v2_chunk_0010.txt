0.88 0.87 1.54±0.16 2.62±0.44 B. Analysis of Retrieval Depth Trade-offs Elasticsearch BM25 retrieval has an average response time of82±37ms, which remains constant across all retrieval depths since it ranks all documents regardless of how many are later passed to reranking. The primary factor affecting response time is the cross-encoder reranking step using Med- CPT, which processes a subset of the retrieved documents and incurs additional computational overhead. Increasing the number of retrieved documents leads to marginal accuracy improvements but significantly increases the rerank time. Retrieving 50 documents before reranking yields the best accuracy (0.90) and F1 score (0.90) while keeping response time manageable at 1.91 seconds. However, retrieving 100 documents leads to a drop in accuracy (0.87) and an increase in total response time to 2.62 seconds, suggesting diminishing returns beyond 50 documents. The text generation phase relies on the OpenAI API, which introduces additional latency. The mean response time for generation is 1.07 seconds, with a standard deviation of 0.41 seconds. Since the generation time remains stable across con- figurations, the overall system latency is primarily determined by the retrieval depth and reranking time. These results demonstrate that increasing the number of retrieved documents beyond a certain threshold does not necessarily improve system performance. Instead, balancing retrieval depth with reranking efficiency is critical for real- world biomedical question-answering applications. V. CONCLUSION ANDFUTUREDIRECTIONS Biomedical question-answering (QA) systems require both efficient retrieval and generation components for accuracy and scalability. This study examines a Retrieval-Augmented Gen- eration (RAG) system for biomedical QA, evaluating retrieval strategies and response time trade-offs. We assess retrieval methods, including BM25, BioBERT, MedCPT, and a hybrid approach, alongside data stores such as Elasticsearch, MongoDB, and FAISS. Despite strong per- formance, some limitations remain. The reliance on OpenAI’s GPT-3.5 for text generation poses reproducibility challenges due to model updates