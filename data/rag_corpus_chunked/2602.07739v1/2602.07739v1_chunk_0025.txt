Pas- canu, R., Hermann, K. M., Battaglia, P., Bapst, V ., Ra- poso, D., Santoro, A., and de Freitas, N. Hyperbolic atten- tion networks. InInternational Conference on Learning Representations, 2019. URL https://openreview. net/forum?id=rJxHsjRqFQ. Han, H., Wang, Y ., Shomer, H., Guo, K., Ding, J., Lei, Y ., Halappanavar, M., Rossi, R. A., Mukherjee, S., Tang, X., et al. Retrieval-augmented generation with graphs (graphrag).arXiv preprint arXiv:2501.00309, 2024. He, N., Anand, R., Madhu, H., Maatouk, A., Krishnaswamy, S., Tassiulas, L., Yang, M., and Ying, R. HELM: Hy- perbolic large language models via mixture-of-curvature experts. InThe Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025a. URL https: //openreview.net/forum?id=RnbJPkakkm. He, N., Liu, J., Zhang, B., Bui, N., Maatouk, A., King, I., Yang, M., Weber, M., and Ying, R. Position: Be- yond euclidean – foundation models should embrace non- euclidean geometries. InThe Fourth Learning on Graphs Conference, 2025b. URL https://openreview. net/forum?id=WoK4o90lln. He, N., Madhu, H., Bui, N., Yang, M., and Ying, R. Hy- perbolic deep learning for foundation models: A survey. InProceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V . 2, pp. 6021– 6031, 2025c. He, N., Yang, M., and Ying, R. Lorentzian resid- ual neural networks. InProceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V .1, KDD ’25, pp. 436–447, New York, NY , USA, 2025d. Association for Computing Machinery. ISBN 9798400712456. doi: 10.1145/ 3690624.3709292. URL https://doi.org/10. 1145/3690624.3709292. He, N., Yang, M., and Ying, R. Hypercore: The core framework for building hyperbolic foundation models with comprehensive modules.arXiv preprint arXiv:2504.08912, 2025e. Hu, X., Shan, Z., Zhao, X., Sun, Z., Liu, Z., Li, D., Ye, S., Wei, X., Chen, Q., Hu, B., et al. Kalm-embedding: Superior training data brings a stronger embedding model. arXiv preprint arXiv:2501.01028, 2025. Ibrahimi, S., Atigh, M. G., Noord, N. V