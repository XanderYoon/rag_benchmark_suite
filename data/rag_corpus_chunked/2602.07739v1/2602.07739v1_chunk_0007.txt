the Lorentzian inner product is defined as ⟨x,y⟩ L = −x0y0 +Pd i=1 xiyi. This formulation admits closed-form expressions for geodesic distances, barycentric operations, and parallel transport, and expresses similarity directly through Lorentzian inner products. The geodesic distance between two points x,y∈H d K is given by dK(x,y) = 1√−K cosh−1(K⟨x,y⟩ L), which is a monotone function of the Lorentzian inner product. To support optimization, we make use of exponential and logarithmic maps between the manifold and its tangent spaces. For a point x∈H d K, the logarithmic map logx(·) maps nearby points to the tangent space TxHd K, while the exponential map expx(·) maps tangent vectors back to the manifold. These operators are used only where necessary for gradient-based updates, ensuring that all representations remain on Hd K and preserving the hierarchical structure induced by negative curvature. 3.2. Hyperbolic Transformer Components Standard operations cannot be applied directly in hyperbolic space, as they may violate the manifold constraint (Yang et al., 2024). To address this, we introduce hyperbolic com- ponents that serve as the building blocks for our embedding model. These operations are performed via a re-centering procedure that applies Euclidean operations in a latent space and maps the result back to the Lorentz model. By doing so, the resulting vector is constructed to satisfy the Lorentz constraint, thereby preserving the hyperbolic structure of representations. We present these operations as follows. Lorentz Linear Layer.Given curvatures K1, K2, and parameters W∈R (n+1)×m and b∈R m with z= |W⊤x+b| , the Lorentzian linear transformation (Yang et al., 2024) is the map HLT:L K1,n →L K2,m given by, HLT(x;W,b) = r K2 K1 · " p ∥z∥2 −1/K 2,z # Hyperbolic Layer Normalization.Given token embed- dings X={x i}n i=1 ⊂H d K, hyperbolic layer normalization is defined as HypLayerNorm(X) = r K1 K2