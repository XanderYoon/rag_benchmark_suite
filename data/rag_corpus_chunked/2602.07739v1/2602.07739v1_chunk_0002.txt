Bogolin et al., 2022), degrading retrieval preci- sion (Reimers & Gurevych, 2021): a query about a specific subtopic may retrieve documents from sibling or parent cat- egories that share similarity but lack the required specificity. To further see why geometry matters for retrieval, consider a query about transformer attention mechanisms (Figure 1A). Relevant documents form a natural hierarchy—from general concepts like NLP, to transformers, to specific components like multi-head attention—inducing tree-like semantic struc- 1 arXiv:2602.07739v1 [cs.IR] 8 Feb 2026 HypRAG ture. Euclidean embeddings struggle to preserve this organi- zation: representing both broad topics and specialized de- scendants forces a trade-off between semantic proximity and fine-grained separation, causing neighborhood crowding and distortion. Hyperbolic geometry resolves this tension through exponential volume growth, allowing general con- cepts to remain compact while specific documents spread outward. To test whether such structure appears empirically, we analyze Ollivier–Ricci curvature (Ni et al., 2019)—a measure of local geometry where negative values indicate tree-like branching—on graphs built from MS MARCO document embeddings (Bajaj et al., 2016). Across several strong models (Linq Embed Mistral, LLaMA Nemotron 8B, Qwen3 Embedding 4B), curvature distributions are predom- inantly negative (Figure 1B), providing empirical evidence that retrieval-relevant embeddings exhibit intrinsic hyper- bolic structure and motivating hyperbolic geometry as a natural inductive bias for dense retrieval. Recent work has begun exploring hyperbolic geometry for language modeling and RAG systems, though with different focus areas. HELM (He et al., 2025a) introduces a family of hyperbolic language models that operate entirely in hyper- bolic space, but these models target text generation rather than retrieval. In the RAG setting, HyperbolicRAG (Cao et al., 2025) projects embeddings into the Poincaré ball to encode hierarchical depth within a static, pre-built knowl- edge graph, using dual-space retrieval that fuses Euclidean and hyperbolic rankings. However, HyperbolicRAG relies on Euclidean encoders to