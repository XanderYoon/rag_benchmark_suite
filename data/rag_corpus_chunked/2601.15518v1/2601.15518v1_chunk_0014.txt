connections form the basis of a network-theoretic rank. However, the number of connected components when doing so is far too small to be effective on a small query-set of items that we are not necessarily in control of, and would require constructing our own validation or test set so that these popular items are actual part of the recall set. We increase connectivity of the graph across the full article-set by using the K-NN graph which uses a pre-computed document embedding, which ensures that every node has out-going links. Because of the random-restart parameter of PageRank, infor- mation thus flows through all nodes of the network and relative rank is properly computed. One of the simplest method for incorporating these features is by using it to rerank retrieved items. When we use network-theoretic rankings like out-degree, in-degree, or PageRank, we find that this is not an effective technique as the bias toward popular or network- importance is not necessarily the inductive bias needed to complete the tip-of-the tongue connection. We experimented with this as part of a feature-based reranking system, and find that it does not contribute a high degree of information gain relative to the other features that we experimented with. There were other ideas with the graph representation that we might try in the future: retrieval expansion via breadth-first search and seeding for synthetic dataset construction. Retrieval expansion takes advantage of the fact that we capture neighborhood relations from the actual pagelink graph, and we can insert extra items into the set of retrieved item sorted by order of their importance in an attempt to increase recall on retrieval. We could also use important network nodes to generate tip of the tongue query and result-sets by sampling articles proportional to their importance, and looking for similar articles within