training and validation data consist of official train set (143 queries) and the first 200 queries of dev3 set, and the training set of our generated queries (around 4000 queries). Among those, 80% are used for training and 20% for validation. 3 Results 3.1 Synthetic Query Correlation Study To validate that our adapted LLM query generation method pro- duces queries that are similar to the official dataset, we test our method on the Wikipedia articles associated with the first 100 queries of the dev3 set. We also use two baselines for comparison. One baseline randomly generates 200 words as the query, and the other uses the first 200 words of the Wikipedia article as the query. The correlation metrics, the Pearson and Kendall’s Tau scores are calculated on the embeddings of the original queries and the gener- ated queries, as shown in Figure 3.all-MiniLM-L6-v2is used as the embedding model. All LLM-generated queries (Gemini and GPT-4o variants) show very high correlation with original queries (Pearson > 0.93 and Tau > 0.77), suggesting they capture similar semantic content and query characteristics. In comparison, Wikipedia text (the first 200 words of the Wikipedia article) shows moderate correlation. This result demonstrates that the queries generated with the new method have strong correlation with the original queries. Figure 3: Pearson and Kendall’s Tau correlation for synthetic and original queries usingall-MiniLM-L6-v2embeddings. We further compare the retrieval results of the original and generated queries using sparse, dense, and LLM retrieval methods (as shown in Figure 4). The results show that the LLM-generated queries achieve comparable retrieval performance to the origi- nal queries across all retrieval methods, with one outlier: the re- call@1000 for dense retrieval on the original dataset is significantly better than that of the LLM synthetic queries. This further validates the effectiveness of our adapted