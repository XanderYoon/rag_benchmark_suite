produced unsatisfactory results, we used Gemini’s chat interface to manually generate high-quality vari- ants following the same generalization principles. This complete pipeline is illustrated in Figure 2. The retrieval pipeline classifies each query variant to one of the 24 topics using ModernBERT-web-topics, then encodes it with BGE-M3 and searches only the corresponding topic-specific FAISS index for the top-1000 results per variant. Results across all vari- ants are aggregated and deduplicated by document ID, retaining the highest similarity score for each unique document. The final top-1000 documents are selected and formatted in TREC format. This topic-specific routing reduces the search space by focusing on relevant topical subsets of the corpus, while leveraging GPU acceleration for efficient batch processing of embeddings and index operations. DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking Figure 2: Topic-aware multi-index pipeline. 2.4.3 Hybrid Retrieval.We merge the sparse, dense and LLM re- trieval results using a round-robin strategy. Specifically, we iterate through the ranked lists from each retrieval method and alternate which method contributes the next candidate to the merged result. For example, we take the top-ranked result from LLM retrieval, followed by the top-ranked result from dense retrieval, then the top-ranked result from sparse retrieval, and repeat this cycle. When a method runs out of candidates, we continue cycling through the remaining methods. When we encounter duplicate candidates, we keep the one with the highest rank from its original list. 2.5 Reranking 2.5.1 LLM Reranker.We use an LLM to perform listwise reranking. The implementation is based on the RankLLM library[10], where a sliding window algorithm is used to split a large set of docu- ments into groups so that the context can fit within the LLM’s context window. We tested various context settings, such as title only, first paragraph, first