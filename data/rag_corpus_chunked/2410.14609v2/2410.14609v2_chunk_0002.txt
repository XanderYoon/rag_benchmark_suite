thanks to the development of Large Language Models (LLMs) [3, 41, 43]. The goal of the CS task is to retrieve relevant documents from a corpus within a conversational context, in response to the user’s latest utterance. While sharing similarities with ad-hoc retrieval, the main challenge ofCS remains to model the conversational context [8, 54, 64]. More specifically, as the conversation advances, the context becomes longer and noisier, often with topic switches and language ambiguities, making the last user utterance complex to resolve and understand for retrieval systems [2, 10, 18]. Training retrieval models for this task is, however, challenging, because of the lack of large-scale conversational datasets, mak- ing human annotation an essential component of the process. In particular, a lot of effort has been invested first to create conversa- tions with passage relevance judgment [3, 10], and then to rewrite for each user utterance the contextualized version of each query (rewritten query) as the optimal denoised query of each turn [14]. Datasets with rewrites enable us to learn the Conversational Query arXiv:2410.14609v2 [cs.IR] 15 May 2025 SIGIR ’25, July 13–18, 2025, Padua, Italy Simon Lupart, Mohammad Aliannejadi, and Evangelos Kanoulas Rewriting (CQR) task by auto-regressive models (e.g., T5 [55]), and then only pass the rewritten queries to retrieval models instead of the full noisy conversations. However, this two-step approach – rewrite and retrieve – is not efficient [65], and may lead to infor- mation loss and error within the rewrite phase that can propagate to the retrieval phase. Hence, the need for unified retrieval models that do both tasks together in the representation space [46, 52]. Approaches such as ConvDR [65], coSPLADE [19] and LeCoRe [42] all learn both conversational context modeling and retrieval tasks within the representation space, either in a dense or sparse embedding space. As