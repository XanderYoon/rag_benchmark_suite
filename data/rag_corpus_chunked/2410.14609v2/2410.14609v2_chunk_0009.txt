to control it within CS. 3 Proposed Method In this section, we first recall notations from the CS and LSR fields, before presenting DiSCo and our relaxed distillation objective. 3.1 Preliminaries Notation. We consider a set of conversations between a user and a system, each composed of multiple turns. At turn ğ‘›, we have access to previous queries and answers, together with the final user utterance ğ‘ğ‘›. We denote the full conversational context as ğ‘ğ‘ğ‘œğ‘›ğ‘£ , separated with [SEP] tokens, and ğ‘ğ‘Ÿ ğ‘¤ as the gold rewritten query. ğ‘ğ‘Ÿ ğ‘¤ resolves various complexities such as ellipsis and ambiguities user utterance 1answer 1user utterance 2 LLM rewrites LLM rewrite Teachers Student!!"#$ !"!($"#$%) !!($&') !((&) !!!"=#!(%"#)#$(') =#(!(%%&'()#$(') )*++=,-.(!!#$%&,!!!") !!#$%& Figure 2: DiSCo, as the Distillation of LLM rewritten queries through a contrastive objective. Previous works distilled rep- resentations themselves, while our approach distills similar- ities with documents from the corpus, relaxing the learning objective. of the conversation and can be generated by either human or LLM. ğ‘ğ‘ğ‘œğ‘›ğ‘£ = ğ‘ğ‘›, ğ‘ğ‘›âˆ’1, ğ‘ğ‘›âˆ’1, ..., ğ‘0, ğ‘0 . Furthermore, similarly to other approaches in CS [19, 42, 46, 65] we rely on two already trained encoder models ğ¸ğ‘ and ğ¸ğ‘‘, for queries and documents representations. These backbone models are trained on a large-scale IR dataset with regular short-form queries extracted from search engine logs. We also follow the assumption made in CS that ğ¸ğ‘‘ is already good at representing documents and doesnâ€™t need further fine-tuning, onlyğ¸ğ‘ needs further fine-tuning to adapt to long conversational contexts, noted Ëœğ¸ğ‘. This can be done with a contrastive InfoNCE [48] loss on the CS datasets (e.g., convANCE, convSPLADE), or with a distillation loss (e.g., ConvDR and other distillation approaches such as DiSCo). Learned Sparse Retrieval. We rely on the SPLADE architec- ture [15, 17], based on the BERT pretrained