addressRQ3, both Tables 3 and 4 include our DiSCo multi-teach model trained with multiple teachers. Considering the performances of DiSCo multi-teach for in-domain retrieval, we observe significant gains compared to DiSCo Mistral on QReCC. In particular, we observe a 1-point increase in terms of R@10, MRR, and nDCG@3 on QReCC. This result remains consistent for out-of-domain retrieval, where within Table 4 DiSCo multi-teach outperforms its single version Table 5: Inference Efficiency on TREC CAsT 2020. Rewrite and query encoding are measured on GPU, while the inverted index search on CPU with the Numba library. DiSCo Fusion is the fusion of SPLADE MistralQR with DiSCo Mistral. Efficiency (ms) Rewrite Retrieval Total R@100 SPLADE T5QR 190 358 548 0.479 SPLADE LlamaQR 4245 367 4612 0.550 SPLADE MistralQR 2094 356 2450 0.572 convSPLADE 0 356 356 0.446 DiSCo Mistral 0 346 346 0.519 DiSCo multi-teach 0 357 357 0.531 DiSCo Fusion 2094 356 2450 0.611 model, by at least 2 points on all metrics, on CAsT 2020 and 2022. On iKAT 2023, however, we observe mixed results. Two interpretations are possible for these general gains: first, the multiple teachers and their subsequent rewrites produce word synonyms, as a form of query expansion, improving the performance, and second, as one LLM may fail to resolve the context modeling task, another can balance it, offering better robustness. Progressive Improvement. Further addressing RQ3, Figure 4 gives insights on the multiple teachers distillation. While the left part of the Figure gives the performances of the teachers on QReCC, the right part shows the gains when incrementally adding teachers to the distillation. We can also notice the important gains from the distillation of LlamaQR. In particular, DiSCo Llama improves by 8 points compared to SPLADE LlamaQR in terms of Recall@100, while in comparison DiSCo Mistral by only 4