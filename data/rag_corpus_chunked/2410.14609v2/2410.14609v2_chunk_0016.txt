milliseconds on CPU [27, 30, 32]. We also provide Rewrite and Retrieval efficiency, of several mod- els. This is performed per query, averaged over the entire test set. Rewrite is the latency for rewriting, while retrieval is both query encoding and search through the inverted index (in the case of SPLADE models). We used a 4th AMD EPYC CPU and an A100 GPU. We also report the FLOPs [15, 50] values, a metric for efficiency in learned sparse retrieval, which intuitively estimates the number of floating point operations between a query and a document in an inverted index. FLOPs can be computed as follows: ğ¹ ğ¿ğ‘‚ğ‘ƒğ‘  = Eğ‘,ğ‘‘ [ âˆ‘ï¸ ğ‘— âˆˆğ‘‰ ğ‘ (ğ‘) ğ‘— ğ‘ (ğ‘‘ ) ğ‘— ] , (7) where ğ‘ (ğ‘) ğ‘— and ğ‘ (ğ‘‘ ) ğ‘— are the probabilities of activation of the ğ‘—ğ‘¡â„ to- ken in the vocabulary, resp. in query and document representations, over which we average on the dataset distribution. 4.2 Baselines We compare our DiSCo model with a wide range of competitive methods, consisting of query rewriting, supervised fine-tuned, and distillation-based methods, which we list below. Table 2: One-shot prompt used for rewriting with the LLMs teachers. The example is taken out of the QReCC dataset. # Instruction: I will give you a conversation between a user and a system. You should rewrite the last question of the user into a self-contained query. # Example 1: # Context: user: Tell me about the benefit of Yoga? system: Increased flexibility, muscle strength. # Please rewrite the following user question: Does it help in reducing stress? # Re-written query: Does Yoga help in reducing stress? # Example 2: # Context: <ctx> # Please rewrite the following user question: <utterance> # Re-written query: Query rewriting methods. SPLADE-[T5/Llama/Mistral/Human]QR does retrieval using the SPLADE ad-hoc retrieval