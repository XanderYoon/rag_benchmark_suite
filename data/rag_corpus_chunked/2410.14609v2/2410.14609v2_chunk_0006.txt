39]. The main challenge in addressingCS is modeling the conversational context, to only represent useful information from the previous turns [61]. Two possibilities exist to learn this noise reduction: first on the token level, with generative models that learn to generate contextualized queries from past conversations [14], or within the representation spaces [65] of retrieval models [44]. Query rewriting. Learning to resolve the conversational history is difficult, as no or very few conversational search engines are in production today, limiting the availability of user-interaction data. The effort is thus mostly based on human-annotated data. One of the first conversational datasets are QuAC [7] and ORConvQA [53], where human annotators were tasked to create conversations out of existing documents, assuming a human-machine conversation over the topic of the document. Each paragraph could potentially be an utterance and relevant passages would be inferred by construction. Later CANARD [14] was released on top of ORConvQA, consist- ing of human rewrites of each utterance of the conversations, to help learn the context modeling task. This defined one of the main sub-tasks of CS: Conversational Query Rewriting (CQR) [14, 64]. Following studies learned the CQR task at the token level – gener- ating automatic query rewrites based on the conversation history – on autoregressive language models (e.g., T5 or BART) [ 40, 61]. Similar methods [45] used language models to answer the query, before resolving the context. Today, work is still being done to solve the CQR task, using LLMs in zero- or few-shot fashion. CHIQ [43] proposes to decompose the context modeling task into several simpler sub-tasks for the LLMs – history enhancement, answer generation, question disambiguation – to gain in interpretability and effectiveness, LLM4CS aggregates several rewrites and answers within the representation space of the retrieval models [41], and DiSCo: LLM Knowledge Distillation