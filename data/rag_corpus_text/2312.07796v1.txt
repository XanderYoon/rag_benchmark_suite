HarnessingRetrieval-AugmentedGeneration(RAG) forUncoveringKnowledgeGaps JoanFiguerolaHurtadoIndependent Researcherjoanfihu@gmail.com AbstractWe presenta methodologyfor uncoveringknowledgegaps on the internetusingthe RetrievalAugmentedGeneration(RAG)model.By simulatinguser searchbehaviour, theRAGsystemidentifiesandaddressesgapsin informationretrievalsystems.ThestudydemonstratestheeffectivenessoftheRAGsystemingeneratingrelevantsuggestionswith a consistentaccuracyof 93%.Themethodologycan be appliedin variousfieldssuchasscientificdiscovery, educationalenhancement,researchdevelopment,marketanalysis,searchengineoptimization,andcontentdevelopment.Theresultshighlightthevalueofidentifyingand understandingknowledgegapsto guidefutureendeavours. 1 IntroductionTheincreasingnumberof usersdissatisfiedwiththerelevanceofcommercialsearchengineresultsissurprising,giventheunprecedentedaccessto vastinformationandsophisticatedsearchtechnologies[1,2]. In this paper, we employthe RetrievalAugmentedGeneration(RAG)modeltosimulateusersearchbehaviour,aimingto identifyandaddressknowledgegapson theInternet.We positthatuncoveringandbridgingthesegapsis crucialforenhancingtheefficacyofinformationretrievalsystems. 2 RelatedWorkYom.et.al[14]presentsanalgorithmtoestimatequerydifficulty. Estimationisbasedontheagreementbetweenthetop resultsof the full queryandthe top resultsof itssub-queries.In doingso,difficultqueriesrevealgapsinacontentlibrary. Themethodologyis basedontraininganestimatorbasedonasmalldataset.WearguethattherearenowsimplerLLMpromptingtechniquesthatdonotrequiretraininga custommodelandyieldbettergeneralisationacrossmultipledomains. A LargeLanguageModel(LLM)[4]generatestext-basedresponses,whileRAG[3] is an AI frameworkusedtoenhancethe qualityof LLM-generatedresponsesbygroundingthemonexternalsourcesof knowledge.Thesetechnologiescombineto provideaccurate,up-to-dateinformationandimprovethegenerativeprocessoflanguagemodels. 3 MethodologyTo identify knowledgegaps, we simulateuserinteractionswithsearchenginesin a structuredprocess.Initially, webeginwithaqueryandmethodicallyrevieweachsearchresultuntilan answeris found.If thefirsttop10resultsdo not yieldan answer, wegenerateup to fouralternativequeriesandretrieveupto twodocumentsperquery, iteratingthroughthesearchprocessagain. Figure1:Iterationlooptofindknowledgegaps Our approach utilises AskPandi [12], aRetrieval-AugmentedGeneration(RAG)system,to mimicuserbehaviour. AskPandiintegratesBing'swebindexfordataretrievalandGPTasa reasoningengine.Afterfindingananswer, wecapitaliseonthein-contextcapabilities[5,6,7] of LLMsto generatea seriesof relevantfollow-upquestions.Thisprocessis guidedby thepremisethatawell-generalised[8] LLM should provide useful Thisisapreprint.Itisnotpeerreviewedyet. recommendationsbasedontheinitialquestionandanswer.Thepromptweuseis: 'Basedontheanswer'{}'andthequestion'{}',whataresomepotentialshortfollow-upquestions?'Thismethodologydivergesfromtraditionalrecommendersystems[9], whichfilter throughexistingcontent.Incontrast,our systemfocuseson generatingthe mostrelevantcontent,regardlessofitspreexistence,highlightinga shift fromextractiveto generativeapproaches.Theprocessis theniterated,witheachcyclegoingdeeperintothe query’s topic,thusincreasingthedifficultyof findingrelevantinformation.We considerthe emergenceof aknowledgegapwhentheLLMcannolongergenerateananswer. In termsof terminatingtheprocess,weincorporateamechanismtoidentifystopwordsinanswers.We exploredtwomethods:eitherlettingthemodelnaturallyproduceastopwordordirectingthemodeltogenerateoneincasesofuncertainty[10]. Thiscomprehensiveprocessnotonlyhelpsinidentifyingknowledgegapsbutalsoenhancesourunderstandingofthepotentialof generativeAI in facilitatingmorerelevantinformationretrievalsystems. 4 ExperimentsWe builda datasetwith500searchqueriesclassifiedin25categories.We picktheparentcategoriesfromGoogleTrendsasof2023[11].GiventhatGoogleTrendsderivesitsdatafromGooglesearchqueries,itishypothesisedthatthistoolprovidesa representativesampleofthegeneralonlinesearchbehaviour. Allthe500searchqueriescanbefoundinourGitHubrepository[13]. 1. Arts&Entertainment2. Autos&Vehicles3. Beauty&Fitness4. Books&Literature5. Business&Industrial6. Computers&Electronics7. Finance8. Food&Drinks9. Games10. Health11. Hobbies&Leisure12. Home&Garden13. Internet&Telecom14. Jobs&Education15. Law&Government16. News 17. OnlineCommunities18. People&Society19. Pets&Animals20. Property21. Reference22. Science23. Shopping24. Sports25. Travel Foreachcategory, wegenerate20queriesgroupedbytheir complexity:easyand difficult.To determinethecomplexityof each query, we use the followingmethodology: LengthofQuery● Easy:Shortqueries,usually1-3words.● Difficult:Verylongqueriesorfullsentences,morethan6words.SpecificityofQuery● Easy:Generalorbroadqueries.● Difficult:Highlyspecific,niche,ordetailedqueries.UseofJargonorTechnicalTerms● Easy:Commonlanguage,nospecialisedterms.● Difficult:Heavyuseof technicalterms,jargon,oracronyms.AmbiguityorClarityofQuery● Easy:Clearandstraightforward,withlikelyonemaininterpretation.● Difficult:Ambiguous,requiringcontextoradditionalinformationtointerpret.SearchIntent● Easy:Generalinformationseekingor populartopics.● Difficult:In-depthresearch,controversialtopics,orhighlydetailedqueries.KnowledgeLevelRequired● Easy:Suitablefora generalaudience,nospecialknowledgeneeded.● Difficult:Requiresin-depthknowledgeorexpertiseinthefield.QueryFormat● Easy:Basicquestionsorkeywordsearches.● Difficult: Complexquestions,hypotheticals,orrequiringmulti-stepthinking. Foreachsearchsimulation,wemeasuredthefollowingmetrics:● Accuracy:the percentageof queriesthatwereansweredcorrectlybytheRAGsystem.Answersthathavebeenmanuallyreviewed.● TopicDepth:thenumberofiterationsuntiltheLLMsystemstoppedansweringthequestion. Thisisapreprint.Itisnotpeerreviewedyet. ● Averagenumberof sourcesusedper searchsimulation. 5 AnalysisWe carriedout searchsimulationsfor 60 keywords,generating323 answersacross655sources.We havefoundthatusingmorethan60keywordsfromtheinitial500keywordsdatasetdidnotmakea significantdifference.Allthe searchsimulationscan be foundin our GitHubrepository[13].Theresultsdemonstratetheeffectivenessofusinga RAGsystemin simulatingusersearchbehaviourandgeneratingrelevantsuggestions. Witha consistentaccuracyof 93%forbothsimpleandcomplexkeywords,theRAGsystemprovedtobeareliabletool for informationretrieval.Thestudyalsofoundthatfindingsourcesbecomesslightlymorechallengingforspecifictopics,as indicatedby the averagenumberofsourcesneededperkeyworddifficulty, 10.9sourcesforeasyqueriesand11.23for difficultones.Nosignificantdifferenceswereobservedin accuracyor sourcequantityacrosscategories,likelydueto thebroadandbalancednatureoftheselectedcategories. Additionally, we discoveredthat on average,aknowledgegapis encounteredat thefifthlevelof topicdepth.Thissuggeststhattheinternetmayhavelimitationsin providingin-depthinformationon certainsubjects.Ourmethodologyeffectivelyhighlightstheseknowledgegaps,showinga straightforwardapproachto identifyingtheminvarioustopics. 6 ApplicationsRecommendingnonexistentcontentisapowerfultoolforrevealingknowledgegaps.Thisapproachhasawiderangeofapplications,including: 1. ScientificDiscovery:Itcanpinpointunexploredareasinresearch,highlightingfutureresearchtopicsthathaveyettobeinvestigated.2. EducationalEnhancement:By identifyingmissingelementsinlearningmaterials,ithelpsincreatingmorecomprehensiveeducationalresources.3. ResearchDevelopment:This methodcan uncoveruntappedresearchopportunities,guidingscholarsandscientiststowardsnovelinquiries.4. MarketAnalysis:In thebusinessrealm,it canrevealproductgapsin a catalogue,offeringinsightsfornewproductdevelopment. 5. Search Engine Optimization:Improvingsearchrecommendationsby identifyingwhatusersmightbelookingforbutisn’tcurrentlyavailableonline.6. ContentDevelopment:It aidsin recognizingcontentgapswithina contentlibrary, assistingcontentcreatorsinfillingthesevoids. Eachof theseapplicationsdemonstratesthevalueofidentifyingand understandingwhatis missing,therebyguidingfutureendeavoursinvariousfields. 7 ConclusionWe havesuccessfullydemonstrateda methodologyforidentifyingknowledgegapsin contentlibraries.Forfuturework,thereispotentialtoexpandthisresearchbyexploringalternativesearchsimulationmethods.Specifically, utilisingagentscouldbe a promisingavenue.Theseagents,withtheirbroaderbandwidthinsearchengineusageandcontentprocessing,offer capabilitiessurpassingthoseof humanusers.Futureresearchcouldextendthe evaluationtoadditionalanswerengines,therebyenablinga morecomprehensivebenchmarkingof the estimationmethodologyoutlinedinreference[14]. It'sworthpointingoutthatwedon’thavedirectaccesstoa webindextodoa morerigorousevaluation.Futureworkcouldconsiderthe system’s abilityto predictwhetheraqueryis a MCQ(missingcontentquery)[14] givengold-standardlabels(perhapsusinga TREC-styletestcollectionandremovingtherelevantdocumentsfromthecollectionforsomequeries). REFERENCES[1] Dmitri Brereton. 2022. Google Search Is Dying. Published onFebruary15, 2022. [Online]. Available: https://dkb.io/post/google-search-is-dying[2] EdwinChen. 2022. IsGoogleSearchDeteriorating?MeasuringGoogle'sSearch Quality in 2022. Published on January 10, 2022. [Online].Available:https://www.surgehq.ai/blog/is-google-search-deteriorating-measuring-search-quality-in-2022[3] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, VladimirKarpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021.Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.arXiv:2005.11401[cs.CL].[4] Alec Radford, Jeff Wu, Rewon Child, DavidLuan, DarioAmodei, andIlyaSutskever. 2019. Language Models are Unsupervised MultitaskLearners. In Proceedings of the 2019 Conference. [Online]. Available:https://api.semanticscholar.org/CorpusID:160025533[5] Jason Wei, Xuezhi Wang, DaleSchuurmans, MaartenBosma, EdH. Chi,Quoc Le, and Denny Zhou. 2022. Chain of Thought Prompting ElicitsReasoninginLargeLanguageModels. CoRR, abs/2201.11903. [Online].Available: https://arxiv.org/abs/2201.11903[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared DKaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, GirishSastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, GretchenKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler,Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Thisisapreprint.Itisnotpeerreviewedyet. Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and DarioAmodei. 2020. Languagemodelsarefew-shot learners. NeurIPS.[7] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, KarthikNarasimhan, and Yuan Cao. 2023. ReAct: Synergizing Reasoning andActinginLanguageModels. arXiv:2210.03629[cs.CL].[8] Kenji Kawaguchi, Yoshua Bengio, and Leslie Kaelbling. 2022.Generalisation in Deep Learning. In Mathematical Aspects of DeepLearning, Philipp Grohs and Gitta Kutyniok, Eds. Cambridge UniversityPress, Cambridge, 112–148. DOI:https://doi.org/10.1017/9781009025096.003[9] Ricci, F., Rokach, L., Shapira, B. (2022). Recommender Systems:Techniques, Applications, and Challenges. In: Ricci, F., Rokach, L.,Shapira, B. (eds) Recommender Systems Handbook. Springer, NewYork, NY. https://doi.org/10.1007/978-1-0716-2197-4_1[10] Anthropic's Team. Let Claude Say "I Don't Know" to PreventHallucinations. Anthropic. Accessed in 2023. [Online]. Available:https://docs.anthropic.com/claude/docs/let-claude-say-i-dont-know[11] Google Trend's Team. Google Trends. Google. Accessed in 2023.[Online]. Available: https://trends.google.com/trends/[12] AskPandi's Team. AskPandi - Ask Me Anything. AskPandi. Accessedin2023. [Online]. Available: https://askpandi.com[13] https://github.com/webeng/llm_knowledge_gap_finder[14] Yom-Tov, Elad et al. “Learning to estimate query difficulty: includingapplications to missing content detection and distributed informationretrieval.” Annual International ACM SIGIR Conference on ResearchandDevelopment inInformationRetrieval (2005). Thisisapreprint.Itisnotpeerreviewedyet.