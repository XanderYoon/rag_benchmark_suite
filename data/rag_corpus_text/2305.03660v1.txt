Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models Mercy Ranjit∗ meranjit@microsoft.com Department of Computer Science Bharathidasan University, Trichy, India Gopinath Ganapathy gganapathy@gmail.com Department of Computer Science Bharathidasan University, Trichy, India Ranjit Manuel† ranjit.f.manuel@gmail.com AI for Digital Health and Imaging Indian Institute of Science, Bengaluru, India Tanuja Ganu taganu@microsoft.com Microsoft Research, Bengaluru, India Editor: Editor’s name Abstract We propose Retrieval Augmented Generation (RAG) as an approach for automated radi- ology report writing that leverages multimodally aligned embeddings from a contrastively pretrained vision language model for retrieval of relevant candidate radiology text for an in- put radiology image and a general domain generative model like OpenAItext-davinci-003, gpt-3.5-turbo and gpt-4 for report generation using the relevant radiology text retrieved. This approach keeps hallucinated generations under check and provides capabilities to gen- erate report content in the format we desire leveraging the instruction following capa- bilities of these generative models. Our approach achieves better clinical metrics with a BERTScore of 0.2865 (∆+ 25.88 %) and Semb score of 0.4026 (∆+ 6.31 %). Our approach can be broadly relevant for diﬀerent clinical settings as it allows to augment the automated radiology report generation process with content relevant for that setting while also having the ability to inject user intents and requirements in the prompts as part of the report gen- eration process to modulate the content and format of the generated reports as applicable for that clinical setting. 1. Introduction Automated Radiology Report Generation Systems can improve the report writing workﬂow of radiologists in various ways. These AI systems can generate free text content or structured report content for review by the radiologists w.r.t various attributes of interests like organ ∗ MR is also associated with Microsoft Research, Bangalore † RM is also associated with Databricks Inc., Bangalore © M. Ranjit, G. Ganapathy, R. Manuel & T. Ganu. arXiv:2305.03660v1 [cs.CL] 5 May 2023 CXR-RePaiR-Gen systems, pathology, abnormalities, severity, size or location of ﬁndings, progression status etc. Some of the existing work around AI enabled radiology report generation cast the radi- ology report generation problem as an image captioning problem or generative task [Chen et al. (2020); Miura et al. (2020)]. An interesting recent work CXR-RePaiR [Endo et al. (2021)] cast it as a retrieval problem taking advantage of the ﬁnite set of diagnostic details and attributes associated with radiology images. This approach is powerful in that it can leverage a very large database of past and present radiological reports while making im- pression recommendations. But all these approaches suﬀer from various issues related to irrelevant content or hallucinations in the generations. A very recent work CXR-ReDonE by Ramesh et al. (2022) addressed one such issue in report generation related to prior references by creating a new dataset CXR-PRO [Ramesh et al.] that eliminated the prior references found in the radiology text reports of MIMIC- CXR [Johnson et al. (2019)] and used this dataset to improve CXR-RePaiR [Endo et al. (2021)] to establish a new SOTA benchmark in radiology report impression generations. But purely retrieval-based report writing models like CXR-RepaiR and CXR-ReDonE does not allow the user to modulate the retrievals per their need which is useful for appli- cability in various clinical settings. Below are some limitations with pure retrieval-based approaches, some of which were mentioned for future work in these papers: • Pure retrieval-based report generation may include irrelevant retrievals for no-ﬁndings case reports especially when the number of relevant retrievals, K is set > 1 for gener- ating the report. • There are some unwanted noises in the generations like prior report references, men- tion of doctor names, user speciﬁc details, etc which are extracted as-is if they are available. Pure retrieval-based report generation also suﬀer from duplicate content in the retrievals. • It is also not possible to generate the radiology report in a speciﬁc format which may be the requirement for diﬀerent report generation downstream applications. It may be useful to create structured radiology reports extracting attributes of interest like pathologies, positional information, severity, size etc instead of a raw text output. • Pure retrieval-based systems may have some incoherent information in the generated report as the retrievals may bring sentences from reports belonging to two diﬀerent patients as-is. With very capable generative Large Language Models (LLM) like text-davinci-003, gpt-3.5-turbo(Chat GPT) and gpt-4 being available for the general domain which can generate relevant content based on instructive prompts in a zero-shot or few-shot setting for a wide variety of downstream tasks, it would be useful to explore how they can be leveraged for the work of radiology report generation to assist the radiologists. These models, however, lack the up-to-date information or domain speciﬁc information required speciﬁcally in a medical domain setting. Updated and relevant domain speciﬁc content when available for these models during the time of generation can allow to extend the capabilities of these large language models to do tasks with data, they were not exposed to during the training phase. 2 CXR-RePaiR-Gen In-addition we can leverage the instructions following capabilities of these models to elicit the required responses we require from these models. This additional context available to the LLMs for generations makes them hallucinate less. We are motivated by the advantages of Retrieval Augmented Generation (RAG) experimented in the work by Lewis et al. (2020) which showed that the generations from RAG are more strongly grounded in real factual knowledge causing less hallucinations and its broad application for various downstream tasks called out in the “Broader Impact” section of the paper. We propose Contrastive X-ray-Report Pair Retrieval based Generation (CXR-RePaiR- Gen) as a RAG based methodology for radiology report generation extending on top of the work by CXR-RepaiR [Endo et al. (2021)] and CXR-ReDonE [Ramesh et al. (2022)]. As illustrated in Figure 1, we leverage the contrastively pretrained ALBEF model [Li et al. (2021)] from CXR-ReDonE to generate the vision-language aligned embeddings for a database of radiology reports. The same model is used to generate the embedding for an input radiology image. As the image and text embeddings were aligned during the contrastive pre-training, the most relevant text radiology text (reports or sentences) is re- trieved for an input x-ray image based on the similarity of the input image embeddings to the radiology report embeddings. A consolidated radiology report impression is generated from the ﬁltered set of records using the OpenAI text-davinci-003, gpt-3.5-turbo and gpt-4 models. RAG based approach not only makes the radiology report generations grounded on the relevant radiology text retrieved from the radiology text corpus but also allows the user to inject user intents as instructions and few shot examples as part of the generation process via prompt engineering to generate content in the required format applicable for the clinical setting. Generalizable Insights about Machine Learning in the Context of Healthcare Our approach brings the below key insights for ML in healthcare: • Retrieval augmented generation can help bridge the advantages of various domain speciﬁc healthcare encoder models with that of the general domain generative models leveraging the best of both models. We show this improves the clinical metrics. • We also measure the radiology report generations for hallucinations by comparing the LLM generated response with the retrieved radiology text from the radiology reports or sentences corpus. This can help in decision making when planning to practically use these systems in a real clinical setting. • Our paper also shows how we can leverage prompt engineering in LLM to inject user intents and requirements to produce radiology reports in diﬀerent output formats relevant for the downstream application with few-shot learning. Our approach achieves better clinical metrics with a BERTScore [Yu et al. (2022)] of 0.2865 (∆+ 25.88%) and Semb score [Endo et al. (2021)] of 0.4026 (∆+ 6.31%) over the pre- vious state-of-the-art retrieval method CXR-ReDonE. In clinical settings, the improvement of these scores means we are able to generate radiology reports that are closer to the ground truth impression semantically, at the same time being very concise reducing the noise from 3 CXR-RePaiR-Gen Figure 1: We project all the text embeddings of sentences from radiology impression using a contrastively pretrained vision-language encoder (CXR-ReDonE) to a vector database index and retrieve the most matching sentences for an input image embedding using the same encoder model. The retrieved impression reports or sentences form the context of the prompt to the LLM along with instructions to generate the impression. the retrievals. We are also on par with CXR-ReDonE on the RadGraph F1 metric [Yu et al. (2022)]. This metric measures if we are able to retrieve all the clinical entities accurately. We cannot exceed on this metric beyond the retrieval model CXR-ReDonE as the RAG generation are based on the retrieved records from CXR-ReDonE. 2. Related Work Recent works in radiology report generation approached the problem as a generative task like the work of Chen et al. (2020) which used a Transformer decoder architecture R2Gen and the work of Miura et al. (2020) which focused on generating complete, consistent, and clinically accurate reports using a reward-based reinforcement leaning approach by name M2 Trans. Endo et al. (2021) in their work CXR-RePaiR approached radiology report generation problem using a retrieval approach and set a new SOTA benchmark using more clinically reliable metrics. The retrieval was based on their constrastively pretrained vision-language model using the MIMIC-CXR dataset [Johnson et al. (2019)]. A new clinical eﬃcacy sim- ilarity metric Semb was introduced in the paper to calculate the semantic similarity using the last hidden representations from the CheXbert [Smit et al. (2020)] labeler between the 4 CXR-RePaiR-Gen reference report and the predicted report. The paper also used the BERTScore metric [Zhang et al. (2019)] as another measure for semantic similarity. Ramesh et al. (2022) in their work addressed one key issue pertaining to all automated radiology report generation approaches which are prior report references in the radiology report which impacts the quality of report generation. They built a new dataset CXR-PRO [Ramesh et al.] by addressing this issue on the MIMIC-CXR dataset [Johnson et al. (2019)]. They also retrained CXR-RepaiR using the CXR-PRO dataset and an updated architecture ALBEF [Li et al. (2021)] and set the current SOTA for the radiology report generation task. They also used the RadGraph F1 [Yu et al. (2022)] score as an additional metric to measure the completeness and accuracy of the clinical entities available in the predicted report using the RadGraph model [Jain et al. (2021)] With the rise of the LLMs, Retrieval Augmented Generation (RAG) was introduced in the work by Lewis et al. (2020) which brought some key advantages of leveraging external knowledge sources to augment the knowledge of LLMs to do a task. LLMs generations are also strongly grounded in real factual knowledge which makes it “hallucinate” less and produce generations that are more factual. The broarder impact statement from the paper mentioned its application in a wide variety of scenarios, for example by endowing it with a medical index. We in this work endow the LLMs with the index of radiology report text and use it as a knowledge base to allow LLMs generate a radiology report impression for an input radiology image. To enable the multimodal retrieval of Images and Text, we use the constrastively pretrained vision language model from CXR-ReDonE [Ramesh et al. (2022)] which improved the work of CXR-RepaiR [Endo et al. (2021)] for multimodal retrievals to see if augmented generation on top of these retrievals can further push the report generation benchmark. We also see if we can use the general capabilities of LLMs to modulate the report generation outputs per user requirements to enable a wide variety of usage patterns across diﬀerent clinical settings. We also measure the hallucinations from RAG to pivot the application of the proposed approach in a real-world clinical setting. 3. Methods In this paper we propose radiology report generation as a data augmented generation task using large language models like text-davinci-003, gpt-3.5-turbo and gpt-4. Our hy- pothesis is that it is not required to have domain speciﬁc generative models, but domain speciﬁc retrievers. We can leverage embeddings from domain speciﬁc encoders for the data retrieval task and use the retrieved data for augmentation using a general domain generative model. We build on top of the work by CXR-RePaiR [Endo et al. (2021)] and CXR-ReDonE [Ramesh et al. (2022)] by considering the problem of radiology report generation as retrieval task but adding a generative step using the retrieved impressions. We use the contrastively pretrained vision language model ALBEF [Li et al. (2021)] from CXR-ReDonE to generate the image and text embeddings from the radiology images and reports. For selecting the top K records for data augmentations, we tried both report level corpus R = r1, ..., rn and sentence level corpus S = s1, ..., sn as in CXR-RePaiR. We use the ALBEF [Li et al. (2021)] model from CXR-ReDonE to generate contrastively aligned text embeddings for the radiology report text corpus using the CXR-PRO dataset 5 CXR-RePaiR-Gen [Ramesh et al.] and index it in the vector database. We use the same model for generating the contrastively aligned image embedding for the input radiology image x and use the embedding to retrieve the top-K records from the reports or sentences corpus based on dot- product similarity. The top-K reports or sentences that have the highest similarity to the in- put image embeddings are selected for augmenting the generation usingtext-davinci-003, gpt-3.5-turbo and gpt-4 models. We generate impression I by prompting the LLM with prompt P passing in the retrieved top-K sentences of the sentence corpus S as the context along with instructions Q for the generation. I = LLM(P (Q, k∑ i=1 Si)) Where top K sentences from S is selected using the function argmaxs∈S(R), f(s, x), f indicating the similarity dot product function on the input sentence s and radiology image x as in CXR-RePaiR. If the size of the context records for the LLM generation is beyond the token limit of the LLM, we propose to use the reﬁne methodology for iteratively generating the response from the LLM. We generate an initial impression from the LLM by prompting the LLM with the ﬁrst retrieved report or sentence of the top K records from the radiology text corpus as the context and then we pass the initial impression response generated by the LLM, second sentence or report as context and so on to get a ﬁnal reﬁned answer from the LLM. Ik denotes the iteratively constructed impression from the LLM using reﬁne prompt P r constructed using the impressions from the previous iterations, instructions Q and Sk denoting the kth sentence from the sentence corpus. Ik = LLM(P r(Q, Ik−1, Sk)) Reﬁne mechanism is available with LLM based frameworks like langchain [Chase (2022)] and llama-index [Liu (2022)]. As the size of context for RAG based generations could vary in diﬀerent clinical settings, the paper proposes the usage of reﬁne approach. In the context of our experiments, for this paper reﬁne mechanism was not required as we experimented with smaller K = 1 , 2, 3 values and the context were still within the limit of LLMs and iterative response building was not required. In addition to free text radiology report generation, we also hypothesize that it would be more useful to have the radiology reports in a structured format including key attributes of interest from the retrievals. These attributes of interest could be pathologies, severity related to pathology, severity, size, or position etc. We use prompt engineering with few shot examples to generate a structured radiology report output. 3.1. Retrieval Corpus We base the retrieval corpus on the train impressions of the CXR-PRO dataset [Ramesh et al.] which consists of 374,139 free-text radiology reports and their associated chest radiographs. As CXR-PRO is based on MIMIC-CXR which is a de-identiﬁed dataset, no protected health information (PHI) is included. CXR-PRO is an adapted version of the MIMIC-CXR dataset [Johnson et al. (2019)]] with prior references omitted. It addresses 6 CXR-RePaiR-Gen the issue of hallucinated reference to priors produced by radiology report generation models. We use the impressions sections of the radiology reports in the corpus and consider both report-level impressions and as well as the sentences comprising the report-level impressions as the retrieval corpus for report generation as in CXR-RePaiR [Endo et al. (2021)] 3.2. Baselines We consider CXR-ReDonE [Ramesh et al. (2022)] which does retrieval-based report gener- ation with CXR-PRO dataset [Ramesh et al.] as the retrieval corpus as our baseline. We aim to see if retrieval augmented generation using LLMs on top of these retrievals can help improve radiology report generation clinical metrics. 3.3. Prompt Design We design two sets of prompts to generate the radiology report as free-text report, one for the text-davinci-003 model and another for report generation in the conversational setup with the gpt-3.5-turbo and gpt-4 model as shown in Table 1 We provide instructions to the LLM to use the retrieved sentences as a context to generate the radiology report. For gpt-3.5-turbo and gpt-4 the prompt design involves system prompt and a user prompt in a conversation setting. The system prompt instructs the system to generate a radiology report impression from the context that the user will send. The user prompt sends the retrieved records as a context requesting the system to provide the radiology report as a response. 3.4. Structured Report Output We also experiment with the ability to modulate the report generation output with speciﬁ- cations on the desired report output format in the prompts as few shot examples. It can be interesting for the radiologist and downstream applications to generate certain attributes of interest from the radiology report apart from generating the free text radiology impression. These attributes of interest could be extracting the pathologies, severity related to pathol- ogy, severity, size, or position of ﬁndings etc. We instruct LLM to generate the radiology report in a structured output format containing the impression summary and attributes of interest seen in the retrieved context. We provide speciﬁcations on the pathology we are interested in and other attributes of interest along with few shot prompts as shown in the prompt design in Table 2 3.5. Experiments We conducted the retrieval augmented generation experiments using the OpenAI LLMs - text-davinci-003, gpt-3.5-turbo and gpt-4 based on the retrieved records using the CXR-ReDonE embeddings. We consider both report-based corpus and sentence-based cor- pus in our experiments. The retrieved records from the corpus forms the context in the prompt based on which the LLM generates the free text radiology impression. We experi- mented with zero shot settings for free text impression generation and few shot settings for the structured report generation. 7 CXR-RePaiR-Gen Table 1: Prompts for the OpenAI LLMs for Radiology Report Impression Generation from the retrieved reports as context text in the zero-shot setting. The text in italics in the prompts corresponds to the variables used in formatting the prompt. text-davinci-003 gpt-3.5-turbo/gpt-4 System Prompt gpt-3.5-turbo/gpt-4 User Prompt Generate an impression summary for the radiology report using the context given. Strictly follow the instructions below while generating the impressions. Instructions: • Impression summary should be based on the information in the context. • Limit the generation to maxlen words. CONTEXT: maxlen Impression summary: You are an assistant designed to write impression summaries for the radiology report. Users will send a context text and you will respond with an impression summary using that context. Instructions: • Impression should be based on the informa- tion that the user will send in the context. • The impression should not mention anything about follow-up actions. • Impression should not contain any mentions of prior or previous studies. • Limit the generation to maxlen words. CONTEXT: context Impression summary: 8 CXR-RePaiR-Gen Table 2: Prompts for the OpenAI LLMs for Structured Radiology Report Generation from the retrieved reports as context text in the Few-Shot setting. The text inside brackets in the prompts corresponds to the variables used while formatting the prompt. Prompt Design Few Shots Example Generate an impression summary for the ra- diology report using the context. Pathology for impression should be from list of words as in: {pathology} Positional words should be from list of words as in: {positional words} Severity should should be from list of words as in: {severity words} Size should should be from list of words as in: {size words} CONTEXT: {example context} IMPRESSION: {example report json} CONTEXT: {example context} IMPRESSION: {example report json} CONTEXT: {example context} IMPRESSION: {example report json} CONTEXT: {context} IMPRESSION: CONTEXT: Right suprahilar opacities may relate to pulmonary vascular congestion although infectious process or aspiration not entirely excluded in the appropriate clinical setting. IMPRESSION: { ”impression”: ”Mild bibasilar atelectasis is present. Right suprahilar opacities may be due to pulmonary vascular congestion. ”, ”attributes”: [ { ”pathology”: ”atelectasis”, ”positional”: ”bibasilar” }, { ”pathology”: ”opacities”, ”positional”: ”Right suprahilar” } ] } 9 CXR-RePaiR-Gen 4. Results on Real Data 4.1. Evaluation Dataset We evaluate the performance on two golden benchmark datasets, MS-CXR [Boecking et al.] and the test impressions from the CXR-PRO dataset [Ramesh et al.] . Both datasets are created with the help of board-certiﬁed radiologists. CXR-PRO consists of 2,188 radiology images and associated reports. CXR-PRO dataset was preprocessed to remove duplicate lines. MS-CXR dataset provides 1162 image–sentence pairs across eight diﬀerent cardiopul- monary radiological ﬁndings. Both these datasets though from the same data distribution are diﬀerent, MS-CXR is a phrase grounding dataset which also contains bounding boxes to ground the phrases on the radiology image, it contains very precise and concise phrases whereas CXR-PRO has longer text for the impressions. We evaluate the performance across these two setups as in some clinical settings it may be required to give precise and concise phrases about the radiology image. 4.2. Evaluation Approach We evaluate the free text radiology impressions generated using the LLMs from the retrieved records of the report level corpus and sentence level corpus. For sentence level corpus we evaluate the impressions generated from top K sentence retrievals with K= 1, 2, 3. Our baselines are the impressions retrieved from CXR-ReDonE. We evaluate on the two semantic metrics – BERTScore [Zhang et al. (2019)] andSemb [Endo et al. (2021)] to see the similarity of the generation to the ground truth impression. We see this more meaningful as in the medical context phrases like lung collapse can represent atelectasis though the exact word may not be in the sentence. BERTScore computes a similarity score for each token in the predicted impressions with each token in the ground truth impressions. Token level similarity is computed using contextual embeddings instead of direct token matches. Semb uses CheXbert model [Smit et al. (2020)] to calculate the cosine similarity between the embeddings from the ﬁnal hidden state representations. To evaluate the overlap in clinical entities included in both the generated and ground truth reports we use RadGraph F1, a metric proposed by Yu et al. (2022) that makes use of a RadGraph model [Jain et al. (2021)] to evaluate the overlap in clinical entities. We also generate the radiology report impressions in a structured json format to evaluate if we can format the output the generated impression as per user requirements. At this point in time these are not quantitatively measured but we show qualitative outputs for structured generation. 4.3. Measuring Hallucinations We also qualitatively and quantitatively evaluate if the report impression summary hallu- cinates from the top K sentences corpus given to the LLM as context. We use the Semb score between the LLM generations and the top-k context records to see if they semantically equivalent. 10 CXR-RePaiR-Gen Table 3: Evaluation of CXR-RePaiR-Gen(RAG based approach) on CXR-PRO test im- pressions for report corpus retrieval and sentence corpus retrieval. Metrics evaluated are BERTScore, Semb score and RadGraph F1. Our approach outperforms the baseline on both the clinical metrics BERTScore and Semb score for both the report and sentence corpus- based retrieval for all values of K and at par with CXR-ReDonE for RadGraph F1 at k=3. Italics denote improvement over the baseline, bold denotes the highest value obtained by our approach at the highest value of RadGraph F1 which is at k=3. We should note that CXR-RePaiR-Gen (based on RAG) cannot exceed CXR-ReDonE on the RadGraphF1 score as otherwise it means we are hallucinating on the clinical entities which are not present in the context. K Method Evaluation Metrics BERTScore Semb RadGraph F1 N/A CXR-ReDonE 0.2482 0.3647 0.0921 CXR-RePaiR-Gen (text-davinci-003) 0.2600 0.3741 0.0839 1 CXR-ReDonE 0.2455 0.4029 0.0861 CXR-RePaiR-Gen (text-davinci-003) 0.2610 0.4116 0.0774 2 CXR-ReDonE 0.2465 0.3892 0.1045 CXR-RePaiR-Gen (text-davinci-003) 0.2753 0.4036 0.0926 3 CXR-ReDonE 0.2276 0.3787 0.1104 CXR-RePaiR-Gen(text-davinci-003) 0.2782 0.4030 0.1018 CXR-RePaiR-Gen(gpt-3.5-turbo) 0.2748 0.3973 0.0991 CXR-RePaiR-Gen(gpt-4) 0.2865 0.4026 0.1061 4.4. Results – CXR-PRO We evaluate the performance of radiology report impressions generated using a purely retrieval-based approach in CXR-ReDonE as our baseline. We ﬁnd that RAG based gen- erations improves the BERTScore metrics for both report and sentence corpus retrievals bringing in an absolute improvement of 5.06% at k=3 for sentence-based retrieval. Simi- larly, it also improves Semb scores for both report and sentence corpus retrievals, bringing in an absolute improvement of 2.43% at k=3 for sentence-based retrieval. RadGraph F1 metric that measures the retrievals of clinical entities is on par with CXR-ReDonE at k=3 and slightly lower at lower k values. We should note that our approach generates the im- pressions on the augmented data so we cannot exceed CXR-ReDonE on RadGraph F1 as otherwise we are hallucinating clinical entities not based on the context. The evaluation metrics are available in Table 3. 4.5. Results – MS-CXR Our approach improves the BERTScore on MS-CXR phrase grounding text by an absolute value of 8.67 and Semb by an absolute value of 3.86. The evaluation metrics are available in Table 4. 11 CXR-RePaiR-Gen Table 4: Evaluation of CXR-RePaiR-Gen on MS-CXR phrases using text-davinci-003 for sentence corpus-based retrieval at k = 3. Metrics evaluated are BERTScore, Semb and Rad- Graph F1. Our approach outperforms the baseline on both the clinical metrics BERTScore and Semb and at par for RadGraph F1. Italics denotes improvement over the baseline, while bold denotes the highest value obtained by our approach. Method Evaluation Metrics BERTScore Semb RadGraph F1 CXR-ReDonE 0.1102 0.3494 0.0626 CXR-RePaiR-Gen(text-davinci-003) 0.1970 0.3880 0.0617 4.6. Qualitative Analysis We ﬁnd the retrieval augmented generations-based impressions are very concise and less noisy when compared to the outputs from a pure retrieval-based strategy but still retaining all the relevant clinical entities. Refer Table 5 and Table 6 to see the concise impression summary created by the RAG based approach for examples from CXR-PRO and MS-CXR respectively. RAG also tries to avoid insigniﬁcant details in the retrieved corpus. In the last sample of Table 5, RAG based generations automatically exclude details like follow-up recommendations and gives a cleaner impression. Table 5: Examples from CXR-PRO dataset: Generated reports compared to the reference report and the baseline method CXR-RedonE. RAG based generations from CXR-RepaiR- Gen provides very concise impression summaries with ability to retain the important clinical entities. Outputs were generated at top K retrievals set to 3. Ground Truth CXR-ReDonE (K=3) CXR-RepaiR-Gen (K=3) (text-davinci-003) CXR-RepaiR-Gen (K=3) (gpt-4) 12 CXR-RePaiR-Gen Right hilar mass is as- sociated with atelec- tasis of right mid- dle lobe and there is a signiﬁcant adjacent lymphangitic carcino- matosis and consolida- tion. Right hilar mass is associated with at- electasis of right mid- dle lobe and there is a signiﬁcant adjacent lymphangitic carcino- matosis and consolida- tion. Although this may reﬂect dense consol- idative pneumonia, ﬁndings at least raise concern for the possi- bility of an underlying mass with associated pneumonitis as a possible alternative diagnosis. Regions of conﬂuent consol- idation in the right middle lobe and right suprahilar region, which could repre- sent superimposed infection or atelec- tasis. Right middle lobe consolidation in part due to known underlying metastatic disease with possible superimposed postob- structive infection or atelectasis. Large right perihilar mass with associated extensive atelectasis and regions of conﬂu- ent consolidation in the right middle lobe and right suprahilar region, raising concern for underlying malig- nancy and possible alternative diagnosis of pneumonitis. Apparent right hilar mass, concerning for obstructive adenopa- thy. Conﬂuent consol- idation in right middle lobe and suprahilar region, possibly due to infection or atelectasis. Findings worrisome for large right perihilar mass with extensive atelectasis, suggesting potential malignancy. PA and lateral chest: Signiﬁcantly low lung volume exaggerates mild cardiomegaly, but pulmonary vas- cular engorgement accompanied by mild interstitial edema in the lower lungs has an indication of cardiac decompensation. Clearing fail- ure.Moderate pul- monary edema from the right upper lung , and residual edema considered as the likely explanation for resid- ual opaciﬁcation at the right lung base , unless it proves subsequently unresponsive to diure- sis.Mild pulmonary edema with moderate cardiomegaly , small right pleural eﬀusion , and cephalization of vasculature. Mild pulmonary edema with mod- erate cardiomegaly, small bilateral pleural eﬀusions, and cephal- ization of vasculature, reﬂecting cardiac decompensation. Mild pulmonary edema, moderate cardiomegaly, small right pleural eﬀusion, cephalization of vas- culature, and possible infectious process in right perihilar opacities. 13 CXR-RePaiR-Gen AP chest: Lung volumes are lower, exaggerating severe enlargement of the cardiac silhouette and volume of moderate- sized bilateral pleural eﬀusions.There is enlargement of the cardiac silhouette with pulmonary vascular congestion and bi- lateral opaciﬁcations consistent with signiﬁ- cant layering eﬀusions and compressive basilar atelectasis. Hazy opaciﬁcation of the hemithoraces is with bilateral pleural eﬀusions and compres- sive atelectasis , along with enlargement of the cardiac silhouette and pulmonary vascu- lar congestion. Hazy opaciﬁcation of the lower lungs suggests bilateral layering pleu- ral eﬀusions with some atelectatic changes at the bases.Hazy opaci- ﬁcations bilaterally are consistent with pleural eﬀusions and compressive atelectasis at the bases. Bilateral pleural eﬀu- sions, compressive at- electasis, enlargement of cardiac silhouette, and pulmonary vas- cular congestion are seen. Mild pulmonary edema and interstitial edema cannot be ex- cluded. Bilateral hazy opaciﬁ- cations, layering pleu- ral eﬀusion, compres- sive atelectasis, en- larged cardiac silhou- ette, pulmonary vascu- lar congestion, bibasi- lar opacities, and pos- sible mild pulmonary edema. 4.7. Instruction Driven Output We also evaluate the instructions following capabilities of GPT-4 by passing speciﬁc prompts to exclude any mentions of prior report reference and follow-up actions in the generated impression. Observations from CXR-PRO evaluation: • All the 40 occurrences related to follow-up recommendations in the retrieved context documents were not included in the ﬁnal impression. • Out of 87 references to previous/prior reports, 80 references were successfully excluded in the impression. Some sample cases where the prior report references and follow-up actions were removed based on the instructions in the prompt are shown in Table 7 4.8. Modulate Report Generation Format One of the key advantages of RAG is the ability to modulate output generation format via prompt engineering. Table 8 shows the report generation outputs in a structured json format extracting the attributes of interest using the few shot prompts in Table 2. 14 CXR-RePaiR-Gen Table 6: Examples from MS-CXR dataset: Generated reports compared to the reference report and the baseline method CXR-RedonE. RAG based generations from CXR-RepaiR- Gen avoids noisy and duplicate details in its generation and still retains the important clinical entities. Outputs were generated at top K retrievals set to 3. Ground Truth CXR-ReDonE (K=3) CXR-RepaiR-Gen (K=3) (text-davinci-003) Subtle opacity in the left peri- hilar region Vague asymmetric opac- ity in the left lower lobe which may represent an area of early infection. Vague left infrahilar den- sity , possibly associated with lower airway inﬂamma- tion or infection , or poten- tially early or mild bronchop- neumonia , but not of deﬁnite signiﬁcance.Indeterminate 3 cm ovoid density in the left lung base with possible retrocardiac correlate on lat- eral view. Vague asymmetric opacity in the left lower lobe is suggestive of early infection or developing pneumonia, depending on the clinical scenario. Left lower lobe consolidation due to pneumonia More conﬂuent basilar opac- ities may reﬂect dependent edema , but aspiration and infectious pneumonia should also be considered in the appropriate clinical setting.Retrocardiac opacity likely reﬂects basilar atelec- tasis , however infection or aspiration may produce a similar appearance , and short term followup radio- graphs may be helpful in this regard if warranted clinically.Right internal jugular line tip is in the right atrium and is needs to be pulled back to be indicate labral junction or above , 3. 5 cm have to be pulled back. Mild pulmonary edema with patchy opacities and bilateral eﬀusions, predominantly on the left. Compressive atelec- tasis and pneumonia are pos- sible. 15 CXR-RePaiR-Gen Table 7: Random examples of cases from CXR-PRO dataset where the RAG based genera- tions from GPT-4 eliminated the references to prior reports and follow-up recommendations based on instruction-based prompts. Context Records RAG Impression Diﬀerential appearance include interstitial lung disease with or without superim- posed developing pneumonia versusasis as- sociated with elevation of the right hemidi- aphragm.Patchy right basilar opacity may re- ﬂect compressive atelectasis however infec- tion cannot be excluded and followup radio- graphs after diuresis are recommended. Bibasilar hazy opacities , right greater than left , possibly due to atelectasis given low lung volumes , however underlying infection cannot be excluded in the appropriate clinical setting. Interstitial lung disease with possible devel- oping pneumonia or atelectasis, patchy right basilar opacity, and bibasilar hazy opacities, right greater than left. Infection cannot be excluded. It is unusual to have a unilateral left eﬀu- sion when the patient has previously had right sided eﬀusions and causes such as pericarditis, pancreatitis or a left up- per quandrant process should be consid- ered. Bilateral opaciﬁcations with silhouet- ting hemidiaphragms is consistent with layer- ing pleural eﬀusions and underlying compres- sive basilar atelectasis. Bilateral layering eﬀu- sions are present with patchy airspace opacity predominantly at the bases, left greater than right, which may represent patchy atelectasis. Unilateral left eﬀusion, bilateral opaciﬁcations with silhouetting hemidiaphragms, compres- sive basilar atelectasis, and patchy airspace opacity predominantly at the bases, left greater than right. 16 CXR-RePaiR-Gen Table 8: Structured Report Generation outputs from CXR-RepaiR-Gen using the few shot prompts in Table 2. We see that we can generate the impression summary and extract pathology, positional information, severity, size from the retrieved context in a structured format. Structured Report Output (JSON) { ”impression”:”The Swan-Ganz catheter tip is seen in the proximal right pulmonary artery. Appropriate position of Dobbhoﬀ line reaching stomach. Combination of severe bilateral lower lobe atelectasis and small to moderate pleural eﬀusions” ”ﬁndings”:[ { ”pathology”:”atelectasis”, ”positional”:”bilateral, base”, ”severity”:”severe”, ”size”:”” }, { ”pathology”:”pleural eﬀusions”, ”positional”:”bilateral”, ”severity”:””, ”size”:” small to moderate” } ] } 17 CXR-RePaiR-Gen 4.9. Hallucinations in Retrieval Augmented Generation We calculate the Semb scores between the generated report impression and the retrieved context from the sentence corpus with K=3 top K retrievals. We ﬁnd that the average similarity score is 0.8466 and around 87% of the test impressions have a Semb > 0.70 which is a good indication that the generations did not hallucinate. Table 9 presents a couple of records which had the lowest Semb scores in the test set. We ﬁnd that even such records did not hallucinate, and the lowest scores may be attributed to the concise impression summary generated. 5. Discussion We ﬁnd that CXR-RepaiR-Gen - Retrieval Augmented Generation based approach for radi- ology report impression generation using embeddings from contrastively pretrained model CXR-ReDonE for retrieval of relevant radiology text and OpenAI LLM models for gener- ation can help generate very concise and precise radiology report impressions and improve the clinical eﬃcacy metrics speciﬁcally the BERTScore and Semb scores without compro- mising on retaining the relevant clinical entities. We also ﬁnd that the LLM based report generations via few shot prompts and instructions allow for modulation of report outputs for desired content and format and helps reduce noisier text (like recommendations for further evaluation, prior report mentions, speciﬁc patient details etc) and avoids repeating content in the impressions which are the typical issues with a pure retrieval-based setup. We note that these limitations were mentioned in the CXR-RePaiR paper which warranted the requirement to have a template database that removed these noisy details or dupli- cates and use the template database for performing the retrievals for better quality report generation. We see that RAG based generation can address this limitation via eﬀective prompt engineering and also using approaches like structured content extraction with few shot prompts to extract only the attributes of interest and produce a more concise, precise, and complete impression summary from the retrieved records. 5.1. Limitations We note that as RAG impression generation eﬃcacy is sensitive to the retrieved sentences from the corpus which is based on the embeddings from the constrastively pretrained model meaning that the clinical entities generated by RAG is limited by the clinical entities from the retrieval unless we allow it to use the general knowledge it has. In our experiments we restricted the model to use the context while making the generations via prompt instructions to alleviate hallucinations. So it is imperative that the retrieval model is able to bring in the all the relevant clinical entities for the generation. 5.2. Future Work We see that RAG based report generations can beneﬁt from more advanced contrastive models that are more sensitive to ﬁne details of the radiology image such as severity, size, position, pathology, and other attributes of interest from the radiology image. Advances in prompt engineering for medical text is another area to explore so that we can elicit the LLM more eﬃciently for a speciﬁc downstream task. 18 CXR-RePaiR-Gen Table 9: Examples of cases where the Semb scores were less between the retrieved context sentence corpus and the generations from the LLM model. Semb uses CheXbert model to calculate the cosine similarity between the embeddings from the ﬁnal hidden state repre- sentations and can give an indication of hallucination. We see there are no hallucinations. Semb Context Records (K=3) RAG Impression 0.1508 Lung volumes with right basi- lar atelectasis versus consoli- dation which could represent pneumonia in the right clini- cal context. Low lung volumes with bibasilar opacities which may represent atelectasis ver- sus aspiration. Low lung vol- umes with bibasilar opacities which could potentially be due to atelectasis. Right basilar atelectasis and consolidation likely due to pneumonia. Bibasilar opaci- ties may be due to atelectasis or aspiration. Low lung vol- umes present. 0.2116 The left lung remains grossly clear, although there is mini- mal linear opacity at the left costophrenic angle, which may represent post - inﬂammatory scarring or subsegmental at- electasis. There is a sugges- tion of a tiny left apical pneu- mothorax which me if there is attempted line placement from the left side prior to the right. There is enlargement of the cardiac silhouette there is sug- gestion of some mild engorge- ment of pulmonary vessels on the left, raising the possibility of asymmetric elevation of pul- monary venous pressure. The left lung is clear with minimal linear opacity at the left costophrenic angle. Tiny left apical pneumotho- rax and mild engorgement of pulmonary vessels on the left suggest asymmetric elevation of pulmonary venous pressure. Enlargement of cardiac silhou- ette noted. 19 CXR-RePaiR-Gen Table 10: RAG based report generation metrics at diﬀerent temperature settings for the text-davinci-003 model using the sentence corpus and top K retrievals set to K=3. Temperature Evaluation Metrics BERTScore Semb RadGraph F1 T=0 0.2782 0.4030 0.1018 T=1 0.2783 0.3996 0.1013 T=2 0.2787 0.3998 0.1011 6. Appendix 6.1. GPT-3 Hyperparameters We tried with temperature values of 0, 0.5 and 1 for the zero shot impression generations from the text-davinci-003 model using the top K retrievals(K=3) from the sentence level corpus as the context. We found that it did not inﬂuence the output scores much as seen from Table 10. The instruction to use retrieved sentence corpus as context for generations may be responsible for this behavior. References Benedikt Boecking, Naoto Usuyama, Shruthi Bannur, Daniel C Castro, Anton Schwaighofer, Stephanie Hyland, Maria Wetscherek, Tristan Naumann, Aditya Nori, Javier Alvarez- Valle, et al. Ms-cxr: Making the most of text semantics to improve biomedical vision- language processing. Harrison Chase. Langchain, 2022. URL https://github.com/hwchase17/langchain. Zhihong Chen, Yan Song, Tsung-Hui Chang, and Xiang Wan. Generating radiology reports via memory-driven transformer. arXiv preprint arXiv:2010.16056 , 2020. Mark Endo, Rayan Krishnan, Viswesh Krishna, Andrew Y Ng, and Pranav Rajpurkar. Retrieval-based chest x-ray report generation using a pre-trained contrastive language- image model. In Machine Learning for Health , pages 209–219. PMLR, 2021. Saahil Jain, Ashwin Agrawal, Adriel Saporta, Steven QH Truong, Du Nguyen Duong, Tan Bui, Pierre Chambon, Yuhao Zhang, Matthew P Lungren, Andrew Y Ng, et al. Rad- graph: Extracting clinical entities and relations from radiology reports. arXiv preprint arXiv:2106.14463, 2021. Alistair EW Johnson, Tom J Pollard, Nathaniel R Greenbaum, Matthew P Lungren, Chih- ying Deng, Yifan Peng, Zhiyong Lu, Roger G Mark, Seth J Berkowitz, and Steven Horng. Mimic-cxr-jpg, a large publicly available database of labeled chest radiographs. arXiv preprint arXiv:1901.07042, 2019. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K¨ uttler, Mike Lewis, Wen-tau Yih, Tim Rockt¨ aschel, et al. Retrieval- 20 CXR-RePaiR-Gen augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474, 2020. Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shaﬁq Joty, Caiming Xiong, and Steven Chu Hong Hoi. Align before fuse: Vision and language representation learning with momentum distillation. Advances in neural information processing systems , 34: 9694–9705, 2021. Jerry Liu. Llamaindex, 2022. URL https://github.com/jerryjliu/gpt_index. Yasuhide Miura, Yuhao Zhang, Emily Bao Tsai, Curtis P Langlotz, and Dan Jurafsky. Improving factual completeness and consistency of image-to-text radiology report gener- ation. arXiv preprint arXiv:2010.10042 , 2020. Vignav Ramesh, Nathan Chi, and Pranav Rajpurkar. Cxr-pro: Mimic-cxr with prior refer- ences omitted. Vignav Ramesh, Nathan A Chi, and Pranav Rajpurkar. Improving radiology report gen- eration systems by removing hallucinated references to non-existent priors. In Machine Learning for Health , pages 456–473. PMLR, 2022. Akshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj Pareek, Andrew Y Ng, and Matthew P Lungren. Chexbert: combining automatic labelers and expert annotations for accurate radiology report labeling using bert. arXiv preprint arXiv:2004.09167 , 2020. Feiyang Yu, Mark Endo, Rayan Krishnan, Ian Pan, Andy Tsai, Eduardo Pontes Reis, Eduardo Kaiser Ururahy Nunes Fonseca, Henrique Min Ho Lee, Zahra Shakeri Hossein Abad, Andrew Y Ng, et al. Evaluating progress in automatic chest x-ray radiology report generation. medRxiv, pages 2022–08, 2022. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675 , 2019. 21