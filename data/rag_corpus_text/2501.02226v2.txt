Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation Shijie Wang1, Wenqi Fan1*, Yue Feng2*, Shanru Lin3, Xinyu Ma4, Shuaiqiang Wang4, Dawei Yin4, 1The Hong Kong Polytechnic University, 2University of Birmingham, 3City University of Hong Kong, 4Baidu Inc, shijie.wang@connect.polyu.hk; wenqifan03@gmail.com; y.feng.6@bham.ac.uk; lllam32316@gmail.com; xinyuma2016@gmail.com; shqiang.wang@gmail.com; yindawei@acm.org Abstract Recommender systems have become increas- ingly vital in our daily lives, helping to allevi- ate the problem of information overload across various user-oriented online services. The emergence of Large Language Models (LLMs) has yielded remarkable achievements, demon- strating their potential for the development of next-generation recommender systems. De- spite these advancements, LLM-based recom- mender systems face inherent limitations stem- ming from their LLM backbones, particularly issues of hallucinations and the lack of up-to- date and domain-specific knowledge. Recently, Retrieval-Augmented Generation (RAG) has garnered significant attention for addressing these limitations by leveraging external knowl- edge sources to enhance the understanding and generation of LLMs. However, vanilla RAG methods often introduce noise and neglect structural relationships in knowledge, limiting their effectiveness in LLM-based recommenda- tions. To address these limitations, we propose to retrieve high-quality and up-to-date structure information from the knowledge graph (KG) to augment recommendations. Specifically, our approach develops a retrieval-augmented framework, termed K-RagRec, that facilitates the recommendation generation process by in- corporating structure information from the ex- ternal KG. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed method. 1 Introduction Recommender systems, as techniques designed to assist people in making decisions in their daily lives, are increasingly gaining impact in various fields (Kenthapadi et al., 2017; He et al., 2020; Fan et al., 2019), such as online shopping, job matching, and social media. Recently, Large Lan- guage Models (LLMs) have achieved significant *Corresponding authors (c) KG RAG for LLM Recommendation User (b) Lack of Knowledge LLM (a) Hallucinations I have watched {Godfather} What movie do you recommend I watch next? You may want to watch the movie Godmother ... User LLM I have watched {Dune Ⅱ } What movie do you recommend I watch next? As of December 2022 ， I don't have knowledge about Dune Ⅱ ... User LLM I have watched {Dune Ⅱ } What movie do you recommend I watch next? Based on your watching history, I recommend you to watch Interstellar. Retrieve Vector Database Context Augment Science Timmy is is act_by act_by act_by Romance is Knowledge Sub-graphs Figure 1: Illustration of the issues of hallucinations and lack of domain-specific knowledge in LLM-based recommender systems and how they can be addressed by knowledge graph retrieval-augmented generation (KG RAG). breakthroughs, which further drive developments in various domains (Fan et al., 2024b; Zhao et al., 2024; Wu et al., 2023a). Especially with the suc- cess of LLMs, recommender systems have seen rapid growth (Geng et al., 2022; Bao et al., 2023; Qu et al., 2024). By training on a wide range of data, LLMs (e.g., GPT-4 (Achiam et al., 2023) and LLaMA (Touvron et al., 2023)) are able to acquire extensive knowledge and demonstrate ex- ceptional language understanding capability. This capability enables LLM-based recommender sys- tems to capture user preferences through a nu- anced understanding of relevant attributes (e.g., user profiles, item descriptions, historical inter- actions) for more accurate recommendations. As a result, LLM-based recommender systems have emerged as a new paradigm in recommendation technology (Zhao et al., 2024). However, despite their powerful language un- derstanding and generalization capability, LLM- based recommender systems face significant chal- lenges, including hallucinations and lack of up-to- date and domain-specific knowledge (Luo et al., 2023). Specifically, one key issue is that LLM- arXiv:2501.02226v2 [cs.IR] 28 May 2025 based recommender systems may generate recom- mendations that are entirely fictional due to the inherent limitations of LLMs. For example, an LLM-based recommender system may recommend "Godmother", a non-existent film, to the user who has watched "The Godfather", as illustrated in Fig- ure 1 (a). Additionally, LLMs usually lack up-to- date knowledge, which can prevent them from rec- ommending the latest films or products in a timely manner. As illustrated in Figure 1 (b), the LLM- based recommender system is unable to recom- mend the latest films due to the training data only containing up to December 2022. Furthermore, LLMs often lack domain-specific knowledge, as recommendation-oriented corpora are very limited during the training phase of LLMs (Geng et al., 2022). Consequently, LLMs may struggle to meet the nuanced needs of recommendation tasks. To alleviate these issues, one potential solution is to frequently fine-tune the LLMs with up-to-date and domain-specific knowledge. However, the mas- sive parameters of LLMs make this process com- putationally expensive and time-consuming, which severely hinders the practical application in the real world. More recently, Retrieval-Augmented Generation (RAG) leveraging external databases to provide specific knowledge shows promise to solve these problems (Fan et al., 2024a; Gao et al., 2023). By incorporating an external knowledge base, RAG can retrieve relevant and up-to-date information to complement the LLM’s inherent knowledge, thereby mitigating the issues of hallucinations and knowledge gaps (Khandelwal et al., 2019; Min et al., 2020; Li et al., 2024). This makes RAG a promising technique for enabling LLMs to pro- vide effective recommendations without the need for costly fine-tuning (Ram et al., 2023). Despite this potential, vanilla RAG methods that rely on documents and paragraphs often introduce unnecessary noise and even harmful disturbance, which can negatively impact the accuracy and relia- bility of recommendations (He et al., 2024). In ad- dition, the structural relationships between entities are overlooked in typical RAG, resulting in the sub- optimal reasoning capability of LLM-based rec- ommender systems (Luo et al., 2023). To address the limitations, a prospective solution is to incor- porate structured knowledge such as items’ knowl- edge graph (KG) to help improve recommendation performance. Specifically, KGs offer structured, factual, and editable representations of knowledge, which can provide a faithful knowledge source for recommendations. As shown in Figure 1 (c), re- trieving structured knowledge from the KG can significantly enhance the recommendation capabil- ities of LLM-based recommender systems. However, it is challenging to effectively retrieve KGs to enhance the recommendation capabilities of LLMs. First, KGs store rich factual knowl- edge in a structured format. Simply retrieving the triplets or first-order neighbors of an entity (i.e., item) with semantic information neglects the im- portance of these higher-order neighborhood ef- fects among entities/items, resulting in sub-optimal recommendation performance. Second, indiscrimi- nate retrieving for each item, regardless of whether the retrieval is necessary or the content is relevant, can degrade the performance of the recommen- dation while severely reducing the model’s effi- ciency (Asai et al., 2023; Labruna et al., 2024). Furthermore, structured data in KGs is typically en- coded for LLM in the form of serialized text (Wu et al., 2023b; Sun et al., 2023), which is insuffi- cient for fully exploiting the structural information inherent in the data (Perozzi et al., 2024; Fatemi et al., 2023). Therefore, it is crucial to explore more effective and expressive ways of representing struc- tured data, allowing LLMs to effectively leverage the structure information of retrieved knowledge sub-graphs for recommendations. To address the aforementioned challenges, in this paper, we propose a knowledge retrieval- augmented recommendation framework, namelyK- RagRec, to provide up-to-date and reliable knowl- edge by retrieving relevant knowledge from item’s KGs for recommendation generation in the era of LLMs. Specifically, our proposed framework first performs knowledge sub-graph indexing on the items’ KG at a coarse and fine granularity to con- struct the knowledge vector database. Next, a pop- ularity selective retrieval policy is designed to de- termine which items should be retrieved, followed by the retrieval of specific sub-graphs from the knowledge vector database. To refine the quality of retrieval and ensure the most relevant results are prioritized at the top of the input, we subsequently re-rank the retrieved knowledge sub-graphs. Fi- nally, we introduce a GNN and projector to align the retrieved knowledge sub-graphs into the seman- tic space of the LLM for knowledge-augmented recommendation. The main contributions of this paper can be summarized as follows: • We propose a novel framework that retrieves faithful knowledge from KGs to augment the recommendation capability of LLM. Note that we introduce a flexible indexing method for KGs, which can provide a comprehensive view of a node’s neighborhood within KG. • We design a popularity selective retrieval strat- egy to determine whether an item needs to be retrieved based on its popularity, significantly improving efficiency. • We introduce a more expressive graph encoder for structured data inclusion in LLMs, that can fa- cilitate the LLM to effectively leverage the struc- ture information and avoid long context input. • We conduct comprehensive experiments on vari- ous real-world datasets to evaluate the effective- ness of the proposed K-RagRec framework. 2 Related Work Recently, RAG has emerged as one of the most representative technologies in the field of genera- tive AI, combining the strengths of retrieval sys- tems and language models (LM) to produce co- herent and informative text. Early methods, such as REALM (Guu et al., 2020), RETRO (Borgeaud et al., 2022), and DPR (Karpukhin et al., 2020), typ- ically involve retrieving relevant fragments from a large corpus to guide the LM generation. However, standard RAG methods often struggle to accurately retrieve all relevant textual chunks, due to unnec- essary noise and even harmful disturbance in the documents. To address these limitations, recent studies (Baek et al., 2023; Wu et al., 2023b; He et al., 2024; Luo et al., 2023; Wang et al., 2023; Sen et al., 2023; Sun et al., 2023) focus on re- trieving structured and faithful knowledge from graphs for enhancing generations. For example, Retrieve-Rewrite-Answer (Wu et al., 2023b) re- trieves relevant sub-graphs from KG and converts retrieved sub-graphs into text for the generation. G-Retriever (He et al., 2024) explores retrieving sub-graphs from various types of graphs to alleviate the hallucinations of LLM. With the explosion of LLMs in recommenda- tions, a few works (Di Palma, 2023; Wu et al., 2024; Ang et al., 2024) make initial explorations in RAG for recommendations. For instance, the work (Di Palma, 2023) proposes leveraging knowl- edge from movie or book datasets to enhance rec- ommendations. Nevertheless, retrieving faithful structured knowledge from the KGs for recommen- dations is under-explored and shows great potential. To fill this gap, we propose to retrieve knowledge sub-graphs from KGs to enhance the recommenda- tion performance of LLM. We provide more com- prehensive related work on Appendix A.3. 3 Methodology In this section, we first introduce some key nota- tions and concepts in this work. Then, we provide the details for each component of our proposed framework K-RagRec. 3.1 Preliminary Knowledge Graph: In this work, we propose to leverage external knowledge databases (i.e., KGs) to augment LLMs for recommendations. KGs con- tain abundant factual knowledge in the form of a set of triples: G = {(n, e, n′) | n, n′ ∈ N , e ∈ E}, where N and E denote the set of entities and relations, respectively. For example, a triple Interstellar directed_by − − − − − − − →N olan indicates that the movie "Interstellar" was directed by the direc- tor "Nolan". LLM-based Recommendations: Let U = {u1, u2, . . . , un} and V = {v1, v2, . . . , vm} repre- sent the sets of users and items, where n and m are the sizes of users and items, respectively. The goal of an LLM-based recommender system is to under- stand users’ preferences by modeling users’ histor- ical items interactions V ui = [vui 1 , vui 2 , · · · , vui |Lui |] (e.g., clicks, bought, etc.), where |Lui| is interac- tion sequence length for user ui. Notably, item vj’ side information, such as title and description, is publicly available to enhance LLM for model- ing user preferences. In our setting, we consider asking the LLM to select user u’s preferred item v from the candidate set C = {vj}M j=1, where M is the number of candidate items. The candidate set C typically consists of one positive sample as well as M − 1 negative samples. Specifically, for a frozen LLM fδ with parameters δ, we denote an input-output sequence pair as (Q, A), where Q is the recommendation query/prompt, which consists of task descriptions and users’ historical items. The output A is the LLM’s prediction. Furthermore, we introduce the concept of GNNs in appendix A.2. 3.2 The Overview of Proposed Method As shown in Figure 2, our proposed K-RagRec con- sists of five crucial components: Hop-Field Knowl- edge Sub-graphs for Semantic Indexing, Popularity Selective Retrieval Policy, Knowledge Sub-graphs Retrieval, Knowledge Sub-graphs Re-Ranking, and Knowledge-augmented Recommendation. The model first performs indexing of hop-field knowl- edge sub-graphs within the KG. Following this, a popularity selective retrieval policy is implemented to determine which items should be retrieved or augmented. The model then retrieves specific sub- graphs from the knowledge vector database. Sub- sequently, the retrieved knowledge sub-graphs are re-ranked to refine the retrieval quality. Finally, the retrieved knowledge sub-graphs are utilized with the original prompt to generate recommendations. 3.3 Hop-Field Knowledge Sub-graphs for Semantic Indexing Typically, retrieving knowledge from KG chunks the KG into nodes (He et al., 2024) or triplets (Luo et al., 2023) and only retrieves content locally around the target entity in the KG. However, these methods just naively retrieve the first-order neigh- bors of an entity (i.e., item), which makes it difficult to capture these higher-order neighborhood effects among entities/items in the recommendation pro- cess. Therefore, to effectively retrieve knowledge from the KG, we propose performing semantic in- dexing on hop-field knowledge sub-graphs, which can flexibly chunk KGs and provide a comprehen- sive view of a node’s neighborhood in KG. As illustrated in Figure 2 component 1, we first intro- duce a pre-trained language model (PLM), such as SentenseBert (Reimers, 2019), to capture the semantic information for node no as follows: zno = PLM(xno) ∈ Rd, (1) where d is the dimension of the output represen- tation. Similarly, we also capture the semantic information for edge/relation eo in KG: reo = PLM(xeo) ∈ Rd, (2) where xno and xeo are the text attributes (e.g., item’s title and descriptions) of node no and edge/relation eo, respectively. To retrieve nuanced knowledge of both coarse and fine graph structures from KG, we introduce a GNN (i.e., GNNIndexing ϕ1 (·) with parameters ϕ1) to aggregate information from neighbors for entities, where the lth-hop embedding z(l) no of a central entity no can be defined by: zl no = GNNIndexing ϕ1 ({z(l−1) nm , r(l−1) e<o,m> : nm ∈ N (no)}), (3) where N (no) is the set of neighbours of node no, and e<o,m> is the edge between node no and nm. For each entity, its l-hop representation can be seen as a knowledge sub-graph representation contain- ing the l-hop neighbors of itself. Therefore, we can express the knowledge sub-graph representation of go ∈ G as zgo, where G is the set containing all the knowledge sub-graphs. For each sub-graph, we store its representation in a knowledge vector database. 3.4 Popularity Selective Retrieval Policy Although RAG can augment the LLM for model- ing user preferences with retrieved knowledge, re- trieving each item can cost a significant amount of retrieval time, which can severely degrade the user experience and cause user churn. Meanwhile, most users’ online behaviours in recommender systems are following the power law distribution (Abdol- lahpouri et al., 2017; Celma and Herrera, 2008) in which a small proportion (e.g., less than 20%) of items (i.e., popular items) often account for a large proportion of users’ online behaviours (e.g., more than 80%), while cold-start items have a few inter- actions from users. Therefore, most models tend to keep rich knowledge of popular items, resulting in an inferior performance for cold-start items (Zhao et al., 2023). To this end, we design a popularity selective retrieval policy to determine whether an item needs to be augmented from KG based on its popularity (e.g., sales volume and page view). Particularly, the item is retrieved if its popularity is less than the pre-defined threshold p, otherwise not. By incorporating this strategy, the retrieval time in K-RagRec can be significantly reduced to achieve more efficient retrieval. 3.5 Knowledge Sub-graphs Retrieval Given the query for knowledge sub-graphs retrieval, we adopt the same PLM as the first indexing step to ensure that the query is in the consistent embedding space as the knowledge sub-graph representation. We define the text attribute (e.g., item’s title and descriptions) xqj of the item vj that needs to be retrieved as the query and obtain its semantic infor- mation qj as: qj = PLM(xqj) ∈ Rd. (4) Next, we retrieve the top- K most similar sub- graphs Gj = {g′ 1, ..., g′ K} from G for item vj: Gj = argtopKg∗∈G sim qj, zg∗  , (5) where sim(·, ·) is a similarity metric for measuring the similarity between the query representation qj and knowledge sub-graph g∗’s representationzg∗ in knowledge vector database. Finally, the retrieved knowledge sub-graphs for items required to be re- l-hop2-hop1-hop node edge movie_j PLM Movies Other Entities PLM GNNIndexing Layer GNNIndexing Layer GNNIndexing Layer ... 1. Hop-Field Knowledge Sub-graphs for Semantic Indexing Knowledge Vector Database 3. Knowledge Sub-graphs Retrieval GNNEncoding Prompt (Query): What is the top recommended movie for user_63 who watched {movie_1, ..., }? Projector Large Language Model (LLM) Response: The user may want to watch the movie_*, because ... 5. Knowledge-augmented Recommendation Retrieved Knowledge Sub-graphs 4. Knowledge Sub-graphs Re-Ranking ... {movie_1, ... , movie_5} User Historical Interactions {movie_1 <RET>, ... , movie_5} ... ... 2. Popularity Selective Retrieval Policy ... Knowledge Graph for Items Retrieved Knowledge Sub-graphs ... ... Semantic Information node attributes edge attributes Re-ranked Knowledge Sub-graphs War (tag) English Bomb (actor) Cartoon (genre) perform_in perform_in is contain contain show is Figure 2: The overview of the K-RagRec. It contains five key components: Hop-Field Knowledge Sub-graphs for Semantic Indexing, Popularity Selective Retrieval Policy, Knowledge Sub-graphs Retrieval, Knowledge Sub-graphs Re-Ranking, and Knowledge-augmented Recommendation. trieved from user ui’s historical interactions V ui will be used to form a knowledge sub-graph set G. 3.6 Knowledge Sub-graphs Re-Ranking To refine the quality of retrieval for enhancing rec- ommendation performance, the next crucial step is knowledge sub-graphs re-ranking. Feeding all re- trieved knowledge sub-graphs g′ ∈ G directly into LLM can lead to information overload if the userui has a long historical interaction list towards items. Therefore, we execute re-ranking to shorten the re- trieved knowledge sub-graphs and ensure the most relevant knowledge sub-graphs are prioritized at the top of the prompt. Specifically, we adopt the recom- mendation prompt as a query for re-ranking, which consists of task descriptions and users’ historical items. For example, this recommendation prompt can be "What is the top recommended movie for the user who watched {Matrix, ..., Iron Man}?" . For consistency, we adopt the same PLM to capture the semantic information of the above prompt as p, and re-rank the knowledge sub-graphs in G to obtain a Top-N knowledge sub-graphs set ˆG: ˆG = argtopNg′∗∈G sim p, zg′∗  . (6) 3.7 Knowledge-augmented Recommendation To facilitate the LLM’s better understanding of the structure of retrieved knowledge sub-graphs and to avoid long contexts, we further integrate another GNN encoder GNNEncoding ϕ2 with parameter ϕ2 to enhance the representation learning of structural information: h ˆg∗ = GNNEncoding ϕ2 ({ ˆg∗ : ˆg∗ ∈ ˆG}). (7) An MLP projector MLPθ with parameter θ is fur- ther introduced to shift to mapping all sub-graphs embedding in ˆG into the LLM embedding space: ˆh ˆG = MLPθ([h ˆg1; ...; h ˆgN ]), (8) where [.; .] represents the concatenation operation. The extracted knowledge sub-graphs embedding ˆh ˆG as the soft prompt is then appended before the input token embedding in LLM. 3.8 Optimization for K-RagRec The training process can be broadly considered as soft prompt tuning, where the retrieved knowledge sub-graphs are a series of soft graph prompts. For- mally, the generation process can be expressed as follows: pδ,θ,ϕ1,ϕ2 (Y | ˆG, xq) = rY k=1 pδ,θ,ϕ1,ϕ2 (yk | y<k, ˆh ˆG, xq). (9) Therefore, instead of fine-tuning the LLM model extensively, we only learn parameters of two GNNs (i.e., GNNIndexing ϕ1 , GNNEncoding ϕ2 ) and projec- tor MLPθ, while parameters δ of LLM backbone are frozen. We update the parameters ϕ1, ϕ2 and θ through the Cross-Entropy Loss L(Y, A), where Y is the ground-truth and A is LLM’s prediction. 4 Experiment In this section, we evaluate the effectiveness of our proposed framework through comprehensive exper- iments. First, we present the experimental settings, including details about the datasets, compared base- lines, evaluation metrics, and the parameter config- urations. Then, we report the main experimental results, highlighting the performance of the pro- posed framework compared with various baseline methods. Finally, we analyze the contributions of individual model components and the impact of parameters used in our framework. We also assess the generalizability of K-RagRec in the zero-shot setting. We present the generalizability study in Appendix A.7. 4.1 Experimental Settings 4.1.1 Datasets To evaluate the performance of our K-RagRec framework, we adopt three real-world datasets. MovieLens-1M1 is a dataset containing approx- imately one million movie ratings and textual de- scriptions of movies (i.e., “title”). MovieLens- 20M2 is a large-scale movie ratings dataset encom- passing over 20 million ratings from more than 138,000 users on 27,000 movies. Amazon Book3 is a book recommendation dataset that records more than 10 million user ratings of books and the titles of the books. In addition, we adopt the popular knowledge graph Freebase4 and filter out the triples related to the three datasets to recon- struct the KG. The statistics of these three datasets and KG are presented in Table 3. 4.1.2 Baselines In the realm of LLM-based recommendation re- search, our work pioneers the investigation of re- trieving knowledge from KGs to enhance the rec- ommendation capabilities of LLMs. Therefore, to evaluate the effectiveness, we compare our pro- posed framework with a series of meticulously crafted KG RAG-enhanced LLM recommendation baselines. We first include two typical inference- only methods Retrieve-Rewrite-Answer (Wu et al., 2023b) (KG-Text) and KAPING (Baek et al., 2023), where the former retrieves sub-graphs and textu- alizes them, and the latter retrieves triples. We exclude some knowledge reasoning path-based ap- proaches (Luo et al., 2023), as it is difficult to re- trieve faithful knowledge reasoning paths solely from the user’s interaction items. Next, we com- pare K-RagRec with various prompt-tuning ap- 1https://grouplens.org/datasets/movielens/1m/ 2https://grouplens.org/datasets/movielens/20m/ 3https://jmcauley.ucsd.edu/data/amazon/ 4https://developers.google.com/freebase proaches augmented by retrieval, including Prompt Tuning with KG-Text (PT w/ KG-Text), GraphTo- ken (Perozzi et al., 2024) with retrieval (GraphTo- ken w/ RAG) as well as G-retriever (He et al., 2024). Additionally, we evaluate our method against Lora Fine-tuning with retrieval (Lora w/ KG-Text) (Hu et al., 2021). 4.1.3 Evaluation Metrics To evaluate the effectiveness of our K-RagRec framework, we employ two widely used evalua- tion metrics: Accuracy (ACC), and Recall@k (He et al., 2020). We present results for k equal to 3, and 5. Inspired by recent studies (Zhang et al., 2024; Hou et al., 2022), we adopt the leave-one- out strategy for evaluation. Specifically, for each user, we select the last item that the user inter- acted with as the target item and the 10 interaction items prior to the target item as the historical in- teractions. Then, we leverage LLM to predict the user’s preferred item from a pool of 20 candidate items (M = 20), which contains one target item with nineteen randomly sampled items. For trained models (including prompt tuning and fine-tuning), we compute Recall@k by extracting the probability assigned to each item and evaluating the model’s ability to rank the target item within the top-k pre- dictions. In addition, we also conduct comparison experiments with 10 candidate items (M = 10) as shown in Appendix A.5. 4.1.4 Parameter Settings We implement the framework on the basis of Py- Torch and conduct the experiments on 2 NVIDIA A6000-48GB GPUs. We adopt the SentenceBert to encode entities, relations, and query attributes. We use the 3 layers Graph Transformer as the GNNIndexing and GNNEncoding for MovieLens-1M and 4 layers for MovieLens-20M and Amazon Book. The layer dimension is set to 1024, and the head number is set to 4. The popularity selec- tive retrieval policy threshold p is set to 50%. For each item that needs to be retrieved, we retrieve the top-3 most similar sub-graphs. The re-ranking knowledge sub-graph number N is set to 5. More experiment details are shown in Appendix A.1. We also present several prompt examples in Ap- pendix A.12. 4.2 Overall Performance Comparison We compare the recommendation performance of K-RagRec with various baselines on three open- Table 1: Performance comparison of different KG RAG-enhanced LLM recommendations. The best performance and the second-best performance are marked in red and blue, respectively. ACC and R@k denote Accuracy and Recall@k, respectively. Models Methods MovieLens-1M MovieLens-20M Amazon Book ACC R@3 R@5 ACC R@3 R@5 ACC R@3 R@5 LLama-2 Inference-only KG-Text (Wu et al., 2023b)0.076 - - 0.052 - - 0.058 - -KAPING (Baek et al., 2023)0.079 - - 0.069 - - 0.063 - - Frozen LLM w/ PT PT w/ KG-Text 0.0780.1910.3080.0510.1520.2500.0740.1650.245GraphToken w/ RAG (Perozzi et al., 2024)0.2680.4210.4660.1860.4330.5760.3260.5150.624G-retriever (He et al., 2024)0.2740.5320.6500.3420.6190.7390.2750.4870.612K-RagRec 0.4350.7250.8310.6000.8500.9130.5080.6900.780 Improvement 58.6%33.0%27.8%75.4%37.3%23.5%55.8%34.0%25.0 % Fine-tuning Lora w/ KG-Text 0.4020.7180.8330.6090.8480.9050.4460.6480.758Lora w/ K-RagRec 0.4660.7700.8630.6370.8720.9270.5160.7200.799 Improvement 15.9%7.2% 3.6% 4.5% 2.7% 2.4% 15.7%11.1%5.4% LLama-3 Inference-only KG-Text (Wu et al., 2023b)0.095 - - 0.060 - - 0.054 - -KAPING (Baek et al., 2023)0.084 - - 0.069 - - 0.062 - - Frozen LLM w/ PT PT w/ KG-Text 0.1340.2940.4330.0940.2050.2960.0830.2070.314GraphToken w/ RAG (Perozzi et al., 2024)0.3550.6220.7370.4730.7190.8050.4280.5670.661G-retriever (He et al., 2024)0.3520.6320.7460.5020.7360.7960.4170.5840.682K-RagRec 0.4720.7040.7650.6340.7790.8180.5140.6620.723 Improvement 32.9%11.4%2.5% 26.3%5.8% 1.6% 20.0%13.4%6.0% Fine-tuning Lora w/ KG-Text 0.4490.6940.7500.6480.7570.7900.4900.6380.698Lora w/ K-RagRec 0.4980.7120.7710.6740.7860.8170.5460.6720.733 Improvement 10.9%2.6% 2.8% 4.0% 3.8% 3.4% 11.4%5.3% 5.0% QWEN2 Inference-only KG-Text (Wu et al., 2023b)0.160 - - 0.174 - - 0.194 - -KAPING (Baek et al., 2023)0.196 - - 0.208 - - 0.220 - - Frozen LLM w/ PT PT w/ KG-Text 0.1900.3710.4990.2590.3970.4940.3030.4510.553GraphToken w/ RAG (Perozzi et al., 2024)0.2590.4870.6080.3700.5500.6320.3650.5680.658G-retriever (He et al., 2024)0.3040.5510.6440.3890.6060.6850.3550.5520.658K-RagRec 0.4160.7120.8290.5860.8420.9040.5020.6860.767 Improvement 36.8%29.2%28.4%50.6%38.9%32.0%37.5%20.8%16.6 % Fine-tuning Lora w/ KG-Text 0.4000.7010.8150.6010.8420.9060.4780.6670.751Lora w/ K-RagRec 0.4660.7630.8600.6310.8680.9280.5100.7040.780 Improvement 16.5%8.8% 5.5% 5.0% 3.1 %2.4% 6.7% 5.5% 3.9% source backbone LLMs: LLama-2-7b (Touvron et al., 2023), LLama-3-8b (Dubey et al., 2024), and QWEN2-7b (Yang et al., 2024). We present the results in Table 1. From the comparison, we have the following main observations: • Naively retrieve KG and augment LLM with text methods (i.e., KG-Text and KAPING), have limited recommendation accuracy on the MovieLens-1M and MovieLens-20M and Ama- zon Book datasets. • Compared to other prompt tuning RAG methods, K-RagRec with LLama-2-7B as the backbone LLM leads to an average of 41.6% improvement over the sub-optimal baseline across all datasets. With LLama-3-8B and QWEN2-7B as the back- bone LLM, K-RagRec also brought an average of 13% to 32% improvement, highlighting the effec- tiveness of our proposed method in augmenting LLMs’ recommendation performance. • Compared to the LoRA fine-tuning with the naive RAG approach, K-RagRec with prompt tuning achieves close to or better performance in most settings. Notably, K-RagRec achieves the best performance when fine-tuned with LoRA. 4.3 Ablation Study To evaluate the impact of each component in our proposed framework, we conduct the ablation study to compare the K-RagRec with four ablated vari- ants on MovieLens and Amazon Book datasets, us- ing LLama-2-7B as the backbone LLM. Details of each ablation variant are provided in Appendix A.6. The results are illustrated in Figure 3. Observing the experiment results, we find that eliminating any component of the framework leads to a decrease in the overall performance of the recommendations, demonstrating the effectiveness of each module. Secondly, removing the GNN Encoder leads to a 37% decrease and a 45.9% decrease in the ac- curacy of the model on MovieLens and Amazon Book datasets, respectively, highlighting the signif- icance of employing GNN to encode the structure of knowledge sub-graphs. Refer to Appendix A.6 for more details. 4.4 Efficiency Evaluation In this sub-section, we evaluate the inference effi- ciency of our proposed K-RagRec framework com- -Indexing -Popularity-Re-ranking -EncodingK-RagRec 0.20 0.25 0.30 0.35 0.40 0.45 0.50ACCURACY (a) ML1M ACC -Indexing -Popularity-Re-ranking -EncodingK-RagRec 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80RECALL@3 (b) ML1M R@3 -Indexing -Popularity-Re-ranking -EncodingK-RagRec 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90RECALL@5 (c) ML1M R@5 -Indexing -Popularity -Re-ranking -EncodingK-RagRec 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55ACCURACY (d) BOOK ACC -Indexing -Popularity-Re-ranking -EncodingK-RagRec 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75RECALL@3 (e) BOOK R@3 -Indexing -Popularity-Re-ranking -EncodingK-RagRec 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85RECALL@5 (f) BOOK R@5 Figure 3: Comparison among K-RagRec and its four ablated variants on MovieLens-1M and Amazon Book datasets and LLama-2-7b across metrics Accuracy, Re- call@3 and Recall@5. Table 2: Comparison of the inference efficiency on the MovieLens-1M dataset and LLama-2-7b in seconds (s). ACC denote Accuracy. Methods ACC Time (s) w/o RAG - 0.92 KG-Text 0.076 2.19 KAPING 0.079 6.47 GraphToken w/ RAG0.268 3.14 G-retriever 0.274 5.86 K-RagRec 0.429 1.06 pared with baselines on the MovieLens-1M dataset and LLama-2-7b. We record the time cost for one inference utilizing two NVIDIA A6000-48G GPUs. The time cost for a single inference is reported in Table 2. By observing the experimental results, we notice that various KG RAG approaches signifi- cantly increase the inference time, which is due to the large scale of the KG. In contrast, K-RagRec achieves the best computational efficiency com- pared to various KG RAG methods and is only about 0.1s slower than direct inference without re- trieval. These findings highlight the efficiency of K-RagRec and validate the effectiveness of our popularity selective retrieval policy. 4.5 Parameter Analysis In this section, we evaluate the impact of three main hyper parameters of K-RagRec, namely popular- ity selective retrieval policy threshold p, retrieved knowledge sub-graph numbers K, and re-ranking knowledge sub-graph numbers N. In addition, we analyze the impact of various GNN encoder vari- ants and different GNN layer numbers for the pro- posed framework in Appendix A.10 and A.11. 1) Impact of popularity selective retrieval pol- icy threshold p: To understand how the popular- ity selective retrieval policy threshold p affects K- RagRec, we conduct experiments on MovieLens- 1M and LLama-2-7b across two metrics. Results are shown in Figure 4. As the threshold p in- creases, the recommendation performance initially improves and then decreases. When the thresh- old p is set to a small value, only a few items are augmented. This leads to insufficient retrieval and poor recommendation accuracy. When p is set to a larger value, more items are retrieved for augmen- tation. However, due to the re-ranking sub-graph numbers N being fixed, some retrieved cold-start item knowledge sub-graphs are discarded or ranked at the back of the list, resulting in sub-optimal rec- ommendation performance. On the other hand, as observed in Figure 4 (c), the inference time in- creases almost linearly with threshold p. Therefore, selecting an appropriate threshold p is crucial to balance the performance and inference time. 2) Impact of retrieved knowledge sub-graph numbers K and re-ranking sub-graph numbers N: In this part, we analyze the impact of two key hyper parameters, which are retrieved knowledge sub-graph numbers K and re-ranking sub-graph numbers N. First, to measure the impact of K, we perform experiments on the MovieLens dataset and fix p = 50%, N = 5. As shown in Figure 5, some relevant knowledge sub-graphs may be overlooked when K = 1. On the other hand, larger values ofK can introduce irrelevant information. Therefore, we set K equal to 3 in our experiments. Next, we eval- uate the effect ofN by fixing p = 50% and K = 3, and present the results in Figure 6. We observe that setting N to between 5 and 7 results in improved performance on the Amazon Book dataset. In gen- eral, it is important to carefully choose K and N based on the scale of the dataset and the KG. 5 Conclusion In this paper, we propose a novel framework K- RagRec to augment the recommendation capabil- ity of LLMs by retrieving reliable and up-to-date knowledge from KGs. Specifically, we first intro- duce a GNN and PLM to perform semantic index- ing of KGs, enabling both coarse and fine-grained retrieval for KGs. To further improve retrieval effi- ciency, we introduce a popularity selective retrieval policy that determines whether an item needs to be retrieved based on its popularity. Notably, K- RagRec performs more expressive graph encoding of the retrieved knowledge sub-graphs, facilitat- ing the LLM to effectively leverage the structure information and avoid long context input. Exten- sive experiments conducted on three real-world datasets demonstrate the effectiveness of our pro- posed framework. 6 Limitations To the best of our knowledge, this work is a pioneer- ing study in investigating knowledge-graph RAG for LLM-based recommendations. Therefore, we realise that this work still has the following three main limitations that can be improved in the future research: • Firstly, due to the GPU resource constraints, we were only able to evaluate our framework on 7b and 8b models. Therefore, in future work, we plan to extend our method to larger models to fully assess its effectiveness and scalability. • Additionally, we only utilize Freebase as the ex- ternal KG as it is most commonly used for recom- mendation tasks. Thus we also aim to adopt other KGs, such as YAGO, DBpedia, and Wikipedia, to better understand how different knowledge sources impact the performance of the proposed method. • Lastly, designing an intelligent selective retrieval policy for LLM-based recommender systems is an important and challenging task. In this work, we propose to leverage popularity to determine which items to retrieve to improve retrieval effi- ciency. In the future, we will investigate more flexible mechanisms (e.g., reinforcement learn- ing) to dynamically update policies according to changes in user interest. 7 Acknowledgements The research described in this paper has been partly supported by General Research Funds from the Hong Kong Research Grants Council (project no. PolyU 15207322, 15200023, 15206024, and 15224524), internal research funds from The Hong Kong Polytechnic University (project no. P0042693, P0048625, P0051361, P0052406, and P0052986). References Himan Abdollahpouri, Robin Burke, and Bamshad Mobasher. 2017. Controlling popularity bias in learning-to-rank recommendation. In Proceedings of the eleventh ACM conference on recommender systems, pages 42–46. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774. Yihao Ang, Yifan Bao, Qiang Huang, Anthony KH Tung, and Zhiyong Huang. 2024. Tsgassist: An inter- active assistant harnessing llms and rag for time se- ries generation recommendations and benchmarking. Proceedings of the VLDB Endowment, 17(12):4309– 4312. Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023. Self-rag: Learning to retrieve, generate, and critique through self-reflection. arXiv preprint arXiv:2310.11511. Jinheon Baek, Alham Fikri Aji, and Amir Saffari. 2023. Knowledge-augmented language model prompting for zero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136. Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023. Tallrec: An ef- fective and efficient tuning framework to align large language model with recommendation. In Proceed- ings of the 17th ACM Conference on Recommender Systems, pages 1007–1014. Sebastian Borgeaud, Arthur Mensch, Jordan Hoff- mann, Trevor Cai, Eliza Rutherford, Katie Milli- can, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022. Improving language models by retrieving from tril- lions of tokens. In International conference on ma- chine learning, pages 2206–2240. PMLR. Òscar Celma and Perfecto Herrera. 2008. A new ap- proach to evaluating novel recommendations. In Proceedings of the 2008 ACM conference on Rec- ommender systems, pages 179–186. Dario Di Palma. 2023. Retrieval-augmented recom- mender system: Enhancing recommender systems with large language models. In Proceedings of the 17th ACM Conference on Recommender Systems , pages 1369–1373. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. 2024a. A survey on rag meeting llms: Towards retrieval-augmented large language models. In Pro- ceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 6491– 6501. Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph neural networks for social recommendation. In The world wide web conference, pages 417–426. Wenqi Fan, Shijie Wang, Jiani Huang, Zhikai Chen, Yu Song, Wenzhuo Tang, Haitao Mao, Hui Liu, Xi- aorui Liu, Dawei Yin, et al. 2024b. Graph machine learning in the era of large language models (llms). arXiv preprint arXiv:2404.14928. Bahare Fatemi, Jonathan Halcrow, and Bryan Perozzi. 2023. Talk like a graph: Encoding graphs for large language models. arXiv preprint arXiv:2310.04560. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997. Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (rlp): A unified pretrain, person- alized prompt & predict paradigm (p5). In Proceed- ings of the 16th ACM Conference on Recommender Systems, pages 299–315. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu- pat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training. In International confer- ence on machine learning, pages 3929–3938. PMLR. Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs.Ad- vances in neural information processing systems, 30. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yong- dong Zhang, and Meng Wang. 2020. Lightgcn: Sim- plifying and powering graph convolution network for recommendation. In Proceedings of the 43rd Inter- national ACM SIGIR conference on research and de- velopment in Information Retrieval, pages 639–648. Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V Chawla, Thomas Laurent, Yann LeCun, Xavier Bresson, and Bryan Hooi. 2024. G-retriever: Retrieval-augmented generation for textual graph understanding and ques- tion answering. arXiv preprint arXiv:2402.07630. Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards universal sequence representation learning for recom- mender systems. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 585–593. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adap- tation of large language models. arXiv preprint arXiv:2106.09685. Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023. Ac- tive retrieval augmented generation. arXiv preprint arXiv:2305.06983. Vladimir Karpukhin, Barlas O˘guz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906. Krishnaram Kenthapadi, Benjamin Le, and Ganesh Venkataraman. 2017. Personalized job recommen- dation system at linkedin: Practical challenges and lessons learned. In Proceedings of the eleventh ACM conference on recommender systems, pages 346–347. Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. 2019. Generalization through memorization: Nearest neighbor language models. arXiv preprint arXiv:1911.00172. Thomas N Kipf and Max Welling. 2016. Semi- supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907. Tiziano Labruna, Jon Ander Campos, and Gorka Azkune. 2024. When to retrieve: Teaching llms to uti- lize information retrieval effectively. arXiv preprint arXiv:2404.19705. Jiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Yong Wei, Hui Liu, Jiliang Tang, and Qing Li. 2024. Empower- ing molecule discovery for molecule-caption transla- tion with large language models: A chatgpt perspec- tive. IEEE Transactions on Knowledge and Data Engineering. Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. 2023. Reasoning on graphs: Faithful and interpretable large language model reasoning. arXiv preprint arXiv:2310.01061. Costas Mavromatis and George Karypis. 2024. Gnn- rag: Graph neural retrieval for large language model reasoning. arXiv preprint arXiv:2405.20139. Sewon Min, Julian Michael, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2020. Ambigqa: Answering ambiguous open-domain questions. arXiv preprint arXiv:2004.10645. Bryan Perozzi, Bahare Fatemi, Dustin Zelle, Anton Tsit- sulin, Mehran Kazemi, Rami Al-Rfou, and Jonathan Halcrow. 2024. Let your graph do the talking: En- coding structured data for llms. arXiv preprint arXiv:2402.05862. Haohao Qu, Wenqi Fan, Zihuai Zhao, and Qing Li. 2024. Tokenrec: Learning to tokenize id for llm- based generative recommendation. arXiv preprint arXiv:2406.10450. Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented lan- guage models. Transactions of the Association for Computational Linguistics, 11:1316–1331. N Reimers. 2019. Sentence-bert: Sentence embed- dings using siamese bert-networks. arXiv preprint arXiv:1908.10084. Priyanka Sen, Sandeep Mavadia, and Amir Saffari. 2023. Knowledge graph-augmented language models for complex question answering. In Proceedings of the 1st Workshop on Natural Language Reasoning and Structured Explanations (NLRSE), pages 1–8. Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjin Wang, and Yu Sun. 2020. Masked label prediction: Unified message passing model for semi-supervised classification. arXiv preprint arXiv:2009.03509. Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung Shum, and Jian Guo. 2023. Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph. arXiv preprint arXiv:2307.07697. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and effi- cient foundation language models. arXiv preprint arXiv:2302.13971. Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, et al. 2017. Graph attention networks. stat, 1050(20):10– 48550. Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and Zhang Xiong. 2023. Knowledge-driven cot: Exploring faith- ful reasoning in llms for knowledge-intensive ques- tion answering. arXiv preprint arXiv:2308.13259. Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2024. Llmrec: Large language models with graph augmentation for recommendation. In Pro- ceedings of the 17th ACM International Conference on Web Search and Data Mining, pages 806–815. Junda Wu, Cheng-Chun Chang, Tong Yu, Zhankui He, Jianing Wang, Yupeng Hou, and Julian McAuley. 2024. Coral: Collaborative retrieval-augmented large language models improve long-tail recommendation. In Proceedings of the 30th ACM SIGKDD Confer- ence on Knowledge Discovery and Data Mining , pages 3391–3401. Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, and Tat-Seng Chua. 2023a. Next-gpt: Any-to-any multi- modal llm. arXiv preprint arXiv:2309.05519. Yike Wu, Nan Hu, Sheng Bi, Guilin Qi, Jie Ren, An- huan Xie, and Wei Song. 2023b. Retrieve-rewrite- answer: A kg-to-text enhanced llms framework for knowledge graph question answering. arXiv preprint arXiv:2309.11206. Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, and Zhen-Hua Ling. 2024. Corrective retrieval augmented generation. arXiv preprint arXiv:2401.15884. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2 technical report. arXiv preprint arXiv:2407.10671. Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2024. Agentcf: Collaborative learning with autonomous language agents for recommender systems. In Proceedings of the ACM on Web Confer- ence 2024, pages 3679–3689. Yang Zhang, Fuli Feng, Jizhi Zhang, Keqin Bao, Qi- fan Wang, and Xiangnan He. 2023. Collm: In- tegrating collaborative embeddings into large lan- guage models for recommendation. arXiv preprint arXiv:2310.19488. Jujia Zhao, Wenjie Wang, Xinyu Lin, Leigang Qu, Jizhi Zhang, and Tat-Seng Chua. 2023. Popularity-aware distributionally robust optimization for recommenda- tion system. In Proceedings of the 32nd ACM Inter- national Conference on Information and Knowledge Management, pages 4967–4973. Zihuai Zhao, Wenqi Fan, Jiatong Li, Yunqing Liu, Xi- aowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xi- angyu Zhao, Jiliang Tang, et al. 2024. Recommender systems in the era of large language models (llms). IEEE Transactions on Knowledge and Data Engi- neering. A Appendix A.1 Implementation Details The hyper parameters used for K-RagRec and their corresponding values are shown in Table 4. The first part provides the general training setting for K-RagRec. The second part presents the details of (GNNIndexing, GNNEncoding). Then we list the Lora and acceleration settings. Lastly, we provide the hyper parameters for retrieval, including candi- date item number M, popularity selective retrieval policy threshold p, retrieve knowledge sub-graphs numbers K, and re-ranking knowledge sub-graphs numbers N. If not specified, we run all methods three times with different random seeds and report the averaged results. Table 3: Basic statistics of three datasets and the KG. "Items in KG" indicates the number of items that ap- peared in both the KG and the dataset. DatasetsMovieLens-1MMovieLens-20MAmazon Book User 6,038 138,287 6,106,019Item 3,533 20,720 1,891,460Interaction575,281 9,995,410 13,886,788Items in KG3,498 20,139 91,700 Entitys 250,631 1,278,544 186,954Relations 264 436 16KG triples 348,979 1,827,361 259,861 A.2 Graph Neural Networks GNNs are a critical technique in graph machine learning and are widely employed in various graph tasks. By iteratively updating node representations through aggregating information from neighboring nodes, GNNs effectively capture the underlying topology and relational structure of graphs. For- mally, a typical GNN operation can be formulated as follows: x(l+1) j = x(l) j ⊕ AGG(l+1) n x(l) i | i ∈ N xj o , (10) where x(l+1) j express node j’s feature on the l-th layer, and N (xj) is the set of neighbours of node j. AGG is a aggregation function to aggregates neighbors’ features, and ⊕ combines neighbors’ information with the node itself. A.3 More Related Work The remarkable breakthroughs in LLMs have led to their widespread adoption across various fields, particularly in the recommendations. Given power- ful reasoning and generalization capabilities, many studies have actively attempted to harness the power of the LLM to enhance recommender sys- tems (Geng et al., 2022; Bao et al., 2023; Qu Table 4: Statistics of Hyper Parameters. Item Value batch size 5 epochs 3 grad steps 2 learning rate 1e-5 Indexing layer numbers 4 Indexing hidden dimension1024 Encoding layer numbers 4 Encoding hidden dimension1024 Encoding head numbers 4 lora_r 8 lora_alpha 16 lora_dropout 0.1 int8 True fp16 True candidate item numbers 20 thresholdp 50% top-K 3 top-N 5 et al., 2024; Wei et al., 2024; Zhang et al., 2023). For example, P5 (Geng et al., 2022) proposes an LLM-based recommendation model by unifying pre-training, prompting, and prediction for various recommendation tasks, such as sequential recom- mendation and rating predictions. Furthermore, Tallrec (Bao et al., 2023) fine-tunes LLM (i.e., LLaMA-7B) to align with recommendation data for sequential recommendations. To further capture higher-order collaborative knowledge and enhance the model’s ability to generalize users and items, TokenRec (Qu et al., 2024) proposes a masked vector-quantized tokenizer to tokenize users and items in LLM-based recommendations. Despite their effectiveness, these models often face chal- lenges, such as hallucinations and the lack of up- to-date knowledge. While fine-tuning can partially mitigate these issues, it is resource-costly and time- consuming due to the massive parameters of LLMs. To overcome these challenges, we propose a knowl- edge retrieval augmented recommendation frame- work that leverages external KGs to provide reli- able and up-to-date knowledge instead of costly fine-tuning. A.4 Comparison with Existing Methods Existing LLM-based recommender systems usually require frequent fine-tuning on specific datasets to address the lack of knowledge and hallucinations, which is time-consuming and costly. To solve these challenges and avoid costly fine-tuning, our work is the first to augment the recommendation per- formance of LLMs by retrieving structured data (i.e., knowledge graph). Specifically, our approach differs from existing work in the following ways: • K-RagRec introduces an indexing GNN to ef- ficiently retrieve structured data to enhance the recommendation capability of LLMs. Al- though some GraphRAG approaches also intro- duce GNNs to capture higher-order neighbour- hood information, they only apply the last layer of the GNN representation, leading to coarse re- trieval (He et al., 2024; Mavromatis and Karypis, 2024). In contrast, our approach leverages the representation of each GNN layer to retrieve nu- anced knowledge of both coarse and fine-grained graph structures from KG, achieving a more com- prehensive and precise retrieval. • In the recommendation domain that pursues in- ference speed, excessive retrieval time can se- riously degrade the user experience resulting in user churn. Although many studies have explored selective retrieval for RAGs (Yan et al., 2024; Jiang et al., 2023), it is still an open question to determine whether an item needs to be retrieved and to reduce the retrieval time in the recommen- dation domain. We propose to use popularity to decide whether an item needs to be retrieved based on power law distribution, which greatly reduces the retrieval time. Table 2 shows that K- RagRec achieves inference times close to direct inference while maintaining high recommenda- tion accuracy. • Typical RAG methods usually incorporate the re- trieved content into the prompt as text (Wu et al., 2023b; Baek et al., 2023). However, vanilla RAG methods rely on documents and paragraphs often introduce unnecessary noise and even harmful disturbance, which can negatively impact the ac- curacy and reliability of recommendations. In addition, the structural relationships between en- tities are overlooked in typical RAG, resulting in the sub-optimal reasoning capability of LLM- based recommender systems. We propose to incorporate the retrieved knowledge subgraphs (Knowledge-GraphRAG) into the query as a graph prompt, which facilitates LLMs to better understand the retrieved knowledge subgraphs and avoids long contexts. A.5 Comparison with 10 Candidate Items In this section, we conduct additional experiments to evaluate the effectiveness of K-RagRec with a Table 5: Performance comparison of different KG RAG- enhanced LLM recommendations with candidate item numbers M = 10 on the MovieLens and Amazon Book dataset and LLama-2-7b across two metrics. The best performances are labeled in bold. ACC and R@3 denote Accuracy and Recall@3, respectively. Methods MovieLens-1MAmazon Book ACC R@3 ACC R@3 KG-Text 0.185 - 0.142 - KAPING 0.165 - 0.119 - PT w/ KG-Text0.159 0.493 0.1230.384 GraphToken w/ RAG0.512 0.753 0.4440.682 G-retriever 0.469 0.721 0.3670.610 K-RagRec 0.568 0.779 0.6060.770 candidate item number M = 10. In this setting, we randomly select nine negative samples with the target item. The results are presented in Table 5. We exclude the results of some backbone LLM models (e.g., LLama-3 and QWEN2), as similar observations as Table 1 can be found. Observing the experimental results, we can note that our pro- posed K-RagRec method consistently outperforms all baseline methods on MovieLens and Amazon Book datasets, further highlighting the effective- ness of our framework. A.6 Ablation Study Setting To assess the impact of each module in K- RagRec, we compare the framework with four ab- lated variants: K-RagRec (-Indexing), K-RagRec (-Popularity), K-RagRec ( -Re-ranking), and K- RagRec (-Encoding). (1) K-RagRec ( -Indexing) eliminates the GNNIndexing and stores semantic information of PLM in the knowledge vector database. For the retrieved nodes, we extract their second-order sub-graphs as the retrieved knowl- edge sub-graphs. (2) K-RagRec (-Popularity) does not apply the popularity selective retrieval policy and retrieves all items from the user’s historical interactions. (3) ( -Re-ranking) removes the re- ranking module and inputs the knowledge sub- graphs directly. (4) K-RagRec ( -Encoding) re- moves the GNNEncoding and replaces it with a train- able soft prompt. The retrieved knowledge sub- graphs will be added to the prompt as triples (e.g., {Moonraker, film writer film, Christopher Wood (writer)}). A.7 Generalization Study To evaluate the generalization capability of our proposed framework in the zero-shot setting, we trained a version of the model on the MovieLens- Table 6: The generalization results for our K-RagRec model in a zero-shot setting. In this setting, our models are trained on MovieLens-1M dataset and evaluated on MovieLens-20M and Amazon Book datasets. ACC and R@k denote Accuracy and Recall@k, respectively. Models Methods MovieLens-20MAmazon Book ACCR@3R@5ACCR@3R@5 LLama2K-RagRec0.5390.7400.7950.3900.5810.671Lora w/K-RagRec0.5390.7830.8630.4050.5800.796 LLama3K-RagRec0.5970.7970.8390.4280.6280.706Lora w/K-RagRec0.6110.7750.8140.4240.6220.732 QWEN K-RagRec0.5070.7690.8610.4180.6120.687Lora w/K-RagRec0.5450.8140.8970.4410.6230.706 Table 7: Quantitative comparison of hallucination on the MovieLens-1M dataset. ∆ denotes the reduction in hallucinations for K-RagRec compared to Direct Infer- ence. Models Direct InferenceK-RagRec ∆ LLama-2 39.1% 2.7% 93.1% QWEN2 4.7% 0.9% 80.9% 1M dataset and assessed it on the MovieLens-20M and Amazon Book datasets. The experiment re- sults are shown in Table 6. We note that although the K-RagRec performance in the zero-shot set- ting is slightly degraded when compared to the well-trained model in Table 1, it still demonstrates 21.6% improvement over SOTA baselines on the MovieLens-20M dataset. Furthermore, despite the differences between the book recommendation and movie recommendation tasks, the model trained on MovieLens-1M delivers about 8.7% improvement in the zero-shot setting compared to prompt-tuned baselines on the Amazon Book dataset. The experi- mental results demonstrate that K-RagRec exhibits strong generalization capabilities and is adaptable across different domains. A.8 Study of Hallucination In this section, we present a qualitative analysis of hallucinations in the LLama-2-7b and QWEN2 models on the MovieLens dataset. Specifically, we include a few fictional movies in the candi- date items to observe the probability of the fic- tional movie being recommended. We compare direct recommendations and recommendations aug- mented with K-RagRec, and the results are shown in Table 7. We note that K-RagRec significantly reduced hallucinations by 93.1% compared to di- rect inference on LLama-2. In contrast to LLama- 2, QWEN2 rarely recommends fictional movies. Nevertheless, K-RagRec reduced hallucinations by Table 8: Performance comparison of different KG RAG- enhanced LLM recommendation methods on the cold- start dataset and QWEN2 across three metrics. The best performances are labeled in bold. ACC and R@k denote Accuracy and Recall@k, respectively. Methods ACC R@3 R@5 PT w/ KG-Text 0.106 0.239 0.395 GraphToken w/ RAG0.258 0.473 0.620 G-retriever 0.185 0.384 0.488 K-RagRec 0.406 0.705 0.834 Table 9: Comparison of different GNN Encoders on the MovieLens-1M dataset and LLama-2-7b across three metrics. We use bold fonts to label the best performance. ACC and R@k denote Accuracy and Recall@k, respec- tively. GNN Types ACC R@3 R@5 GCN (Kipf and Welling, 2016)0.397 0.704 0.809 GAT (Velickovic et al., 2017)0.420 0.693 0.804 Graph Transformer (Shi et al., 2020)0.429 0.711 0.779 GraphSAGE (Hamilton et al., 2017)0.418 0.699 0.823 80.9%, demonstrating the effectiveness of our ap- proach in addressing hallucinations. A.9 Study of Cold Start Recommendation The cold start problem is an important issue in most recommendation research. To comprehensively evaluate our approach, we particularly design a case study to evaluate the model’s recommendation performance under the cold-start setting. Specif- ically, we construct a separate cold-start dataset based on the MovieLens dataset that only contains these identified cold-start items as target items. We compare K-RagRec with three KG RAG-enhanced LLM recommendation methods, and the experi- ment results are shown in Table 8. The results demonstrate that our proposed K-RagRec still has satisfactory performance under the cold-start rec- ommendation scenario, highlighting the effective- ness of our framework in all the cases. A.10 Study of Four GNN Encoders To further understand the generality of our pro- posed approach, we conduct a comparative study of four variants applying different GNN encoders. Specifically, we compare GCN (Kipf and Welling, 2016), GAT (Velickovic et al., 2017), Graph Trans- former (Shi et al., 2020), and GraphSAGE (Hamil- ton et al., 2017) as four K-RagRec variants of GNN encoder. Specifically, Graph Convolutional Net- Table 10: Comparison of different GNN layers on the Amazon Book dataset and LLama-2-7b across three metrics. ACC and R@k denote Accuracy and Recall@k, respectively. GNN LayersACC R@3 R@5 3 layers 0.496 0.653 0.736 4 layers 0.506 0.690 0.780 5 layers 0.498 0.656 0.729 work (GCN) (Kipf and Welling, 2016) first intro- duces convolutional operations to graph-structured data. By aggregating features from neighboring nodes, GCN facilitates the learning of rich node rep- resentations. GraphSAGE (Hamilton et al., 2017) learns an aggregation function that samples and combines features from a node’s local neighbor- hood in an inductive setting, enabling the effec- tive use of new nodes. Graph Attention Network (GAT) (Velickovic et al., 2017) further incorporates attention mechanisms, allowing the model to dy- namically assign varying attention to neighboring nodes, thereby enhancing the focus on the most relevant information. Inspired by the success of the transformer, the Graph Transformer (Shi et al., 2020) adapts transformer architectures to graph data, enhancing the modeling of graphs, particu- larly textual graphs. We report the experiment results on the MovieLens-1M dataset and the LLama-2-7b back- bone in Table 9. It is noted that the GCN Encoder variant method performs second-best on the Re- call@5 metric, although it is slightly worse than other GNN encoders on the Accuracy metric. Over- all, four GNN encoder variants exhibit close perfor- mance on the MovieLens dataset, highlighting the generality and robustness of our framework across different GNN encoders. A.11 Study of GNN Layer Numbers In this subsection, we evaluate the impact of the number of GNN layers on model performance. We vary the numbers of the GNN layer numbers in the range of {3, 4, 5} and test on the Amazon Book dataset and LLama-2-7b across three metrics. As observed in Table 10, the model performance first improves and then decreases as the number of GNN layers increases, and the model achieves the best results across the three metrics when setting the number of GNN layers is set to four. Therefore, a smaller number of GNN layers may not have suffi- cient depth to capture the intricate relationships and dependencies in the graph, leading to sub-optimal performance. On the other hand, too many layers can result in indistinguishable node representations. Thus, selecting the optimal number of GNN layers is crucial for effective model training. A.12 Used Prompt In this part, we present the prompts designed for movie recommendations and book recommenda- tions. We show two examples in Table 11, and set the candidate items M equal to 20. For inference, we leverage the model to make the prediction based on the user’s recent watching history and candidate items. 0.0 0.2 0.4 0.6 0.8 1.0 threshold p 0.40 0.41 0.42 0.43 0.44 0.45ACCURACY (a) Accuracy 0.0 0.2 0.4 0.6 0.8 1.0 threshold p 0.70 0.72 0.74 0.76 0.78 0.80RECALL@5 (b) Recall@5 0.0 0.2 0.4 0.6 0.8 1.0 threshold p 0.4 0.6 0.8 1.0 1.2 1.4 1.6Inference Time (s) (c) Inference Time Figure 4: Effect of popularity selective retrieval policy threshold p on MovieLens-1M and LLama-2-7b across metrics Accuracy, Recall@5 and inference time (seconds) for K-RagRec. 0 2 4 6 8 K 0.40 0.42 0.44 0.46 0.48 0.50 0.52ACCURACY (a) Amazon Book: Accuracy 0 2 4 6 8 K 0.56 0.58 0.60 0.62 0.64 0.66 0.68 0.70RECALL@3 (b) Amazon Book: Recall@3 0 2 4 6 8 K 0.60 0.65 0.70 0.75 0.80RECALL@5 (c) Amazon Book: Recall@5 Figure 5: Effect of retrieved knowledge sub-graph numbers K on Amazon Book datasets and LLama-2-7b across metrics Accuracy, Recall@3 and Recall@5 for K-RagRec. 2 4 6 8 10 12 N 0.42 0.44 0.46 0.48 0.50 0.52ACCURACY (a) Amazon Book: Accuracy 2 4 6 8 10 12 N 0.62 0.64 0.66 0.68 0.70RECALL@3 (b) Amazon Book: Recall@3 2 4 6 8 10 12 N 0.70 0.72 0.74 0.76 0.78 0.80RECALL@5 (c) Amazon Book: Recall@5 Figure 6: Effect of re-ranking knowledge sub-graph numbers N on Amazon Book datasets and LLama-2-7b across metrics Accuracy, Recall@3 and Recall@5 for K-RagRec. Table 11: Example of the used prompt for K-RagRec. The user’s recent watching/reading history and candidate items are marked in red and blue, respectively. Datasets Used Prompt Movies Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Instruction: Given the user’s watching history, select a film that is most likely to interest the user from the options. Watching history: {"History of the World: Part I", "Romancing the Stone", "Fast Times at Ridgemont High", "Good Morning, Vietnam", "Working Girl", "Cocoon", "Splash", "Pretty in Pink", "Terms of Endearment", "Bull Durham"}. Options: {A: "Whole Nine Yards", B: "Hearts and Minds", C: "League of Their Own", D: "Raising Arizona", E: "Happy Gilmore", F: "Brokedown Palace", G: "Man Who Knew Too Much", H: "Light of Day", I: "Tin Drum", J: "Blair Witch Project", K: "Red Sorghum", L: "Flintstones in Viva Rock Vegas", M: "Anna, N: Roger & Me" O: "Land and Freedom", P: "In Love and War", Q: "Go West", R: "Kazaam", S: "Thieves", T: "Friends & Lovers"}. Select a movie from options A to T that the user is most likely to be interested in. Books Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. Instruction: Given the user’s reading history, select a book that is most likely to interest the user from the options. Watching history: {"Practice Makes Perfect: Spanish Verb Tenses", "NTC’s Dictionary of Common Mistakes in Spanish", "Streetwise Spanish Dictionary/Thesaurus", "Buscalo! (Look It Up!) : A Quick Reference Guide to Spanish Grammar and Usage", "La lengua que heredamos: Curso de espaol para bilinges", "V ox Diccionario De Sinonimos Y Antonimos", "Schaum’s Outline of Spanish V ocabulary", "Nos Comunicamos (Spanish Edition)", "The Oxford Spanish Business Dictionary", "Bilingual Dictionary of Latin American Spanish"}. Options: {"A: Folk and Fairy Tales, Childcraft (V olume 3)", B: "The Waves", C: "Dead End Kids: Gang Girls and the Boys They Know", D: "Opera Stars in the Sun: Intimate Glimpes of Metropolitan Opera Personalities", E: "Five-Minute Erotica", F: "Spanish Verbs: Oxford Minireference", G: "Motorcycle Maintenance Techbook: Servicing & Minor Repairs for All Motorcycles & Scooters", H: "Father and Son: A Study of Two Temperaments (Classic, 20th-Century, Penguin)", I: "Manga Mania Fantasy Worlds: How to Draw the Amazing Worlds of Japanese Comics", J: "MCSE Designing a Windows Server 2003 Active Directory & Network Infrastructure: Exam 70-297 Study Guide and DVD Training System", K: "The Atmospheric Boundary Layer (Cambridge Atmospheric and Space Science Series)", L: "St. Augustine and St. Johns County: A pictorial history", M: "A Will to Survive: Indigenous Essays on the Politics of Culture, Language, and Identity", N: "Saved: A Guide to Success With Your Shelter Dog", O: "Mosaic (Star Trek V oyager)", P: "Fantastical Tarot: 78-Card Deck", Q: "American Sign Language-A Look at Its History, Structure and Community", R: "Warrior’s Heart (Zebra Historical Romance)", S: "The New Money Management: A Framework for Asset Allocation", T: "Megabrain"}. Select a book from options A to T that the user is most likely to be interested in.