Adaptive Retrieval-Augmented Generation for Conversational Systems Xi Wang1, Procheta Sen2, Ruizhe Li3, Emine Yilmaz4 1University of Sheffield, 2University of Liverpool, 3University of Aberdeen, 4University College London xi.wang@sheffield.ac.uk1, procheta.sen@liverpool.ac.uk2, ruizhe.li@abdn.ac.uk3, emine.yilmaz@ucl.ac.uk4 Abstract Despite the success of integrating large lan- guage models into the development of con- versational systems, many studies have shown the effectiveness of retrieving and augmenting external knowledge for informative responses. Hence, many existing studies commonly as- sume the always need for Retrieval Augmented Generation (RAG) in a conversational system without explicit control. This raises a research question about such a necessity. In this study, we propose to investigate the need for each turn of system response to be augmented with exter- nal knowledge. In particular, by leveraging hu- man judgements on the binary choice of adap- tive augmentation, we develop RAGate, a gat- ing model, which models conversation context and relevant inputs to predict if a conversational system requires RAG for improved responses. We conduct extensive experiments on devising and applying RAGate to conversational models and well-rounded analyses of different conver- sational scenarios. Our experimental results and analysis indicate the effective application of RAGate in RAG-based conversational sys- tems in identifying system responses for appro- priate RAG with high-quality responses and a high generation confidence. This study also identifies the correlation between the genera- tion‚Äôs confidence level and the relevance of the augmented knowledge. 1 Introduction Recently, the advancement of Large Language Models (LLMs) has significantly improved con- versational systems, enabling the generation of nat- ural and high-quality responses (Ni et al., 2023). Despite these advancements, recent studies have identified several limitations on the simple use of LLMs to address conversational tasks (Onoe et al., 2022; Huang et al., 2021; Ren et al., 2018). These limitations include the lack of up-to-date knowledge (Onoe et al., 2022), the generation of Can you find me some interesting things to do?Knowledge Cloud on earth, clouds are formed by the saturation of air in the homosphere. Cloud the Droplets or particles are suspended in the atmosphere above the surface of a planetary body. Sure! Here are a few interesting things you can do: 1.Explore the science of clouds.2.Virtual museum tours3.Online Courses4.Read a Book or listen to an audiobook. Sure! Here are a few suggestions based on different interests:1.Creative activities: painting, writing, DIY crafts2.Physical activities: exercise, outdoor walk and dancing3.Entertainment: movies, games, books Use Knowledge Not Use Knowledge Figure 1: Example conversation when generating a re- sponse with or without a knowledge snippet using a language model (GPT-4 in this example). non-factual or hallucinated content (Huang et al., 2021), and restricted domain adaptability (Ren et al., 2018). These issues can hinder the develop- ment of conversational agents with satisfactory user experience. To address these identified challenges, a common approach is to retrieve and augment LLMs with external knowledge to enhance the con- versational response, making them more accurate, reliable, and adaptable to different domains (Zhao et al., 2020; Lian et al., 2019; Ye et al., 2024). For example, Shuster et al. (2021) demonstrated that us- ing a dense retrieval model (DPR) (Karpukhin et al., 2020) to retrieve relevant knowledge for augmenta- tion can significantly reduce the hallucination rate, according to a corresponding human evaluation. Similarly, Yang et al. (2020) showed that leverag- ing a graph-structured knowledge base can boost the reasoning ability and domain generalisability of task-oriented conversational agents. These achieve- ments of knowledge-augmented techniques high- arXiv:2407.21712v1 [cs.CL] 31 Jul 2024 light a promising direction for enhancing conversa- tional agents and address the current limitations. However, while implementing retrieval augmen- tation to a conversational system for improved re- sponse, we question the necessity of knowledge augmentation for every turn of system responses. To develop effective human-computer conversa- tions, it is essential to provide factual and relevant responses, offer appropriate amount of informa- tion, and not unnaturally drive and shift the con- versation to non-relevant topics (Kasirzadeh and Gabriel, 2023; Miehling et al., 2024). We argue that overusing external knowledge could result in sys- tem responses against these core criteria. Figure 1 presents a conversation example that shows how the system response to a generic user utterance about suggesting activities can vary with and without augmented knowledge. The knowledge-augmented system response is being information conditioned with limited diversity and assuming specific user preferences. In contrast, without the addition of external knowledge, the system response is more diverse and natural in this early stage of a conversa- tion. This indicates that misusing external knowl- edge can lead to problematic system responses and a negative user experience. To address this, we investigate an adaptive retrieval-augmented generation solution for effec- tive conversational systems. In particular, moti- vated by the gate function in long-short term mem- ory models (Graves and Graves, 2012), which explicitly controls the use of input and memory, we propose a binary knowledge gate mechanism, called RAGate, to manipulate the use of external knowledge for a conversational system. To model the conversation context and accurately estimate the need for augmentation, we leverage the hu- man labels as ground truth and develop RAGate by exploring the use of recent advanced language models or constructing attention neural gate mod- els. To validate the effectiveness of RAGate, we conduct extensive experiments on an annotated Task-Oriented Dialogue (TOD) system dataset, KETOD, that builds upon the SGD dataset with TOD-spanning 16 domains, such as Restaurant and Weather. The experimental results show that RA- Gate enables conversational systems to efficiently use external knowledge at appropriate conversation turns, producing high-quality system responses. In particular, by modelling the uncertainty and confi- dence level of the system ‚Äì which correlates with the likelihood of hallucinated output (Varshney et al., 2023) ‚Äì we show that the "always" aug- mentation of external knowledge can significantly increase generation uncertainty and the risk of hal- lucination. After applying RAGate, we can effec- tively control the conversation system to make con- fident and informative responses. In addition, by varying the use of knowledge snippets in different relevance levels, we also observe the positive corre- lation between the calculated confidence score and the relevance of augmented knowledge, which can be valuable for many future studies. 2 Related Work In the pipeline of knowledge-augmented generation for a conversation system, two main components are identified: the knowledge retriever and the re- sponse generator. Existing studies have improved conversational responses to different extents by im- proving one or both components (Li et al., 2022; Komeili et al., 2022; Wang et al., 2024). Knowledge Retrieval: Several studies have ex- plored the use of dense passage retrieval techniques (Lewis et al., 2020; Karpukhin et al., 2020) and public search service for effective retrievers (Li et al., 2022). For example, Li et al. (2022) retrieved Wikipedia passages through a database interface and then ranked them according to statistical rele- vance, calculated by TF-IDF, or semantic relevance as per cosine similarity. Similarly, Komeili et al. used a search engine API to retrieve relevant knowl- edge but first transformed the dialogue context into a natural search query using an encoder-decoder model before searching. Joint Optimisation of Retriever and Genera- tor: On the other hand, another thread of re- search studies has explored joint optimisation ap- proaches. For instance, Shi et al. (2023) introduced a retriever-generator architecture that aims to im- prove the performance of Task-Oriented Dialogue (TOD) systems by using a dual-feedback mecha- nism. The retriever identifies relevant knowledge from a database, while the generator uses this in- formation to create appropriate system responses. The feedback from the generator is further used as pseudo-labels to train the retriever to select perti- nent information. Shen et al. (2023) introduced a training method based on maximal marginal like- lihood. This method jointly optimise a perceptive retriever and the response generation in a feed- back loop. The proposed approach incorporates meta-knowledge, which guides the generator to Add&NormFeedForwardAdd&NormMulti-HeadAttention Nx InputEmbedding PositionEncoding ‚äï LinearSoftmaxPrediction LLMPrompt‚äïContextor(Context + knowledge) Prediction LLM Contextor(Context + knowledge) ùëü+Prediction RAGateExternal KnowledgeResponse Generator Contextor(Context & knowledge) Figure 2: RAGate variants for implementing the gating function. The three variants are the prediction with pre- trained language models after prompting (1), after parameter-efficient fine-tuning (2), and with a multi-head attention encoder (3). improve the utilisation of knowledge and, conse- quently, the quality of the generated responses. Kang et al. (2023) further advance the retriever by proposing SUbgraph Retrieval-augmented GEn- eration (SURGE), which employed a graph neural network (GNN)-based context-relevant subgraph retriever. SURGE incorporates contrastive learn- ing to optimise the latent representation space, en- suring that generated texts closely resemble the retrieved subgraphs. Despite the richness of existing retrieval- augmented generation techniques for conversa- tional systems, they commonly hypothesise that every conversation turn needs external knowledge. However, the necessity of augmenting every turn of the conversation with external knowledge re- mains questionable. A relevant thread of work that aims to answer this question is the introduction of the knowledge-seeking turn detection task using the DSTC-9 dataset (Kim et al., 2020), and the follow-up studies, such as (Hong et al., 2023; Jin et al., 2021). However, this task is to identify the turns in conversations injected by human workers about knowledge enquiry instead of identifying the system responses that require knowledge augmen- tation for improvements. This research gap high- lights the value and novelty of this study, which investigates the adaptive use of retrieval-augmented generation for advanced conversational systems. 3 Methodology 3.1 Problem Formulation This study addresses the challenge of effectively identifying conversation turns that require augmen- tation of external knowledge. In particular, we aim to develop a gate mechanism that dynamically de- termines when to search for external knowledge to ensure natural, relevant and contextually appro- priate responses. First, we define the task of user- system conversation. Let D = {d1, d2, ..., d|D|} be a set of user-system dialogues, and each dialogue d comprises a sequence of interactions between users and systems (i.e., d = {u0, s0, u1, s1, ..., uT , sT }) with varying lengths. Here, ut and st denote the user utterance and system response at the t-th turn, respectively. The conversational context up to turn t can be formulated by aggregating the previous user-system interactions, i.e., ct = u0, s0, .., ut. With this context information ct, the conversation system can augment it with a list of retrieved exter- nal knowledge, et,k, where k represents the rank- ing cutoff for the retrieved knowledge. Hence, the binary gate mechanism proposed in this study, de- ciding the knowledge augmentation, can be formu- lated as f(ct) = {0, 1} or f(ct, et,k) = {0, 1} if the external knowledge et,k is considered. Then, the follow-up response generation functiong(¬∑) can be formulated as follows: g(¬∑) = ( g(ct, et,k) if f(ct) or f(ct, et,k) g(ct) otherwise. (1) Hence, by evaluating and estimating the necessity of augmenting with external knowledge, we dy- namically update the conversational response gen- eration accordingly. 3.2 RAGate Gate Mechanism To effectively estimate the need to use external knowledge and implement adaptive retrieval aug- mented generation for a conversation system, we introduce our proposed gate mechanism, RAGate, that uses the conversational context and, option- ally, the retrieved external knowledge to predict the binary choice of using external knowledge. In par- ticular, we explore three RAGate variants that are implemented by the use of Large Language Mod- els (LLMs) with devised prompts, with parameter efficient fine-tuning (e.g., QLoRA (Dettmers et al., 2024)) and the construction of an end-to-end multi- head attention encoder. This exploration is moti- vated by the recent advancement of transformer- structured neural models in natural language pro- cessing. In Figure 2, we illustrate the application of RAGate and its three variants. We describe each of these three variants to clarify the use of RAGate: RAGate-Prompt: As denoted by Arora et al. (2022), a language model can effectively adapt to new tasks by using a natural language prompt that explains the process to address the tasks with- out extra training. Hence, we can formulate a gate function f(¬∑) as f(y|ct) = f(y|Œò, ct, p), where Œò denotes the used language model with its pre-trained weights and p is the devised nat- ural language prompt. Alternatively, if the re- trieved knowledge is also involved in prediction, we have f(y|ct) = f(y|Œò, ct, et,k, p). Specifically, we explore two types of prompts: zero-shot and in-context learning. Zero-shot prompts describe the task that uses the conversational context and, optionally, the retrieved knowledge to generate a response with binary feedback. As for the in- context learning prompts, we augment the zero- shot prompts with illustrative examples. We show the set of prompts in Appendix A. RAGate-PEFT: Despite the high adaptabil- ity of the language model with devised prompts, we further explored the use of instruction tun- ing on language models with a parameter-efficient fine-tuning method (i.e., QLoRA (Dettmers et al., 2024)) to meet the goal of an effective gate func- tion. QLoRA is built upon the known Low-rank Adapter (LoRA) (Hu et al., 2021), which keeps the pre-trained weight matrix W0 frozen and addresses the gradient updates of the weight matrix ‚àÜW through low-rank approximation (i.e., ‚àÜW = BA, where B and A are the result of lower-rank de- composition on ‚àÜW ). Hence, the forward pass during the model training can be updated from h = W0x + ‚àÜW x to h = W0x + BAx. QLoRA (Dettmers et al., 2024), which is used in this study, further quantises the language model into a 4-bit NormalFloat data type and leverages the page-to- page transfer between the CPU and GPU to fur- ther avoid memory spikes. To implement RAGate- PEFT, we format the train data with devised in- structions, joined with paired inputs and outputs for developing parameter-efficient fine-tuned large language models. In particular, we provide a set of instruction-input-output triples for model train- ing. The input can vary with the provision of a set of available features. Apart from the use of the conversational context (contx), we also include the system response (resp), synthetic responses gener- ated by the language model (syn-resp) due to the missing responses as input in the practical scenario, the name entities within the incoming responses (ner), retrieved knowledge (know) and the descrip- tion of the knowledge source, e.g., the WikiHow website (source). By using various combinations of inputs and customising the corresponding instruc- tions, we explore the effectiveness of the result- ing learned language models that implement the RAGate-PEFT. RAGate-MHA: Apart from the use of pre- trained language models and further fine-tuned lan- guage models, we also explore the introduction of a multi-head attention neural encoder to model the context as input and estimate the augmenta- tion necessity (i.e., RAGate-MHA). Here, we de- scribe the model structure of RAGate-MHA. At first, as denoted by (Vaswani et al., 2017), the at- tention mechanism is formulated as the interaction between three objects, queries Q, keys K, and val- ues V : Attention(Q, K, V ) = softmax( QKT ‚àödk )V . To estimate the necessity of augmentation, we fit the context and the retrieved knowledge into the roles of these three objects. Specifically, we in- clude the setups of (1) using context only (contx) or (2) using the concatenated context and retrieved knowledge (contx ‚äï know) as queries, keys, and values, and (3) using the context as queries and interact with the retrieved knowledge as keys and values (contx √ó know). Next, following (Vaswani et al., 2017) in the encoder construction of a trans- former model, we encode the inputs via an input embedding layer into latent vectors and a position encoding layer to encode the order of tokens in the sequence. After that, we leverage the multi-head attention to learn attention weights on the inputs and then followed by a feed-forward network: F F N(x) = max(0, xW1 + b1)W2 + b2 (2) where W1 and W2 are two learned parameter matrics with two bias terms (b1 and b2). Both multi- head attention and feed-forward neural modules are followed by residual connection (He et al., 2016) Retrieval ModelsRecall@1 Recall@3 TF-IDF 0.0227 0.0871 BERT-Ranker 0.2475 0.4714 Table 1: Retrieval Performance Evaluation when using context as the query. and layer normalisation (Ba et al., 2016). Unlike the introduction of another decoder module that addresses the sequence-to-sequence generation in (Vaswani et al., 2017), we followed the encoder out- put with a linear projection module and a softmax function for our binary classification task. 4 Model Training and Evaluation Setups We evaluate the performance of introducing RA- Gate according to its binary classification perfor- mance and the effectiveness of the resulting re- sponse generation. Specifically, we use the KE- TOD dataset (Chen et al., 2022), which has fully annotated 5,324 dialogues and 52,063 turns of con- versations. In particular, it is associated with 33,761 knowledge snippets to be retrieved and augmented. In addition, KETOD was developed with human labels on turns of conversations (around 12.1% of turns) about the need for augmenting with retrieved knowledge snippets for a natural and informative system response. Hence, we use these human labels as natural ground truths when evaluating RAGate. It is worth indicating that many current knowledge- augmented conversational datasets often ground their conversations on the knowledge snippet, such as Wizard of Wikipedia (Dinan et al., 2018) and CMU_DoG (Zhou et al., 2018), which makes them not a natural fit to be investigated in this study. Due to the limited computational resource avail- ability, we explore the use of Llama-v2-7B and Llama-v2-13B to implement RAGate-prompt and fine-tune Llama-v2-7B for RAGate-PEFT. We im- plement QLoRA using the PEFT library (Man- grulkar et al., 2022) and set the lower rank to 16. As discussed in Section 3, we have various input fea- tures to be combined for performance optimisation. We begin with the use of context only, then concate- nate the context with the real response (contx-resp), with the synthetic response and recognised enti- ties (contx-syn-resp-ner) and further extend with the use of retrieved knowledge (contx-syn-resp-ner- know) or the source of knowledge (contx-syn-resp- ner-source). Specifically, we retrieve the relevant knowledge by exploring the use of TF-IDF and a learned BERT ranker. We evaluate their perfor- mance with the classic Recall@1 and Recall@3 on the test collection. We use a shallow cutoff because we only use top-relevant knowledge snippets for augmentation. Table 1 shows their retrieval per- formance. According to the leading performance of BERT-Ranker, we augment knowledge with its retrieved top 3 relevant knowledge snippets (i.e., k = 3). Regarding the development of RAGate- MHA, we explore the combinations of 2 to 8 layers, 2 or 4 heads and the embedding size in [64, 128, 256] for the best classification accuracy. We report the precision, recall, F1, Area Under Curve (AUC) and the False Discovery Rate (FDR) as the main measures to show the classification effectiveness. Next, we further deploy the best-performing RA- Gate gate function to update the KETOD dialogue system (Chen et al., 2022), which uses GPT-2 (Rad- ford et al., 2019) as the backbone model. To high- light the effect of various augmentation setups, we use the context with the gold action without extra prediction as input to KETOD. Then, we compare the resulting performance to the KETOD model without knowledge augmentation and aug- menting every system response as baselines. To report the response generation effectiveness, we report how close the response is to the ground truth via BLEU, ROUGE-1/2/L and BERTScores and the confidence score calculated by the minimum probabilities of individual tokens that compose the response. As argued by Varshney et al. (2023), this calculated confidence score can highly correlate with a language model‚Äôs likelihood of generating hallucinated responses. We trained our models and conducted the evaluations on one machine with one NVIDIA 4090 GPU. 5 Results and Analysis 5.1 Augmentation Need Classification First, we evaluate the classification accuracy of our developed RAGate gate methods for addressing the adaptive RAG to system responses. Table 2 presents the classification performance of RAGate baselines while evaluated on the test collection of the KETOD dataset, which includes rich human labels on the use of RAG for response generation. As discussed in Section 3, we explore the devel- opment of RAGate with three variants: the use of LLM prompting (RAGate-Prompt), parameter- efficient fine-tuned LLMs (RAGate-PEFT), and a neural classifier with Multi-Head Attention struc- ture (RAGate-MHA). Model Variants PrecisionRecall F1 RAGate-Prompt: LLMs ‚Äì Zero Shot Llama-2-7B 0.1323 0.0278 0.0460 Llama-2-13B 0.1422 0.1083 0.1230 RAGate-Prompt: LLMs ‚Äì In-Context Learning Llama-2-7B 0.1417 0.0294 0.0487 Llama-2-13B 0.0989 0.0851 0.0915 RAGate-PEFT:Parameter Efficient Fine-tuned LLMs (Llama2-7B) [contx‚äïresp] 0.4926 0.3095 0.3802 contx-only 0.5203 0.3359 0.4082 contx-(syn-resp)-ner 0.6818 0.2321 0.3464 contx-(syn-resp)-ner-know 0.4698 0.0603 0.1069 contx-(syn-resp)-ner-source 0.4000 0.0185 0.0355 RAGate-MHA:Context with / without Knowledge Input MHA(contx)-h(4)-l(5)-emb(64) 0.3210 0.5541 0.4065 MHA([contx‚äïknow])-h(4)-l(2)-emb(64) 0.2795 0.5201 0.3636 MHA(contx√óknow)-h(4)-l(2)-emb(64) 0.22720.58350.3271 RAGate-MHA:Context-Response Input MHA([contx‚äïresp])-h(4)-l(4)-emb(64) 0.3500 0.5510 0.4281 Table 2: Classification accuracy on adaptive augmenta- tion for system response. "contx", "resp", and "know" refer to the use of context, initial system response, and retrieved knowledge snippets as input. "syn-resp" and "ner" are the additional synthetic response and name en- tity recognition steps in the model fine-tuning prompts. h, l and emb refer to the best-performed configuration on the number of heads, layers and embedding size. RAGate performance with LLM prompting ver- sus fine-tuning. By comparing the corresponding performance reported in Table 2, we observe that, on average, fine-tuning a Llama-2-7B with QLoRA (i.e., RAGate-PEFT) can significantly outperform RAGate-Prompt. For example, by looking at the RAG-PEFT with context-only input, without using extra input features and instruction updates, it can outperform all RAG-Prompt approaches by a big margin (e.g., 0.4082 versus the highest 0.1230 F1 scores). This reflects the difficulty of this adap- tive knowledge augmentation task, which can not be properly addressed by prompting a general pre- trained language model. In particular, the use of larger language models and the in-context learn- ing setup, which often result in improved perfor- mance (Arora et al., 2022), can not guarantee the enhancement of models‚Äô classification accuracy re- garding this classification task. Regarding the performance of RAGate-PEFT approaches, by first examining the effect of us- ing synthetic response and recognised name enti- ties, we observe significantly improved precision (0.5203 to 0.6818) but with the cost of lower recall (0.3359 to 0.2321). In addition, when we add the retrieved knowledge to the input features for pre- diction, we observe a significant performance drop across all evaluated aspects. This can be caused by the additional complexity introduced by the in- cluded retrieved knowledge snippets. Furthermore, we also explored the performance impact of nam- ing the source of the knowledge snippet. We use wikiHow1 in this study, which can provide rich task instructions for offering informative task-oriented system response (Sen et al., 2023). However, the fine-tuned model cannot reasonably connect the promised rich resource from the knowledge source and the prediction of augmentation necessity. RAGate Performance between fine-tuned LLM and MHA classifier. Next, by comparing the ex- perimental results of RAGate-MHA and RAGate- PEFT in Table 2, we observe a wide-margin re- call improvement using RAGate-MHA, reaching a minimum recall of 0.52, but with significantly lower precision accuracy. In Table 2, we also in- clude the use of both the context and the initial system responses (i.e., MHA([contx, resp])) for additional insights. We can observe that a higher precision can be achieved but the use of response does not improve the recall performance. These re- sults are consistent with the observed performance of RAGate-PEFT, which further encourages the use of a synthetic response due to the unavailability of a system response in a practical scenario. In addition, we also observe a similar performance drop when including the retrieved knowledge snip- pets for classification. Even though the RAGate- MHA model, using the interaction between context and retrieved knowledge snippets, can achieve the highest recall of 0.5835, it can not outperform the RAGate-MHA using context-only on other metrics. Hence, considering the similar F1 and AUC perfor- mance levels of RAGate-PEFT and RAGate-MHA leads to a trade-off balance between precision and recall for the two groups of approaches. To further evaluate the classification effectiveness of RAGate, in Appendix B, we provide a detailed discussion of a conducted user study that explores whether RAGate can also assess the potential contribution of retrieved snippets when predicting the decision for retrieval augmentation. 5.2 Adaptive Augmentation Analysis In addition to the classification accuracy, we also compare the choice of human workers and RA- Gate approaches in augmenting specific turns. 1https://www.wikihow.com 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Position of Turns in a Conversation 0 50 100 150 200 250 300Number of Selected Augmentations RAGate-PEFT RAGate-MHA Human Labels Figure 3: Frequency analysis of adaptive augmentations about the position of a conversation. Specifically, we analyse the frequency of aug- mentation in different positions of conversations and different domains covered in the KETOD dataset. We use the RAGate-PEFT (contx-(syn- resp)-ner) with the highest precision and RAGate- MHA (MHA(contx)) with the best overall perfor- mance in the above analysis as representatives for comparison. Figure 3 presents the frequency in different positions. Due to the unequal number of conversational turns, we use the ratio to indicate the relative position. According to the reported results in Figure 3, most human augmentation se- lections happen at the beginning of a conversation. This trend is also effectively captured by both RA- Gate approaches, especially RAGate-MHA. This can be caused by the reason that a conversation is semantically coherent, and once sufficient addi- tional information is provided at the early stage, the value of knowledge augmentation to the later turns is naturally lower. On the other hand, Figure 4 presents the augmen- tation frequency over different domains. We ob- serve that system responses about certain domains are selected more often by humans than other do- mains, such as travel, hotels, trains, flights, service and rental cars, which require access to additional information to assist the suggestion-making, and the domains, like movies, music, media, events that often include entities require enriched de- scription. By looking into the performance of RAGate-PEFT and RAGate-MHA, RAGate-MHA can make aligned selections for humans. However, the RAGate-PEFT does not guarantee the identifi- cation of appropriate augmentation use and often presents fewer augmentations, apart from the travel domain. Hence, by considering both position and 0 20 40 60 80 100 120 Number of Selected Augmentations Messaging RentalCars RideSharing Events Buses Media Weather Services Payment Music Restaurants Trains Movies Calendar Flights Hotels Homes Travel Alarm Domains RAGate-PEFT RAGate-MHA Human Labels Figure 4: Frequency analysis of adaptive augmentations about dialogue domains. Variants # AugsBLEUROUGE-LBERTScoreConfidence No-Aug 0 9.38‚Ä¢ 0.3780‚Ä¢ 0.8105‚Ä¢ 9.3425‚Ä¢ ‚Äì Augment BERT Ranker Retrieved KnowledgeRAGate-PEFT230 10.45 0.3825 0.8144 9.3374 -0.05%RAGate-MHA787 12.14 0.3882 0.8192 9.3083 -0.36%Random-Aug230 9.53 0.3784 0.8110 9.2984 -0.47%Random-Aug787 10.010.3795 0.8126 9.1877 -1.65%Human-label631 11.66 0.3856 0.8176 9.2550 -0.93%Aug-All 496416.080.3927 0.8258 8.3677 -10.43% Augment Rank-1 Relevant Knowledge RAGate-Llama230 10.54 0.3822 0.8142 9.3642 +0.23%RAGate-MHA787 11.99 0.3883 0.8191 9.3774 +0.37%Random-Aug230 9.51 0.3784 0.8110 9.3328 -0.10%Random-Aug787 10.010.3800 0.8127 9.2982 -0.47%Human-label631 11.52 0.3846 0.8170 9.3218 -0.22%Augment-All496416.050.3944 0.8259 9.0655 -2.9% Table 3: Performance of applying RAGate and com- pared to the KETOD baseline on the KETOD dataset. Confidence is calculated by the average value over the lowest logit of each generation. domain augmentation frequency, we conclude that RAGate-MHA can outperform RAGate-MHA and effectively capture the trend of augmentation needs. 5.3 RAGate for Response Generation To evaluate the effect of adaptive RAG for a conver- sational system, we use RAGate-PEFT (contx-(syn- resp)-ner) with the highest precision and RAGate- MHA (MHA(contx)) with the best overall perfor- mance in the above analysis, to support the adaptive retrieval augmented conversational response gen- eration. Table 3 presents the results of applying RAGAte to the KETOD model for adaptive knowl- edge augmentation when evaluated on the KETOD dataset. We include four types of adaptive augmen- tation, namely the use of RAGate and comparison to the random selection with equal numbers of se- lections, human choice, and the commonly used "all" augmentation. In addition, to explore the ef- fect of varied quality of knowledge snippets, we also extend the evaluation of using the top-3 knowl- edge snippets ranked by different retrievers (i.e., BERT-ranker and TF-IDF) and the use of knowl- edge snippets at the 1st and 5th rank according to the BERT-ranker. Due to the space limit, we first present the results of using BERT-ranker retrieved and top-1 relevant knowledge and top-1 relevant in Table 3 and show the full results in the Appendix C. At first, without adaptive knowledge augmenta- tion, we compare the choice of response generation without augmentation and with "always" augmenta- tion (i.e., No-Aug versus Aug-All). In Table 3, we observe that by augmenting a total of 4,964 system responses in the test collection, the conversational model can generate more informative and effec- tive responses according to the reported scores of BLEU, ROUGE and BERTscore. This aligns with the reported effectiveness of RAG in many existing studies. However, we also identify a significant drop in the model‚Äôs generation confidence level. As denoted by Varshney et al. (2023), a lower con- fidence level can correlate with a higher chance of generating hallucinated responses, which could be caused by the unnecessary use of external knowl- edge. Hence, to investigate the effectiveness of adaptive knowledge augmentation, we examine the impact of using RAGate. According to the reported experimental results in Table 3, the adaptive aug- mented response generation with fewer knowledge snippets can indeed result in a higher confidence level than Aug-All. Moreover, comparing the performance between RAGate and random selections shows that, consid- ering equal numbers (230 or 787 according to the classification with RAGate) of system responses for augmentation, RAGate can further result in a higher quality of generated response. RAGate-MHA even enables results that are comparable to Aug-All‚Äôs response quality, with only 787 turn augmentations instead of all 4964 turns. Specifically, the use of RAGate-PEFT, which identifies 230 turns of sys- tem responses for knowledge augmentation, can even outperform the random baseline that augments 787 system response turns with improved response quality. Apart from the improved response quality, RAGate also enables the conversational model to maintain a high confidence level and ensure faith- ful responses. Indeed, using RAGate-MHA, which augments 787 system responses, only lowers the average confidence score by 0.36%, instead of the 1.65% when randomly selecting an equal number of turns to augment. In addition, considering the use of different qual- ity and amount of knowledge snippets for augmen- tation, we also include the use of the most rele- vant knowledge snippet according to BERT-ranker in Table 3. We observe that the use of different amounts of knowledge snippets in different rele- vance levels has a marginal effect on this learned dialogue system. However, we observe a signif- icant difference in the confidence level. We ob- serve that using only the most relevant knowledge snippet enables the Aug-All to suffer less from a lower confidence level. In particular, the applica- tion of RAGate can even increase the confidence level of the conversation system in response gen- eration. This indicates that the confidence score can also correlate with the quality of the augmented knowledge snippets. This observation is further val- idated using knowledge snippets with fifth-ranking positions by BERT-ranker and the use of TF-IDF ranker. We include the full experimental results in Table 4 and attached in the Appendix. These observations indicate the value of adaptive system response augmentation via RAGate in generating high-quality outputs, ensuring faithful responses, and potentially saving retrieval costs. We also show the value of using confidence scores to reflect the contribution of RAG. 6 Conclusions Our study investigates a core research question about whether retrieval-augmented generation is always useful to a conversational system. To an- swer this research question, we propose adaptive retrieval-augmented generation for conversational systems and introduce corresponding gate func- tions, RAGate, for explicit control. A comprehen- sive set of experiments and results show the RA- Gate approaches can effectively identify augmen- tation needs. In addition, RAGate can capture hu- man preference by augmenting the beginning turns of conversations, and RAGate can further identify knowledge augmentation for assisting suggestion- making and enriching description. When applying RAGate to conversational systems, we observe that it can ensure comparable quality of generated re- sponses and enable the system to increase genera- tion confidence for faithful outputs, especially with the appropriate use of relevant knowledge snippets. Limitations There are three limitations of this study. At first, due to the main focus of examining the adaptive retrieval-augmented generation for a conversation system. We only consider a few examples of retrieval techniques (TF-IDF and BERT-ranker), which can be further extended to recent retrieval techniques, such as dense passage retrieval for ad- ditional insights. The second limitation is the miss- ing use of larger language models, such as GPT-4, due to the shortage of computational resources. In- cluding larger language models for conversational systems could introduce additional experimental in- sights. The third limitation is the shortage of appro- priate conversational data for extensive evaluations. This is mainly caused by the recent development of the retrieval augmented generation technique and its application to conversational systems. Future research is encouraged to address this limitation. Ethics Statement All experiments in this study were conducted us- ing publicly available datasets and open-released language models, which do not contain any private information that could raise ethical concerns. References Simran Arora, Avanika Narayan, Mayee F Chen, Lau- rel Orr, Neel Guha, Kush Bhatia, Ines Chami, and Christopher Re. 2022. Ask me anything: A sim- ple strategy for prompting language models. In The Eleventh International Conference on Learning Rep- resentations. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hin- ton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450. Zhiyu Chen, Bing Liu, Seungwhan Moon, Chinnadhurai Sankar, Paul A Crook, and William Yang Wang. 2022. Ketod: Knowledge-enriched task-oriented dialogue. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 2581‚Äì2593. Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2024. Qlora: Efficient finetuning of quantized llms. Advances in Neural Information Processing Systems, 36. Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2018. Wizard of wikipedia: Knowledge-powered conversational agents. In International Conference on Learning Representations. Alex Graves and Alex Graves. 2012. Long short-term memory. Supervised sequence labelling with recur- rent neural networks, pages 37‚Äì45. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recog- nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770‚Äì 778. Taesuk Hong, Junhee Cho, Haeun Yu, Youngjoong Ko, and Jungyun Seo. 2023. Knowledge-grounded dia- logue modelling with dialogue-state tracking, domain tracking, and entity extraction. Computer Speech & Language, 78:101460. Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021. Lora: Low-rank adaptation of large lan- guage models. In International Conference on Learn- ing Representations. Xinxian Huang, Huang He, Siqi Bao, Fan Wang, Hua Wu, and Haifeng Wang. 2021. Plato-kag: Unsu- pervised knowledge-grounded conversation via joint modeling. In Proc. of NLP4ConvAI. Di Jin, Shuyang Gao, Seokhwan Kim, Yang Liu, and Dilek Hakkani-Tur. 2021. Towards zero and few-shot knowledge-seeking turn detection in task- orientated dialogue systems. In 3rd Workshop on Natural Language Processing for Conversational AI, NLP4ConvAI 2021, pages 281‚Äì288. Minki Kang, Jin Myung Kwak, Jinheon Baek, and Sung Ju Hwang. 2023. Knowledge graph-augmented language models for knowledge-grounded dialogue generation. arXiv preprint arXiv:2305.18846. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open- domain question answering. In Proc. of EMNLP. Atoosa Kasirzadeh and Iason Gabriel. 2023. In conver- sation with artificial intelligence: aligning language models with human values. Philosophy & Technol- ogy, 36(2):27. Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam Hedayatnia, Yang Liu, and Dilek Hakkani- Tur. 2020. Beyond domain apis: Task-oriented con- versational modeling with unstructured knowledge access. In Proc. of SIGDIAL. Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2022. Internet-augmented dialogue generation. In Proceed- ings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8460‚Äì8478. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Hein- rich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rock- t√§schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neu- ral Information Processing Systems, 33:9459‚Äì9474. Yu Li, Baolin Peng, Yelong Shen, Yi Mao, Lars Li- den, Zhou Yu, and Jianfeng Gao. 2022. Knowledge- grounded dialogue generation with a unified knowl- edge representation. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 206‚Äì218. Rongzhong Lian, Min Xie, Fan Wang, Jinhua Peng, and Hua Wu. 2019. Learning to select knowledge for response generation in dialog systems. In Proc. of IJCAI. Sourab Mangrulkar, Sylvain Gugger, Lysandre De- but, Younes Belkada, Sayak Paul, and Benjamin Bossan. 2022. Peft: State-of-the-art parameter- efficient fine-tuning methods. https://github. com/huggingface/peft. Erik Miehling, Manish Nagireddy, Prasanna Sattigeri, Elizabeth M Daly, David Piorkowski, and John T Richards. 2024. Language models in dialogue: Con- versational maxims for human-ai interactions. arXiv preprint arXiv:2403.15115. Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, and Erik Cambria. 2023. Recent advances in deep learn- ing based dialogue systems: A systematic survey. Artificial intelligence review, 56(4):3055‚Äì3155. Yasumasa Onoe, Michael Zhang, Eunsol Choi, and Greg Durrett. 2022. Entity cloze by date: What lms know about unseen entities. In Proc. of NAACL. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9. Liliang Ren, Kaige Xie, Lu Chen, and Kai Yu. 2018. Towards universal dialogue state tracking. In Proc. of EMNLP. Alireza Salemi and Hamed Zamani. 2024. Evaluating retrieval quality in retrieval-augmented generation. Preprint, arXiv:2404.13781. Procheta Sen, Xi Wang, Ruiqing Xu, and Emine Yilmaz. 2023. Task2kb: A public task-oriented knowledge base. In Proceedings of the AAAI Conference on Artificial Intelligence. Weizhou Shen, Yingqi Gao, Canbin Huang, Fanqi Wan, Xiaojun Quan, and Wei Bi. 2023. Retrieval- generation alignment for end-to-end task-oriented dialogue system. arXiv preprint arXiv:2310.08877. Tianyuan Shi, Liangzhi Li, Zijian Lin, Tao Yang, Xi- aojun Quan, and Qifan Wang. 2023. Dual-feedback knowledge retrieval for task-oriented dialogue sys- tems. arXiv preprint arXiv:2310.14528. Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021. Retrieval augmentation reduces hallucination in conversation. In Proc. of EMNLP. Neeraj Varshney, Wenlin Yao, Hongming Zhang, Jian- shu Chen, and Dong Yu. 2023. A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation. arXiv preprint arXiv:2307.03987. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30. Hongru Wang, Wenyu Huang, Yang Deng, Rui Wang, Zezhong Wang, Yufei Wang, Fei Mi, Jeff Z Pan, and Kam-Fai Wong. 2024. Unims-rag: A uni- fied multi-source retrieval-augmented generation for personalized dialogue systems. arXiv preprint arXiv:2401.13256. Shiquan Yang, Rui Zhang, and Sarah Erfani. 2020. Graphdialog: Integrating graph knowledge into end- to-end task-oriented dialogue systems. In Proc. of EMNLP. Linhao Ye, Zhikai Lei, Jianghao Yin, Qin Chen, Jie Zhou, and Liang He. 2024. Boosting conversa- tional question answering with fine-grained retrieval- augmentation and self-check. arXiv preprint arXiv:2403.18243. Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, and Zhaofeng Liu. 2024. Evaluation of retrieval-augmented generation: A survey. Preprint, arXiv:2405.07437. Xueliang Zhao, Wei Wu, Can Xu, Chongyang Tao, Dongyan Zhao, and Rui Yan. 2020. Knowledge- grounded dialogue generation with pre-trained lan- guage models. In Proc. of EMNLP. Kangyan Zhou, Shrimai Prabhumoye, and Alan W Black. 2018. A dataset for document grounded con- versations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 708‚Äì713. A Prompts for RAGate-Prompt In this section, we list the used prompts for the RAGate-Prompt gate mechanism. Zero-Shot Prompt: Below is an instruction that describes a task. Please respond with ‚ÄòTrue‚Äô or ‚ÄòFalse‚Äô only that appropriately completes the request. ### Instruction: Analyse the conversational con- text so far. Generate an appropriate response. Con- sider the invovled entites. Estimate if augmenting the response with external knowledge is helpful with an output of ‚ÄòTrue‚Äô or ‚ÄòFalse‚Äô only. ### Input: [Converstion Context Input] ### Response: In-Context Learning Prompt: Augmentation Variants# AugsBLEUROUGE-1ROUGE-2ROUGE-LBERTScoreConfidence No-Aug 0 9.38 0.4111 0.2246 0.3780 0.8105 9.3425 Augment BERT Ranker Retrieved Knowledge RAGate-Llama 230 10.45 0.4165 0.2273 0.3825 0.8144 9.3374 RAGate-MHA 787 12.14 0.4227 0.2318 0.3882 0.8192 9.3083 Random-Aug 230 9.53 0.4119 0.2250 0.3784 0.8110 9.2984 Random-Aug 787 10.01 0.4138 0.2265 0.3795 0.8126 9.1877 Human-label 631 11.66 0.4198 0.2297 0.3856 0.8176 9.2550 Augment-All 4964 16.08 0.4301 0.2364 0.3927 0.8258 8.3677 Augment TF-IDF Ranker Retrieved Knowledge RAGate-Llama 230 10.52 0.4165 0.2273 0.3826 0.8144 9.3418 RAGate-MHA 787 12.11 0.4233 0.2319 0.3889 0.8193 9.3058 Random-Aug 230 9.47 0.4118 0.2251 0.3783 0.8110 9.3006 Random-Aug 787 9.93 0.4136 0.2259 0.3793 0.8125 9.1942 Human-label 631 11.60 0.4198 0.2293 0.3854 0.8175 9.2639 Augment-All 4964 15.76 0.4289 0.2345 0.3914 0.8256 8.4188 Augment Rank-1 Relevant Knowledge RAGate-Llama 230 10.54 0.4162 0.2271 0.3822 0.8142 9.3642 RAGate-MHA 787 11.99 0.4227 0.2316 0.3883 0.8191 9.3774 Random-Aug 230 9.51 0.4117 0.2250 0.3784 0.8110 9.3328 Random-Aug 787 10.01 0.4140 0.2267 0.3800 0.8127 9.2982 Human-label 631 11.52 0.4189 0.2289 0.3846 0.8170 9.3218 Augment-All 4964 16.05 0.4308 0.2365 0.3944 0.8259 9.0655 Augment Rank-5 Relevant Knowledge RAGate-Llama 230 10.47 0.4161 0.2272 0.3823 0.8142 9.3592 RAGate-MHA 787 12.18 0.4224 0.2314 0.3883 0.8192 9.3704 Random-Aug 230 9.52 0.4118 0.2252 0.3785 0.8110 9.3315 Random-Aug 787 10.01 0.4135 0.2263 0.3794 0.8127 9.2961 Human-label 631 11.58 0.4186 0.2287 0.3845 0.8170 9.3210 Augment-All 4964 15.97 0.4290 0.2349 0.3927 0.8256 9.0604 Table 4: Performance of applying RAGate and compared to KETOD on the SGD dataset. Confidence is calculated by the average value over the lowest logit of each generation. Below is an instruction that describes a task. Please respond with ‚ÄòTrue‚Äô or ‚ÄòFalse‚Äô only that appropriately completes the request. ### Instruction: Analyse the conversational con- text so far. Generate an appropriate response. Con- sider the invovled entites. Estimate if augmenting the response with external knowledge is helpful with an output of ‚ÄòTrue‚Äô or ‚ÄòFalse‚Äô only. ### Example 1: USER: I‚Äôm planning a trip, can you help me look for a flight? SYSTEM: Which day are you planning to return and from which city? USER: I want to go from NYC the day after tomorrow and return on the 13th of this month. SYSTEM: Where would you like to go? USER: I want to go to Vancouver, BC. Can you look for a Premium Economy class ticket. SYSTEM: I found 1 flight for you. It is a Delta Airlines flight that takes off at 6 am and returns at 2:50 am. The price is $505. USER: What is the departure airport, and how many stops does the flight have? ### Response: True ### Example 2: USER: Get me bus tickets to a Cher event on March 6th. SYSTEM: How many to buy? USER: only one, please. ### Response: False ### Input: [Converstion Context Input] ### Response: B Impact of Retrieval Quality on Adaptive RAG To have a successful conversation model with a retrieval-augmented system, two main criteria must be met. One is identifying insufficient context, and the other is the quality of retrieved information (Salemi and Zamani, 2024; Yu et al., 2024). A conversational model performs better when both criteria are satisfied. In our proposed approach, as shown in Table 2, we have already assessed whether our adaptive retrieval method can detect insufficient context. We further explored to deter- mine whether our model can inherently estimate the quality of the retrieved snippets to address such insufficiency and, based on that, decide on the re- trieval. Although we do not explicitly provide re- trieved snippets to our model, retrieval comes with a corpus that includes potentially relevant knowl- edge snippets. Consequently, given a query and a retrieval collection, it can be estimated whether useful information for the query exists in the corpus to address the insufficient context. To investigate by following this direction, we randomly selected 50 samples from instances where our proposed ap- proach (RAGate-MHA, the best-performing gate model) predicted using retrieval augmentation. We asked domain experts (co-authors) to score whether they thought the retrieved snippets in those scenar- ios could be useful to response generation. Users rated the snippets on a scale of 0 ‚àí 4, with scores of 3 or 4 indicating ‚Äòuseful‚Äô or ‚Äòhighly useful‚Äô. We found that in 54% of cases where the prediction was for augmentation, users also found the snippets useful. This indicates that our proposed approach can implicitly capture the potential for obtaining high-quality retrieval snippets. C Additional experimental results about RAGate for Response Generation In Table 4, we include the complete experimental results of applying RAGate for adaptive retrieval- augmented system response generation. Specif- ically, explore the use of retrieved knowledge snippets to different extents of relevance. We in- clude top-3 knowledge snippets retrieved by BERT- ranker and TF-IDF. In addition, we also explore the use of knowledge snippets in different ranking positions (rank 1 and 5) according to the BERT- ranker retriever. The experimental result shows that precisely using a suitable amount of relevant knowledge can generate a response with higher confidence (i.e., less is more). In addition, this observation also indicates the potential use of con- fidence levels to evaluate the quality of the aug- mented knowledge.