arXiv:2504.14689v1 [cs.HC] 20 Apr 2025 Designing AI Systems that Augment Human Performed vs. Demons trated Critical Thinking KATELYN XIAOYING MEI, University of Washington, USA NIC WEBER, University of Washington, USA The recent rapid advancement of LLM-based AI systems has acceler ated our search and production of information. While the ad- vantages brought by these systems seemingly improve the perform ance or eﬃciency of human activities, they do not necessarily enhance human capabilities. Recent research has started to examine t he impact of generative AI on individuals’ cognitive abilities, especially critical thinking. Based on deﬁnitions of critical thinking across psychology and education, this position paper proposes the distinction between demonstrated and performed critical thinking in the era of generative AI and discusses the implication o f this distinction in research and development of AI systems that aim to augm ent human critical thinking. CCS Concepts: • Human-centered computing → Human computer interaction (HCI) ; • Computing methodologies → Ar- tiﬁcial intelligence ; Additional Key Words and Phrases: Critical Thinking, Intelligence Augment ation, Social Implications of Technological Design ACM Reference Format: Katelyn Xiaoying Mei and Nic Weber. 2025. Designing AI Systems that Augment Human Performed vs. Demonstrated Critical Think- ing. 1, 1 (April 2025), 6 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 INTRODUCTION Generative AI (GenAI) powered by large language models (LLM s) has boosted productivity in tasks such as writing, coding, information analysis, and decision-making. Howev er, these purported gains in eﬃciency do not always result in better task outcomes or human performance. In addition, t he use of these systems could potentially undermine hu- man capabilities as people develop an overreliance on AI sys tems for tasks ranging from simple to complex [4, 14]. For example, while tools like GitHub Copilot may increase codin g quality and eﬃciency [23], the mechanism of autocom- plete does not inherently enhance individuals’ programming skills or understanding [17]. Similarly, while ChatGPT and similar LLMs can increase the speed and improve the ﬂuency of writing deliverables, they do not necessarily improve individuals’ inherent writing abilities and potentially r esulting in biased outcomes and content lack of depth[13, 19 ]. Amidst these ﬁndings, we consider the current landscape of A I tools reveals a concerning pattern: the design of AI systems is often output-driven yet overlooks its impact on h uman cognitive capabilities. Recent research has started to pay attention to how generative AI (GenAI) impacts individuals’ critical thinking and researchers have found mixed This paper was presented at the 2025 ACM Workshop on Human-AIInteraction for Augmented Reasoning (AIREASONING-2025-01). This is the authors’ version for arXiv. Authors’ addresses: Katelyn Xiaoying Mei, kmei@uw.edu, Un iversity of Washington, , Seattle, W A, USA, ; Nic Weber, nmweber@uw.edu, University of Washington, , Seattle, W A, USA, . Permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee pr ovided that copies are not made or distributed for proﬁt or commercial advantage and th at copies bear this notice and the full citation on the ﬁrst pa ge. Copyrights for components of this work owned by others than ACM must be honored. Abstrac ting with credit is permitted. To copy otherwise, or republi sh, to post on servers or to redistribute to lists, requires prior speciﬁc permissio n and/or a fee. Request permissions from permissions@acm.o rg. © 2025 Association for Computing Machinery. Manuscript submitted to ACM Manuscript submitted to ACM 1 2 Mei et al. ﬁndings [1, 3, 12, 15, 16]. Based on this line of work, this pos ition paper proposes a distinction between performed critical thinking and demonstrated critical thinking. In the context of human-AI interaction,we deﬁne performed critical thinking as cognitive process undertaken by humans independent of AI assistance. In contrast, demonstrated critical thinking refers to either the process or product of critical thinkingthat occurs through the assistance of or collaboration with generative AI systems. These distinctions are important since the choice of interpretation could lead to diﬀerent implications for i) research that examines the impact of generative AI on critical thinki ng and ii) divergent design objectives for AI systems to augment human critical thinking. We identify that current evaluation on the impact of GenAI on critical thinking skills often focuses on demonstrated rather than performed critical thinking and provide considerations for future re search designs. Drawing insight from the intellect augmentation framework conceptualized by Douglas Engelbart [6], we argue that while current AI systems and interaction paradig ms may enhance the demonstrated critical thinking, they do not necessarily improve the performed critical thinking. We also discuss design considerations t o accomplish the latter. 2 DEFINITION AND EV ALUATION OF CRITICAL THINKING Critical thinking has been conceptualized through various frameworks over decades of research in education and psy- chology [2, 7, 18]. Its deﬁnition varies from a general deﬁni tion to a procedural process. Ennis [7] describes critical thinking as the correct assessing of statements . Scriven and Paul [18] deﬁne it as a “a disciplined process th at actively and skillfully conceptualize, apply, analyze, synthesize, and evaluate information gathered from or generated by obs er- vation, experience, reﬂection, reasoning or communicatio n, to guide one’s belief and action”. Similarly focusing on t he process, Bloom et al. [2] identiﬁes six cognitive activities that occur during critical thinking: knowledge, comprehension, application, analysis, synthesis, and evaluation. The deﬁnitions by Ennis [7] and Scriven and Paul [18] align w ith what we term performed critical thinking—independent cognitive processes witho ut external assistance. Yet all components within the deﬁnition by Bloom et al. [2] can be either perform ed independently or demonstrated through human-AI collaboration. Researchers in psychology and education have adopted vario us quantitative and qualitative approaches to evaluate critical thinking [4, 5]. Via a quantitative approach, researchers develop standardized tests or instruments [8–10, 2 2]. In qualitative assessment, researchers such as open-ended qu estions and augmentative writing, as well as online discus- sion [20, 24]. Across these tools, some tend to measure critical disposition [8]—the tendency to think critically—wher eas the others measure performance or application of critical t hinking [22]. To examine the latter, Watson and Glaser [22] asks students to read scenarios of statements and arguments and make judgments on speciﬁc inferences, assumptions, deductions, conclusions based on each scenario. Since these traditional assessment are designed to evaluate individuals’ capabilities in situations where AI assistance is not prese nt, we consider that they measure performed critical thinking. However, qualitative assessment could be used to measure demonstrated critical thinking if we evaluate individuals’ responses to open-ended questions and argumentative writi ng that are produced together with AI assistance. 3 EV ALUATING THE IMPACT OF GENERATIVE AI ON PERFORMED VS. DEMONSTRATED CRITICAL THINKING Recent research raises questions about how generative AI aﬀ ects individuals’ critical thinking abilities [3, 11, 12, 1 5]. Current research often conﬂates performed and demonstrated critical thinking by primarily assessing the latter rather than the former. For example, recent studies that suggest th e use of GenAI improves critical thinking evaluate only Manuscript submitted to ACM Designing AI Systems that Augment Human Performed vs. Demon strated Critical Thinking 3 Table 1. Cognitive activities defined in Bloom’s taxonomy [ 2, 15]. Cognitive activity Description Knowledge Recognition or recall of ideas, material, or phen omena Comprehension Organising, summarising, translating, gen eralising, giving descriptions, and stating the main ideas Application Using acquired knowledge to solve problems in n ew situations Analysis Examining and breaking information into componen t parts, determining how the parts relate to one another, identifying motives or caus es, making infer- ences, and ﬁnding evidence to support generalisations Synthesis Building a structure or pattern from diverse elem ents; putting parts together to form a whole or bringing pieces of information together to fo rm a new mean- ing Evaluation Presenting and defending opinions by making jud gements about information, the validity of ideas, or quality of work based on a set of crit eria the ﬁnal outputs (e.g., written responses) that participan ts produce with AI assistance [3, 12]. Such methodologies fail to measure whether individuals’ performed critical thinking has improved. We encourage future resear ch to adopt methodologies that can distinctly evaluate both forms of cr itical thinking. To robustly assess the impact of AI on criti - cal thinking abilities, researchers should implement stud y designs that assess participants’ performed critical thinking. For example, several studies have used quasi-experiments o r interventions to evaluate whether the usage of ChatGPT impacts students’ critical thinking abilities where stude nts’ critical thinking is assessed before and after the inte rven- tions Alarcón-López et al. [1], Liu and Wang [16]. Cui and Zha o [4] conduct a qualitative assessment of students’ dialogue in a classroom setting. Future research should als o consider longitudinal frameworks that track changes in independent cognitive abilities over time. 4 AUGMENTING PERFORMED VS. DEMONSTRATED CRITICAL THINKING Designing technology to augment human capabilities has been one of the major objectives of technology development. In 1962, Engelbart [6] presents the intellect augmentation framework to delineate how we can design artifacts to augment human capabilities. He considers augmentation is a chieved if humans are more eﬃcient in ﬁnding better solutions to complex problems. Engelbart [6] indicates tha t there are processes (”little steps or actions”) that take place in humans’ problem solving. Intellect augmentation can be accomplished by making any of these processes eﬃcient and better. It is worth noting that within his framework, intellect augmentation is not of human but of a system where humans with augmenta- tion means—which he referred as “ H-LAM/T ” system (Humans using Language, Artifacts, and Methodology). Deta iled description of each component is included in Table 2. While Engelbart’s framework provides an insightful road ma p for intellect augmentation, the rapid evolution of AI and intelligent technologies has necessitated expandin g these foundational ideas. Xia and Maes [25] provides a new interpretation of intellect that goes beyond problem so lving, extending it to other cognitive domains of human capabilities such as memory, motivation, and decision maki ng. Building upon the intellect augmentation framework, they derive steps for designing artifacts that support augm entation of diﬀerent cognitive domains: 1) consider the Manuscript submitted to ACM 4 Mei et al. desired state after augmentation ; 2) identify the processes for the task ; 3) identify how artifacts can change a process or processes. Based on these augmentation frameworks, we interpret what i t means to augment human critical thinking via AI systems. To augment critical thinking, the distinction bet ween performed and demonstrated critical thinking presents diﬀerent design paths for AI systems. Augmenting demonstrated critical thinking focuses on the quality of the ﬁnal output or collaborative process that is associated wit h individuals’ critical thinking. Augmenting performed critical thinking emphasizes the improvement of independent critical thinki ng activity after the interaction with AI systems. Building upon the deﬁnition of Bloom et al. [2] for c ritical thinking, augmentation of demonstrated critical thinking can be accomplished by improving the ﬁnal output associated with any of the components (e.g. knowledge, comprehension, application, analysis, synthesis, evaluation). For example, current conversational AI systems can explain complex concepts to individuals, enabling more eﬃcient and rapid comprehension, thus augmentation is accomplished. Yet it does not necessarily augment individuals’ performed comprehension skill. On the contrary, overrelying on AI assistance to comprehend complex concepts may negatively impact individuals’ independent comprehension capability as they practice it less on their own. Both forms of augmentation serve important but distinct pur poses in human-AI collaboration. Augmenting demon- strated critical thinking may be particularly valuable in t ime-sensitive contexts, collaborative workﬂows, or when addressing highly complex problems that exceed individual cognitive capacity. Meanwhile, augmenting performed critical thinking becomes essential for long-term skill de velopment, educational settings, and maintaining human au - tonomy in reasoning. To cultivate performed critical thinking, AI systems need to train and empower user s to practice high-quality critical thinking independently. We encoura ge future research to draw insight from research in educa- tion and learning to identify eﬀective interactive paradig ms or features that scaﬀold critical thinking processes rat her than simply delivering conclusions. For example, numerous work in education research identify the eﬀective use of questioning, classroom debates, and writing could promote critical thinking in students [21]. Future research could e x- plore similar strategies—such as providing structured fra meworks, guiding questions without resolving the analytic al process completely— could support users in developing thei r own critical thinking skills. Table 2. Augmentation Means within the Intellect Augmentat ion Framework by Engelbart [6] Augmentation Means Description Artifacts Physical objects designed to provide for human comfort, for the manipulation of things or materials, and for the manipulation of symbols. Language The way in which the individual parcels out the picture of his world into the concepts that his mind uses to model that world, and the symbo ls that he at- taches to those concepts and uses in consciously manipulati ng the concepts ("thinking"). Methodology The methods, procedures, strategies, etc., with which an in dividual organizes his goal-centered (problem-solving) activity. Training The conditioning needed by the human being to bring his skills in using Means 1, 2, and 3 to the point where they are operationally eﬀective . Manuscript submitted to ACM Designing AI Systems that Augment Human Performed vs. Demon strated Critical Thinking 5 5 CONCLUSION The rapid development and integration of AI systems in our everyday lives raises questions not only for their impact on human cognitive abilities but also for established concepts and methodologies in research. Focusing on critical thinking, this position paper identiﬁes the need to further distingui sh types of critical thinking in the era of AI: performed versus demonstrated critical thinking. Via such distinction, we discuss the nua nces in current research ﬁndings regarding the impact of AI systems on human critical thinking, calling for explicit considerations of this distinction in future stud ies. More importantly, such a distinction implicates our design of AI systems to augment critical thinking. We encourage researchers and developers to keep this distinction in mind as systems that augment demonstrated critical thinking are not the same as those that augment performed critical thinking. REFERENCES [1] Claudia Alarcón-López, Pius Krütli, and Denis Gillet. 2 024. Assessing ChatGPT’s Inﬂuence on Critical Thinking in S ustainability Oriented Activities. In 2024 IEEE Global Engineering Education Conference (EDUCON ). 1–10. https://doi.org/10.1109/EDUCON60312.2024.1057 8790 [2] Benjamin S Bloom, Max D Engelhart, EJ Furst, Walker H Hill , and David R Krathwohl. 1956. Handbook I: cognitive domain. New York: David McKay (1956), 483–498. [3] Ching-Yi Chang, Hui-Chen Lin, Chengjiu Yin, and Kai-Hsi ang Yang. 2025. Generative AI-assisted reﬂective writing f or improving students’ higher order thinking. Educational Technology & Society 28, 1 (2025), 270–285. [4] Ruiguo Cui and Lili Zhao. 2024. Assessing Students’ Crit ical Thinking in Dialogue. Journal of Intelligence 12, 11 (2024), 106. [5] Sara Beth Elson, Robert O. Hartman, Adam Beatty, Matthew J. Trippe, Kerry W. Buckley, John Bornmann, Elaine M. Bochni ewicz, Mark Lehner, Liliya Korenovska, Jessica Lee, Leslie D. Servi, Alison Din gwall, Paul Edward Lehner, Maurita Soltis, Mark Brown, Bran don Beltz, and Amber M Sprenger. 2018. Critical Analytic Thinking Skills: Do They Predict Job-Related Task Performance Above and Beyond Gene ral Intelligence? Public Administration and Development 1 (2018), 2. https://api.semanticscholar.org/CorpusID: 4951887 [6] Douglas C Engelbart. 2023. Augmenting human intellect: A conceptual framework. In Augmented Education in the Global Age . Routledge, 13–29. [7] Robert H Ennis. 1962. A concept of critical thinking . Harvard educational review. [8] P Facione, Noreen Facione, and Carol Giancarlo. 2001. Ca lifornia critical thinking disposition inventory: Invent ory manual. Millbrae. CA: Insight Assessment (2001). [9] John Follman, Carolyn Lavely, and Neal Berger. 1996. Inv entory of instruments of critical thinking. Informal Logic 18, 2 (1996). [10] Tina Gerdts-Andresen, Mette Tindvik Hansen, and Vigdi s Abrahamsen Grøndahl. 2022. Educational Eﬀectiveness: Va lidation of an Instrument to Measure Students’ Critical Thinking and Disposition. International Journal of Instruction 15, 1 (2022), 685–700. [11] Michael Gerlich. 2025. AI Tools in Society: Impacts on C ognitive Oﬄoading and the Future of Critical Thinking. Societies 15, 1 (Jan. 2025), 6. https://doi.org/10.3390/soc15010006 Number: 1 Publishe r: Multidisciplinary Digital Publishing Institute. [12] Chahna Gonsalves. 2024. Generative AI’s Impact on Crit ical Thinking: Revisiting Bloom’s Taxonomy. Journal of Marketing Education (Dec. 2024), 02734753241305980. https://doi.org/10.1177/027347532 41305980 Publisher: SAGE Publications Inc. [13] Maurice Jakesch, Advait Bhat, Daniel Buschek, Lior Zal manson, and Mor Naaman. 2023. Co-writing with opinionated l anguage models aﬀects users’ views. In Proceedings of the 2023 CHI conference on human factors in com puting systems. 1–15. [14] Artur Klingbeil, Cassandra Grützner, and Philipp Schr eck. 2024. Trust and reliance on AI—An experimental study on the extent and costs of overreliance on AI. Computers in Human Behavior 160 (2024), 108352. [15] Hao-Ping Hank Lee, Advait Sarkar, Lev Tankelevitch, Ia n Drosos, Sean Rintel, Richard Banks, and Nicholas Wilson. 2025. The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cogni tive Eﬀort and Conﬁdence Eﬀects From a Survey of Knowledge Wo rkers. (2025). [16] Wenxia Liu and Yunsong Wang. 2024. The eﬀects of using AI tools on critical thinking in English literature classes am ong EFL learners: An intervention study. European Journal of Education 59, 4 (2024), e12804. [17] James Prather, Brent N Reeves, Paul Denny, Brett A Becke r, Juho Leinonen, Andrew Luxton-Reilly, Garrett Powell, Ja mes Finnie-Ansley, and Eddie Antonio Santos. 2023. “It’s weird that it knows what i w ant”: Usability and interactions with copilot for novice pr ogrammers. ACM transactions on computer-human interaction 31, 1 (2023), 1–31. [18] Michael Scriven and Richard Paul. 1987. Critical think ing. In The 8th Annual International Conference on Critical Thinki ng and Education Reform, CA, Vol. 7. [19] Matthias Stadler, Maria Bannert, and Michael Sailer. 2 024. Cognitive ease at a cost: LLMs reduce mental eﬀort but co mpromise depth in student scientiﬁc inquiry. Computers in Human Behavior 160 (2024), 108386. https://doi.org/10.1016/j.chb.2024 .108386 [20] Paul Stapleton. 2001. Assessing critical thinking in t he writing of Japanese university students: Insights about assumptions and content familiarity. Written communication 18, 4 (2001), 506–548. [21] Stacy E Walker. 2003. Active learning strategies to pro mote critical thinking. Journal of athletic training 38, 3 (2003), 263. Manuscript submitted to ACM 6 Mei et al. [22] Goodwin Watson and Edward M. Glaser. 1980. Watson-Glas er critical thinking appraisal: Forms A and B Manual. [23] Thomas Weber, Maximilian Brandmaier, Albrecht Schmid t, and Sven Mayer. 2024. Signiﬁcant productivity gains thro ugh programming with large language models. Proceedings of the ACM on Human-Computer Interaction 8, EICS (2024), 1–29. [24] Brian White, Marilyne Stains, Marta Escriu-Sune, Eden Medaglia, Leila Rostamnjad, Clark Chinn, and Hannah Sevian . 2011. A novel instrument for assessing students’ critical thinking abilities. Journal of College Science Teaching 40, 5 (2011). [25] Cassandra Xia and Pattie Maes. 2013. The design of artif acts for augmenting intellect. In Proceedings of the 4th Augmented Human International Conference. ACM, Stuttgart Germany, 154–161. https://doi.org/10.11 45/2459236.2459263 accepted 24 March 2025 Manuscript submitted to ACM