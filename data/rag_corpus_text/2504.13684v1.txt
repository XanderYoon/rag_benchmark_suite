Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation XIANGRONG (DANIEL) ZHU, YUAN XU, and TIANJIAN LIU, The Hong Kong University of Science and Technology (Guangzhou), China JINGWEI SUN and YU ZHANG, Lenovo Research, China XIN TONG†, The Hong Kong University of Science and Technology (Guangzhou) and The Hong Kong University of Science and Technology, China Human cognition is constrained by processing limitations, leading to cognitive overload and inefficiencies in knowledge synthesis and decision-making. Large Language Models (LLMs) present an opportunity for cognitive augmentation, but their current reactive nature limits their real-world applicability. This position paper explores the potential of context-aware cognitive augmentation, where LLMs dynamically adapt to users’ cognitive states and task environments to provide appropriate support. Through a think-aloud study in an exhibition setting, we examine how individuals interact with multi-modal information and identify key cognitive challenges in structuring, retrieving, and applying knowledge. Our findings highlight the need for AI-driven cognitive support systems that integrate real-time contextual awareness, personalized reasoning assistance, and socially adaptive interactions. We propose a framework for AI augmentation that seamlessly transitions between real-time cognitive support and post-experience knowledge organization, contributing to the design of more effective human-centered AI systems. Additional Key Words and Phrases: Cognitive Support, Context Awareness, Large Language Models, Spatial Interactions, Proactive AI ACM Reference Format: Xiangrong (Daniel) Zhu, Yuan Xu, Tianjian Liu, Jingwei Sun, Yu Zhang, and Xin Tong. 2025. Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation. 1, 1 (April 2025), 8 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn 1 Introduction Human cognition is constrained by fundamental processing limitations, creating a gap between perception and reasoning [6]. While sensory systems acquire information at approximately 109 bits per second, cognitive processing operates at only about 10 bits per second [18]. This bottleneck limits individuals’ ability to synthesize, connect, and apply knowledge efficiently, often leading to cognitive overload and decision-making biases. LLMs offer a promising solution by augmenting human reasoning, but their current reactive nature restricts real-world applicability [ 19]. To bridge this gap, we propose context-aware cognitive augmentation, where LLMs dynamically adapt to users’ This paper was presented at the 2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning (AIREASONING-2025-01). This is the authors’ version for arXiv. ∗corresponding author Authors’ Contact Information: Xiangrong (Daniel) Zhu, xzhu744@connect.hkust-gz.edu.cn; Yuan Xu, yuanxu@hkust-gz.edu.cn; Tianjian Liu, tianjianl@ hkust-gz.edu.cn, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Jingwei Sun, sunjw12@lenovo.com; Yu Zhang, zhangyu29@lenovo.com, Lenovo Research, Beijing, China; Xin Tong, The Hong Kong University of Science and Technology (Guangzhou) and The Hong Kong University of Science and Technology, Guangzhou, China, xint@hkust-gz.edu.cn. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. Manuscript submitted to ACM Manuscript submitted to ACM 1 arXiv:2504.13684v1 [cs.HC] 18 Apr 2025 2 Zhu et al. cognitive states and task environments, proactively assisting in information processing, structured reasoning, and decision-making. By integrating multi-modal signals and real-time context, LLMs can move beyond passive knowledge retrieval to actively supporting human cognition in complex, information-rich settings. Human cognition follows a structured process that filters, interprets, and applies information [8]. Perception channels sensory inputs (e.g., vision, audition, touch), but selective attention limits what enters cognitive processing. Cognitive mechanisms then organize and integrate the selected information, constrained by working memory capacity and processing bandwidth [11]. Finally, individuals apply processed knowledge in real-world tasks, yet memory retrieval often suffers from decay and reconstruction, affecting accuracy and efficiency [13]. Understanding these limitations is critical for designing AI-driven cognitive support systems that enhance human reasoning. However, supporting human cognition effectively requires more than just providing access to vast amounts of information. The ability to filter, contextualize, and apply relevant knowledge in real time is crucial for mitigating cognitive constraints. Despite their potential, existing LLMs lack contextual awareness, providing one-size-fits-all responses rather than adapting to users’ cognitive processes [2]. Effective augmentation requires LLMs to be proactive, leveraging real-time contextual information to tailor responses and facilitate structured reasoning. Our preliminary study tends to investigate two research questions: • How do individuals sense, process, and apply information in real-world tasks, and what cognitive support do they expect? • How should AI-driven cognitive support systems be designed to enhance knowledge augmentation? To explore these questions, we conducted a think-aloud study in an exhibition setting. Participants navigated exhibits while capturing and synthesizing information for later use. This scenario provided a rich multi-modal environment to observe cognitive behaviors. Findings reveal challenges in structuring contextual information, retrieving knowledge, and leveraging digital tools for context-aware, structured, and proactive engagement. Based on these insights, we outline a context-aware cognitive augmentation approach that allows LLMs to adjust responses dynamically based on user interactions and cognitive needs. This work contributes by identifying key cognitive challenges in knowledge augmentation, offering empirical insights into users’ expectations for AI-driven support, and suggesting design considerations for integrating context-aware reasoning into LLM-based systems. 2 Related Work 2.1 Context-Aware in AI-Augmented System With the current information explosion [ 10], the amount of data we can access keeps increasing. A core objective of modern AI-augmented systems is to help people collect and process information within limited attention spans and working memory capacities [20]. Chen et al. [5] proposed LangAware, which uses in-situ contextual data to filter unnecessary notifications, allowing people to reduce cognitive burdens in different life scenarios, thus achieving better human-machine collaboration. Another approach involves user embeddings, where AI systems create numerical representations of a user’s interac- tion history and cognitive style [12]. These embeddings allow LLMs to adjust response styles dynamically, improving personalization. However, they lack structured knowledge dependencies, such as how a user’s beliefs evolve over time or how exposure to new perspectives influences reasoning [17]. Knowledge graphs provide a structured method for representing user information, encoding their knowledge, preferences, and prior interactions into a graph-based system. AI models can query these graphs to retrieve personalized Manuscript submitted to ACM Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation 3 insights, which has been particularly effective in educational AI systems [ 1]. However, applying them to support knowledge-intensive tasks still poses an open research challenge [11]. 2.2 LLM-Empowered Cognitive Augmentation Knowledge Augmentation plays a pivotal role in our life [4, 7], particularly for people with memory impairments [13]. With LLMs demonstrating strong language understanding and mass information processing capabilities [11], having driven innovative applications in information collection. For example, Baek et al. [2] applied LLMs to analyze users’ search engine interaction history as contextual data, providing more personalized web search results. However, this work was limited to traditional desktop interactions without real-world environment integration. Cai et al. [3] further identified interesting but overlooked environmental information through an LLM-empowered system combining explicit and implicit initial triggers. Information organization constitutes another crucial component in knowledge augmentation systems. Yu et al. [16] proposed Bnotehelper, which uses LLMs to rapidly generate note outlines from video content. However, this process neglected the importance of human-in-the-loop mechanisms. Yen et al. [ 15] tackle organizational challenges by transforming static LLM conversation histories into interactive object. LLMs should also assist people in naturally utilizing stored information during daily life. Zulfikar et al. [20] made progress by implementing LLMs that anticipate users’ memory needs through conversational context analysis, reducing retrieval effort. However, their framework focuses exclusively on textual information, neglecting the growing prevalence of visual data like images and videos in personal knowledge systems [9]. 3 Think-Aloud Study 3.1 Study Design To explore how users interact with and record information in a real-world context, we conducted a think-aloud study in an exhibition setting. Participants were tasked with exploring the exhibition, where they encountered various types of information, and were given the flexibility to define and experiment with any interaction mode they deemed suitable for capturing information. Throughout the process, we recorded their interactions via video, capturing what types of information they chose to record, the methods they employed for documentation, and their cognitive processes in interpreting the content. 3.1.1 Exhibition Setting. The study was conducted in the visitor center of our institution, an information-rich exhibition space designed to showcase the university’s research, academic achievements, and institutional history. The exhibition featured a diverse range of interaction channels, including virtual reality (VR), gesture-based interfaces, desktop- based interactions, museum-like installations, video and audio content, and immersive experiences. This multi-modal environment provided a complex, information-intensive setting where participants engaged with dense academic material through various sensory and interactive modalities. Participants were required to navigate, filter, and synthesize information across multiple formats, often switching between passive consumption (e.g., reading and watching videos) and active interaction (e.g., VR exploration and gesture-based engagement). Additionally, the setting introduced contextual challenges such as time constraints, selective attention demands, and varying levels of engagement across different media. By analyzing participants’ behaviors in this environment, we aimed to uncover how individuals process and retain complex academic content and how AI-driven cognitive augmentation can enhance structured reasoning and information synthesis. Manuscript submitted to ACM 4 Zhu et al. Fig. 1. Overview of the exhibition setup, which includes different modalities of information presentation and interaction. The exhibition integrates various digital and physical interfaces, including large-scale digital displays for visual information (a), textual and interactive tabletop interfaces for content exploration (c, f, g), object-based museum-like exhibits (d), and sensor-based gesture interaction (e). Additionally, there are also immersive simulations (h), which provides an overview of the campus resources and map. The information is mainly composed of academic content (b, c, d, e, f, g) and school information (a, h) 3.1.2 Participants. We recruited three participants, all of whom were MPhil or PhD students from the university. Each participant had at least five years of experience in design or development, making them well-versed in knowledge- intensive tasks and interactive systems. Their background ensured they were familiar with information structuring, digital interaction, and knowledge processing, making their insights valuable for understanding cognitive augmentation needs. 3.1.3 Procedure. Before beginning the study, participants were informed that they would need to write a report summarizing key insights from their exhibition visit. This task was designed to ensure they had a concrete goal while navigating the space, encouraging natural engagement with the information. The study followed a think-aloud protocol, where participants freely explored the exhibition while verbalizing their thoughts, strategies, and challenges in processing information. They were allowed to interact with various media, including text, videos, VR, and gesture-based interfaces, and to record notes in any format they preferred. Their interactions were observed and recorded for post-analysis. After the exhibition walkthrough, a semi-structured interview was conducted to capture reflections on their experience, challenges in synthesizing information, and expectations for AI-driven cognitive support. Manuscript submitted to ACM Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation 5 This study was conducted in compliance with institutional ethical guidelines and received approval from the university’s Institutional Review Board (IRB). Participants provided informed consent before participation, and all data were anonymized to protect their privacy. 3.2 Preliminary Findings 3.2.1 Participants’ Information Processing Strategies. Participants processed information through multiple modalities, including text, video, and interactive displays. They used textual content for comprehension and later reference, with some reading aloud to reinforce understanding and others storing text for post-visit review. They treated video recordings as a backup for later reflection rather than an immediate resource. They captured photographs to document key information but struggled with organization and retrieval. Two of the participants (N=2/3) mentioned the intention to annotate images in real-time. Participants unconsciously collected additional information through movement patterns, navigation sequences, and habitual gestures such as finger-pointing and silent reading. For example, a participant is habitually pointing and silently reading the content they are interested to. They took personal notes that focused more on subjective impressions than on structured content, making later recall difficult. These behaviors showed that participants engaged in both explicit and implicit information processing, requiring AI support to help structure and retrieve knowledge effectively. 3.2.2 Environmental and Social Constraints in Context-Aware AI Interaction. Participants adjusted their engagement strategies based on environmental and social constraints. They hesitated to provide real-time verbal commentary due to privacy concerns. They avoided taking photographs in dimly lit areas to prevent disturbing others. They minimized interactions requiring overt gestures or spoken input to maintain discretion in a shared public setting. These behaviors demonstrated a major limitation in existing AI-driven cognitive augmentation systems. AI systems fail to recognize social and environmental contexts, leading to rigid or intrusive interactions. Participants needed AI support that could adapt to their surroundings, offering subtle interaction methods such as silent note-taking suggestions, discreet notifications for summarization, and adaptive interfaces that adjusted based on the environment. The exhibition setting also introduced cognitive load challenges, requiring participants to selectively focus on key information while filtering distractions. AI tools need to track users’ cognitive states and provide timely, relevant support, such as summarizing dense content or reinforcing key insights. 3.2.3 Participants’ Expectations for Adaptive AI Support. Participants identified two key areas where AI could improve their experience: (1) real-time comprehension support and (2) post-visit knowledge organization. They needed AI systems to help process and contextualize information as they explored, rather than requiring them to manually curate their knowledge afterward. They also expected AI to assist in aggregating, organizing, and structuring recorded content for later reference. Participants demonstrated different cognitive workflows for structuring information. A participant constructed broad conceptual frameworks before revisiting specific details. Two others adopted a detail-oriented approach, capturing comprehensive information first before synthesizing key insights. These differences showed that rigid, one-size-fits-all AI models failed to support diverse cognitive needs. AI-driven augmentation need to recognize user-specific cognitive patterns and dynamically adjust interventions—whether by prompting reflective questions, restructuring information hierarchically, or offering personalized synthesis tools. Manuscript submitted to ACM 6 Zhu et al. 3.3 Implications for Context-Aware Cognitive Augmentation Participants’ behaviors suggest the potential benefits of multi-modal, context-sensitive, and adaptive AI systems in supporting human cognition. Existing AI models primarily rely on reactive interactions, requiring users to explicitly request information [14]. However, our findings indicate that AI systems could be more effective if theyadapted to users’ cognitive states and environments to provide more relevant support. Based on these observations, we outline key considerations for designing AI-driven cognitive augmentation systems: • Multi-modal Awareness: AI could integrate text, images, movement patterns, and behavioral cues to enhance contextualized knowledge augmentation. • Cognitive Workflow Adaptation: AI might benefit from recognizing whether a user is engaging in exploratory or structured information processing and adjusting its interventions accordingly. • Socially Adaptive Interaction: AI should consider offering discreet, unobtrusive engagement methods that respect social constraints while assisting cognition. • Seamless Transition Between Real-Time and Long-Term Support: AI could function both as a real-time cognitive assistant and a post-experience knowledge synthesizer. 4 Conclusion Our study highlights the critical need for AI systems that go beyond static, prompt-driven interactions to proactively assist users in sensing, processing, and utilizing information in real-world tasks by adapting to cognitive constraints and integrating seamlessly into daily workflows. By examining how individuals engage with information in real- world settings, we identified key challenges in context-aware knowledge capture, information organization, and adaptive cognitive support. Our findings reinforce that effective AI-driven cognitive augmentation must be multi-modal, personalized, and socially adaptive—capable of understanding user behaviors, guiding engagement dynamically, and transitioning seamlessly between real-time assistance and long-term cognitive scaffolding. Building upon these insights, future research should focus on developing structured user-context knowledge spaces that empower LLMs to function as proactive collaborators rather than passive responders. By incorporating context-awareness, proactive engagement, and structured knowledge integration, AI systems can move closer to fostering meaningful, personalized cognitive augmentation. Acknowledgments We thank CCF-Lenovo Research Fund (Grant No. 20240102) for supporting this work. We also acknowledge the support from Guangdong Provincial Key Lab of Integrated Communication, Sensing and Computation for Ubiquitous Internet of Things (No.2023B1212010007). References [1] Hasan Abu-Rasheed, Christian Weber, and Madjid Fathi. 2024. Knowledge graphs as context sources for llm-based explanations of learning recommendations. In 2024 IEEE Global Engineering Education Conference (EDUCON) . IEEE, 1–5. [2] Jinheon Baek, Nirupama Chandrasekaran, Silviu Cucerzan, Allen Herring, and Sujay Kumar Jauhar. 2024. Knowledge-augmented large language models for personalized contextual query suggestion. In Proceedings of the ACM Web Conference 2024 . 3355–3366. [3] Runze Cai, Nuwan Janaka, Hyeongcheol Kim, Yang Chen, Shengdong Zhao, Yun Huang, and David Hsu. 2025. AiGet: Transforming Everyday Moments into Hidden Knowledge Discovery with AI Assistance on Smart Glasses. arXiv preprint arXiv:2501.16240 (2025). [4] Samantha WT Chan. 2020. Biosignal-sensitive memory improvement and support systems. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems . 1–7. Manuscript submitted to ACM Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation 7 [5] Weihao Chen, Chun Yu, Huadong Wang, Zheng Wang, Lichen Yang, Yukun Wang, Weinan Shi, and Yuanchun Shi. 2023. From gap to synergy: Enhancing contextual understanding through human-machine collaboration in personalized systems. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology . 1–15. [6] L. Goette, H. J. Han, and B. T. K. Leung. 2020. Information Overload and Confirmation Bias. (2020). doi:10.17863/CAM.52487 [7] M. F. Hau. 2024. Towards ‘augmented sociology’? A practice-oriented framework for using large language model-powered chatbots.Acta Sociologica (2024). doi:10.1177/00016993241264152 [8] Martin Hilbert and Priscila López. 2011. The World’s Technological Capacity to Store, Communicate, and Compute Information. Science 332, 6025 (2011), 60–65. doi:10.1126/science.1200970 arXiv:https://www.science.org/doi/pdf/10.1126/science.1200970 [9] Yongquan Hu, Jingyu Tang, Xinya Gong, Zhongyi Zhou, Shuning Zhang, Don Samitha Elvitigala, Florian’Floyd’ Mueller, Wen Hu, and Aaron J Quigley. 2025. Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design. arXiv preprint arXiv:2501.13443 (2025). [10] M. Kitsuregawa and T. Nishida. 2010. Special Issue on Information Explosion. New Generation Computing 28 (2010), 207–215. doi:10.1007/s00354- 010-0086-8 [11] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems 33 (2020), 9459–9474. [12] Lin Ning, Luyang Liu, Jiaxing Wu, Neo Wu, Devora Berlowitz, Sushant Prakash, Bradley Green, Shawn O’Banion, and Jun Xie. 2024. User-llm: Efficient llm contextualization with user embeddings. arXiv preprint arXiv:2402.13598 (2024). [13] Jennifer Rhiannon Roberts, Catrin Hedd Jones, Gill Windle, and Caban Group. 2023. Knowledge Is Power: Utilizing Human-Centered Design Principles with People Living with Dementia to Co-Design a Resource and Share Knowledge with Peers. International Journal of Environmental Research and Public Health 20, 20 (2023), 6937. [14] Li Shi, Houjiang Liu, Yian Wong, Utkarsh Mujumdar, Dan Zhang, Jacek Gwizdka, and Matthew Lease. 2024. Argumentative Experience: Reducing Confirmation Bias on Controversial Issues through LLM-Generated Multi-Persona Debates. arXiv preprint arXiv:2412.04629 (2024). [15] Ryan Yen and Jian Zhao. 2024. Memolet: Reifying the Reuse of User-AI Conversational Memories. InProceedings of the 37th Annual ACM Symposium on User Interface Software and Technology . 1–22. [16] Fangyu Yu, Peng Zhang, Xianghua Ding, Tun Lu, and Ning Gu. 2024. BNoteHelper: a note-based outline generation tool for structured learning on video-sharing platforms. ACM Transactions on the Web 18, 2 (2024), 1–30. [17] Zhehao Zhang, Ryan A Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, et al. 2024. Personalization of large language models: A survey. arXiv preprint arXiv:2411.00027 (2024). [18] Jieyu Zheng and Markus Meister. 2025. The unbearable slowness of being: Why do we live at 10 bits/s? Neuron 113, 2 (Jan. 2025), 192–204. doi:10.1016/j.neuron.2024.11.008 Publisher: Elsevier. [19] Lexin Zhou, Wout Schellaert, Fernando Martínez-Plumed, Yael Moros-Daval, Cèsar Ferri, and José Hernández-Orallo. 2024. Larger and more instructable language models become less reliable. Nature 634, 8032 (2024), 61–68. [20] Wazeer Deen Zulfikar, Samantha Chan, and Pattie Maes. 2024. Memoro: Using large language models to realize a concise interface for real-time memory augmentation. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems . 1–18. A Semi-Structured Interview Guide This appendix presents the semi-structured interview guide used in our study. A.1 Information Needs • What specific information is essential for writing about the exhibition? • How do you determine what data to collect during the visit? A.2 Interaction Preferences • What is the best way to interact with the data collection system? • Are certain interactions more intuitive or effective? • What are the public concerns regarding interaction with such a system? A.3 Data Organization • How should the system organize the collected data? Manuscript submitted to ACM 8 Zhu et al. • Should there be a data organization/reorganization step? How do you prefer to participate in this step? • Do you prefer manual involvement in organizing the data, or should AI handle this step? A.4 Collaboration with AI • What role should AI play in assisting with organizing data during writing/preparing for presentation? • How can collaboration between the user and AI be improved? A.5 Information Triggers • What types of information should be captured during the tour? • Are there specific triggers or guidelines for initiating data collection? • Do you think there are some guidelines regarding the information collection/trigger process? Manuscript submitted to ACM