IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Xingliang Hou 1 Yuyan Liu1 Qi Sun 1 Haoxiu Wang 2 Hao Hu 3 Shaoyi Du 3 Zhiqiang Tian 1 Abstract Retrieval-augmented generation (RAG) equips large language models (LLMs) with reliable knowledge memory. To strengthen cross-text as- sociations, recent research integrates graphs and hypergraphs into RAG to capture pairwise and multi-entity relations as structured links. How- ever, their misaligned memory organization ne- cessitates costly, disjointed retrieval. To address these limitations, we propose IGMiRAG, a frame- work inspired by human intuition-guided reason- ing. It constructs a hierarchical heterogeneous hypergraph to align multi-granular knowledge, incorporating deductive pathways to simulate re- alistic memory structures. During querying, IG- MiRAG distills intuitive strategies via a question parser to control mining depth and memory win- dow, and activates instantaneous memories as an- chors using dual-focus retrieval. Mirroring human intuition, the framework guides retrieval resource allocation dynamically. Furthermore, we design a bidirectional diffusion algorithm that navigates deductive paths to mine in-depth memories, em- ulating human reasoning processes. Extensive evaluations indicate IGMiRAG outperforms the state-of-the-art baseline by 4.8% EM and 5.0% F1 overall, with token costs adapting to task com- plexity (average 6.3 k+, minimum 3.0 k+). This work presents a cost-effective RAG paradigm that improves both efficiency and effectiveness. 1School of Software Engineering, Xi’an Jiaotong University 2School of Engineering, Westlake University 3State Key Labora- tory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center for Visual Information and Applica- tions, and Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University. Correspondence to: Zhiqiang Tian <zhiqiang- tian@xjtu.edu.cn>. Preprint. February 10, 2026. 1. Introduction Humans instantly activate long-term memory and think rapidly to generate goal-directed solutions in complex envi- ronments. Our cognitive maturity is rooted in the continuous consolidation of memory and reasoning. While Large Lan- guage Models (LLMs) leverage vast parametric knowledge for broad competence (Naseer et al., 2024; Dagdelen et al., 2024; Ullah et al., 2024), their rigid, static memory often causes hallucinations. This limits their reliability for high- precision and complex decision-making tasks in dynamic environments (Huang et al., 2025b; Jones, 2025). To enhance LLM expertise and reliability, Retrieval- Augmented Generation (RAG) has become a dominant approach by non-parametrically integrating external knowl- edge, enabling low-cost updates (Lewis et al., 2020; Asai et al., 2023). However, its reliance on flat vector similarity limits deep reasoning by failing to capture complex mem- ory connections (Xie et al., 2023; Zhong et al., 2024). To address this, recent research (Edge et al., 2024; Huang et al., 2025a) attempts to build structured knowledge repositories. Graph-enhanced methods (Tian et al., 2024; Wang et al., 2025) map pairwise relationships as edges to form seman- tic paths, while hypergraph-enhanced methods (Feng et al., 2025; Hu et al., 2025) further leverage hyperedges to model high-order concepts like processes and events to establish associative paths among multiple entities. Although these methods have built structured memory banks with semantic links, their homogeneous modeling often iso- lates basic and high-order knowledge as structurally dis- parate nodes and edges. This architectural misalignment leads to costly, fragmented retrieval, resulting in poor multi- hop reasoning and generalization (Jimenez Gutierrez et al., 2024). Therefore, recent work (Xu et al., 2025; Guti ´errez et al., 2025) employs heterogeneous graphs to align memo- ries within a unified relevance space to mitigate this limita- tion, but the resulting connections remain limited to binary relations and lack systematic modeling. Consequently, such disordered, low-order connectivity fundamentally limits the depth of memory association and reasoning. How can RAG’s memory retrieval be optimized without significant computational overhead? Inspired by human 1 arXiv:2602.07525v1 [cs.IR] 7 Feb 2026 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory A Ecouple treat G Q 1: Who is A’s wife? A1: E is the wife of ASo easy, i know A and E are a couple. A2: I think he is a doctor because his friends A and B have treated G together, and A is a doctor. C friends A B treat G couple Q2: What might be C's occupation? It's a bit difficult. I don't know the occupation of C. Stage 1: Structured Memory construction Stage 2: Intuition Instantly Emerging Stage 3: Reasoning Dynamically Q3: Please briefly describe the marital status of couples from A to H. A3: A and E are a couple a n d a r e r e s p e c t i v e l y a doctor and a lawyer. They... There is another couple, D and F. D is an athlete and F is also a lawyer. They... It's too difficult, b e c a u s e I n e e d more information to describe clearly! L e t m e t h i n k i t over carefully. couple A E D F colleague teammate treat G H couple Stage 4: Answering Accordingly Relation Memory Space Event Memory Space B? C? treat G friends Atomic Entity Memory Space teammate H is a football player... colleague A is a male doctor... couple E is a lawyer... couple D? F? Figure 1. Stage1 represents the formation of human memory, while Stage2–Stage4 represent intuition-guided reasoning mechanism in human cognition. Upon query encounter, we instantaneously assess and retrieve memory anchors, followed by deeper associative recall. intuition-guided reasoning, we proposeIGMiRAG, a novel framework featuring a more authentic memory architec- ture. As illustrated in Stage1 of Figure 1, the human brain organizes knowledge into a hierarchical associative network. This structure arises from inherent deductive path- ways: high-order memories aggregate multiple low-order atomic facts, while single atoms contribute to various high- level concepts. Thus, knowledge is stored in a hierarchy that integrates multi-order associations. Grounded in this, IG- MiRAG emulates this structure using a Hierarchical Hetero- geneous Hypergraph, where heterogeneous vertices repre- sent multi-granular knowledge and hierarchical hyperedges model deductive pathways. This design establishes a foun- dation for efficient, human-like retrieval. In response to specific tasks (Stage2−Stage4 in Figure 1), humans rapidly activate experiential memories to form intu- ition, determining strategies and locating key memory an- chors. Strategy-guided reasoning then proceeds along hier- archical deductive pathways. This association is inherently bidirectional: top-down (broadcast) activates subordinate low-order memories to enrich details, whereas bottom-up (screening) integrates shared high-order memories to dis- till abstraction. This enables efficient, in-depth reasoning within hierarchical repositories, facilitating precise deci- sions. Inspired by this, IGMiRAG introduces a two-stage retrieval paradigm. First, it analyzes the query to generate an intuitive strategy, guiding the entire retrieval process. Subse- quently, it executes preference-aware bidirectional diffusion based on activated anchors, thereby mining deep memories. Our main contributions are as follows: • Better Memory Architecture: We propose a Hier- archical Heterogeneous Hypergraph to model multi- granular knowledge, capturing deductive associations via hierarchical hyperedges. This architecture emulates human memory hierarchy, enabling interpretable and efficient retrieval. • Efficient Retrieval Paradigm: We introduce an intuition-inspired “Strategy-Diffusion” two-stage re- trieval paradigm. By first generating an intuitive strat- egy to guide the depth and scope of memory access, followed by anchor-based associative diffusion, this paradigm significantly improves both precision and efficiency with lower retrieval cost. • In-Depth Reasoning Mechanism: We design a preference-aware bidirectional diffusion algorithm. By performing adaptive mining from anchors along the deductive pathways, it integrates top-down detail en- richment and bottom-up abstraction to support deep reasoning and significantly improve decision accuracy. Evaluations on six benchmarks show IGMiRAG outper- forms the state-of-the-art baseline by 4.8% EM and 5.0% F1 on average, with token costs adapting to task difficulty. These results validate that by mimicking intuition-guided reasoning, our approach improves efficiency while simulta- neously enhancing memory precision and reasoning depth, offering a viable solution to memory fragmentation and retrieval inefficiency in RAG systems. 2. Related Works Structure Optimization.Text-based RAG methods (Lewis et al., 2020; Gao et al., 2023a) extend LLM capabilities by simply concatenating raw text chunks, but often struggle with semantic sparsity and cross-contextual tasks (Gupta et al., 2024). Recent work has introduced graphs to sys- tematically capture entity-level relationships, enhancing the richness of knowledge connections. However, these meth- ods overlook higher-order multi-entity interactions, leading to information gaps (Srinivasan et al., 2018; Santos et al., 2022; Labatut & Bost, 2019). GraphRAG (Edge et al., 2024) thus supplemented thematic summaries with dense commu- nity reports to enable macroscopic analysis. Hypergraphs extend graphs by enabling a single hyperedge to connect multiple vertices at once (Gao et al., 2022; Feng et al., 2024). 2 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory leveraging this capability, Hyper-RAG (Feng et al., 2025) further unifies high-order multi-entity relations, thereby re- ducing fragmentation. Nevertheless, both homogeneous graphs and hypergraphs only capture surface-level seman- tic links. While NodeRAG (Xu et al., 2025) introduced node-type heterogeneity to encode cross-granular structural connections, IGMiRAG advances further by constructing a hierarchical heterogeneous hypergraph whose layered hy- peredges explicitly encode deductive pathways, achieving improvements at both structural and semantic levels. Query Optimization.Beyond structural enrichment, a complementary line of work optimizes the query side to improve recall. Query rewriting narrows semantic gaps via context augmentation or rephrasing (Gao et al., 2023b), while query decomposition iteratively retrieves sub-answers through progressive queries to construct final answers (Chen et al., 2025b). HyDE (Gao et al., 2023a) generated hypo- thetical documents to enhance dense retrieval. Furthermore, keywords are also extracted to provide term-based matching with methods like BM25 (Robertson & Walker, 1994). Al- though these methods have made improvements over static searchable sources, they still employ fixed strategies that lack task adaptivity. IGMiRAG departs from this paradigm by parsing intuitive strategies from queries to jointly adapt the retrieval process, thereby enabling adaptive deep mining. Retrieval Optimization.Beyond these optimizations, some studies enhance retrieval effectiveness to obtain more rel- evant knowledge. LightRAG (Guo et al., 2024) employs bidirectional expansion to augment adjacent knowledge. PathRAG (Chen et al., 2025a) applies streaming pruning to suppress redundant paths. Cog-RAG (Hu et al., 2025) adopts a cognitive two-stage retrieval to ensure thematic consistency. The PPR (Haveliwala, 2002) algorithm is em- ployed to mine multi-hop nodes (Xu et al., 2025). Despite these refinements, they are still constrained in multi-hop reasoning. Guided by strategies, IGMiRAG drives a depth- adaptive process via deductive pathways to mine in-depth knowledge, significantly advancing multi-hop performance. 3. IGMiRAG 3.1. Overview As illustrated in Figure 2, IGMiRAG consists of four core components: HHHG Index, Retrieval-Strategy Parser (RSP), Intuitive Anchors Retrieval, and Adaptive Deep Min- ing. Specifically, IGMiRAG employs an HHHG to encode knowledge memories and deductive pathways. Prior to re- trieval, the RSP module distills intuitive strategies from queries, providing interpretable guidance for subsequent retrieval processes. Subsequently, the framework first iden- tifies high-quality knowledge as intuitive anchors via BM25 string matching and dual-focus retrieval. During the deep mining phase, IGMiRAG performs preference-aware bidi- rectional diffusion along deductive pathways to uncover latent, relevant knowledge memories. Finally, knowledge and chunks are adaptively selected based on semantic depth, which reflects the question complexity, yielding a compact yet highly relevant context that enables accurate and efficient knowledge-enhanced generation. 3.2. Index construction 3.2.1. HIERARCHICALHETEROGENEOUSHYPERGRAPH By unifying four knowledge memory types and hierarchi- cally modeling their deductive pathways, the HHHG archi- tecture addresses the limitations of homogeneous graphs and hypergraphs in aligning diverse knowledge and cross- dimensional links simultaneously. Within IGMiRAG, an LLM-based analyzer processes raw chunks D, encoding extracted entities N , binary relations L, and multi-entity relationsHas dimensionally consistent heterogeneous ver- tices. Deductive pathways are then encoded via hierarchical hyperedges, including LR (N ↔ L ) and HR (N ↔ H ). Formally as follows: GHHHG = (V,E),(1) V=N ∪ L ∪ H,E=LR ∪ HR.(2) Furthermore, D and F R ({N,L,H} ↔ D ) serve exclu- sively to preserve source-text mapping. The internal struc- tures ofN,L, andHare uniformly formalized as follows: N=  ⟨Na N i ,De N i ,A N i ⟩ |N | i=1, L=  ⟨Na L j ,De L j ,A L j ⟩ |L| j=1,(3) H=  ⟨Na H k ,De H k ,A H k ⟩ |H| k=1, where Na, De, and A denote thename,semantic descrip- tion, andadditional informationof knowledge memories respectively. For L and H, uniqueness is ensured by con- catenating the associated entity names in a fixed order. 3.2.2. DUAL-FOCUSINDEX The Hierarchical Navigable Small World (HNSW) algo- rithm (Malkov & Yashunin, 2018) is employed to construct a semantic-vector index for knowledge memories. Notably, within the unified semantic space of the HHHG, single-pass global approximate nearest-neighbor retrieval is prone to cross-type semantic drift. This occurs when vectorially proximate yet typologically irrelevant units introduce false positives, thereby degrading recall precision. To mitigate this drift, IGMiRAG introducesDF-Index, a dual-focus in- dexing library that operationalizes the intuitive focus within queries through local indexing over type-specific features. The specific construction process is as follows: IG = HNSW({De N ,De L,De H}),(4) 3 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Documents Books Reports Chunk 1 Chunk 2 Chunk 3 Chunk n ... LLM Multi-Entity Relations Atomic Entities Pairwise Relations Indexing: Index with HHHG and DF-Index User Queries Hypergraph DB DF-Index based on HNSW BM25 HNSW-L2 HNSW-L1 HNSW-G HNSW-L3 HHHG Knowledge Vertices Description of Vertices Name of Vertices KE: Key Entities QI: Query Intentions l: Target Layer m: Matching Score NQ: Rewriten Query Intuitive Anchors Retrieval ... Memory Anchors Retrieval Strategy Paser Preference-Aware Bidirectional DiffusionMemory Context Window In-Depth Memories ... Relevant Chunks ... d: Semantic Depth A B C LLM Intuition Response D E Adaptive Deep MiningHHHG Index Knowledge Memory Extraction Retrieval: Intuition Inspired Two-Stage Retrieval Figure 2.The framework of IGMiRAG. Indexing:A. An LLM-based analyzer extracts multi-granular knowledge memories from each chunk.BOrganizing all knowledge into a hierarchical heterogeneous hypergraph (HHHG) persisted in HyperGraph-DB. The semantic descriptions of all units are embedded and indexed as a global–local dual-focus HNSW index (DF-Index), and a separate BM25 corpus is built from name fields.Retrieval:C. An LLM-based Retrieval-Strategy Parser (RSP) distills strategies from user queries by simulating human intuition response.D. Multi-channel recall, combining BM25 string matching with dual-focus vector retrieval, identifies high-quality seed vertices as intuitive memory anchors.E. Preference-aware bidirectional diffusion traverses the HHHG to mine latent, in-depth memories. These units are then aggregated into a context window, the size of which is dynamically scaled according to query complexity, before being fed to the LLM. Two examples of the indexing and Retrieval process are provided in Appendix B. IL = HNSW(X),X ∈ {De N ,De L,De H}.(5) Global Indexinginserts thesemantic-descriptionvectors of all knowledge into a single HNSW graph IG. This establishes a cross-type global navigation structure, en- abling rapid localization of candidate regions across the entire knowledge space.Local Indexingconstructs separate HNSW subgraphs IL for vectors of each type in {N,L,H} . Searching within these type-homogeneous neighborhoods could provide targeted supplements to the global candidates. 3.3. Query Parsing User queries imply high-level strategic cues that integrate surface semantics with task-specific features (e.g., evalua- tive focus and response difficulty). To exploit these cues, IGMiRAG employs an LLM-based RSP that simulates in- tuitive judgment. Beyond generating standard outputs, in- cluding the rewritten query (NQ), key entities (KE), and query intent (QI ), the RSP explicitly extracts two implicit signals. These signals provide fine-grained control over the subsequent retrieval and reasoning pathways. Target Layer l and Matching Score m.The RSP predicts the knowledge layerl∈ {N,L,H} most critical for answer- ing and assigns a coverage score m∈[1,5]∩Z reflecting the comprehensiveness of the query regarding that layer. The (l,m) pair directs target-layer selection and modulates the global–local weighting during dual-focus retrieval. Semantic Depth d.The RSP analyzes NQ to estimate complexity, abstraction, and inference depth, producing a semantic depth d∈[1,5]∩Z . The depth determines the number of diffusion iterations and the context-window size. By decomposing the query into a multidimensional retrieval strategy, the RSP shifts retrieval from a passive, static pro- cess to an active, strategy-guided one, providing an inter- pretable and quantifiable basis for adaptive deep mining. 3.4. Intuitive Anchors Retrieval 3.4.1. MULTI-CHANNEL RECALL Keywords Matching.Using the KE and QI produced by the RSP, IGMiRAG forms a composite query via term concatenation. BM25 matching is subsequently applied to the name field of all knowledge units, with the resulting candidatesC BM25 ranked by descending BM25 score. 4 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Dual-Focus Vector Retrieval (DF-Retrieval).Beyond key- word matching, IGMiRAG employs a dual-focus semantic retrieval mechanism. Guided by the target layerl and match- ing score m provided by the RSP, the system searches the corresponding HNSW subgraph, thereby reinforcing global recall while suppressing cross-type semantic drift. Given a base quota kb, and the allowed bounds kmin, kmax for global retrieval, and the dynamic quota for DF-Retrieval are defined as follows: kG = min l 1− m 6  ·k b +k min m , k max  ,(6) kL = j m 6 ·k b k .(7) The resulting candidates CDF are sorted by descending simi- larity score. Local rankings are appended subsequent to the global rankings, ensuring global candidates retain priority. The union CBM25 ∪ CDF finally constitutes intuitive anchors. 3.4.2. RRF FUSION ANDCHUNKRELEVANCE Both rankings are converted to RRF scores (Cormack et al., 2009) as relevance scores s(v) with smoothing hyper- parameterk 0 = 60: s(v) = X c∈{CBM25,CDF} 1 k0 +rank c(v) , v∈ C BM25 ∪CDF.(8) Scores s(v) are propagated to chunks via unit–chunk asso- ciations. After normalizing each s(v) by its degree (number of associated chunks) to reduce bias from high-frequency vertices, scores are accumulated per chunk to produce the initial chunk-relevance scores(c)as below: s(c) = X (v,c)∈F R s(v) |{c′ |(v, c ′)∈ F R}| , c∈ D.(9) 3.5. Adaptive Deep Mining 3.5.1. PREFERENCE-AWAREBIDIRECTIONAL DIFFUSION Drawing on the human association introduced in Section 1, three governing principles are posited: (i) vertex relevance is positively correlated with adjacency quality; (ii) diffusion should be directionally amplified along deductive paths; and (iii) the required diffusion depth scales positively with question complexity. Under these constraints, aPreference-Aware Bidirectional Diffusion (PABD)algorithm is formulated. It initiates from anchors and conducts a hierarchical, bidirectional diffusion process across the HHHG. The corresponding workflow and pseudocode are provided in Appendix A. Propagation Mode.Each iteration consists of two sequen- tial phases: (i) top-down broadcasting, in which high-order vertices propagate signals along ⟨H → N,L → N ⟩ to strengthen relevant lower-level memories; and (ii) bottom- up screening, wherein low-order vertices feed signals back along ⟨N → H,N → L⟩ only when co-occurrence support exceeds the adaptive threshold τ, thereby reinforcing the corresponding higher-level memories. Preference-aware mechanism.The preference coeffi- cient ρ integrates the count of adjacent propagation sources with their normalized weights. This mechanism amplifies scores along high-preference paths while attenuating those in low-preference directions. Consequently, vertices reach- able via deep multi-hop propagation overcome distance- based decay, achieving competitive relevance scores. Dynamic threshold.The default thresholds are set to τ (L) 0 = 0.5 and τ (H) 0 = 0.4 . A bias b is automatically adjusted based on activation feedback during each iteration. If no new vertices are activated, b increases to trigger back- tracking; otherwise, it decreases. Ultimately, The effective threshold is τ (t) =τ (t) 0 −b , where t∈ {L,H} . This mech- anism balances exploration and exploitation, preventing diffusion stagnation while suppressing noise amplification to ensure controllable propagation. The PABD algorithm terminates upon reaching the query’s semantic depth d or upon diffusion stagnation. The activated vertices are sorted in descending order of extended relevance s′(v)for context-window truncation. 3.5.2. ADAPTIVECONTEXT-WINDOW Depth Amplification Mechanism.Defined by default as ku = 5 (knowledge-unit multiplier) and kc = 2 (chunk mul- tiplier), these amplification coefficients jointly determine the adaptive recall quotas: Top-Ku =k u ·d,Top-K c =k c ·d.(10) Final knowledge selection.After diffusion ends, the Top-Ku expanded vertices (excluding anchors) are ex- tracted from the PABD output and merged with the initial vertices to form the final knowledge setset u. Final chunks selection.The extended relevance score of each chunk is computed by applying the same normalized ac- cumulation strategy as Equation (9) to the vertex-extension scores s′(v). The final chunk relevance is derived via a weighted fusion of these extended scores with the initial relevance values. Chunks are then ranked by this composite score in descending order. The Top-Kc selections, com- bined with the filtered setu, constitute the retrieved content for the final context window. The system utilizes the depth amplification coefficient and an “initial–expansion” fusion strategy to adaptively scale the memory window. This guarantees comprehensive knowl- 5 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory edge coverage for complex problems while preserving effi- ciency and cost-effectiveness for simple queries. 4. Experiment 4.1. Experimental Setup Baselines.We compared our approach with the state-of- the-art (SOTA) and widely adopted RAG methods. These include: Naive RAG; graph-enhanced methods ( LightRAG, PathRAG, and NodeRAG) and hypergraph-enhanced meth- ods (Hyper-RAG and Cog-RAG). Detailed descriptions of these baselines are provided in Appendix D.1. Benchmarks.To comprehensively assess the cross-task generalisation of RAG methods, we utilize six public bench- marks spanning three representative tasks: (i)Detail Cap- ture (Simple QA)—PopQA (Mallen et al., 2023); (ii)Multi- Hop Reasoning (Multi-Hop QA)—MuSiQue (Trivedi et al., 2022)and 2WikiMultihop (Ho et al., 2020) (2Wiki), and HotpotQA (Yang et al., 2018); and (iii)Knowledge Explanation (Explanatory QA)—Mix (Qian et al., 2024) and Pathology (Xiong et al., 2024). Simple QA targets single-fact detail questions, and Multi-Hop QA demands cross-context aggregation and logical deduction, emphasiz- ing error correction and chained reasoning following initial retrieval failures. Explanatory QA utilizes long passages with random-hop questions to evaluate comprehensive se- mantic representation and latent association mining. Bench- mark statistics are detailed in Appendix D.2. Metrics.We adopt three metrics across tasks: Exact Match (EM) andF1scores to measure literal overlap and n-gram recall rates between model outputs and reference answers, and average tokens per query (Avg. Tokens) to measure method efficiency. For Explanatory QA, we employ an LLM-based evaluator to assign EM and F1 scores, assessing factual correctness and semantic relevance. Metric details are provided in Appendix D.3. Implementation Details.We employ text-embedding-3- small for text encoding and GPT-4o-mini (Achiam et al., 2023) as the LLM. For IGMiRAG, the slice length is set to 1024 tokens for Explanatory QA and 780 for all others. All baselines are configured using their officially recom- mended indexing and retrieval hyperparameters (detailed in Appendix D.4) to ensure fair and reproducible comparisons. 4.2. Main Results We report QA performance and average token costs per query across all benchmarks, calculated against the gold- standard question–answer pairs. QA Performance.Table 1 presents the performance of each method across six benchmarks. IGMiRAG achieves the highest average scores (58.3% EM, 65.9% F1), maintaining a consistent lead across different tasks. Naive RAG exhibits monotonic improvement with additional slices, albeit with diminishing marginal returns. While Naive RAG (T op−5) ranks third overall, it performs second-best on MuSiQue and HotpotQA, outperforming several structure-enhanced meth- ods despite its lower retrieval cost. Among graph-enhanced methods, PathRAG ranks last overall ( 42.1% EM, 49.5% F1), with minimal gains (4.5% EM and 7.5% F1) over the LLM baseline. NodeRAG, however, emerges as the SOTA Table 1.QA performanceincluding EM, F1 scores (%) on six RAG benchmarks. This table, along with the following ones, highlight the bestand second-best results. Methods Simple QA Multi-Hop QA Explanatory QA Overall PopQA MuSiQue 2Wiki HotpotQA Mix Pathology Avg. EM F1 EM F1 EM F1 EM F1 EM F1 EM F1 EM F1 GPT-4o-mini 20.7 24.5 12.4 21.7 32.2 37.4 30.8 41.4 57.5 57.5 72.1 69.4 37.6 42.0 Naive RAG RAG (T op−1) 41.3 51.9 21.4 31.4 28.8 35.1 41.4 55.6 69.6 68.4 76.5 74.8 46.5 52.9 RAG (T op−3) 46.6 58.6 27.4 38.4 37.9 45.1 48.5 62.7 73.9 72.2 76.8 75.5 51.8 58.8 RAG (T op−5) 48.9 60.6 28.6 40.3 41.1 48.9 50.2 65.1 74.5 73.0 77.3 75.9 53.4 60.6 Graph-enhanced RAG LightRAG 49.1 60.3 22.6 32.4 35.2 41.4 40.3 54.3 74.5 72.8 75.5 73.6 49.5 55.8 PathRAG 33.1 44.3 19.3 31.1 40.2 47.8 41.1 55.8 56.8 56.1 61.9 61.8 42.1 49.5 NodeRAG50.2 62.7 27.8 40.1 40.9 49.7 50.1 64.0 75.3 73.5 76.6 75.6 53.5 60.9 Hypergraph-enhanced RAG Hyper-RAG 49.1 59.9 22.6 32.6 45.3 54.0 41.0 54.9 71.4 69.7 75.9 75.2 50.9 57.7 Cog-RAG 30.1 44.3 15.5 26.6 27.5 40.7 28.1 44.1 73.7 72.2 78.9 78.0 42.3 51.0 IGMiRAG (Ours) 49.8 62.4 33.0 45.0 57.5 67.4 54.0 69.1 76.5 74.4 79.277.4 58.3 65.9 6 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory 14.61313.41513.915.714.311.612.211.411.912.713.812.24.756.55.85.15.55.412.312.712.913.212.214.51329.329.530.431.527.733.830.33.154.75.88.7116.4PopQA HotpotQA 2Wiki MuSiQue Mix Pathology Overall05101520253035Avg. Tokens (k)Benchmarks LightRAG PathRAG NodeRAG Hyper-RAG Cog-RAG IGMiRAG (a)The comparison of average token costs 0 1 2 3 4 5 5 10 15 20 25 30 35 16 18 20 22 24 26 28 30 32 34 Avg. Tokens (k) EM (%) Avg. Time (s) (b)The comprehensive comparison Figure 3.Efficiency Comparison.Subfigure (a) shows the token costs (k) comparison across structure-enhanced methods, while subfigure(b)provides a comprehensive comparison of all RAG methods on MuSiQue regardingEM,Avg. Tokens, andAvg. Time. baseline, securing the top spot on Simple QA and second place on Mix. Hypergraph-enhanced Cog-RAG observably exceeds Hyper-RAG on Explanatory QA but underperforms on Simple QA and Multi-Hop QA, with drops up to 19.0% EM and 15.6% F1 on PopQA. Crucially, on the two most challenging benchmarks—MuSiQue and 2WikiMultiHop, IGMiRAG surpasses the second-best method by4.4%/4.7% and 12.2%/13.4% in EM/F1, respectively, confirming its effectiveness in multi-hop reasoning. Besides securing sec- ond place on Simple QA, IGMiRAG achieves the highest performance on all five other benchmarks, demonstrating strong generalization and robustness. QA Efficiency.Query efficiency is critical for the practi- cal viability of RAG systems. As shown in Figure 3 (a), the token consumption varies significantly across structure- enhanced methods. NodeRAG consumes the fewest tokens on average 5.4 k+, while IGMiRAG requires only ≈0.9 k more (6.3 k+). In contrast, all other methods exceed 11 k to- kens (maximum 33.8 k+) per query. A task-level breakdown reveals the following efficiency/performance trade-offs. (i) Simple QA: IGMiRAG ranks second in performance while consuming only 3.0 k+ avg. tokens— 1.7 k+ fewer than NodeRAG (4.7 k+). (ii) Multi-Hop QA: Averaged across three benchmarks, IGMiRAG achieves the best performance with a minimum of5.1 k+ tokens, 10.37% (0.5 k+) less than NodeRAG (5.7 k+) and 60.04% (7.7 k+) less than Hyper- RAG (12.9 k+). (iii) For Explanatory QA, where cross- domain knowledge fusion is required, IGMiRAG increases its token usage to 8.6 k+ on Mix and 11.0 k+ on Pathology. Despite this increase, it achieves the highest performance at the second-lowest token cost. Notably, the token con- sumption of all baselines, including NodeRAG, remains approximately constant across varying task complexities, exhibiting only minor and irregular fluctuations. In contrast, IGMiRAG’s consumption scales proportionally with task complexity, enabling cost savings while maintaining strong performance. Furthermore, Figure 3 (b) presents a com- prehensive comparison of all RAG methods on MuSiQue. Obviously, IGMiRAG achieves the highest performance while maintaining both low time and token consumption. 5. Discussions The following sections will analyze the effectiveness of each proposed module and its internal mechanisms, clarifying their individual contributions and synergistic interactions. Table 2.Ablations.We compare the QA performance and token cost of alternative retrieval and diffusion strategies on MuSiQue against the final IGMiRAG configuration. ModelsEM (%) F1 (%) Avg. (k) IGMiRAG33.0 45.05.84 Retrieval Ablation w/o BM25 30.6 41.58 5.60 w/o DF-Retrieval w/oI L 28.1 41.0 5.56 w/I G (T op−10) 29.5 42.6 5.65 w/I G (T op−20) 31.6 43.2 6.56 w/I G (dynamicT opk) 31.6 43.6 6.19 Diffusion Ablation w/o PABD 31.3 42.54.44 w/o Dynamic Threshold 31.7 44.1 5.84 w/o Preference Aware 32.4 44.4 5.75 5.1. Ablation Study To validate the effectiveness of the strategy-driven retrieval mechanism, we conducted ablation studies on MuSiQue while keeping the question parsing strategy fixed. As shown in Table 2, each module and mechanism yields a significant performance improvement for IGMiRAG. Retrieval Ablation.Both BM25 and DF-Retrieval improve initial candidates quality, with the latter yielding larger gains. Ablating local semantic retrieval alone reduces EM by4.1% 7 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory and F1 by 3.7%. Three global-only ablations further con- firm this: while IG T op−20 outperforms IG T op−10, it matches the performance of Dynamic IG (which reallocates the local retrieval budget to the global while maintaining the same T opk as DF-Retrieval) yet consuming 0.3 k+ extra tokens. This indicates that expanding global candidates in- troduces redundancy and inefficiency. In contrast, the local perspective injects targeted units atop the global candidates, effectively offsetting the diminishing returns of scale. Diffusion Ablation.Removing the PABD module results in answering based solely on initial retrieval, consuming only 4.4 k+ tokens. In contrast, dropping the dynamic threshold mechanism degrades diffusion into indiscriminate expan- sion, amplifying high-order noise with longer texts. Conse- quently, this ablation suffers a worse performance drop than removing the preference-aware mechanism alone, despite the higher costs. Crucially, across all ablations, degrading the diffusion process proves less detrimental than impairing retrieval quality. This confirms that low-quality seeds steer diffusion along false paths, ultimately amplifying errors. 0.299 0.302 0.3110.320.330.3240.322 0.324 0.317 4 5 6123kc ku 0.29900.30520.31140.31760.32380.3300EM (%) (a)Amplification Coefficients 30.43332.731.6 6 12 18 24272829303132333435 4.55.05.56.06.57.07.58.0Avg. Tokens (k) EM Avg. Token kb EM (%) (b)Base quota of DF-Retrieval Figure 4.Hyperparameter Sensitivity Analysis.Subfigure ( a) is the heatmap for different combinations of ku and kc, while subfigure (b) shows the comparison results with differentkb. 80.85.61210 19.248.362.434.411 42.924.3543421 3.11.31.6587573PopQAHotpotQA2WikiMusiqueMixPathology0 20 40 60 80 100The Percentage of different depths (%)Benchmarks 1 2 3 4 5 Figure 5.The percentage of different depths on six benchmarks. 5.2. Controlling Amplification Coefficients While chunks link fragmented units to improve response completeness and fluency, oversized chunks risk overload- ing the LLM’s semantic filter and burying critical evidence. Therefore, we set the amplification coefficients to ku = 5 and kc = 2, achieving the optimal trade-off between preci- sion and readability as demonstrated in Figure 4 (a). For DF- Retrieval, the quota kb influences both token costs and the correctness of the diffusion path. As shown in Figure 4 (b), performance peaks at the default setting ofk b = 12. 1 2 3 4 5272829303132333435 0123456789101112131415Avg. Tokens (k) EM Avg. Tokens EMAuto Avg. TokensAuto IterationsEM (%) (a)Control Iterations Only 1 2 3 4 5272829303132333435 0123456789101112131415Avg. Tokens (k) EM Avg. Tokens EMAuto Avg. TokensAuto SizesEM (%) (b)Control Sizes Only Figure 6.Ablation on Iterations and Window Sizes.Impact of various semantic depth on QA performance and token costs. 5.3. The Effectiveness of Adaptive Deep-mining To ascertain whether adaptive deep mining and dynamic context windows constitute effective, explainable mecha- nisms or compromise performance, we conducted controlled experiments on MuSiQue with a fixed retrieval strategy. Figure 6 (a) shows that performance peaks at iteration 3 and then declines. Although the fixed-iteration variant consumes a comparable number of tokens, it consistently lags behind IGMiRAG. The peak coincides with Figure 5, where IGMi- RAG allocates the largest proportion of depth 3 (54.0%) on MuSiQue. This confirms that a fixed iteration budget cannot adapt to the true distribution of reasoning depths. Figure 6 (b) presents that while performance initially im- proves with an expanding context window, the trend flattens. Even at the maximum token budget of 9.6 k+, the ceiling remains below that of IGMiRAG. These results confirm that marginal gains from naively stacking context degrade rapidly. In contrast, IGMiRAG’s complexity-driven window allocation achieves superior accuracy at a lower cost. 6. Conclusion We propose IGMiRAG, a novel RAG framework designed to optimize reasoning depth and retrieval efficiency. By constructing a Hierarchical Heterogeneous Hypergraph to model human-like memory structures and employing an intuition-inspired strategy to guide associative diffusion, IG- MiRAG introduces a “Strategy-Diffusion” paradigm. This paradigm enables in-depth memory mining with adaptive context scaling, achieving superior performance with fewer dynamic tokens. Such a cognitively inspired approach not only enhances retrieval efficiency and effectiveness but also bridges artificial mechanisms with human-like memory pro- 8 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory cessing. Despite the approximate nature of current intuition signals, refining intuition-retrieval alignment holds promise for advancing LLM memory recall and complex reasoning. Impact Statement This paper presents work on Retrieval-Augmented Gen- eration (RAG), aiming to advance the field by improving retrieval efficiency and effectiveness to enhance memory precision and reasoning depth in Large Language Models. While our work may have various potential societal impli- cations, we do not foresee specific concerns that warrant emphasis beyond the general risks associated with large language models and information retrieval systems. References Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. Gpt-4 technical report.arXiv preprint arXiv:2303.08774, 2023. Asai, A., Wu, Z., Wang, Y ., Sil, A., and Hajishirzi, H. Self- rag: Learning to retrieve, generate, and critique through self-reflection. InThe Twelfth International Conference on Learning Representations, 2023. Chen, B., Guo, Z., Yang, Z., Chen, Y ., Chen, J., Liu, Z., Shi, C., and Yang, C. Pathrag: Pruning graph-based re- trieval augmented generation with relational paths.arXiv preprint arXiv:2502.14902, 2025a. Chen, S., Zhou, C., Yuan, Z., Zhang, Q., Cui, Z., Chen, H., Xiao, Y ., Cao, J., and Huang, X. You don’t need pre-built graphs for rag: Retrieval augmented genera- tion with adaptive reasoning structures.arXiv preprint arXiv:2508.06105, 2025b. Cormack, G. V ., Clarke, C. L., and Buettcher, S. Reciprocal rank fusion outperforms condorcet and individual rank learning methods. InProceedings of the 32nd interna- tional ACM SIGIR conference on Research and develop- ment in information retrieval, pp. 758–759, 2009. Dagdelen, J., Dunn, A., Lee, S., Walker, N., Rosen, A. S., Ceder, G., Persson, K. A., and Jain, A. Structured infor- mation extraction from scientific text with large language models.Nature communications, 15(1):1418, 2024. Edge, D., Trinh, H., Cheng, N., Bradley, J., Chao, A., Mody, A., Truitt, S., Metropolitansky, D., Ness, R. O., and Larson, J. From local to global: A graph rag ap- proach to query-focused summarization.arXiv preprint arXiv:2404.16130, 2024. Feng, Y ., Yang, C., Hou, X., Du, S., Ying, S., Wu, Z., and Gao, Y . Beyond graphs: Can large language models com- prehend hypergraphs?arXiv preprint arXiv:2410.10083, 2024. Feng, Y ., Hu, H., Hou, X., Liu, S., Ying, S., Du, S., Hu, H., and Gao, Y . Hyper-rag: Combating llm hallucinations using hypergraph-driven retrieval-augmented generation. arXiv preprint arXiv:2504.08758, 2025. Gao, L., Ma, X., Lin, J., and Callan, J. Precise zero-shot dense retrieval without relevance labels. InProceed- ings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1762–1777, 2023a. Gao, Y ., Feng, Y ., Ji, S., and Ji, R. Hgnn+: General hyper- graph neural networks.IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(3):3181–3199, 2022. Gao, Y ., Xiong, Y ., Gao, X., Jia, K., Pan, J., Bi, Y ., Dai, Y ., Sun, J., Wang, H., and Wang, H. Retrieval-augmented generation for large language models: A survey.arXiv preprint arXiv:2312.10997, 2(1), 2023b. Guo, Z., Xia, L., Yu, Y ., Ao, T., and Huang, C. Lightrag: Simple and fast retrieval-augmented generation.arXiv preprint arXiv:2410.05779, 2024. Gupta, S., Ranjan, R., and Singh, S. N. A comprehensive sur- vey of retrieval-augmented generation (rag): Evolution, current landscape and future directions.arXiv preprint arXiv:2410.12837, 2024. Guti´errez, B. J., Shu, Y ., Qi, W., Zhou, S., and Su, Y . From rag to memory: Non-parametric continual learning for large language models.arXiv preprint arXiv:2502.14802, 2025. Haveliwala, T. H. Topic-sensitive pagerank. InProceedings of the 11th international conference on World Wide Web, pp. 517–526, 2002. Ho, X., Nguyen, A.-K. D., Sugawara, S., and Aizawa, A. Constructing a multi-hop qa dataset for compre- hensive evaluation of reasoning steps.arXiv preprint arXiv:2011.01060, 2020. Hu, H., Feng, Y ., Li, R., Xue, R., Hou, X., Tian, Z., Gao, Y ., and Du, S. Cog-rag: Cognitive-inspired dual-hypergraph with theme alignment retrieval-augmented generation. arXiv preprint arXiv:2511.13201, 2025. Huang, H., Huang, Y ., Yang, J., Pan, Z., Chen, Y ., Ma, K., Chen, H., and Cheng, J. Retrieval-augmented gen- eration with hierarchical knowledge.arXiv preprint arXiv:2503.10150, 2025a. 9 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., et al. A survey on hallucination in large language models: Principles, taxon- omy, challenges, and open questions.ACM Transactions on Information Systems, 43(2):1–55, 2025b. Jimenez Gutierrez, B., Shu, Y ., Gu, Y ., Yasunaga, M., and Su, Y . Hipporag: Neurobiologically inspired long-term memory for large language models.Advances in Neural Information Processing Systems, 37:59532–59569, 2024. Jones, N. Ai hallucinations can’t be stopped—but these techniques can limit their damage.Nature, 637(8047): 778–780, 2025. Labatut, V . and Bost, X. Extraction and analysis of fictional character networks: A survey.ACM Computing Surveys (CSUR), 52(5):1–40, 2019. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., K¨uttler, H., Lewis, M., Yih, W.-t., Rockt¨aschel, T., et al. Retrieval-augmented generation for knowledge- intensive nlp tasks.Advances in neural information pro- cessing systems, 33:9459–9474, 2020. Malkov, Y . A. and Yashunin, D. A. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs.IEEE transactions on pattern analysis and machine intelligence, 42(4):824– 836, 2018. Mallen, A., Asai, A., Zhong, V ., Das, R., Khashabi, D., and Hajishirzi, H. When not to trust language models: Inves- tigating effectiveness of parametric and non-parametric memories. InProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 9802–9822, 2023. Naseer, F., Khan, M. N., Tahir, M., Addas, A., and Aejaz, S. H. Integrating deep learning techniques for personal- ized learning pathways in higher education.Heliyon, 10 (11), 2024. Press, O., Zhang, M., Min, S., Schmidt, L., Smith, N. A., and Lewis, M. Measuring and narrowing the composi- tionality gap in language models. InFindings of the As- sociation for Computational Linguistics: EMNLP 2023, pp. 5687–5711, 2023. Qian, H., Zhang, P., Liu, Z., Mao, K., and Dou, Z. Mem- orag: Moving towards next-gen rag via memory-inspired knowledge discovery.arXiv preprint arXiv:2409.05591, 1, 2024. Robertson, S. E. and Walker, S. Some simple effective approximations to the 2-poisson model for probabilis- tic weighted retrieval. InSIGIR’94: Proceedings of the Seventeenth Annual International ACM-SIGIR Confer- ence on Research and Development in Information Re- trieval, organised by Dublin City University, pp. 232–241. Springer, 1994. Santos, A., Colac ¸o, A. R., Nielsen, A. B., Niu, L., Strauss, M., Geyer, P. E., Coscia, F., Albrechtsen, N. J. W., Mundt, F., Jensen, L. J., et al. A knowledge graph to interpret clinical proteomics data.Nature biotechnology, 40(5): 692–702, 2022. Srinivasan, G., Hyman, J. D., Osthus, D. A., Moore, B. A., O’Malley, D., Karra, S., Rougier, E., Hagberg, A. A., Hunter, A., and Viswanathan, H. S. Quantifying topolog- ical uncertainty in fractured systems using graph theory and machine learning.Scientific reports, 8(1):11665, 2018. Tian, Y ., Song, H., Wang, Z., Wang, H., Hu, Z., Wang, F., Chawla, N. V ., and Xu, P. Graph neural prompt- ing with large language models. InProceedings of the AAAI Conference on Artificial Intelligence, volume 38, pp. 19080–19088, 2024. Trivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. Musique: Multihop questions via single-hop ques- tion composition.Transactions of the Association for Computational Linguistics, 10:539–554, 2022. Ullah, E., Parwani, A., Baig, M. M., and Singh, R. Chal- lenges and barriers of using large language models (llm) such as chatgpt for diagnostic medicine with a focus on digital pathology–a recent scoping review.Diagnostic pathology, 19(1):43, 2024. Wang, S., Fang, Y ., Zhou, Y ., Liu, X., and Ma, Y . Archrag: Attributed community-based hierarchi- cal retrieval-augmented generation.arXiv preprint arXiv:2502.09891, 2025. Xie, J., Zhang, K., Chen, J., Lou, R., and Su, Y . Adaptive chameleon or stubborn sloth: Revealing the behavior of large language models in knowledge conflicts. InThe Twelfth International Conference on Learning Represen- tations, 2023. Xiong, G., Jin, Q., Lu, Z., and Zhang, A. Benchmarking retrieval-augmented generation for medicine. InFindings of the Association for Computational Linguistics ACL 2024, pp. 6233–6251, 2024. Xu, T., Zheng, H., Li, C., Chen, H., Liu, Y ., Chen, R., and Sun, L. Noderag: Structuring graph-based rag with heterogeneous nodes.arXiv preprint arXiv:2504.11544, 2025. 10 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Yang, Z., Qi, P., Zhang, S., Bengio, Y ., Cohen, W., Salakhut- dinov, R., and Manning, C. D. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 conference on empirical methods in natural language processing, pp. 2369–2380, 2018. Zhong, X. et al. Assessing knowledge editing in language models via multi-hop questions. InProceedings of the 2024 Conference on Empirical Methods in Natural Lan- guage Processing (EMNLP), 2024. 11 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Appendix Within this supplementary material, we elaborate on the following aspects: • Appendix A: PABD Algorithm • Appendix B: IGMiRAG Pipeline Example • Appendix C: Case Studies • Appendix D: Experimental Details • Appendix E: Additional Discussions • Appendix F: All LLM Prompts A. PABD Algorithm To clearly elucidate the internal mechanisms of the PABD algorithm, we present a complete workflow example in Figure 7, and provide corresponding pseudocode in Algorithm 1. The PABD algorithm follows an alternating inference rule of “top-down broadcasting and bottom-up screening”. Starting from the memory anchors, it performs bidirectional diffusion across knowledge levels at each iteration, enabling the deductive propagation of relevance scores. Specifically, the score propagation within each iteration comprises two directed phases: (i)The top-down diffusion process will broadcast scores from high-order anchors to their associated low-order knowledge; (ii)The bottom-up diffusion process will propagate from low-order anchors to high-order knowledge units that satisfy the threshold criteria. The intensity of this propagation is governed by both a decay factor γ and a preference coefficient ρ. While γ is a fixed hyperparameter, ρ is dynamically determined by the relevance quality of the target vertex’s adjacent vertices (detailed in Algorithm 2). The bottom-up propagation is constrained by a dynamic threshold (illustrated in Algorithm 3). This threshold adaptively adjusts its bias based on activation feedback from the diffusion process: the bias increases upon activating new vertices to suppress the introduction of noise, and decreases otherwise to inject diffusion power. The specific bias regulation mechanism is detailed in Algorithm 3. By combining this dynamic threshold mechanism with the preference-aware mechanism, the PABD algorithm effectively amplifies the scores of relevant paths while suppressing those of irrelevant ones, thereby revealing latent vertices. Furthermore, upon the completion of each iteration, all newly activated vertices are merged with the current anchors to form the starting anchors for the subsequent iteration. The PABD algorithm terminates upon complete cessation of diffusion or upon reaching the maximum iterations, returning all activated vertices and their corresponding relevance scores in descending order. New Vertices Final Vertices New Vertices Diffusion New Vertices Diffusion Initial Vertices Diffusion Iteration 1 Iteration 2 Iteration 3 The End Figure 7.An example workflow of the Preference-Aware Bidirectional Diffusion Algorithm. 12 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Algorithm 1Preference-Aware Bidirectional Diffusion (PABD) 1:Input:initial scoress(v), target layerl, max iterationd 2:Output:extended scoress ′(v) 3:Require: GHHHG ▷The Hierarchical Heterogeneous Hypergraph id2l(·)▷The mapping from key to layer (all vertices) 4:Definitions: LFN(u,dir): layer-filtered neighbors ofualongdir∈ {FORWARD,BACKWARD} HC(u,dir): number of neighbors in LFN(u,dir)with score> S[u] PA(n): preference coefficient∈[0,1], rising withn PAG(c, v, S, γ,dir): score increment for forward/backward diffusion▷Detailed in Algorithm 2 DTF(c, τ 0, l, b): returns TRUEifcpasses thresholdτunder offsetb ▷Detailed in Algorithm 3 DTA(VF ,VB,VA, l2id, b, i,dir): updatesV A, l2id, b, iwith newly activated nodes▷Detailed in Algorithm 4 5:Initialize: S←s(v);V A ←keys(S) buildl2id[ℓ], ℓ∈ {1,2,3}fromV A viaid2l(·)▷The mapping from layer to key (activated vertices) decay factorγ←0.2 thresholdsτ (L) ←0.5,τ (H) ←0.4 biasb←0 6:fori= 0toddo 7:S ′ ←S;V F ← ∅;V B ← ∅ 8:Top-Down: Forward Diffusion Stage▷L,H → N 9:V H ←l2id[3]∪l2id[2]▷Get the high-order anchors 10:forc∈ V H do 11:forv∈LFN(c,FORWARD)do 12:ifS[c]> S[v]andHC(v,FORWARD)>0then 13:S ′[v]←S ′[v] +PAG(c, v, S, γ,FORWARD)▷Update the scores of lower-level vertices 14:ifv /∈ V A then 15: addvtoV F 16:end if 17:end if 18:end for 19:end for 20: DTA(V F ,∅,V A, l2id, b, ,FORWARD)▷Update the activated vertices, mapping, and bias 21:Bottom-Up: Backward Diffusion Stage▷N → L,H 22:V L ←l2id[1] ▷Get the low-order anchors 23:forv∈ V L do 24:forc∈LFN(v,BACKWARD)do 25:ifS[v]> S[c]andDTF(c, τ 0, l, b)then 26:S ′[c]←S ′[c] +PAG(c, v, S, γ,BACKWARD)▷Update the scores of higher-level vertices 27:ifc /∈ V A then 28: addctoV B 29:end if 30:end if 31:end for 32:end for 33: DTA(∅,V B,VA, l2id, b, i,BACKWARD)▷Update the activated vertices, mapping, bias, andi 34:S←S ′ ▷Update the memory anchors for next iteration 35:ifV F =∅andV B =∅andb= 0.50then▷Whether the termination condition has been met 36:break 37:end if 38:i←i+ 1 ▷Next iteration 39:end for 40:s ′(v)←S 41:returns ′(·) 13 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory Algorithm 2Preference-Aware Gain (PAG) 1:procedurePAG(c, v, S, γ,dir) 2:ifdir=FORWARDthen▷Forward 3:n←HC(v,FORWARD)▷HC is defined in Algorithm 1 4:ρ←PA(n)▷PA is defined in Algorithm 1 5:s ′ ←(S[c]−S[v])·ρ·γ 6:else ▷Backward 7:n←HC(c,BACKWARD) 8:ρ←PA(n) 9:P ←n/LFN(v,BACKWARD)▷Get the adjacent activation proportion 10:s ′ ←(S[v]−S[c])·(ρ·0.5 +P 2 ·0.5)·γ 11:end if 12:returns ′ 13:end procedure Algorithm 3Dynamic Threshold Filtering (DTF) 1:procedureDTF(u,τ 0,l,b) 2:ifl u =lthen▷ l u is the layer ofu 3:b←b+ 0.05 4:end if 5:τ ′ ←τ t 0 −b ▷tis the type ofu 6:if Pass←(P> τ ′) 7:returnif Pass 8:end procedure Algorithm 4Dynamic Threshold Adjusting (DTA) 1:Definitions: UFA(VF ,VA, l2id): updateV A andl2idwith newly activated verticesV F UBA(VB,VA, l2id): updateV A andl2idwith newly activated verticesV B 2:procedureDTA(V F ,V B,V A,l2id,b,i,dir) 3:ifdir=FORWARDthen▷Forward 4:ifV F ̸=∅then 5:UFA(V F ,V A, l2id)) 6:else 7:b←min(b+ 0.1,0.5) 8:end if 9:else ▷BACKWARD 10:ifV B ̸=∅then 11:UBA(V B,V A, l2id) 12:b←max(b−0.10,0.0) 13:else 14:b←min(b+ 0.15,0.5) 15:i←i−1▷Backtracking 16:end if 17:end if 18:returnb,i ▷Return newbandi 19:end procedure 14 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory B. IGMiRAG Pipeline Example Figure 8 and Figure 9 illustrate a representative example of the IGMiRAG indexing process and querying process, respectively. In the querying process example, content directly related to the final answer is highlighted in green. C. Case Study To illustrate the advantages of IGMiRAG, representative cases across three tasks are presented. Semantic elements in the figure are color-coded as follows: green regions denote the correct knowledge matching the standard answer; yellow regions indicate irrelevant or information-deficient contents; and red regions represent misleading noise fragments that misguide the model. As demonstrated in Figure 10 and Figure 11, IGMiRAG generates responses faithful to the standard answers by synthesizing logically coherent and highly relevant retrieval results. In contrast, NodeRAG fails to derive correct conclusions due to fragmented reasoning stemming from missing critical supporting facts. Furthermore, Hyper-RAG produces compromised outputs, as the injection of irrelevant noise leads to misjudgment. In the Knowledge Explanation task (Figure 12), the blue areas highlight critical information points essential for a complete answer. IGMiRAG’s response precisely covers all key points without redundancy. In contrast, NodeRAG omits two core pieces of information—“Ritika’s father’s name” and “the film’s screenwriter”—while introducing irrelevant descriptions and factual inaccuracies absent from the gold standard. More severely, Hyper-RAG fails to address the film’s core plot (e.g., “the conflict between Prabhu and Rithika’s father”), instead generating extensive abstract summaries. This deficiency stems from Hyper-RAG’s diffusion process lacking relevance constraints, causing retrieved fragments to deviate significantly from the query. Consequently, the model is forced to produce vacuous, hallucinatory summaries driven by noise. D. Experiment Details D.1. Baselines A comparative analysis was conducted against state-of-the-art and widely adopted RAG methods. Details regarding these baselines are provided below. NaiveRAG(Lewis et al., 2020): This baseline method segments the source text into fine-grained chunks. Each chunk is then embedded into a vector representation and stored in a vector database. During the retrieval phase, the system identifies the most similar vectors and concatenates the corresponding chunks to construct the final context. LightRAG(Guo et al., 2024): A standard graph-enhanced RAG method. It leverages graph structures to capture pairwise relationships among knowledge units, storing both entities and relations as vectors in two separate databases. The method employs a two-stage retrieval strategy: first, it retrieves entity and relation candidates based on vector similarity; next, it explores the graph starting from these candidates, gathering adjacent nodes and edges to form the final retrieved context. PathRAG(Chen et al., 2025a): A graph-enhanced RAG method that employs a flow-control pruning mechanism. It constructs its index identically to LightRAG. During retrieval, the system first identifies candidate entities and relations via keyword search. Subsequently, the flow-control pruning mechanism retains only the most relevant paths, with the final result comprising the sequence of entities and relations along these paths. NodeRAG(Xu et al., 2025): A graph-enhanced RAG method that operates on heterogeneous graphs. It employs such a graph structure to uniformly model all knowledge units and generates high-level community summaries through clustering. During retrieval, the system first aggregates global candidates using both keyword search and vector similarity. Subsequently, a shallow Personalised PageRank (PPR) is executed over these candidates to mine potential nodes, yielding the final retrieval context. Hyper-RAG(Feng et al., 2025): A standard hypergraph-enhanced RAG method. It models both pairwise and higher-order relationships as hyperedges, using an index construction process similar to LightRAG. During retrieval, the system first retrieves entity candidates and pairwise/multi-entity relation candidates separately via vector similarity. It then propagates activation through the hyperedges to generate the final set of entities and relations. Cog-RAG(Hu et al., 2025): A hypergraph-enhanced RAG method that employs dual hypergraph modeling for topics and entities. Building on Hyper-RAG, it leverages a topic hypergraph to capture topic associations within text chunks and adopts 15 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory /cogIndexing: Extracting knowledge from the original chunks Title: Portrait of George Dyer Talking Text:Portrait of George Dyer Talking is an oil painting by Francis Bacon executed in 1966. It is a portrait of his lover George Dyer made at the height of Bacon’s creative power. It depicts Dyer sitting on a revolving office stool in a luridly coloured room. His body and face are contorted, and his legs are tightly crossed. His head appears to be framed within a window or door. Above him is a naked hanging lightbulb, a favourite motif of Bacon’s. The work contains a number of spatial ambiguities, not least that Dyer’s body seems to be positioned both in the fore- and background. -*Entities*– • George Dyer • Francis Bacon -*Pairwise Relations*- •<George Dyer, Francis Bacon> •<Francis Bacon, Portrait of George Dyer Talking> Title: Francis Bacon Text:Francis Bacon was born on 22 January 1561 at York House near the Strand in London, the son of Sir Nicholas Bacon (Lord Keeper of the Great Seal) by his second wife, Anne (Cooke) Bacon, the daughter of the noted humanist Anthony Cooke. His mother’s sister was married to William Cecil, 1st Baron Burghley, making Burghley Bacon’s uncle. -*Entities*- • Francis Bacon • Anne (Cooke) Bacon • Sir Nicholas Bacon • William Cecil, 1st Baron Burghley -*Pairwise Relations*- •<Francis Bacon, Sir Nicholas Bacon> •<Francis Bacon, Anne (Cooke) Bacon> •<Sir Nicholas Bacon, Francis Bacon> •<Francis Bacon, William Cecil, 1st Baron Burghley> -*Multiple Associations*- •<Francis Bacon, Sir Nicholas Bacon, Anne (Cooke) Bacon> Title: Head I Text:Head I is a relatively small oil and tempera on hardboard painting by the Irish-born British figurative artist Francis Bacon. Completed in 1948, it is the first in a series of six heads, the remainder of which were painted the following year in preparation for a November 1949 exhibition at the Hanover Gallery in London. Like the others in the series, it shows a screaming figure alone in a room, and focuses on the open mouth. The work shows a skull which has disintegrated on itself and is largely a formless blob of flesh. The entire upper half has disappeared, leaving only the jaw, mouth and teeth and one ear still intact... -*Entities*- • Head I • Francis Bacon -*Pairwise Relations*- •<Francis Bacon, Head I> Figure 8.An Example of the Indexing Process. 16 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory ♂searchQuering: Answering by retrieving knowledge (including original chunks) Question: Who was the father of The Portrait of George Dyer Talking’s creator? rewrite question:Who is the father of Francis Bacon, the creator of the artwork titled ’The Portrait of George Dyer Talking’? key entities:Francis Bacon|Father, The Portrait of George Dyer Talking|Artwork|Painting keywords:father, Francis Bacon, The Portrait of George Dyer Talking, creator, art target layer:1,matching score:4,semantic depth:2 -*Entities*– • George Dyer • Francis Bacon • Anne (Cooke) Bacon • Diana Watson • Head I • William Cecil, 1st Baron Burghley • Albrecht D ¨urer • Albrecht D ¨urer the Elder • D ¨urer’s Father • Portrait of D ¨urer’s Father at 70 • Sir Nicholas Bacon -*Pairwise Relations*- •<Francis Bacon, Portrait of George Dyer Talking> •<George Dyer, Francis Bacon> •<Francis Bacon, 1945 painting> •<Francis Bacon, Anne (Cooke) Bacon> • <Francis Bacon, Sir Nicholas Bacon> •<Francis Bacon, Head I> •<George Dyer, Albrecht D ¨urer> •<Albrecht D ¨urer, Albrecht D¨urer the Elder> -*Multiple Associations*- • <Francis Bacon, Sir Nicholas Bacon, Anne (Cooke) Bacon> •<Figure in a landscape, Francis Bacon, Eric Hall, Diana Watson> -*Passages*- • Title: Portrait of George Dyer Talking • Title: Francis Bacon • Title: Head I • Title: Figure in a landscape • Title: Portrait of D ¨urer’s Father at 70 -*LLM Output*- • Thought: The creator of “Portrait of George Dyer Talking” is Francis Bacon. To determine his father, I refer to the information about Francis Bacon’s family lineage. According to the data, Francis Bacon was the son of Sir Nicholas Bacon, who held the position of Lord Keeper of the Great Seal. Therefore, Sir Nicholas Bacon is the father of Francis Bacon, the artist who created “Portrait of George Dyer Talking.” • Answer: Sir Nicholas Bacon. Figure 9.An Example of the Quering Process.The highlighted green area contains information directly related to the answer. 17 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory ὖECase study on Detail Capture –Details Capture– Question:In what city was Ray Strauss born? Gold Answer:[“Perth, Australia”, “Perth, Western Australia”, “Perth”, “Perth, W.A.”] • IGMiRAG:Thought: The provided data mentions that Raymond Bernard Strauss was from Perth, Western Australia. It describes his background and ties to the area where he played cricket and field hockey. Since Ray Strauss is identified with this individual and no other city is mentioned in association with his birth, I can deduce that he was born in the same city as listed. Answer: Perth. • NodeRAG:Thought: The query is about the birthplace of Ray Strauss. From the information provided, specifically referencing notable individuals named Strauss, it is mentioned that Ray Strauss was an Australian cricketer. While the specific city of his birth is not indicated directly in the information given, we can infer from his nationality that he was likely born in an Australian city. However, to provide an accurate answer, I would need more precise details on Ray Strauss’s birthplace, which are not included in the data presented. Since the data does not provide the exact city where Ray Strauss was born, I cannot conclude definitively. Answer: Unable to determine. • HyperRAG:Thought: The data does not explicitly state the city where Ray Strauss was born. However, it does mention that he was involved in local governance in Buckeye City, Arizona. It’s essential to infer that while he has a notable connection to Buckeye City, the birthplace might not be directly stated in the available information. Given that he represents Buckeye City, I will assume it is also where he was likely born unless otherwise specified. However, I should note that the details regarding his birthplace are absent, as there are no specific entries related to his exact birthplace. Answer: Buckeye City. Figure 10.A Case Study on Detail Capture Task. a two-stage retrieval process inspired by cognitive mechanisms. First, the system retrieves global candidates from the topic hypergraph; it then further retrieves fine-grained, relevant information from the entity hypergraph. D.2. Benchmarks We evaluated all methods on six benchmarks spanning three task types, with statistics details for each benchmark provided in Table 3. For the Explanatory QA task, Mix comprises fragmented paragraphs sampled from 61 distinct domains, while Pathology is a domain-specific benchmark focused on pathology, containing only a single document. Table 3.The statistics details for each benchmark. Statistics Simple QA Multi-Hop QA Explanatory QA PopQA MuSiQue 2Wiki HotpotQA Mix Pathology # Passages (Documents)8,676 11,656 6,119 9,811 61 1 # Chunks1,780 2,191 1,056 2,096 980 1,099 # Tokens1,184,847 1,362,612 684,059 1,306,249 615,355 905,760 # Entities41,315 43,827 22,041 39,899 18,792 20,556 # Pairwise Relations16,697 21,941 9,843 19,941 8,820 10,510 # Multiple Associations6,654 8,941 4,359 7,566 3,373 4,158 # Queries1,000 1,000 1,000 1,000 100 100 PopQA:We randomly sampled 1,000 queries following HippoRAG 2 (Guti´errez et al., 2025). This benchmark focuses on single-entity descriptive questions, designed to evaluate entity recognition and retrieval capabilities in the context of simple question answering. MuSiQue, 2WikiMultiHop and HotpotQA:Following prior work (Press et al., 2023; Jimenez Gutierrez et al., 2024), 18 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory ὖECase study on Multi-Hop Reasoning –Multi-Hop Reasoning– Question:Who is the chief judge? Gold Answer:[“Honorable Justice Abiodun Smith”] • IGMiRAG:Thought: Friday Ossai Osanebi was born in Nigeria, specifically representing Ndokwa East Local Government Constituency in the Delta State House of Assembly. To determine the chief judge of his birthplace, I need to identify the current chief judge of Delta State. According to the data, Rosaline Pa- tricia Irorefe Bozimo was the Chief Justice of Delta State until her retirement on January 1, 2011, and she was succeeded by Honorable Justice Abiodun Smith. Therefore, the current chief judge of Delta State, which is the likely birthplace of Friday Osanebi, is Honorable Justice Abiodun Smith. Answer: Honorable Justice Abiodun Smith. • NodeRAG:Thought: Friday Ossai Osanebi is a politician from Nigeria, specifically representing Ndokwa East Local Government Constituency in Delta State. His birthplace, although not explicitly mentioned, can be inferred to be in Delta State, Nigeria. As of 2016, the acting Chief Judge of Rivers State is Adama Lamikanra, succeeded by Daisy W. Okocha, but this information is not related to Delta State. There is no information provided about the Chief Judge specifically for Delta State, where Friday Osanebi is likely from. Therefore, since the directly related information regarding Chief Judges does not include Delta State or a specific individual, I cannot provide a definitive name based on the current data. Answer: Information not provided for Chief Judge of Delta State. • HyperRAG:Thought: Friday Ossai Osanebi is a politician from Nigeria, and he was born in the Delta State region...Looking at the provided data, the entry for “CHIEF JUSTICE OF DELTA STATE” indicates the head of the judiciary in that jurisdiction, which previously mentioned was Daisy W. Okocha, noted as the first female Chief Judge of Rivers State. However, to clarify, the term “chief judge” often refers to a similar position within the context of a state or court...If Daisy W. Okocha’s term overlapssignificantly or continues dominantly as recognized, then it would typically provide context upon which current legal proceedings reflect. The assertion can be made that Daisy W. Okocha or someone explicitly listed in the database would fulfill the role, thus needing the reference for the title within Delta pursuits distinctly. Answer:Chief Judge of Delta State (Daisy W. Okocha was significant historically). Figure 11.A Case Study on Multi-Hop Reasoning Task. we randomly sampled 1,000 queries from each validation set. These benchmarks primarily feature complex multi-hop questions that obscure target entities through multiple layers of relational embedding, thereby challenging both vector and keyword-based retrieval methods. Mix and Pathology:We further refined the question generation methodology employed in Hyper-RAG and Cog-RAG. Consecutive, lengthy text segments were fed into an LLM, with instructions to generate 100 questions per reasoning hop (ranging from 1 to 3 hops) along with corresponding standard answers in the form of paragraph-level descriptions. We then randomly sampled 100 question-answer (QA) pairs to construct benchmarks with diverse hop counts. These benchmarks are designed to evaluate knowledge-explanation tasks that require extensive descriptive responses, necessitating models to integrate information across multiple contexts and produce coherent, detailed explanations. The prompt templates used for QA pair generation are provided in Appendix F.4. D.3. Metrics For detail-capture and multi-hop tasks, short-form outputs are evaluated using exact match (EM) and F1 scores computed directly against reference answers. In contrast, knowledge explanation tasks involve open-ended, long-form responses that cannot be reliably assessed via string matching. To address this, we adopt the LLM-as-a-judge paradigm: for each instance, the question, reference answer, and model-generated response are jointly fed into an LLM, which is prompted to score the output in terms of EM, precision, and recall—based on which F1 is then calculated. Detailed evaluation prompt templates are provided in Appendix F.4. Across all benchmarks, we record the total token consumption of the model and normalize it 19 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory ὖECase study on Knowledge Explanation –Knowledge Explanation– Question:What is the significance of Manimaran’s directorial debut Udhayam NH4 in understanding the themes of youthful rebellion and familial conflict in Tamil cinema, and how does the character development of Prabhu reflect these themes during the narrative? Gold Answer:Udhayam NH4 marks the directorial debut of Manimaran in the Tamil film industry, recognized for its narrative that centers on youthful rebellion and the pursuit of love amidst adversity, reflecting the changes in the protagonist’s character throughout the storyline. Specifically, after encountering various conflicts, Prabhu and Rithika’s relationshipevolves significantly, showing not only their challenges stemming from familial disapproval but also highlighting their determination to fight for their love despite societal limitations. The film, produced under the banner of Meeka Entertainment and Grass Root Film Company, demonstrates the struggle against traditional family dynamics, which manifests through palpable tensions between Prabhu and Rithika’s father, Avinash Gowda, further complicated by an aggressive law enforcement character, ACP Manoj Menon. • IGMiRAG: Manimaran’s directorial debut, Udhayam NH4, serves as a significant entry point into the themes of youthful rebellion and familial conflict within Tamil cinema. The film revolves around Prabhu...who becomes enmeshedin a turbulent romantic relationship with his classmate Rithika amid opposition from her father, Avinash Gowda...Prabhu’s character embodies the struggle of modern youth navigating love and the pressures imposed by tradition and authority figures...His relentless pursuit to elope with Rithika...underscores the psycho- logical turmoil faced by young individuals when confronted with societal norms...Prabhu’s development—from a lovesick youth to a determined individual willing to risk everything for love—reflects the internal struggles of many young people...the film deftly intertwines these themes with thrilling elements, demonstrated through the involvement of law enforcement, particularly ACP Manoj Menon...Manimaran, with the collaboration of Vetrimaaran—who wrote the film’s script and screenplay—successfully crafts a narrative that resonates with the youth...Udhayam NH4 effectively articulates the struggles between personal passion and societal duty...Prabhu’s character arc serves as a poignant reflection of modern-day challenges faced by young people... • NodeRAG: Manimaran’s directorial debut, “Udhayam NH4,” serves as a pivotal representation of youthful rebellion and familial conflict within Tamil cinema. The film centers on Prabhu, a character who embodies the struggles faced by young individuals caught between their desires and familial expectations. Prabhu’s love for Rithika is initially thwarted by her father’s disapproval, encapsulating the intense familial conflict...As the narrative unfolds, Prabhu’s determination to elope with Rithika signifies not only his personal fight for love but also a challenge to conventional upbringing and family expectations...the authoritative figure of Manoj, the encounter specialist assigned to contain their budding romance...Each confrontation between Manoj and Prabhu underscores the film’s thematic exploration of rebellion asPrabhu strives to take control of his fate...Overall, “Udhayam NH4” utilizes Prabhu’s character development to delve into the complexities of growing up, where familial conflict often fuels rebellion...Manimaran’s narrative thus becomes a lens through which the audience can explore the intricacies of youthful rebellion and the weight of familial obligations... • HyperRAG: Manimaran’s directorial debut, “Udhayam NH4,” holds significant relevance in exploring the themes of youthful rebellion and familial conflict...The narrative...portrays the journey of Prabhu, a young man entangled in a conflict driven by love and familial loyalties...Prabhu’s character encapsulates the struggle be- tween personal desires and family expectations...Prabhu and his love interest, Rithika, decide to elope...marking their defiance against traditional familial structures...Prabhu’s character development illustrates a poignant evolution from a carefree youth towards a more conscious and resolute individual...Prabhu’s rebellious act of eloping signifies a larger commentary on the youth’s quest for autonomy against societal norms...interactions between Prabhu and...Manoj, a law enforcement officer representing family authority, amplify the generational clash...Manoj’s pursuit of Prabhu...symbolizes...the struggle against the limitations imposed by family ex- pectations...In summary, “Udhayam NH4” is instrumental in enhancing the discourse on youthful rebellion and familial conflict...Through the character of Prabhu, Manimaran masterfully illustrates the complexities of navigating relationships... offering reflections that resonate with youths...This thematic exploration marks “Udhayam NH4” as a pivotal contribution to the evolving narrative landscape of Tamil cinema... Figure 12.A Case Study on Knowledge Explanation Task. 20 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory by the number of questions to compute the average token cost per instance. D.4. Implementation Details and Hyperparameters For all baseline methods, we strictly follow the default hyperparameters and optimal operational modes specified in their official implementations. Detailed configurations are summarized in Table 4. Table 4.The implementation details of each baseline. BaselinesNaive RAG LightRAG PathRAG NodeRAG Hyper-RAG Cog-RAG Chunk Token Size1,200 1,200 1,200 1,024 1,200 1,200 Chunk Overlap Token Size100 100 100-100 100 Query Mode - hybrid hybrid - hyper cog Top-k for Retrieve1,3,5 60 40 10 60 60 Max Token for Local Context -1,000 2,500-300 300 Max Token for Global Context -2,400 2,100-1,600 1,600 Max Token for Text Context -2,500 2,100-1,600 1,600 Damping factorαof PPR - - -0.5- - Max Iterations of PPR - - -2- - LLM ModelGPT-4o-mini Embedding Modeltext-embedding-3-small Temperature0 E. Additional Discussions Using the target layer l and matching score m, DF-Retrieval dynamically allocates search quotas between global and target-layer local retrieval. To evaluate its effectiveness, we conducted comparative experiments with fixedl∈[1,3]∩Z andm∈[1,5]∩Zon MuSiQue. Figure 13 (a) illustrates the performance variation across different target layer settings. As the target layer increases, the Exact Match (EM) score exhibits a monotonically decreasing trend. This is attributed to the nature of MuSiQue queries, which involve multi-hop entity searches with nested, multi-layer relationships. Setting the target layer too high (e.g., at the binary relation or multi-event level) introduces misplaced focus and consequently increases noise, significantly degrading the quality of initial retrieval. These initial errors are then amplified during the subsequent diffusion stage, leading to a substantial performance decline. As shown in Figure 13 (b), any fixed quota configuration significantly underperforms IGMiRAG’s dynamic strategy. Further analysis reveals that excessive bias toward either global or local granularity degrades retrieval effectiveness. These results indicate a strong complementarity between the two semantic spaces, suggesting that adaptively adjusting quotas based on task focus is crucial for enhancing retrieval quality. F. All LLM Prompts F.1. Prompts for Indexing Extracting Entities Prompt:Identify as many entities as possible in the text, ensuring that no nouns with referential functions (including proper nouns, common nouns, place nouns, abstract concepts, etc.) are omitted. #Special attention: - All pronouns must be forcibly parsed into the explicit entities they refer to, and converted into the form of “specific reference + identity/role” (such as: he→Tom’ s father; this matter→the argument between Tom and Mickey); 21 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory 1 2 3272829303132333435 0123456789101112131415Avg. Tokens (k) EM Avg. Token EMAuto Avg. TokensAuto l EM (%) (a)Control Target Layer Only 1 2 3 4 5272829303132333435 45678Avg. Tokens (k) EM Avg. Tokens EMAuto Avg. TokensAuto mEM (%) (b)Control Matching Score Only Figure 13.Ablation on target layer and matching score.Impact of various target layer l and matching score m on QA performance and token costs. - For implicit entities (such as objects indirectly referred to by verbs or adjectives, for example, “complainer”, “the criticized behavior”), if they play a semantic role in the context, they should also be extracted as independent entities; - If a noun appears in a compound form (such as “Beijing Municipal Government”, “Grandma of Little Red Riding Hood”), it should be regarded as a whole entity and not be split; - The description of the entity must include the entity name to ensure clarity. For each entity, extract the following information: - entity name:Use the complete expressions that appear in the original text. No translation or annotations are needed. If the name is long but has a clear referential meaning, retain the complete name. Choose the complete form for the first mention. - entity description:Based on the content of the original text, describe the information of the entity in detail. The description should adopt the original sentence order and wording, provide a complete narrative without omitting any details; direct quotations of original phrases or appropriate supplements and analyses can be used, but the scattered information should be linked into a coherent, independent and readable paragraph. It is prohibited to summarize with a single sentence. - attribute:List any additional information that is not mentioned in the description but may be important, such as time, location, status, category, etc. If nothing is available, then skip this item. Extracting Low-order Relations Prompt:For all the entities determined in Step 1, conduct a full-scale pairwise analysis (that is, any two entities form a pair to be tested), and determine whether there are any grammatical or semantic relationships. #Special attention: - The types of relationships include but are not limited to: • Grammatical relationships: subject–verb–object, copular–complement, existential, coordinate, comparative, etc., which are grammatical structure relationships involving two entities; • Semantic relationships: synonymy, causality, sequence, containment, opposition, analogy, influence, etc., which are semantic structural associations involving two entities; •Referential relationships: including explicit and implicit aliases. - Different names of the same entity should also establish a pairing relationship! Including the following two types: • Explicit Alias–Whenever parentheses, quotation marks, dashes, “also known as”, “abbreviation”, “nickname”, or “acronym” are used, immediately capture them as synonymous entity pairs; • Implicit Replacement–Observing the “Reference Chain”: If the pronouns, names, or titles of the same subject change, it can be considered as a potential synonym. For each interrelated entity pair, extract the following information: 22 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory - entities pair:The name of paired entities that must be consistent with the results obtained in Step 1. For example:“[entity1, entity2]”. - relationship description:Based on the analysis, describe the relationships between entities in detail. The description should adopt the original sentence order and wording to connect the two entities, provide a complete narrative without omitting any details; direct quotations of original phrases or appropriate supplements and analyses can be used, but the scattered information should be linked into a coherent, independent and readable paragraph. It is prohibited to summarize with a single sentence. - attribute:List any additional information that is not mentioned in the description but may be important, such as the time, place and context of the relationship. If the two entity names refer to the same object, then add the output content “Same Entity” in this item. If nothing is available, then skip this item. Extracting high-level Keywords Prompt:Based on all the identified entity relationships in Step 2, extract the high-level keywords that can summarize the main idea, core concepts, key events or abstract themes of the paragraph or the entire text. # Special attention: • Keywords must be specific and have clear meanings, avoiding the use of vague terms such as “emotion”, “development”, or “process”; • By combining multiple relationship chains, theme-level concepts (such as “family power struggle”, “technology ethics dilemma”, “urban-rural identity recognition”, etc.) can be extracted. - high level keywords:The content of high-level keywords should summarize the overall idea presented in the document. Avoid using specific names of certain entities that focus excessively on details, as well as vague or empty terms. Extracting High-order Relations Prompt:Based on the entities in Step 1, the entities pairs in Step 2 and the high-level keywords in Step 3, try to analyze their multi-dimensional connections or commonalities, and construct a high-order association set that includes as many entities as possible. # Association Types (satisfy one is sufficient): • Event-driven Association: Multiple entities form a high-order association sequence connected together to form a semantic chain, including co-occurring events, event chains, multi-role events, and event nesting, etc.; • Knowledge-logical Association: Multiple entities jointly constitute a certain knowledge system, theoretical framework, or logical structure, including concept composition, explanation of principles, classification system, and axiom system, etc.; • Functional-cooperative Association: Multiple entities undertake different functions in a certain system, process, or organizational structure, collaborating to complete tasks, including process collaboration, system modules, organizational division of labor, and supply chain collaboration, etc.; • Semantic Analogy & Metaphor Association: Multiple entities form cross-domain mapping through analogy, metaphor, and symbolism, including structural analogy, metaphor mapping, and symbolic system, etc.; • Stance & Conflict Association: Multiple entities exhibit positions, interests, conflicts, or negotiation relationships on a certain issue, including position opposition, interest alliance, discourse contention, and role reversal, etc.; • Temporal and Spatial Context Association: Multiple entities form non-event associations through common time, space, and cultural context, including simultaneous coexistence, cultural context, spatial topology, and time evolution, etc.; • Other possible high-level associations among multiple entities that you think exist, as long as they are semanti- cally coherent, are acceptable. # Special attention: •Each set must contain at least 4 entities, the more, the better; 23 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory •It is prohibited to forcibly connect entities without any intersection; • Minimizing inter-group intersection: The intersection of the extracted high-order association sets should be as small as possible, and the redundancy should be minimized. It is not allowed for two sets to have an intersection that is nearly the same as the sets themselves. For each entities set, extract the following information: - entities set:List every member entity exactly as named in Step 1. - relationship description:Based on the relationships among the entities in the set, describe the relevant content represented by this set in detail, such as events, knowledge, functions, etc. The description should adopt the original sentence order and wording to connect all the entities within the set, and provide a complete narrative of at least 3 sentences without omitting any details; direct quotations of original phrases or appropriate supplements and analyses can be used, but the scattered information should be linked into a coherent, independent, and readable paragraph. It is prohibited to only list the relationships or summarize with a single sentence. - attribute:List any additional information that is not mentioned in the description but may be important, such as the time, place, and background circumstances. If nothing is available, then skip this item. F.2. Prompts for Strategy Parsing Knowledge Hypergraph Architecture Prompt:—Role— You are a useful query analysis assistant, responsible for identifying the key entities, keywords, target layer and semantic depth of the user’ s query problem based on the knowledge hypergraph architecture description provided to you. —Knowledge Hypergraph Architecture— -*Hierarchical Hypergraph Architecture*- Layer 1 (Single Entity Layer) Answerable scope: •Entity identity, aliases, definition, category, attribute values, status, capabilities, constituent components. •Key events in the entity’ s life cycle, including “time points” and “locations”. •Version differences of the entity within the same work. Layer 2 (Paired Entity Relationship Layer) Answerable scope: • Whether there is a specified relationship between two entities; relationship type, strength, direction, evidence sentences. •Direct motives and results of a single interaction. •Evolution of the relationship over time. Layer 3 (Multi-Entity Event Layer) Answerable scope: • Event causality chain: background → trigger → process → result → impact (This event may not have been fully documented. The knowledge in this layer may only include a few parts of the causal chain, such as “role →process→result”). •Roles and conflicts of interest of each entity in the event. •Quantitative impact of the event on subsequent plot or storyline. Implicit Strategy Parsing Prompt:—Goal— -Initial query decomposition: 1.question:Consistent with the original question. 2.rewrite question:Without altering the original intention of the user, expand, clarify, structure and align the input query with entities, making it more convenient for downstream search engines or knowledge bases to retrieve, while 24 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory enhancing semantic integrity. •Provide context (For example, time, place, topic, etc.). • Entity alignment and period matching (If the entities in the query have specific names at different stages, then replace them with the original terms that match the corresponding stage). • Disambiguation and Reference Clarification (Replace vague references such as “it”, “this”, and “influence” with specific nouns to avoid ambiguity.). • Synonyms / Domain Terminology Expansion (Introduce synonyms, near-synonyms, and domain-specific terms to enhance the recall rate). 3.key entities:Extract nouns or noun phrases that have clear referential meanings from the query, such as people, places, organizations, events, technologies, concepts, etc. •The entity should be linkable (able to correspond to the entries in the knowledge base). • Provide all the aliases, abbreviations, names, titles, etc. of this entity at different stages (including obscure ones) to enhance the coverage of search results. •Output format: [Entity1|Alias1|Alias2, Entity2|Alias3|Alias4|Alias5]. 4.keywords:Extract a multi-dimensional keyword set from the query, which is used to represent the core intention and retrieval direction of the user. 5.target layer:According to the characteristics of the query problem, combined with the information of the knowledge hypergraph architecture, predict which layer of the architecture the answer vertices related to the problem are located in (ranging from 1 to 3, type as Int). 6.matching score:This score (ranging from 1 to 5, type as Int) reflects the degree of relevance between the query answer and the knowledge at the target layer, as well as the complexity of integrating knowledge across different layers during the response. The detailed scoring criteria are as follows: • 5: Very High, the answer must be present in the target layer, and no other layer knowledge is needed; the query can almost be completely resolved within the target layer without cross-layer reference. Usually, it includes simple and isolated facts, superficial information, or macro themes (queries with macro themes almost only focus on the fourth layer). The knowledge at the target layer can provide about 95% to 100% of the content in the answer. • 4: Relatively High, the answer mainly focuses on the target layer, but may still need to call upon a small amount of knowledge from adjacent layers to provide background or supplementary information; most doubts can be resolved within a single domain or layer. The knowledge at the target layer can provide about 80% to 95% of the content in the answer. • 3: Medium, the answer mainly relies on the support of the target layer and its upper-layer knowledge, with limited but necessary cross-layer requirements. The knowledge at the target layer can provide about 60% to 80% of the content in the answer. • 2: Relatively Low, the answer requires the collaboration of multiple layers to support, especially relying on the adjacent upper and lower layers. Any missing key layer will lead to an incomplete answer. The knowledge at the target layer can provide about 35% to 60% of the content in the answer. • 1: Very Low, all or most layers of knowledge must be integrated to provide an accurate answer. The construction of the answer relies on a complete information chain from the raw data to the abstract layer. This is usually related to broader significant events or complex knowledge, and needs to be explored throughout the knowledge base architecture. The knowledge at the target layer can provide about 5% to 35% of the content in the answer. 7.semantic depth:Evaluate the complexity, abstraction and reasoning depth of the query to determine whether multi-step reasoning or cross-domain knowledge integration is required and predict the semantic depth of the query (ranging from 1 to 5, type as Int). • Caution: If you decide to set the semantic depth to 1, do so with caution as it may result in some relevant content being omitted in the subsequent search. 25 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory F.3. Prompts for Answering Answering Briefly Prompt:—Goal— You are a helpful assistant responding to questions about data in the tables provided, and your task is to analyze the data tables provided and the corresponding questions meticulously. —Data tables— {info} —Example— -input- Question: When was Neville A. Stanton’s employer founded? -output- Thought: The employer of Neville A. Stanton is the University of Southampton. The University of Southampton was founded in 1862. Answer: 1862. —Query— -input- Question:{query} Your response starts after “Thought:”, where you will methodically break down the reasoning process, illustrating how you arrive at conclusions. Conclude with “Answer:” to present a concise, definitive response, devoid of additional elaborations. -output- Answering in Detail Prompt:—Goal— You are a helpful assistant responding to questions about data in the tables provided, and your task is to analyze the data tables provided and the corresponding questions meticulously. —Data tables— {info} —Example— -input- Question: What were the key design features and operational capabilities of the Polar Satellite Launch Vehicle (PSLV) in relation to its development history, and how did these features contribute to its success in launching satellites, particularly in the context of India’s evolving space ambitions? -output- The Polar Satellite Launch Vehicle (PSLV) was designed and operated by the Indian Space Research Organisation (ISRO) as a medium-lift launch vehicle specifically developed to place satellites into sun-synchronous orbits... —Query— -input- Question:{query} The information you are responding with can only be obtained from the provided table. If possible, please provide an accurate and comprehensive answer directly in one or two paragraphs, with a word count of approximately 450 to 600 words. -output- 26 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory F.4. Prompts for Explanatory Task Generating One-Hop Question Prompt:-Goal- You are a professional teacher, and you are now asked to design a question that meets the requirements based on the reference. -Reference- Given the following fragment of a data set: {context} -Requirements- 1. This question should be of the question-and-answer (QA) type, and a precise and comprehensive answer is required. 2. This question mainly tests the details of the information and knowledge in the reference. Avoid general and macro questions. 3. The question must not include any conjunctions such as “specifically”, “particularly”, “and”, “or”, “and how”, “and what” or similar phrases that imply additional inquiries. 4. The question must focus on a single aspect or detail from the reference, avoiding the combination of multiple inquiries. 5. Please design a question from the professional perspective and domain factors covered by the reference. 6. This question needs to be meaningful and difficult, avoiding overly simplistic inquiries. 7. This question should be based on the complete context, so that the respondent knows what you are asking and doesn’t get confused. 8. State the question directly in a single sentence, without statements like “How in this reference?” or “What about this data set?” or “as described in the reference. ” 9. The answer to the question should consist of one or two paragraphs, with a word count ranging from 450 to 500 words; it should contain sufficient contextual information and provide a detailed and thorough explanation of the question. -Output- Question: ..., Answer: ... Generating Multi-Hop Question Prompt:-Goal- You are a professional teacher, and your task is to design a single question that contains {n} interconnected sub-questions, demonstrating a progressive relationship based on the reference. -Reference- Given the following fragment of a data set: {context} -Requirements- 1. This question should be of the question-and-answer (QA) type, and a precise and comprehensive answer is required. 2. The question must include {n} sub-questions connected by transitional phrases such as “and” or “specifically”, indicating progression. 3. Focus on testing the details of the information and knowledge in the reference. Avoid general and macro questions. 4. Design the question from a professional perspective, considering the domain factors covered by the reference. 27 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory 5. Ensure the question is meaningful and challenging, avoiding trivial inquiries. 6. The question should be based on the complete context, ensuring clarity for the respondent. 7. State the question directly in a single sentence, without introductory phrases like “How in this reference?” or “What about this data set?”. 8. The answer to the question should consist of one or two paragraphs, with a word count ranging from 500 to 550 (depending on {n}) words; it should contain sufficient contextual information and provide a detailed and thorough explanation of the question. -Output- Question: ..., Answer: ... Evaluating for EM and F1 Prompt:# Task Providing a question and its reference answer, your task is to assess the quality of the given answers. -Commonalities identification- First, analyze the similarities between the given answer and the reference answer, and summarize these commonalities into several key points. -Score- The assessment is conducted from three perspectives: - **Exact Match** - Based on the reference answer, conduct a comprehensive evaluation of the given answer. Level|score range|description Level 1 | 0-20 | The answer has serious errors and is extremely incomplete, its core facts, data, or conclusions contradict the reference answer, and it omits most essential points; it can hardly answer the question accurately. Inconsistent; basically does not match the reference answer, and is unable to answer the question. Level 2 | 20-40 | The answer has obvious errors and is incomplete; some of its core points do not match the reference answer, and it lacks multiple important pieces of information; the degree of matching with the reference answer and overall accuracy is low, and it can mislead readers. Level 3 | 40-60 | The answer is generally correct but incomplete; its main facts, data, and conclusions are consistent with the reference answer, but there are some minor errors and a few essential points are missing. The facts are correct, but there are still some data, details, or conclusions that do not match the correct answer. Level 4 | 60-80 | The answer is basically correct and relatively complete; its majority of facts, data, and conclusions are consistent with the reference answer, and only a few details or expressions have minor deviations, with very few missing points; it is matched closely with the reference answer and can accurately answer the question. Level 5 | 80-100 | The answer is completely correct and complete: all core facts, data, and conclusions are consistent with the reference answer, there are no factual errors, and it covers all the required points of the question; it is matched completely with the reference answer so that can be regarded as the benchmark for an accurate answer to the question. - **Recall** - Measure the degree of information coverage of the given answer relative to the reference answer; the more compre- hensive the coverage, the higher the score; the more omissions, the lower the score. Level|score range|description Level 1 | 0-20 | The given answer fails to cover any key facts, entities or conclusions of the reference answer; a large amount of core information is missing. Level 2 | 20-40 | The given answer only touches upon a few marginal details of the reference answer; the main facts and key arguments are still largely omitted. Level 3 | 40-60 | The given answer covers the main part of the reference answer, but there are still significant core facts, details or sub-arguments missing or omitted. Level 4 | 60-80 | The given answer covers the majority of the key information and core arguments of the reference 28 IGMiRAG: Intuition-Guided Retrieval-Augmented Generation with Adaptive Mining of In-Depth Memory answer, with only a few minor details or sub-arguments missing. Level 5 | 80-100 | The given answer fully covers all the key facts, entities, logical chains and details of the reference answer, without any substantive omissions. - **Precision** - Measures the degree of consistency between the given answer and the reference answer in terms of semantics, facts, and details; the higher the similarity and fewer the interfering factors, the higher the score; the greater the contrast and the more redundant or incorrect elements, the lower the score. Level 1 | 0-20 | The given answer has almost no intersection with the reference answer, contains a large number of factual errors, opposite statements, or irrelevant noise, and can be regarded as irrelevant to the question. Level 2 | 20-40 | The given answer shares only a few common points with the reference answer, but the core facts, key entities, or conclusions significantly differ from those of the reference answer. Level 3 | 40-60 | The given main framework or some key information of the answer is consistent with the reference answer, but there are still obvious factual deviations, omissions, or redundant details. Level 4 | 60-80 | The majority of the key facts, entities, and logic of the given answer closely match those of the reference answer, with only a few details or expressions having slight differences or redundancies. Level 5 | 80-100 | The given answer is almost one-to-one corresponding to the reference answer in terms of facts, entities, logic, and details; synonyms can be used, and there is no additional noise or contradictions. # Question {query} # Reference Answer {gold answer} # Answer that Requires Judgment {pre answer} Evaluate the answer using the criteria above: You need to provide the level and explanation for the answer according to the indicator descriptions, and then give the score within the rating range of that level. Output your evaluation in the following JSON format: {{ “Commonalities”:“The common contents between the given answer and the reference answer obtained through analysis” “Exact Match”:{{ “Explanation”: “Provide explanation here” “Level”: “A level range 1 to 5” # This should be a single number, not a range “Score”: “A value range 0 to 100” # This should be a single float number that is precise to two decimal places, not a range }}, “Recall”:{{ “Explanation”: “Provide explanation here” “Level”: “A level range 1 to 5” # This should be a single number, not a range “Score”: “A value range 0 to 100” # This should be a single float number that is precise to two decimal places, not a range }}, “Precision”:{{ “Explanation”: “Provide explanation here” “Level”: “A level range 1 to 5” # This should be a single number, not a range “Score”: “A value range 0 to 100” # This should be a single float number that is precise to two decimal places, not a range }}, }} 29