HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores Guohang Yan, Yue Zhang, Pinlong Cai ∗, Ding Wang, Song Mao, Hongwei Zhang Yaoze Zhang, Hairong Zhang, Xinyu Cai, Botian Shi ∗ Shanghai Artificial Intelligence Laboratory, Shanghai, China Abstract:Retrieval-augmented generation (RAG) has become a dominant paradigm for mitigating knowledge hallucination and staleness in large language models (LLMs) while preserving data security. By retrieving relevant evidence from private, domain-specific corpora and injecting it into carefully engineered prompts, RAG delivers trustworthy responses without the prohibitive cost of fine- tuning. Nevertheless, existing systems remain brittle when confronted with (i) multimodal evidence that spans text, images, and structured graphics; (ii) com- plex queries requiring compositional reasoning over long, noisy contexts; and (iii) continuously evolving knowledge scattered across heterogeneous corpora. Tra- ditional retrieval-augmented generation (RAG) systems are text-only and often rely on a single storage backend—typically a vector database. In practice, this monolithic design suffers from unavoidable trade-offs: vector search captures se- mantic similarity yet loses global context; knowledge graphs excel at relational precision but struggle with recall; full-text indexes are fast and exact yet se- mantically blind; and relational engines such as MySQL provide strong trans- actional guarantees but no semantic understanding. We argue that these hetero- geneous retrieval paradigms are complementary, and propose a principled fusion scheme to orchestrate them synergistically, mitigating the weaknesses of any sin- gle modality. In this work we introduce HetaRAG, a hybrid, deep-retrieval aug- mented generation framework that orchestrates cross-modal evidence from hetero- geneous data stores. HetaRAG handles multimodal documents—text, diagrams, tables, mathematical notation, and more—and performs sophisticated, compo- sitional reasoning over long-form, noisy contexts. We plan to design a system that unifies vector indices, knowledge graphs, full-text engines, and structured databases into a single retrieval plane, dynamically routing and fusing evidence to maximize recall, precision, and contextual fidelity. To achieve this design goal, we carried out preliminary explorations and constructed an initial RAG pipeline; this technical report provides a brief overview. The partial code is available at https://github.com/KnowledgeXLab/HetaRAG. Keywords:retrieval-augmented generation, heterogeneous data stores, deep re- trieval, large language model 1 Introduction With the rapid development of information technology and the explosion of data volume, efficiently acquiring and utilizing knowledge has become crucial for the advancement of intelligent systems. A knowledge engine, as a decision-support system that integrates data, models, and inference rules, plays an essential role in transforming unstructured and non-centralized data into structured knowl- edge, enabling effective information retrieval, reasoning, and decision-making in specific domains. ∗Corresponding authors arXiv:2509.21336v1 [cs.IR] 12 Sep 2025 In recent years, large language models have demonstrated remarkable capabilities in natural lan- guage understanding and generation. However, when applied to specialized domains or high- precision tasks, these models often lack sufficient factual grounding, resulting in unreliable or inac- curate outputs. Therefore, integrating external knowledge sources with large language models has become essential to enhance their practical applicability. By leveraging a knowledge engine capable of providing accurate and multimodal information, large language models can better perform infor- mation extraction, retrieval matching, and content generation—ultimately improving the efficiency and quality of knowledge processing. Despite the availability of several knowledge engine products, these systems still exhibit notable limitations. For instance, they are primarily designed for individual users uploading small volumes of documents, with limited scalability in document processing. Moreover, most rely on vector simi- larity matching and keyword-based retrieval, which often result in low precision. Their multimodal processing capabilities remain rudimentary, failing to meet the growing demand for cross-modal integration. Modern knowledge bases must go beyond simple storage and retrieval functions. They should support advanced features such as knowledge reasoning, dynamic updating, and data privacy protection to cater to diverse application scenarios across industries. Additionally, the construction and optimization of knowledge bases are ongoing processes that require continuous user feedback and iterative improvements. In this technical report, we present HetaRAG, a hybrid, deep-retrieval RAG framework that unifies multiple heterogeneous data stores—vector indices, knowledge graphs, full-text search engines, and relational databases. The pipeline proceeds in two phases. First, we perform multimodal document ingestion that extracts text, images, tables, and mathematical formulae from raw files. Each modality is then transformed into the most appropriate storage format: dense vectors for semantic proximity, symbolic triples for relational precision, inverted indices for lexical recall, and normalized tables for transactional integrity. Second, at generation time, the system orchestrates evidence from these disparate stores to answer user questions or synthesize comprehensive, multi-modal research reports. The open-source release of HetaRAG currently offers the following core features: •Multimodal document parsing: decomposing the input document into semantically dis- tinct segments—text, images, tables, mathematical formulas, etc. •Heterogeneous storage index construction: simultaneous indexing into vector databases, knowledge graphs, full-text engines, and relational databases. •Deep research report generation: transforms unstructured documents into verified, query-aligned Markdown reports by fusing text, tables, and visuals via LLM synthesis and vector retrieval. •Complex question answering via iterative, reasoning: iteratively rewrites queries and retrieves evidence until a coherent, cross-source answer emerges. 2 Related Work 2.1 Bottlenecks and Drivers for RAG System Improvement With the development of large language models (LLMs), retrieval-augmented generation (RAG) has become a crucial approach to addressing knowledge staleness and reducing hallucinations. How- ever, practical applications still face several challenges. First, there exists a knowledge conflict issue, where retrieved content may contradict internal model knowledge, leading to unfaithful or erroneous outputs [1, 2]. Second, noise interference and irrelevant information significantly degrade output quality due to redundant or misleading documents [3, 4]. In multi-hop question-answering tasks, reasoning path deviation and cascading errors can lead to systemic failures in subsequent retrieval and generation steps [5, 6]. Moreover, most RAG systems lack effective dynamic retrieval mecha- nisms, failing to determine when retrieval is necessary, which affects response efficiency [7, 8, 9]. Finally, knowledge boundary identification remains inadequate, as many models cannot effectively respond with “I don’t know” when facing questions beyond their knowledge scope [10, 8]. 2 2.2 Technological Pathways to Address RAG Challenges To tackle these challenges, recent studies have proposed various technical approaches. Preference modeling and gain assessment have emerged as promising strategies for improving paragraph fil- tering accuracy, exemplified by GainRAG, which quantifies the contribution of each paragraph to the correct answer [11]. To address knowledge conflict and factual consistency issues, FaithfulRAG and RPO introduce self-knowledge verification mechanisms and reinforcement learning strategies, respectively, to enhance the reliability of generated results [1, 12]. In complex tasks like multi- hop QA, reasoning chain optimization and structured organization have become mainstream di- rections. RankCoT, DualRAG, and KiRAG improve reasoning capabilities through CoT ranking, dual-channel architecture, and iterative knowledge triplet utilization [13, 14, 6]. Meanwhile, docu- ment filtering and noise suppression mechanisms are widely explored, with MAIN-RAG introducing a multi-agent scoring filtering mechanism and Lexical Diversity-aware methods using contrastive learning to remove irrelevant content [3, 4]. Furthermore, dynamic retrieval and trigger control mechanisms are evolving, with DioR proposing early and real-time classifiers to enable on-demand retrieval and significantly improve system responsiveness [7]. 2.3 Reasoning Guidance and Knowledge Distillation An increasing number of studies are leveraging reasoning guidance and knowledge distillation to improve the intelligence of RAG systems. For example, Rationale Distillation utilizes LLMs to generate “rationales” as signals for re-ranking documents and fine-tuning the reranker to better align with the generator’s preferences [15, 16]. Memory-inspired iterative frameworks use multi-agent collaboration to integrate historical retrieval results, dynamically adjust queries, and filter noise, thus improving retrieval efficiency and quality [17]. Additionally, self-refinement mechanisms play a role in formalization tasks, with LTRAG building a thought-guided knowledge base to assist the formalization process and integrating symbolic solvers for dynamic optimization [18]. 2.4 Graph Enhancement and Structured Knowledge Modeling Structured knowledge sources, such as knowledge graphs and causal graphs, are playing an increas- ingly important role in RAG. SimGRAG transforms user queries into structured graph patterns and uses graph semantic distance to measure matching accuracy, thereby improving knowledge graph- driven retrieval effectiveness [19]. GEAR introduces a graph expansion mechanism (SyncGE) com- bined with a multi-step retrieval agent framework to support diverse path exploration in multi-hop QA tasks [20]. FRAG customizes retrieval workflows for queries of varying complexity, leveraging KG to provide explicit entity relationship support [21]. CausalRAG further introduces causal graphs to guide information filtering during retrieval, enhancing contextual coherence and reasoning accu- racy [22]. RAKG effectively addresses cross-document relation extraction and entity disambigua- tion by introducing a RAG-based document-level pre-entity retrieval and knowledge construction pipeline, enhancing knowledge graph accuracy [23].These methods collectively push RAG toward structured knowledge fusion and graph-enhanced reasoning. 2.5 Cross-modal and Fine-grained Retrieval As application scenarios expand, RAG is gradually extending into visual, tabular, and multi-modal domains. Fine-Grained VQA-RAG proposes a multi-modal knowledge unit (KU) combining im- ages and textual descriptions to achieve zero-shot cross-modal retrieval and reasoning [24].VaLiK leverages vision-language models for image-text alignment and semantic verification, enabling unla- beled multimodal knowledge graph construction to enhance LLM reasoning [25]. CoRE Framework focuses on structured data processing (e.g., tables), generating experience trajectories via Monte Carlo Tree Search (MCTS) and combining contrastive prompt design to enhance model reasoning [26]. Additionally, PIC chunking method proposes pseudo-instruction-based semantic segmenta- tion without training, significantly optimizing document splitting and improving retrieval and QA 3 performance [27]. These studies mark RAG’s shift from single-text modalities toward multi-modal, fine-grained, and structured input. 2.6 Interpretability, Honesty, and Controllable Generation To enhance transparency and reliability, multiple studies focus on interpretability, honesty, and con- trollable generation. Judge-as-a-Judge proposes filtering high-quality samples using judgment con- sistency for training, improving evaluation fairness [28]. CTRLA introduces representation-space intervention mechanisms, guiding honesty and monitoring confidence to make models more likely to acknowledge knowledge limitations and avoid false generation [8]. EXIT Mechanism proposes context-aware sentence-level compression to improve long-context processing efficiency while re- ducing interference [29]. Additionally, Debate-Augmented RAG introduces a multi-agent debate mechanism to enhance objectivity and diversity in generated content [30]. These methods form the foundation for RAG’s evolution toward trustworthy AI, controllable generation, and ethical compli- ance . 2.7 Application Expansion and Future Trends As RAG technology matures, its application scenarios are expanding into healthcare, education, law, and other fields. Medical and knowledge-intensive task applications have become hotspots, with RARE and TC–RAG achieving significant results in medical QA and commonsense reasoning [31, 32]. Cross-model knowledge transfer and small-scale deployment have also become key direc- tions, with DRAG and UniRAG promoting RAG in resource-constrained environments [33, 34]. In terms of ethics and controllability, honesty-oriented controllable generation mechanisms are gaining attention, with Divide-Then-Align explicitly requiring models to be capable of responding with “I don’t know” to improve trustworthiness [10]. Additionally, human-machine collaborative and inter- active retrieval-generation systems are emerging, with CR-Planner and ChainRAG supporting multi- turn dialogue and progressive reasoning to enhance user engagement [5, 35]. Lastly, interpretability and traceability enhancements are becoming focal points, with SEAKR’s “self-aware reranking” mechanism and KiRAG’s knowledge path recording helping improve model transparency and au- ditability [36, 6]. 3 Methodolody HetaRAG focuses on handling users’ complex question-answering tasks and generating in-depth research reports by leveraging heterogeneous knowledge stores. 3.1 Data Processing In the HetaRAG system, data processing is a critical step that consists of two key phases: data parsing and data vectorization. In the data processing phase, unstructured files are transformed into semi-structured or structured data. HetaRAG supports two batch data parsing methods: Docling [37] and MinerU [38], offering flexible solutions to meet varying accuracy, structuring requirements, and document format compat- ibility. MinerU is a layout-based PDF parsing method that focuses on extracting precise text blocks, tables, and images. It analyzes the bounding box of each text block to determine the position and structure of content, preserving the layout, and providing detailed metadata for each element. In contrast, Docling is tailored for parsing high-level document structures, making it particularly suit- able for forms and reports with well-defined layouts. These parsing methods facilitate the extraction of key elements from unstructured documents, converting them into structured data for further pro- cessing. After data parsing, HetaRAG performs format conversion and content embedding on the parsed data. For the different parsing results obtained from the two data parsing methods, HetaRAG has 4 Knowledge Graph Generation PDF Parser Semantic Segmentation Image To Text Semantic Similarity Vector Database Full - text database Relational Database Vectorization Semantic Vectorization Document preparation Vector - based Retrieval Web - based Retrieval Graph - based Retrieval Graph Database Node Relation Description Information Extraction Aggregation Node Cross - cluster Relation Hierarchical Clustering Unified attributes Data storage Path Generation Bottom - up - bottom Path Neighboring layer relation P C C C Database Information Retrieval Query Rewrite Summarize Rerank Figure 1: The Framework of the HetaRAG. Raw documents (PDF, image, web) are parsed into unified multimodal chunks. Each chunk is simultaneously indexed into four heterogeneous stores: Milvus (vector), Neo4j (graph), Elasticsearch (full-text), and MySQL (relational). At query time, the system rewrites the question, launches bottom-up graph traversal, semantic vector search, lexical full-text search, and SQL filtering in parallel, then reranks and summarizes the fused evidence to produce a grounded answer or a deep research report. designed specific format conversion and embedding techniques to organize the data into unified fields. This standardization facilitates unified and precise matching and retrieval in the subsequent stages of the project. Regarding embedding, HetaRAG supports two methods: text-only embedding using the BGE-m3 [39] model and multimodal embedding (text and image) using the QwenVL [40] encoder. Text embedding focuses on capturing the semantic representation of textual content, while multimodal embedding focuses on the unified encoding of both text and visual data. Both embedding methods can be used by users in different application scenarios. These operations lay the foundation for high-quality retrieval matching and efficient querying, ensuring optimal performance in later stages of the system. 3.2 Database Construction To support the efficient storage and management of various data types, HetaRAG integrates four distinct database systems: Elasticsearch [41], Milvus [42], MySQL [43], and Neo4j [44]. Each of these databases supports specific operations and is tailored to particular use cases, ensuring that HetaRAG can handle structured and unstructured data on a scale. Elasticsearch is a distributed search engine designed for real-time retrieval and full-text search, sup- porting efficient document indexing and querying. It is used for keyword-based searches across large volumes of text data. Indexes documents in a structured format, enabling efficient real-time retrieval of relevant information. The project supports operations such as index creation, keyword search, and index deletion, as well as uploading and indexing of new data in PKL format. Once the index is established, users can perform fast and accurate search queries, retrieving optimal results based on specific keywords, thereby improving overall retrieval performance and user experience when handling large, unstructured datasets. Milvus serves as a vector database, optimized for storing and performing similarity searches on high- dimensional embeddings. It is utilized to store embeddings generated during the data processing stage in a structured format, enabling vector similarity search across high-dimensional data. The system supports operations such as collection creation, index addition, data insertion, and similarity querying, ensuring that the processed data is efficiently stored and retrieved. By leveraging Milvus, HetaRAG facilitates rapid and accurate retrieval of semantically similar content, which is essential 5 for handling large-scale, vectorized data and optimizing performance in tasks such as information retrieval and content matching. MySQL is a relational database management system that facilitates the storage of structured data in tables, supporting complex queries such as filtering, aggregation, and joins. It is used to store struc- tured data, particularly formatted data (e.g., tabular data), and supports operations such as database and table creation, data import, and complex query execution to enable efficient querying of struc- tured data. By leveraging MySQL, HetaRAG ensures fast and reliable access to formatted data and facilitates complex analytical queries within the system. Neo4j is a graph database that models data as nodes and relationships, offering powerful capabilities for representing and querying complex relational data. It is used to store and manage graph-based data, enabling efficient querying of relationships between entities. The system supports operations such as importing data, building graphs, and performing relationship-based searches. By leveraging Neo4j, HetaRAG can efficiently uncover and analyze complex relationships within the data, making it an essential tool for tasks that require graph-based querying and relationship extraction. 3.3 Knowledge-Graph Building HetaRAG supports two distinct knowledge graph construction methods: HiRAG [45] and LeanRAG [46], which are designed to enhance the integration of structured knowledge into the RAG pipeline and improve the system’s reasoning capabilities over complex data. HiRAG emphasizes hierarchical knowledge aggregation by constructing multi-level entity representations, thereby enabling more effective reasoning and retrieval across different levels of semantic granularity. LeanRAG focuses on generating rich entity-relation triples and organizing them into a comprehensive knowledge graph via a dynamic, multi-level hierarchy. Both approaches contribute to building coherent and scalable knowledge representations, ensuring that HetaRAG can process domain-specific information with higher efficiency and precision. For both HiRAG and LeanRAG construction, HetaRAG abstracts the process into three stages: (1) extraction of entity-relation triples, (2) knowledge graph construction, and (3) graph-based retrieval and question answering. In the first stage, two triple extraction methods are provided: one based on CommonKG and the other on GraphRAG. The CommonKG approach leverages large-scale com- monsense knowledge patterns to extract semantically meaningful triples from unstructured text. In contrast, the GraphRAG method employs LLM-guided extraction tailored for retrieval-augmented generation, enabling more context-aware representations. In the second stage, each method con- structs knowledge graphs according to its respective paradigm. HiRAG integrates knowledge hier- archically through an unsupervised layered indexing mechanism and novel bridging strategy, while LeanRAG utilizes a hierarchical graph aggregation approach to abstract fine-grained entities and relations into a semantically rich, navigable network. These graphs are subsequently used for down- stream graph-based retrieval and reasoning tasks. 3.4 Advanced Retrieval Hybrid Retrievalin HetaRAG combines vector-based retrieval(Milvus), with keyword-based search(Elasticsearch). This approach enables more accurate and comprehensive search results by integrating the strengths of both retrieval methods. The system utilizes a parameter, alpha, to con- trol the weight of each retrieval method, allowing for fine-tuning of the balance between vector search and keyword search. By merging the semantic power of vector-based search and the pre- cision of keyword matching, Hybrid Retrieval ensures that relevant content is effectively retrieved, optimizing performance across a wide range of queries and enhancing retrieval accuracy. Rerankingin HetaRAG provides a flexible reranking framework that further optimizes search re- sults through reranking of retrieved content. The system supports various reranking techniques, such as vLLM deployment, Hugging Face model downloads, and direct API calls. The reranking pro- cess allows for the selection of the most relevant results based on additional context and relevance, thereby improving the quality of the retrieved content. This flexibility enables users to choose from a 6 variety of reranking models, whether downloaded from external repositories or deployed locally. By supporting parent document retrieval and vector-based database systems like Milvus, the reranking mechanism enhances the accuracy and relevance of the final search results, fostering more precise and customized outcomes. 3.5 DeepSearch Question Reasoning System Search System Extract Information If the Question Can Be Answered ? Memory System NO YES Answer DeepSearch Figure 2: The Framework of DeepSearch The DeepSearch component in HetaRAG is designed to address complex queries that require multi- step retrieval and iterative reasoning across diverse information sources. This component integrates semantic retrieval, information extraction, and critical reasoning to iteratively gather and synthesize information, ultimately providing accurate answers. The process is structured in multiple reasoning steps, where each stage refines the search and reasoning process based on intermediate results. The core of the system is the MultiHopAgent—a structured, iterative retrieval-and-reasoning agent whose design is adapted from the WebWalker framework proposed by [47]. The overall framework is illustrated in Figure 2. Initially, the agent rewrites the query to refine its scope and context. Based on the rewritten query, the system performs a search to retrieve relevant documents. The retrieved content is then analyzed, and key information is extracted. The system compares the extracted information with the original query to assess whether the current content is sufficient to answer the question. If the information is inadequate, the system generates new queries derived from the search results and restarts the retrieval process. This cycle of search, analysis, comparison, and refinement continues until the system generates a comprehensive and accurate answer to the original question. Through this multi-step approach, the MultiHopAgent ensures that the generated answer is well- supported by relevant and contextually consistent information. The retrieval process in MultiHopAgent supports multiple data sources, such as pre-constructed knowledge bases and web pages, ensuring that the system can retrieve contextual information from diverse repositories. By integrating various search mechanisms, the multi-hop reasoning framework provides a robust solution for addressing complex queries that require the synthesis of information from multiple domains. 7 3.6 DeepWriter The Multimodal Report Generation component in the HetaRAG system enables the automatic gen- eration of reports from unstructured documents, and it is implemented by DeepWriter [48]. Deep- Writer leverages large language models (LLMs) and a vector database to extract semantic infor- mation from unstructured documents and generate structured textual reports conditioned on user queries. The overall pipeline is illustrated in Figure 3. The system allows users to input queries, which then drive the report generation process, ensuring that the resulting report is comprehensive, coherent, and relevant to the user’s specific needs. This capability is particularly beneficial for gen- erating professional-grade, factually grounded documents, as it integrates both textual and visual data. Online Processing Stage Offline Processing Stage Hierarchical DatabasePDF Processing MinerU Knowledge Level Chunk Level Embedding Generation GME Model Multimodal Captions Database Vector Storage Metadata Index Phase 1: Query Processing Phase 2: Hierarchical Retrieval Phase 3: Content Organization Phase 5: Multimodal Integration Phase 6: Citation Generation Phase 7: Final Assembly Generated Document RewriteQuery DecomposeTask ExtractMultimodalTasks RetrieveFromKB FilterTextContent FilterVisualContent GenerateSections ClusterBySections Phase 4: Section Writing CreateDraft GetSectionContent RefineDraft ComputeRelevance CollectMultimodalContent OptimizePlacement FindSource GenerateCitation AddCitation AddImagePaths ValidateCitations FormatDocument Multimodal Content Factual Grounding Fine-grained Citations Figure 3: The Framework of DeepWriter The report generation process is divided into several stages. First, DeepWriter retrieves contex- tual information through DocFinder by leveraging vector search, ensuring that the retrieved content is relevant and semantically aligned with the query. It then integrates this content, combining the query-driven information with the LLM to generate the report. Visual elements like charts, tables, and images are placed within the report based on their relevance to the text, optimizing the inte- gration of multimodal data. Finally, the ReportProcessor ensures that the generated document is formatted in Markdown and includes all necessary citations. The report is thoroughly fact-checked, with each claim or visual element accurately cited, providing transparency and verifiability. This robust framework enhances the quality and reliability of the generated reports, supporting complex tasks across diverse domains. 4 Experiment The experimental evaluation of the HetaRAG system is divided into three main parts, each targeting a different aspect of the system’s capabilities. Section 3.1, RAG-Challenge Evaluation, focuses on assessing the retrieval results. Section 3.2 evaluates the effectiveness of multi-hop reasoning when handling complex questions that require reasoning across multiple information sources. Section 3.3 is dedicated to evaluating the quality of multimodal report generation, examining how well the system generates structured reports that integrate both textual and visual content. Each section provides valuable insights into the strengths and potential improvements of the system. 8 4.1 RAG-Challenge 4.1.1 Experimental Setup Dataset.To assess the retrieval and reasoning capabilities of HetaRAG, we adopt the dataset and evaluation protocol from the Enterprise RAG Challenge Round 2[49]. The benchmark comprises domain-specific queries paired with gold-standard answers annotated by experts, along with relevant document contexts.Evaluation follows the RAG Challenge metrics, including the Retrieval Score (R) and Generation Score (G) and Score = R/3 + G (max 133), reflecting both retrieval accuracy and answer generation quality. Implementation Details.We conduct experiments using the pipeline designed by Ilya Rice for this dataset, which incorporates Docling for PDF parsing, BGE-m3 for data embedding, and Milvus for constructing the vector database. Multiple large language models, such as Qwen2.5-72B and GPT- 4o, are employed for answer generation. Additionally, the system supports various large model frameworks, including API keys, vLLM, and Ollama. 4.1.2 Result Table 1 presents the experimental results of the HetaRAG system on the RAG-Challenge dataset, highlighting the effects of reranking strategies and query rewriting across two large language mod- els: ChatGPT-4o and Qwen2.5-72B-Instruct. Among all configurations, ChatGPT-4o combined with the bge-reranker-large achieved the highest overall score (117.0), demonstrating that reranking significantly enhances both retrieval (R) and generation (G) performance. For Qwen2.5-72B-Instruct, the best result (109.8) was also obtained using reranking with bge- reranker-v2-gemma, outperforming its baseline configuration by over 3 points. These findings con- firm that rerankers contribute more substantially to performance gains than query rewriting and that the choice of reranker model affects overall effectiveness. The results also suggest that, while com- pact models like Qwen2.5 perform competitively, ChatGPT-4o maintains a notable advantage in generation quality when enhanced with proper reranking strategies. Table 1: RAG-Challenge Result Model Rerank QueryRewrite R G Score ChatGPT-4o - - 78.3 73.8 113.0 - √ 78.9 72.8 112.3 bge-reranker-large - 79.7 77.2 117.0 bge-reranker-v2-gemma - 79.7 74.8 114.7 bge-reranker-v2-m3 - 78.7 73.8 113.2 Qwen2.5-72B-Instruct - - 77.1 70.0 108.6 - √ 76.8 67.8 106.2 bge-reranker-large - 77.5 68.6 107.3 bge-reranker-v2-gemma - 78.2 70.7 109.8 bge-reranker-v2-m3 - 77.8 69.6 108.5 4.2 DeepSearch Dataset.To support qualitative evaluation of the DeepSearch module in the HetaRAG framework, we construct a synthetic DeepSearch QA dataset that emphasizes deep semantic search and compo- sitional reasoning. Each query is designed to require multi-step retrieval, cross-document inference, and entity disambiguation, closely reflecting real-world knowledge-intensive tasks. The accompa- nying document set spans diverse but interconnected facts, enabling controlled testing of iterative querying, memory accumulation, and query rewriting. Result.As shown in Figure 4, the DeepSearch module conducts deep iterative search by decom- posing the query into focused sub-questions. It effectively leverages retrieved information to update 9 memory, enabling cross-document reasoning and evidence accumulation. This result demonstrates DeepSearch’s ability to perform deep semantic search and dynamically utilize intermediate findings to construct accurate, well-supported answers. founder of the company that launched the Falcon Heavy rocket Documents ID 1 : Elon Musk is also the founder of Neuralink and The Boring Company. ID 2 : SpaceX was founded by Elon Musk in 2002 to reduce the cost of space travel. ID 3 : The Tesla Model S, Model 3, Model X, and Model Y are its main electric vehicles. ID 4 : Elon Musk joined Tesla in early 2004 as an investor and became CEO in 2008. ID 5 : SpaceX successfully launched the Falcon Heavy rocket in 2018. ID 6 : Tesla, Inc. was founded in 2003 by engineers Martin Eberhard and Marc Tarpenning. ID 7 : Neuralink develops brain–computer interface technology. ID 8 : Tesla's headquarters is located in Austin, Texas, USA. …… …… Thought 1 : I need to find out which company launched the Falcon Heavy rocket, and then determine who founded that company. Memory Falcon Heavy was launched by SpaceX. Elon Musk founded SpaceX. Elon Musk became CEO of Tesla in 2008. ID 5 ID 2 Thought 2 : The question asks for the headquarters of the company Elon Musk later became CEO of, which implies another company (not SpaceX). I now need to find out which company Elon Musk later became CEO of. which company did Elon Musk become CEO of? …… ID 4 Tesla is headquartered in Austin, Texas, USA. ID 8 If the Question Can Be Answered ?NO YES The founder of the company that launched the Falcon Heavy rocket is Elon Musk. The company he later became CEO of is Tesla, whose headquarters is in Austin, Texas, USA. Query: Who is the founder of the company that launched the Falcon Heavy rocket? Where is the headquarters of the company he later became CEO of? Figure 4: The Example of DeepSearch 4.3 Deepwriter 4.3.1 Experimental Setup Dataset.To evaluate the report generation capability of HetaRAG’s DeepWriter module, we use the World Trade Report (WTR) dataset, which consists of 23 annual reports published by the World Trade Organization from 2001 to 2024. These documents serve as the offline corpus for generat- ing long-form articles in response to user queries. For evaluation, following [50, 51, 52], we adopt Prometheus2-7B[53] as the evaluation model to assess the quality of generated articles. The evalu- ation follows four dimensions—Interest Level, Coherence and Organization, Relevance and Focus, and Broad Coverage—each scored on a 1–5 scale. These criteria comprehensively measure the ef- fectiveness of DeepWriter in producing informative, coherent, and engaging reports grounded in domain-specific knowledge. Implementation Details.We employ MinerU for PDF parsing, storing the preprocessed data in Milvus along with embeddings generated by GME (gme-Qwen2-VL-2B-Instruct). Visual elements such as images and tables are captioned using Qwen2.5-VL-7B, an advanced vision-language model. Qwen2-7B serves as the core language model for executing the report generation tasks. 4.3.2 Result The performance of DeepWriter is evaluated on the WTR dataset and compared against three base- lines: (1) Long-context LLMs such as Qwen-Plus with a 131K token context window; (2) Naive RAG, which retrieves documents based on the original query without structured planning; and (3) specialized long-form writing systems including STORM and CO-STORM. As shown in Table 2, DeepWriter demonstrates competitive results, particularly in coherence and organization, highlight- ing its ability to generate structured long-form content even with compact models. As illustrated in Table 3, DeepWriter achieves performance comparable to GPT-4o-based systems, validating the effectiveness of combining semantic retrieval and structured generation. Notably, incorporating title planning from DeepWriter into Qwen-Plus improves coherence, emphasizing 10 Table 2: Configuration for different systems Qwen-Plus Qwen-Plus (w titles) STORM CO-STORM DeepWriter ModelQwen-Plus Qwen-Plus GPT-4o GPT-4o Qwen2-7B SourceInternal Internal search search offline KB Generationsingle turn single turn multi-turn multi-turn multi-turn Web searchno no yes yes no Table 3: Average Performance Scores Across All Dimensions Qwen-Plus Qwen-Plus (w titles) STORM CO-STORM DeepWriter A ve Score4.92 4.88 4.88 4.68 4.64 the benefits of decomposition and guided generation. Nonetheless, DeepWriter underperforms in certain dimensions, such as Coverage and Relevance, underscoring the limitations of smaller models compared to larger LLMs in complex content generation scenarios. 5 Conclusion We introduce HetaRAG, a deep hybrid retrieval-augmented generation (RAG) framework that op- erates over heterogeneous data stores to answer complex questions from existing knowledge bases and produce in-depth, illustrated research reports. This technical report summarizes our preliminary exploratory work and releases the corresponding open-source code. In future work, we will con- struct a multimodal hybrid-retrieval solution anchored in a knowledge graph that seamlessly unites relational, vector and full-text search databases. 11 References [1] Q. Zhang, Z. Xiang, Y . Xiao, L. Wang, J. Li, X. Wang, and J. Su. Faithfulrag: Fact- level conflict modeling for context-faithful retrieval-augmented generation.arXiv preprint arXiv:2506.08938, 2025. [2] Y . Xu, R. Zhang, X. Jiang, Y . Feng, Y . Xiao, X. Ma, R. Zhu, X. Chu, J. Zhao, and Y . Wang. Parenting: Optimizing knowledge selection of retrieval-augmented language models with pa- rameter decoupling and tailored tuning.arXiv preprint arXiv:2410.10360, 2024. [3] C.-Y . Chang, Z. Jiang, V . Rakesh, M. Pan, C.-C. M. Yeh, G. Wang, M. Hu, Z. Xu, Y . Zheng, M. Das, et al. Main-rag: Multi-agent filtering retrieval-augmented generation.arXiv preprint arXiv:2501.00332, 2024. [4] Z. Zhang, Y . Ma, S. He, S. He, T. Wang, J. Wang, and X. Liu. Lexical diversity-aware relevance assessment for retrieval-augmented generation.openreview, 2025. [5] X. Li, W. Xu, R. Zhao, F. Jiao, S. Joty, and L. Bing. Can we further elicit reasoning in llms? critic-guided planning with retrieval-augmentation for solving challenging tasks.arXiv preprint arXiv:2410.01428, 2024. [6] J. Fang, Z. Meng, and C. Macdonald. Kirag: Knowledge-driven iterative retriever for enhanc- ing retrieval-augmented generation.arXiv preprint arXiv:2502.18397, 2025. [7] H. Guo, J. Zhu, S. Di, W. Shi, Z. Chen, and J. Xu. Dior: Adaptive cognitive detection and contextual retrieval optimization for dynamic retrieval-augmented generation.arXiv preprint arXiv:2504.10198, 2025. [8] L. Huanshuo, H. Zhang, Z. Guo, J. Wang, K. Dong, X. Li, Y . Q. Lee, C. Zhang, and Y . Liu. Ctrla: Adaptive retrieval-augmented generation via inherent control.openreview, 2025. [9] P. Liu, X. Liu, R. Yao, J. Liu, S. Meng, D. Wang, and J. Ma. Hm-rag: Hierarchical multi-agent multimodal retrieval augmented generation.arXiv preprint arXiv:2504.12330, 2025. [10] X. Sun, J. Xie, Z. Chen, Q. Liu, S. Wu, Y . Chen, B. Song, W. Wang, Z. Wang, and L. Wang. Divide-then-align: Honest alignment based on the knowledge boundary of rag.arXiv preprint arXiv:2505.20871, 2025. [11] Y . Jiang, S. Zhao, J. Li, H. Wang, and B. Qin. Gainrag: Preference alignment in retrieval- augmented generation through gain signal synthesis.arXiv preprint arXiv:2505.18710, 2025. [12] S.-Q. Yan and Z.-H. Ling. Rpo: Retrieval preference optimization for robust retrieval- augmented generation.arXiv preprint arXiv:2501.13726, 2025. [13] M. Wu, Z. Liu, Y . Yan, X. Li, S. Yu, Z. Zeng, Y . Gu, and G. Yu. Rankcot: Refining knowl- edge for retrieval-augmented generation through ranking chain-of-thoughts.arXiv preprint arXiv:2502.17888, 2025. [14] R. Cheng, J. Liu, Y . Zheng, F. Ni, J. Du, H. Mao, F. Zhang, B. Wang, and J. Hao. Dualrag: A dual-process approach to integrate reasoning and retrieval for multi-hop question answering. arXiv preprint arXiv:2504.18243, 2025. [15] P. Jia, D. Xu, X. Li, Z. Du, X. Li, X. Zhao, Y . Wang, Y . Wang, H. Guo, and R. Tang. Bridg- ing relevance and reasoning: Rationale distillation in retrieval-augmented generation.arXiv preprint arXiv:2412.08519, 2024. [16] S. Meng, J. Liu, Y . Chen, S. Mao, P. Cai, G. Yan, B. Shi, and D. Wang. From ranking to selection: A simple but efficient dynamic passage selector for retrieval augmented generation. arXiv preprint arXiv:2508.09497, 2025. 12 [17] Q. Qin, Y . Luo, Y . Lu, Z. Chu, and X. Meng. Towards adaptive memory-based optimization for enhanced retrieval-augmented generation.arXiv preprint arXiv:2504.05312, 2025. [18] A. A. submission. Ltrag: Enhancing autoformalization and self-refinement for logical reason- ing with thought-guided rag.openreview, 2025. [19] Y . Cai, Z. Guo, Y . Pei, W. Bian, and W. Zheng. Simgrag: Leveraging similar subgraphs for knowledge graphs driven retrieval-augmented generation.arXiv preprint arXiv:2412.15272, 2024. [20] Z. Shen, C. Diao, P. V ougiouklis, P. Merita, S. Piramanayagam, D. Graux, D. Tu, Z. Jiang, R. Lai, Y . Ren, et al. Gear: Graph-enhanced agent for retrieval-augmented generation.arXiv preprint arXiv:2412.18431, 2024. [21] D. Zhao. Frag: Toward federated vector database management for collaborative and secure retrieval-augmented generation.arXiv preprint arXiv:2410.13272, 2024. [22] N. Wang, X. Han, J. Singh, J. Ma, and V . Chaudhary. Causalrag: Integrating causal graphs into retrieval-augmented generation.arXiv preprint arXiv:2503.19878, 2025. [23] H. Zhang, J. Si, G. Yan, B. Qi, P. Cai, S. Mao, D. Wang, and B. Shi. Rakg: Document-level retrieval augmented knowledge graph construction.arXiv preprint arXiv:2504.09823, 2025. [24] Z. Zhang, Y . Wu, Y . Luo, and N. Tang. Fine-grained retrieval-augmented generation for visual question answering.arXiv preprint arXiv:2502.20964, 2025. [25] J. Liu, S. Meng, Y . Gao, S. Mao, P. Cai, G. Yan, Y . Chen, Z. Bian, B. Shi, and D. Wang. Aligning vision to language: Text-free multimodal knowledge graph construction for enhanced llms reasoning.arXiv preprint arXiv:2503.12972, 2025. [26] J. Gu, Z. Xian, Y . Xie, Y . Liu, E. Liu, R. Zhong, M. Gao, Y . Tan, B. Hu, and Z. Li. Toward structured knowledge reasoning: Contrastive retrieval-augmented generation on experience. arXiv preprint arXiv:2506.00842, 2025. [27] A. A. submission. Document segmentation matters for retrieval-augmented generation.open- review, 2025. [28] S. Liu, X. Li, Z. Liu, Y . Yan, C. Yang, Z. Zeng, Z. Liu, M. Sun, and G. Yu. Judge as a judge: Improving the evaluation of retrieval-augmented generation through the judge-consistency of large language models.arXiv preprint arXiv:2502.18817, 2025. [29] T. Hwang, S. Cho, S. Jeong, H. Song, S. Han, and J. C. Park. Exit: Context-aware extractive compression for enhancing retrieval-augmented generation.arXiv preprint arXiv:2412.12559, 2024. [30] W. Hu, W. Zhang, Y . Jiang, C. J. Zhang, X. Wei, and Q. Li. Removal of hallucination on hallucination: Debate-augmented rag.arXiv preprint arXiv:2505.18581, 2025. [31] Z. Wang, J. Yu, D. Ma, Z. Chen, Y . Wang, Z. Li, F. Xiong, Y . Wang, L. Tang, W. Zhang, et al. Rare: Retrieval-augmented reasoning modeling.arXiv preprint arXiv:2503.23513, 2025. [32] X. Jiang, Y . Fang, R. Qiu, H. Zhang, Y . Xu, H. Chen, W. Zhang, R. Zhang, Y . Fang, X. Chu, et al. Tc-rag: Turing-complete rag’s case study on medical llm systems.arXiv preprint arXiv:2408.09199, 2024. [33] J. Chen, A. Myrzakhan, Y . Luo, H. M. Khan, S. M. Bsharat, and Z. Shen. Drag: Distilling rag for slms from llms to transfer knowledge and mitigate hallucination via evidence and graph- based distillation.arXiv preprint arXiv:2506.01954, 2025. 13 [34] A. A. submission. Unirag: Unified query understanding method for retrieval augmented gen- eration.openreview, 2025. [35] R. Zhu, X. Liu, Z. Sun, Y . Wang, and W. Hu. Mitigating lost-in-retrieval problems in retrieval augmented multi-hop question answering.arXiv preprint arXiv:2502.14245, 2025. [36] Z. Yao, W. Qi, L. Pan, S. Cao, L. Hu, W. Liu, L. Hou, and J. Li. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation.arXiv preprint arXiv:2406.19215, 2024. [37] C. Auer, M. Lysak, A. Nassar, M. Dolfi, N. Livathinos, P. Vagenas, C. B. Ramis, M. Omenetti, F. Lindlbauer, K. Dinkla, V . Weber, L. Morin, I. Meijer, V . Kuropiatnyk, and P. W. J. Staar. Docling technical report.ArXiv, abs/2408.09869, 2024. URLhttps://api. semanticscholar.org/CorpusID:271903952. [38] B. Wang, C. Xu, X. Zhao, L. Ouyang, F. Wu, Z. Zhao, R. Xu, K. Liu, Y . Qu, F. Shang, B. Zhang, L. Wei, Z. Sui, W. Li, B. Shi, Y . Qiao, D. Lin, and C. He. Mineru: An open- source solution for precise document content extraction.ArXiv, abs/2409.18839, 2024. URL https://api.semanticscholar.org/CorpusID:272969114. [39] J. Chen, S. Xiao, P. Zhang, K. Luo, D. Lian, and Z. Liu. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation. In Annual Meeting of the Association for Computational Linguistics, 2024. URLhttps://api. semanticscholar.org/CorpusID:267413218. [40] X. Zhang, Y . Zhang, W. Xie, M. Li, Z. Dai, D. Long, P. Xie, M. Zhang, W. Li, and M. Zhang. Gme: Improving universal multimodal retrieval by multimodal llms.ArXiv, abs/2412.16855, 2024. URLhttps://api.semanticscholar.org/CorpusID:274982316. [41] Elastic. Elasticsearch, 2022. URLhttps://www.elastic.co/elasticsearch/. Open- source search and analytics engine. [42] Zilliz. Milvus: Vector database for ai, 2024. URLhttps://milvus.io/. Open-source vector similarity search engine. [43] Oracle Corporation. Mysql, 2023. URLhttps://www.mysql.com/. Open-source relational database management system. [44] Neo4j, Inc. Neo4j graph database, 2024. URLhttps://neo4j.com/. Leading native graph database for connected data. [45] H. Huang, Y . Huang, J. Yang, Z. Pan, Y . Chen, K. Ma, H. Chen, and J. Cheng. Retrieval- augmented generation with hierarchical knowledge.arXiv preprint arXiv:2503.10150, 2025. [46] Y . Zhang, R. Wu, P. Cai, X. Wang, G. Yan, S. Mao, D. Wang, and B. Shi. Leanrag: Knowledge- graph-based generation with semantic aggregation and hierarchical retrieval.arXiv preprint arXiv:2508.10391, 2025. [47] J. Wu, W. Yin, Y . Jiang, Z. Wang, Z. Xi, R. Fang, D. Zhou, P. Xie, and F. Huang. Webwalker: Benchmarking llms in web traversal, 2025. URLhttps://arxiv.org/abs/2501.07572. [48] S. Mao, L. Cheng, P. Cai, G. Yan, D. Wang, and B. Shi. Deepwriter: A fact-grounded multi- modal writing assistant based on offline knowledge base, 2025. URLhttps://arxiv.org/ abs/2507.14189. [49] R. Abdullin and F. Krause. enterprise-rag-challenge.https://github.com/trustbit/ enterprise-rag-challenge, 2025. Visit date: July 1, 2025. [50] Y . Shao, Y . Jiang, T. A. Kanell, P. Xu, O. Khattab, and M. S. Lam. Assisting in writing wikipedia-like articles from scratch with large language models.arXiv preprint arXiv:2402.14207, 2024. 14 [51] Y . Jiang, Y . Shao, D. Ma, S. J. Semnani, and M. S. Lam. Into the unknown unknowns: Engaged human learning through participation in language model agent conversations.arXiv preprint arXiv:2408.15232, 2024. [52] Z. Xi, W. Yin, J. Fang, J. Wu, R. Fang, N. Zhang, J. Yong, P. Xie, F. Huang, and H. Chen. Omnithink: Expanding knowledge boundaries in machine writing through thinking.arXiv preprint arXiv:2501.09751, 2025. [53] S. Kim, J. Suk, S. Longpre, B. Y . Lin, J. Shin, S. Welleck, G. Neubig, M. Lee, K. Lee, and M. Seo. Prometheus 2: An open source language model specialized in evaluating other lan- guage models.arXiv preprint arXiv:2405.01535, 2024. 15